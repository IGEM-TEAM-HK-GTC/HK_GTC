[08/23 07:58:05 d2.engine.defaults]: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2): Conv2d(
            2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2): Conv2d(
            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2): Conv2d(
            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[08/23 07:58:05 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [RandomBrightness(intensity_min=0.9, intensity_max=1.1), RandomContrast(intensity_min=0.9, intensity_max=1.1), RandomBrightness(intensity_min=0.9, intensity_max=1.1), RandomFlip(prob=0.5), Resize(shape=(720, 1280))]
[08/23 07:58:05 d2.data.datasets.coco]: Loaded 574 images in COCO format from ../input/petbottles/plastic data/annotations/instances_train.json
[08/23 07:58:05 d2.data.build]: Using training sampler TrainingSampler
[08/23 07:58:05 d2.data.common]: Serializing 574 elements to byte tensors and concatenating them all ...
[08/23 07:58:05 d2.data.common]: Serialized dataset takes 0.45 MiB
model_final_2d9806.pkl: 431MB [00:38, 11.1MB/s]                               
[08/23 07:58:45 d2.engine.train_loop]: Starting training from iteration 0
[08/23 07:59:24 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 07:59:24 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 07:59:24 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 07:59:24 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 07:59:24 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 07:59:34 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0019 s/iter. Inference: 0.2648 s/iter. Eval: 0.6168 s/iter. Total: 0.8835 s/iter. ETA=0:01:57
[08/23 07:59:40 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0024 s/iter. Inference: 0.2655 s/iter. Eval: 0.6342 s/iter. Total: 0.9024 s/iter. ETA=0:01:54
[08/23 07:59:45 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0025 s/iter. Inference: 0.2655 s/iter. Eval: 0.6311 s/iter. Total: 0.8994 s/iter. ETA=0:01:48
[08/23 07:59:51 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0027 s/iter. Inference: 0.2660 s/iter. Eval: 0.6360 s/iter. Total: 0.9049 s/iter. ETA=0:01:44
[08/23 07:59:56 d2.evaluation.evaluator]: Inference done 35/144. Dataloading: 0.0027 s/iter. Inference: 0.2674 s/iter. Eval: 0.6428 s/iter. Total: 0.9131 s/iter. ETA=0:01:39
[08/23 08:00:02 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0027 s/iter. Inference: 0.2670 s/iter. Eval: 0.6441 s/iter. Total: 0.9141 s/iter. ETA=0:01:34
[08/23 08:00:07 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0026 s/iter. Inference: 0.2668 s/iter. Eval: 0.6398 s/iter. Total: 0.9096 s/iter. ETA=0:01:28
[08/23 08:00:13 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0027 s/iter. Inference: 0.2668 s/iter. Eval: 0.6395 s/iter. Total: 0.9094 s/iter. ETA=0:01:22
[08/23 08:00:18 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0027 s/iter. Inference: 0.2667 s/iter. Eval: 0.6367 s/iter. Total: 0.9064 s/iter. ETA=0:01:17
[08/23 08:00:23 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0027 s/iter. Inference: 0.2667 s/iter. Eval: 0.6362 s/iter. Total: 0.9060 s/iter. ETA=0:01:11
[08/23 08:00:29 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0029 s/iter. Inference: 0.2668 s/iter. Eval: 0.6391 s/iter. Total: 0.9092 s/iter. ETA=0:01:06
[08/23 08:00:34 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0029 s/iter. Inference: 0.2668 s/iter. Eval: 0.6395 s/iter. Total: 0.9095 s/iter. ETA=0:01:00
[08/23 08:00:40 d2.evaluation.evaluator]: Inference done 83/144. Dataloading: 0.0028 s/iter. Inference: 0.2667 s/iter. Eval: 0.6372 s/iter. Total: 0.9071 s/iter. ETA=0:00:55
[08/23 08:00:45 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0028 s/iter. Inference: 0.2666 s/iter. Eval: 0.6375 s/iter. Total: 0.9073 s/iter. ETA=0:00:49
[08/23 08:00:50 d2.evaluation.evaluator]: Inference done 95/144. Dataloading: 0.0028 s/iter. Inference: 0.2665 s/iter. Eval: 0.6364 s/iter. Total: 0.9061 s/iter. ETA=0:00:44
[08/23 08:00:56 d2.evaluation.evaluator]: Inference done 101/144. Dataloading: 0.0028 s/iter. Inference: 0.2665 s/iter. Eval: 0.6379 s/iter. Total: 0.9077 s/iter. ETA=0:00:39
[08/23 08:01:02 d2.evaluation.evaluator]: Inference done 107/144. Dataloading: 0.0029 s/iter. Inference: 0.2667 s/iter. Eval: 0.6394 s/iter. Total: 0.9094 s/iter. ETA=0:00:33
[08/23 08:01:07 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0029 s/iter. Inference: 0.2667 s/iter. Eval: 0.6392 s/iter. Total: 0.9092 s/iter. ETA=0:00:28
[08/23 08:01:12 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0029 s/iter. Inference: 0.2666 s/iter. Eval: 0.6376 s/iter. Total: 0.9074 s/iter. ETA=0:00:22
[08/23 08:01:18 d2.evaluation.evaluator]: Inference done 125/144. Dataloading: 0.0029 s/iter. Inference: 0.2665 s/iter. Eval: 0.6386 s/iter. Total: 0.9083 s/iter. ETA=0:00:17
[08/23 08:01:23 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0029 s/iter. Inference: 0.2664 s/iter. Eval: 0.6375 s/iter. Total: 0.9071 s/iter. ETA=0:00:11
[08/23 08:01:29 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0029 s/iter. Inference: 0.2663 s/iter. Eval: 0.6378 s/iter. Total: 0.9074 s/iter. ETA=0:00:06
[08/23 08:01:34 d2.evaluation.evaluator]: Inference done 143/144. Dataloading: 0.0029 s/iter. Inference: 0.2663 s/iter. Eval: 0.6387 s/iter. Total: 0.9082 s/iter. ETA=0:00:00
[08/23 08:01:35 d2.evaluation.evaluator]: Total inference time: 0:02:06.281599 (0.908501 s / iter per device, on 1 devices)
[08/23 08:01:35 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:37 (0.266245 s / iter per device, on 1 devices)
[08/23 08:01:35 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 08:01:35 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 08:01:36 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[08/23 08:01:36 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 08:01:36 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[08/23 08:01:36 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:01:36 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.03 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.005
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.020
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.193
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.092
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.221
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.164
[08/23 08:01:36 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.119 | 0.538  | 0.011  | 0.009 | 0.228 | 0.095 |
Loading and preparing results...
DONE (t=0.50s)
creating index...
index created!
[08/23 08:01:37 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 08:01:38 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.34 seconds.
[08/23 08:01:38 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:01:38 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000
[08/23 08:01:38 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.000 | 0.000  | 0.000  | 0.000 | 0.000 | 0.000 |
[08/23 08:01:38 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 08:01:38 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 08:01:38 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:01:38 d2.evaluation.testing]: copypaste: 0.1187,0.5382,0.0106,0.0090,0.2281,0.0951
[08/23 08:01:38 d2.evaluation.testing]: copypaste: Task: segm
[08/23 08:01:38 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:01:38 d2.evaluation.testing]: copypaste: 0.0000,0.0000,0.0000,0.0000,0.0000,0.0000
[08/23 08:01:38 d2.utils.events]:  eta: 0:30:52  iter: 19  total_loss: 1.89  loss_cls: 0.6912  loss_box_reg: 0.4468  loss_mask: 0.7027  loss_rpn_cls: 0.0232  loss_rpn_loc: 0.005293  time: 1.9016  data_time: 0.0560  lr: 4.9953e-06  max_mem: 10889M
[08/23 08:02:16 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 08:02:16 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 08:02:16 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 08:02:16 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 08:02:16 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 08:02:26 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0020 s/iter. Inference: 0.2666 s/iter. Eval: 0.6445 s/iter. Total: 0.9130 s/iter. ETA=0:02:01
[08/23 08:02:31 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0026 s/iter. Inference: 0.2662 s/iter. Eval: 0.6265 s/iter. Total: 0.8956 s/iter. ETA=0:01:53
[08/23 08:02:37 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0026 s/iter. Inference: 0.2660 s/iter. Eval: 0.6328 s/iter. Total: 0.9017 s/iter. ETA=0:01:49
[08/23 08:02:42 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0031 s/iter. Inference: 0.2666 s/iter. Eval: 0.6401 s/iter. Total: 0.9101 s/iter. ETA=0:01:44
[08/23 08:02:48 d2.evaluation.evaluator]: Inference done 35/144. Dataloading: 0.0030 s/iter. Inference: 0.2665 s/iter. Eval: 0.6409 s/iter. Total: 0.9107 s/iter. ETA=0:01:39
[08/23 08:02:53 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0029 s/iter. Inference: 0.2665 s/iter. Eval: 0.6352 s/iter. Total: 0.9049 s/iter. ETA=0:01:33
[08/23 08:02:59 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0029 s/iter. Inference: 0.2666 s/iter. Eval: 0.6361 s/iter. Total: 0.9059 s/iter. ETA=0:01:27
[08/23 08:03:04 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0029 s/iter. Inference: 0.2664 s/iter. Eval: 0.6339 s/iter. Total: 0.9034 s/iter. ETA=0:01:22
[08/23 08:03:09 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0028 s/iter. Inference: 0.2667 s/iter. Eval: 0.6346 s/iter. Total: 0.9043 s/iter. ETA=0:01:16
[08/23 08:03:15 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0028 s/iter. Inference: 0.2669 s/iter. Eval: 0.6377 s/iter. Total: 0.9077 s/iter. ETA=0:01:11
[08/23 08:03:20 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0028 s/iter. Inference: 0.2671 s/iter. Eval: 0.6375 s/iter. Total: 0.9076 s/iter. ETA=0:01:06
[08/23 08:03:26 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0027 s/iter. Inference: 0.2669 s/iter. Eval: 0.6353 s/iter. Total: 0.9052 s/iter. ETA=0:01:00
[08/23 08:03:31 d2.evaluation.evaluator]: Inference done 83/144. Dataloading: 0.0028 s/iter. Inference: 0.2672 s/iter. Eval: 0.6353 s/iter. Total: 0.9056 s/iter. ETA=0:00:55
[08/23 08:03:36 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0028 s/iter. Inference: 0.2671 s/iter. Eval: 0.6343 s/iter. Total: 0.9045 s/iter. ETA=0:00:49
[08/23 08:03:42 d2.evaluation.evaluator]: Inference done 95/144. Dataloading: 0.0028 s/iter. Inference: 0.2671 s/iter. Eval: 0.6355 s/iter. Total: 0.9056 s/iter. ETA=0:00:44
[08/23 08:03:48 d2.evaluation.evaluator]: Inference done 101/144. Dataloading: 0.0028 s/iter. Inference: 0.2671 s/iter. Eval: 0.6378 s/iter. Total: 0.9079 s/iter. ETA=0:00:39
[08/23 08:03:53 d2.evaluation.evaluator]: Inference done 107/144. Dataloading: 0.0028 s/iter. Inference: 0.2670 s/iter. Eval: 0.6382 s/iter. Total: 0.9082 s/iter. ETA=0:00:33
[08/23 08:03:58 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0028 s/iter. Inference: 0.2670 s/iter. Eval: 0.6372 s/iter. Total: 0.9072 s/iter. ETA=0:00:28
[08/23 08:04:04 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0028 s/iter. Inference: 0.2669 s/iter. Eval: 0.6374 s/iter. Total: 0.9074 s/iter. ETA=0:00:22
[08/23 08:04:09 d2.evaluation.evaluator]: Inference done 125/144. Dataloading: 0.0028 s/iter. Inference: 0.2668 s/iter. Eval: 0.6364 s/iter. Total: 0.9063 s/iter. ETA=0:00:17
[08/23 08:04:15 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0027 s/iter. Inference: 0.2667 s/iter. Eval: 0.6369 s/iter. Total: 0.9067 s/iter. ETA=0:00:11
[08/23 08:04:20 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0028 s/iter. Inference: 0.2669 s/iter. Eval: 0.6384 s/iter. Total: 0.9083 s/iter. ETA=0:00:06
[08/23 08:04:26 d2.evaluation.evaluator]: Inference done 143/144. Dataloading: 0.0028 s/iter. Inference: 0.2668 s/iter. Eval: 0.6389 s/iter. Total: 0.9087 s/iter. ETA=0:00:00
[08/23 08:04:27 d2.evaluation.evaluator]: Total inference time: 0:02:06.354956 (0.909028 s / iter per device, on 1 devices)
[08/23 08:04:27 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:37 (0.266777 s / iter per device, on 1 devices)
[08/23 08:04:27 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 08:04:27 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 08:04:27 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[08/23 08:04:27 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 08:04:27 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.12 seconds.
[08/23 08:04:27 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:04:27 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.018
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.007
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.005
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.006
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.072
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.301
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.092
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.329
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.291
[08/23 08:04:27 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.443 | 1.816  | 0.075  | 0.033 | 0.712 | 0.490 |
Loading and preparing results...
DONE (t=0.30s)
creating index...
index created!
[08/23 08:04:28 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 08:04:28 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.21 seconds.
[08/23 08:04:28 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:04:28 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.017
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.045
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.010
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.020
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.056
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.027
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.216
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.525
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.183
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.531
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.576
[08/23 08:04:28 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 1.664 | 4.530  | 0.959  | 0.107 | 2.000 | 5.616 |
[08/23 08:04:28 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 08:04:28 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 08:04:29 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:04:29 d2.evaluation.testing]: copypaste: 0.4426,1.8163,0.0746,0.0329,0.7120,0.4904
[08/23 08:04:29 d2.evaluation.testing]: copypaste: Task: segm
[08/23 08:04:29 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:04:29 d2.evaluation.testing]: copypaste: 1.6641,4.5297,0.9588,0.1071,2.0003,5.6164
[08/23 08:04:29 d2.utils.events]:  eta: 0:30:07  iter: 39  total_loss: 1.834  loss_cls: 0.6338  loss_box_reg: 0.4072  loss_mask: 0.6871  loss_rpn_cls: 0.04646  loss_rpn_loc: 0.007542  time: 1.8951  data_time: 0.0170  lr: 9.9902e-06  max_mem: 10889M
[08/23 08:05:06 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 08:05:06 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 08:05:06 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 08:05:06 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 08:05:06 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 08:05:17 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0019 s/iter. Inference: 0.2661 s/iter. Eval: 0.6223 s/iter. Total: 0.8903 s/iter. ETA=0:01:58
[08/23 08:05:22 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0024 s/iter. Inference: 0.2677 s/iter. Eval: 0.6364 s/iter. Total: 0.9069 s/iter. ETA=0:01:55
[08/23 08:05:28 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0026 s/iter. Inference: 0.2698 s/iter. Eval: 0.6479 s/iter. Total: 0.9205 s/iter. ETA=0:01:51
[08/23 08:05:33 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0026 s/iter. Inference: 0.2697 s/iter. Eval: 0.6434 s/iter. Total: 0.9159 s/iter. ETA=0:01:45
[08/23 08:05:38 d2.evaluation.evaluator]: Inference done 35/144. Dataloading: 0.0026 s/iter. Inference: 0.2687 s/iter. Eval: 0.6368 s/iter. Total: 0.9084 s/iter. ETA=0:01:39
[08/23 08:05:44 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0026 s/iter. Inference: 0.2683 s/iter. Eval: 0.6365 s/iter. Total: 0.9076 s/iter. ETA=0:01:33
[08/23 08:05:49 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0025 s/iter. Inference: 0.2677 s/iter. Eval: 0.6342 s/iter. Total: 0.9047 s/iter. ETA=0:01:27
[08/23 08:05:55 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0025 s/iter. Inference: 0.2673 s/iter. Eval: 0.6369 s/iter. Total: 0.9071 s/iter. ETA=0:01:22
[08/23 08:06:00 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0027 s/iter. Inference: 0.2676 s/iter. Eval: 0.6397 s/iter. Total: 0.9104 s/iter. ETA=0:01:17
[08/23 08:06:06 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0027 s/iter. Inference: 0.2673 s/iter. Eval: 0.6406 s/iter. Total: 0.9109 s/iter. ETA=0:01:11
[08/23 08:06:11 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0027 s/iter. Inference: 0.2671 s/iter. Eval: 0.6379 s/iter. Total: 0.9080 s/iter. ETA=0:01:06
[08/23 08:06:17 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0027 s/iter. Inference: 0.2670 s/iter. Eval: 0.6400 s/iter. Total: 0.9101 s/iter. ETA=0:01:00
[08/23 08:06:22 d2.evaluation.evaluator]: Inference done 83/144. Dataloading: 0.0027 s/iter. Inference: 0.2669 s/iter. Eval: 0.6387 s/iter. Total: 0.9087 s/iter. ETA=0:00:55
[08/23 08:06:28 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0028 s/iter. Inference: 0.2668 s/iter. Eval: 0.6397 s/iter. Total: 0.9097 s/iter. ETA=0:00:50
[08/23 08:06:33 d2.evaluation.evaluator]: Inference done 95/144. Dataloading: 0.0029 s/iter. Inference: 0.2673 s/iter. Eval: 0.6413 s/iter. Total: 0.9118 s/iter. ETA=0:00:44
[08/23 08:06:39 d2.evaluation.evaluator]: Inference done 101/144. Dataloading: 0.0029 s/iter. Inference: 0.2672 s/iter. Eval: 0.6451 s/iter. Total: 0.9155 s/iter. ETA=0:00:39
[08/23 08:06:44 d2.evaluation.evaluator]: Inference done 107/144. Dataloading: 0.0029 s/iter. Inference: 0.2670 s/iter. Eval: 0.6431 s/iter. Total: 0.9133 s/iter. ETA=0:00:33
[08/23 08:06:50 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0029 s/iter. Inference: 0.2670 s/iter. Eval: 0.6436 s/iter. Total: 0.9137 s/iter. ETA=0:00:28
[08/23 08:06:55 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0028 s/iter. Inference: 0.2669 s/iter. Eval: 0.6425 s/iter. Total: 0.9125 s/iter. ETA=0:00:22
[08/23 08:07:01 d2.evaluation.evaluator]: Inference done 125/144. Dataloading: 0.0028 s/iter. Inference: 0.2667 s/iter. Eval: 0.6434 s/iter. Total: 0.9132 s/iter. ETA=0:00:17
[08/23 08:07:06 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0028 s/iter. Inference: 0.2668 s/iter. Eval: 0.6444 s/iter. Total: 0.9144 s/iter. ETA=0:00:11
[08/23 08:07:12 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0028 s/iter. Inference: 0.2668 s/iter. Eval: 0.6440 s/iter. Total: 0.9139 s/iter. ETA=0:00:06
[08/23 08:07:17 d2.evaluation.evaluator]: Inference done 143/144. Dataloading: 0.0028 s/iter. Inference: 0.2667 s/iter. Eval: 0.6426 s/iter. Total: 0.9124 s/iter. ETA=0:00:00
[08/23 08:07:18 d2.evaluation.evaluator]: Total inference time: 0:02:06.880102 (0.912806 s / iter per device, on 1 devices)
[08/23 08:07:18 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:37 (0.266631 s / iter per device, on 1 devices)
[08/23 08:07:18 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 08:07:18 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 08:07:18 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[08/23 08:07:19 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 08:07:19 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.12 seconds.
[08/23 08:07:19 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:07:19 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.024
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.076
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.009
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.007
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.032
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.024
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.035
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.204
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.407
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.150
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.423
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.427
[08/23 08:07:19 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 2.377 | 7.636  | 0.944  | 0.728 | 3.184 | 2.400 |
Loading and preparing results...
DONE (t=0.39s)
creating index...
index created!
[08/23 08:07:20 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 08:07:20 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.37 seconds.
[08/23 08:07:20 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:07:20 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.04 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.051
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.117
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.036
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.006
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.046
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.119
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.089
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.315
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.596
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.183
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.577
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.703
[08/23 08:07:20 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 5.136 | 11.653 | 3.647  | 0.613 | 4.586 | 11.895 |
[08/23 08:07:20 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 08:07:20 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 08:07:20 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:07:20 d2.evaluation.testing]: copypaste: 2.3773,7.6358,0.9440,0.7277,3.1843,2.4004
[08/23 08:07:20 d2.evaluation.testing]: copypaste: Task: segm
[08/23 08:07:20 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:07:20 d2.evaluation.testing]: copypaste: 5.1356,11.6525,3.6475,0.6132,4.5858,11.8954
[08/23 08:07:20 d2.utils.events]:  eta: 0:29:29  iter: 59  total_loss: 1.602  loss_cls: 0.5013  loss_box_reg: 0.3666  loss_mask: 0.6584  loss_rpn_cls: 0.02309  loss_rpn_loc: 0.005019  time: 1.8891  data_time: 0.0156  lr: 1.4985e-05  max_mem: 10889M
[08/23 08:07:58 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 08:07:58 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 08:07:58 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 08:07:58 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 08:07:58 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 08:08:09 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0035 s/iter. Inference: 0.2757 s/iter. Eval: 0.7133 s/iter. Total: 0.9925 s/iter. ETA=0:02:11
[08/23 08:08:14 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0031 s/iter. Inference: 0.2703 s/iter. Eval: 0.6624 s/iter. Total: 0.9361 s/iter. ETA=0:01:58
[08/23 08:08:20 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0029 s/iter. Inference: 0.2684 s/iter. Eval: 0.6588 s/iter. Total: 0.9305 s/iter. ETA=0:01:52
[08/23 08:08:25 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0029 s/iter. Inference: 0.2677 s/iter. Eval: 0.6476 s/iter. Total: 0.9185 s/iter. ETA=0:01:45
[08/23 08:08:30 d2.evaluation.evaluator]: Inference done 35/144. Dataloading: 0.0029 s/iter. Inference: 0.2676 s/iter. Eval: 0.6467 s/iter. Total: 0.9175 s/iter. ETA=0:01:40
[08/23 08:08:36 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0030 s/iter. Inference: 0.2673 s/iter. Eval: 0.6431 s/iter. Total: 0.9137 s/iter. ETA=0:01:34
[08/23 08:08:42 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0031 s/iter. Inference: 0.2686 s/iter. Eval: 0.6499 s/iter. Total: 0.9219 s/iter. ETA=0:01:29
[08/23 08:08:47 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0031 s/iter. Inference: 0.2681 s/iter. Eval: 0.6455 s/iter. Total: 0.9170 s/iter. ETA=0:01:23
[08/23 08:08:52 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0030 s/iter. Inference: 0.2682 s/iter. Eval: 0.6445 s/iter. Total: 0.9161 s/iter. ETA=0:01:17
[08/23 08:08:58 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0030 s/iter. Inference: 0.2679 s/iter. Eval: 0.6414 s/iter. Total: 0.9126 s/iter. ETA=0:01:12
[08/23 08:09:03 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0029 s/iter. Inference: 0.2678 s/iter. Eval: 0.6428 s/iter. Total: 0.9138 s/iter. ETA=0:01:06
[08/23 08:09:08 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0029 s/iter. Inference: 0.2676 s/iter. Eval: 0.6410 s/iter. Total: 0.9117 s/iter. ETA=0:01:01
[08/23 08:09:14 d2.evaluation.evaluator]: Inference done 83/144. Dataloading: 0.0029 s/iter. Inference: 0.2681 s/iter. Eval: 0.6449 s/iter. Total: 0.9162 s/iter. ETA=0:00:55
[08/23 08:09:20 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0029 s/iter. Inference: 0.2679 s/iter. Eval: 0.6430 s/iter. Total: 0.9142 s/iter. ETA=0:00:50
[08/23 08:09:25 d2.evaluation.evaluator]: Inference done 95/144. Dataloading: 0.0030 s/iter. Inference: 0.2680 s/iter. Eval: 0.6427 s/iter. Total: 0.9140 s/iter. ETA=0:00:44
[08/23 08:09:30 d2.evaluation.evaluator]: Inference done 101/144. Dataloading: 0.0029 s/iter. Inference: 0.2679 s/iter. Eval: 0.6409 s/iter. Total: 0.9120 s/iter. ETA=0:00:39
[08/23 08:09:36 d2.evaluation.evaluator]: Inference done 107/144. Dataloading: 0.0029 s/iter. Inference: 0.2679 s/iter. Eval: 0.6410 s/iter. Total: 0.9122 s/iter. ETA=0:00:33
[08/23 08:09:41 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0029 s/iter. Inference: 0.2677 s/iter. Eval: 0.6402 s/iter. Total: 0.9112 s/iter. ETA=0:00:28
[08/23 08:09:46 d2.evaluation.evaluator]: Inference done 118/144. Dataloading: 0.0029 s/iter. Inference: 0.2679 s/iter. Eval: 0.6441 s/iter. Total: 0.9152 s/iter. ETA=0:00:23
[08/23 08:09:52 d2.evaluation.evaluator]: Inference done 124/144. Dataloading: 0.0029 s/iter. Inference: 0.2678 s/iter. Eval: 0.6425 s/iter. Total: 0.9135 s/iter. ETA=0:00:18
[08/23 08:09:57 d2.evaluation.evaluator]: Inference done 130/144. Dataloading: 0.0029 s/iter. Inference: 0.2678 s/iter. Eval: 0.6423 s/iter. Total: 0.9133 s/iter. ETA=0:00:12
[08/23 08:10:02 d2.evaluation.evaluator]: Inference done 136/144. Dataloading: 0.0028 s/iter. Inference: 0.2677 s/iter. Eval: 0.6408 s/iter. Total: 0.9117 s/iter. ETA=0:00:07
[08/23 08:10:08 d2.evaluation.evaluator]: Inference done 142/144. Dataloading: 0.0028 s/iter. Inference: 0.2675 s/iter. Eval: 0.6412 s/iter. Total: 0.9120 s/iter. ETA=0:00:01
[08/23 08:10:10 d2.evaluation.evaluator]: Total inference time: 0:02:06.788681 (0.912149 s / iter per device, on 1 devices)
[08/23 08:10:10 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:37 (0.267501 s / iter per device, on 1 devices)
[08/23 08:10:10 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 08:10:10 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 08:10:10 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[08/23 08:10:10 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 08:10:10 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.12 seconds.
[08/23 08:10:10 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:10:10 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.070
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.181
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.036
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.049
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.090
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.066
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.103
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.301
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.453
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.158
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.459
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.497
[08/23 08:10:10 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 6.978 | 18.108 | 3.554  | 4.870 | 9.031 | 6.610 |
Loading and preparing results...
DONE (t=0.33s)
creating index...
index created!
[08/23 08:10:11 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 08:10:11 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.23 seconds.
[08/23 08:10:11 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:10:11 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.110
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.217
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.099
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.029
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.092
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.195
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.148
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.421
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.611
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.183
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.583
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.736
[08/23 08:10:11 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:------:|:------:|:------:|:-----:|:-----:|:------:|
| 11.024 | 21.682 | 9.932  | 2.914 | 9.169 | 19.495 |
[08/23 08:10:12 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 08:10:12 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 08:10:12 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:10:12 d2.evaluation.testing]: copypaste: 6.9777,18.1075,3.5540,4.8701,9.0312,6.6102
[08/23 08:10:12 d2.evaluation.testing]: copypaste: Task: segm
[08/23 08:10:12 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:10:12 d2.evaluation.testing]: copypaste: 11.0241,21.6818,9.9320,2.9145,9.1691,19.4946
[08/23 08:10:12 d2.utils.events]:  eta: 0:28:51  iter: 79  total_loss: 1.558  loss_cls: 0.3973  loss_box_reg: 0.3756  loss_mask: 0.6106  loss_rpn_cls: 0.02402  loss_rpn_loc: 0.009645  time: 1.8884  data_time: 0.0174  lr: 1.998e-05  max_mem: 10889M
[08/23 08:10:50 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 08:10:50 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 08:10:50 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 08:10:50 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 08:10:50 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 08:11:00 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0021 s/iter. Inference: 0.2680 s/iter. Eval: 0.6411 s/iter. Total: 0.9113 s/iter. ETA=0:02:01
[08/23 08:11:06 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0023 s/iter. Inference: 0.2666 s/iter. Eval: 0.6274 s/iter. Total: 0.8966 s/iter. ETA=0:01:53
[08/23 08:11:11 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0024 s/iter. Inference: 0.2663 s/iter. Eval: 0.6350 s/iter. Total: 0.9041 s/iter. ETA=0:01:49
[08/23 08:11:16 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0025 s/iter. Inference: 0.2659 s/iter. Eval: 0.6304 s/iter. Total: 0.8991 s/iter. ETA=0:01:43
[08/23 08:11:22 d2.evaluation.evaluator]: Inference done 35/144. Dataloading: 0.0025 s/iter. Inference: 0.2657 s/iter. Eval: 0.6345 s/iter. Total: 0.9030 s/iter. ETA=0:01:38
[08/23 08:11:28 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0026 s/iter. Inference: 0.2659 s/iter. Eval: 0.6419 s/iter. Total: 0.9107 s/iter. ETA=0:01:33
[08/23 08:11:33 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0026 s/iter. Inference: 0.2658 s/iter. Eval: 0.6425 s/iter. Total: 0.9112 s/iter. ETA=0:01:28
[08/23 08:11:38 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0026 s/iter. Inference: 0.2657 s/iter. Eval: 0.6391 s/iter. Total: 0.9076 s/iter. ETA=0:01:22
[08/23 08:11:44 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0027 s/iter. Inference: 0.2655 s/iter. Eval: 0.6388 s/iter. Total: 0.9073 s/iter. ETA=0:01:17
[08/23 08:11:49 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0026 s/iter. Inference: 0.2659 s/iter. Eval: 0.6366 s/iter. Total: 0.9054 s/iter. ETA=0:01:11
[08/23 08:11:55 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0026 s/iter. Inference: 0.2659 s/iter. Eval: 0.6371 s/iter. Total: 0.9058 s/iter. ETA=0:01:06
[08/23 08:12:00 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0027 s/iter. Inference: 0.2662 s/iter. Eval: 0.6409 s/iter. Total: 0.9101 s/iter. ETA=0:01:00
[08/23 08:12:06 d2.evaluation.evaluator]: Inference done 83/144. Dataloading: 0.0027 s/iter. Inference: 0.2662 s/iter. Eval: 0.6408 s/iter. Total: 0.9100 s/iter. ETA=0:00:55
[08/23 08:12:11 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0026 s/iter. Inference: 0.2662 s/iter. Eval: 0.6393 s/iter. Total: 0.9084 s/iter. ETA=0:00:49
[08/23 08:12:16 d2.evaluation.evaluator]: Inference done 95/144. Dataloading: 0.0026 s/iter. Inference: 0.2662 s/iter. Eval: 0.6381 s/iter. Total: 0.9072 s/iter. ETA=0:00:44
[08/23 08:12:22 d2.evaluation.evaluator]: Inference done 101/144. Dataloading: 0.0027 s/iter. Inference: 0.2662 s/iter. Eval: 0.6381 s/iter. Total: 0.9073 s/iter. ETA=0:00:39
[08/23 08:12:27 d2.evaluation.evaluator]: Inference done 107/144. Dataloading: 0.0026 s/iter. Inference: 0.2662 s/iter. Eval: 0.6371 s/iter. Total: 0.9062 s/iter. ETA=0:00:33
[08/23 08:12:33 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0027 s/iter. Inference: 0.2665 s/iter. Eval: 0.6406 s/iter. Total: 0.9102 s/iter. ETA=0:00:28
[08/23 08:12:38 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0027 s/iter. Inference: 0.2664 s/iter. Eval: 0.6391 s/iter. Total: 0.9086 s/iter. ETA=0:00:22
[08/23 08:12:44 d2.evaluation.evaluator]: Inference done 125/144. Dataloading: 0.0027 s/iter. Inference: 0.2665 s/iter. Eval: 0.6398 s/iter. Total: 0.9094 s/iter. ETA=0:00:17
[08/23 08:12:49 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0027 s/iter. Inference: 0.2664 s/iter. Eval: 0.6386 s/iter. Total: 0.9082 s/iter. ETA=0:00:11
[08/23 08:12:55 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0027 s/iter. Inference: 0.2665 s/iter. Eval: 0.6388 s/iter. Total: 0.9085 s/iter. ETA=0:00:06
[08/23 08:13:00 d2.evaluation.evaluator]: Inference done 143/144. Dataloading: 0.0027 s/iter. Inference: 0.2664 s/iter. Eval: 0.6379 s/iter. Total: 0.9074 s/iter. ETA=0:00:00
[08/23 08:13:01 d2.evaluation.evaluator]: Total inference time: 0:02:06.389248 (0.909275 s / iter per device, on 1 devices)
[08/23 08:13:01 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:37 (0.266421 s / iter per device, on 1 devices)
[08/23 08:13:01 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 08:13:01 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 08:13:02 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[08/23 08:13:02 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 08:13:02 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.21 seconds.
[08/23 08:13:02 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:13:02 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.03 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.124
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.293
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.088
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.096
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.147
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.129
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.149
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.363
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.472
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.150
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.477
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.520
[08/23 08:13:02 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 12.446 | 29.325 | 8.769  | 9.605 | 14.731 | 12.906 |
Loading and preparing results...
DONE (t=0.33s)
creating index...
index created!
[08/23 08:13:03 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 08:13:04 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.23 seconds.
[08/23 08:13:04 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:13:04 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.178
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.320
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.171
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.060
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.150
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.278
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.199
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.469
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.620
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.183
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.592
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.747
[08/23 08:13:04 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 17.782 | 32.031 | 17.053 | 6.028 | 15.009 | 27.766 |
[08/23 08:13:04 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 08:13:04 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 08:13:04 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:13:04 d2.evaluation.testing]: copypaste: 12.4464,29.3253,8.7685,9.6054,14.7305,12.9057
[08/23 08:13:04 d2.evaluation.testing]: copypaste: Task: segm
[08/23 08:13:04 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:13:04 d2.evaluation.testing]: copypaste: 17.7818,32.0307,17.0531,6.0282,15.0088,27.7655
[08/23 08:13:04 d2.utils.events]:  eta: 0:28:14  iter: 99  total_loss: 1.445  loss_cls: 0.3409  loss_box_reg: 0.395  loss_mask: 0.561  loss_rpn_cls: 0.02577  loss_rpn_loc: 0.007428  time: 1.8896  data_time: 0.0167  lr: 2.4975e-05  max_mem: 10889M
[08/23 08:13:42 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 08:13:42 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 08:13:42 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 08:13:42 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 08:13:42 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 08:13:52 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0021 s/iter. Inference: 0.2657 s/iter. Eval: 0.6103 s/iter. Total: 0.8781 s/iter. ETA=0:01:56
[08/23 08:13:57 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0024 s/iter. Inference: 0.2666 s/iter. Eval: 0.6228 s/iter. Total: 0.8921 s/iter. ETA=0:01:53
[08/23 08:14:03 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0024 s/iter. Inference: 0.2660 s/iter. Eval: 0.6200 s/iter. Total: 0.8887 s/iter. ETA=0:01:47
[08/23 08:14:08 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0024 s/iter. Inference: 0.2658 s/iter. Eval: 0.6378 s/iter. Total: 0.9063 s/iter. ETA=0:01:44
[08/23 08:14:14 d2.evaluation.evaluator]: Inference done 35/144. Dataloading: 0.0024 s/iter. Inference: 0.2672 s/iter. Eval: 0.6343 s/iter. Total: 0.9042 s/iter. ETA=0:01:38
[08/23 08:14:19 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0025 s/iter. Inference: 0.2674 s/iter. Eval: 0.6367 s/iter. Total: 0.9069 s/iter. ETA=0:01:33
[08/23 08:14:25 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0025 s/iter. Inference: 0.2672 s/iter. Eval: 0.6357 s/iter. Total: 0.9058 s/iter. ETA=0:01:27
[08/23 08:14:30 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0026 s/iter. Inference: 0.2670 s/iter. Eval: 0.6364 s/iter. Total: 0.9064 s/iter. ETA=0:01:22
[08/23 08:14:35 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0026 s/iter. Inference: 0.2669 s/iter. Eval: 0.6344 s/iter. Total: 0.9042 s/iter. ETA=0:01:16
[08/23 08:14:41 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0026 s/iter. Inference: 0.2667 s/iter. Eval: 0.6392 s/iter. Total: 0.9088 s/iter. ETA=0:01:11
[08/23 08:14:47 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0026 s/iter. Inference: 0.2666 s/iter. Eval: 0.6391 s/iter. Total: 0.9086 s/iter. ETA=0:01:06
[08/23 08:14:52 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0026 s/iter. Inference: 0.2665 s/iter. Eval: 0.6392 s/iter. Total: 0.9087 s/iter. ETA=0:01:00
[08/23 08:14:57 d2.evaluation.evaluator]: Inference done 83/144. Dataloading: 0.0027 s/iter. Inference: 0.2664 s/iter. Eval: 0.6368 s/iter. Total: 0.9062 s/iter. ETA=0:00:55
[08/23 08:15:03 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0027 s/iter. Inference: 0.2665 s/iter. Eval: 0.6365 s/iter. Total: 0.9061 s/iter. ETA=0:00:49
[08/23 08:15:08 d2.evaluation.evaluator]: Inference done 95/144. Dataloading: 0.0027 s/iter. Inference: 0.2664 s/iter. Eval: 0.6350 s/iter. Total: 0.9044 s/iter. ETA=0:00:44
[08/23 08:15:13 d2.evaluation.evaluator]: Inference done 101/144. Dataloading: 0.0027 s/iter. Inference: 0.2665 s/iter. Eval: 0.6354 s/iter. Total: 0.9049 s/iter. ETA=0:00:38
[08/23 08:15:19 d2.evaluation.evaluator]: Inference done 107/144. Dataloading: 0.0028 s/iter. Inference: 0.2667 s/iter. Eval: 0.6374 s/iter. Total: 0.9072 s/iter. ETA=0:00:33
[08/23 08:15:25 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0027 s/iter. Inference: 0.2669 s/iter. Eval: 0.6370 s/iter. Total: 0.9070 s/iter. ETA=0:00:28
[08/23 08:15:30 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0028 s/iter. Inference: 0.2668 s/iter. Eval: 0.6356 s/iter. Total: 0.9055 s/iter. ETA=0:00:22
[08/23 08:15:35 d2.evaluation.evaluator]: Inference done 125/144. Dataloading: 0.0027 s/iter. Inference: 0.2669 s/iter. Eval: 0.6357 s/iter. Total: 0.9056 s/iter. ETA=0:00:17
[08/23 08:15:41 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0027 s/iter. Inference: 0.2667 s/iter. Eval: 0.6345 s/iter. Total: 0.9043 s/iter. ETA=0:00:11
[08/23 08:15:46 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0027 s/iter. Inference: 0.2667 s/iter. Eval: 0.6355 s/iter. Total: 0.9053 s/iter. ETA=0:00:06
[08/23 08:15:52 d2.evaluation.evaluator]: Inference done 143/144. Dataloading: 0.0027 s/iter. Inference: 0.2668 s/iter. Eval: 0.6369 s/iter. Total: 0.9068 s/iter. ETA=0:00:00
[08/23 08:15:53 d2.evaluation.evaluator]: Total inference time: 0:02:06.092583 (0.907141 s / iter per device, on 1 devices)
[08/23 08:15:53 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:37 (0.266809 s / iter per device, on 1 devices)
[08/23 08:15:53 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 08:15:53 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 08:15:53 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[08/23 08:15:53 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 08:15:53 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.12 seconds.
[08/23 08:15:53 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:15:53 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.177
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.368
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.140
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.094
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.203
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.190
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.201
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.419
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.513
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.225
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.510
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.573
[08/23 08:15:53 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 17.677 | 36.757 | 13.989 | 9.416 | 20.340 | 19.002 |
Loading and preparing results...
DONE (t=0.32s)
creating index...
index created!
[08/23 08:15:54 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 08:15:54 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.22 seconds.
[08/23 08:15:54 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:15:54 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.224
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.382
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.227
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.059
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.190
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.346
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.240
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.509
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.637
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.233
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.611
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.755
[08/23 08:15:54 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 22.436 | 38.152 | 22.741 | 5.918 | 19.006 | 34.560 |
[08/23 08:15:54 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 08:15:54 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 08:15:54 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:15:54 d2.evaluation.testing]: copypaste: 17.6768,36.7565,13.9889,9.4162,20.3401,19.0018
[08/23 08:15:54 d2.evaluation.testing]: copypaste: Task: segm
[08/23 08:15:54 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:15:54 d2.evaluation.testing]: copypaste: 22.4357,38.1523,22.7407,5.9180,19.0057,34.5598
[08/23 08:15:54 d2.utils.events]:  eta: 0:27:36  iter: 119  total_loss: 1.323  loss_cls: 0.3003  loss_box_reg: 0.4054  loss_mask: 0.5095  loss_rpn_cls: 0.04148  loss_rpn_loc: 0.00783  time: 1.8898  data_time: 0.0173  lr: 2.997e-05  max_mem: 10889M
[08/23 08:16:32 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 08:16:32 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 08:16:32 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 08:16:32 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 08:16:32 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 08:16:42 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0019 s/iter. Inference: 0.2704 s/iter. Eval: 0.6270 s/iter. Total: 0.8993 s/iter. ETA=0:01:59
[08/23 08:16:48 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0023 s/iter. Inference: 0.2679 s/iter. Eval: 0.6504 s/iter. Total: 0.9209 s/iter. ETA=0:01:56
[08/23 08:16:54 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0025 s/iter. Inference: 0.2682 s/iter. Eval: 0.6637 s/iter. Total: 0.9347 s/iter. ETA=0:01:53
[08/23 08:16:59 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0025 s/iter. Inference: 0.2690 s/iter. Eval: 0.6515 s/iter. Total: 0.9234 s/iter. ETA=0:01:46
[08/23 08:17:05 d2.evaluation.evaluator]: Inference done 35/144. Dataloading: 0.0025 s/iter. Inference: 0.2683 s/iter. Eval: 0.6483 s/iter. Total: 0.9195 s/iter. ETA=0:01:40
[08/23 08:17:10 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0024 s/iter. Inference: 0.2678 s/iter. Eval: 0.6413 s/iter. Total: 0.9119 s/iter. ETA=0:01:33
[08/23 08:17:15 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0025 s/iter. Inference: 0.2679 s/iter. Eval: 0.6399 s/iter. Total: 0.9106 s/iter. ETA=0:01:28
[08/23 08:17:20 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0026 s/iter. Inference: 0.2676 s/iter. Eval: 0.6369 s/iter. Total: 0.9073 s/iter. ETA=0:01:22
[08/23 08:17:26 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0025 s/iter. Inference: 0.2674 s/iter. Eval: 0.6427 s/iter. Total: 0.9130 s/iter. ETA=0:01:17
[08/23 08:17:32 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0025 s/iter. Inference: 0.2675 s/iter. Eval: 0.6422 s/iter. Total: 0.9126 s/iter. ETA=0:01:12
[08/23 08:17:37 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0025 s/iter. Inference: 0.2674 s/iter. Eval: 0.6417 s/iter. Total: 0.9120 s/iter. ETA=0:01:06
[08/23 08:17:42 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0026 s/iter. Inference: 0.2672 s/iter. Eval: 0.6390 s/iter. Total: 0.9092 s/iter. ETA=0:01:00
[08/23 08:17:48 d2.evaluation.evaluator]: Inference done 83/144. Dataloading: 0.0026 s/iter. Inference: 0.2671 s/iter. Eval: 0.6399 s/iter. Total: 0.9100 s/iter. ETA=0:00:55
[08/23 08:17:53 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0026 s/iter. Inference: 0.2670 s/iter. Eval: 0.6382 s/iter. Total: 0.9081 s/iter. ETA=0:00:49
[08/23 08:17:59 d2.evaluation.evaluator]: Inference done 95/144. Dataloading: 0.0026 s/iter. Inference: 0.2671 s/iter. Eval: 0.6390 s/iter. Total: 0.9090 s/iter. ETA=0:00:44
[08/23 08:18:04 d2.evaluation.evaluator]: Inference done 101/144. Dataloading: 0.0026 s/iter. Inference: 0.2676 s/iter. Eval: 0.6400 s/iter. Total: 0.9106 s/iter. ETA=0:00:39
[08/23 08:18:10 d2.evaluation.evaluator]: Inference done 107/144. Dataloading: 0.0026 s/iter. Inference: 0.2675 s/iter. Eval: 0.6407 s/iter. Total: 0.9112 s/iter. ETA=0:00:33
[08/23 08:18:15 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0026 s/iter. Inference: 0.2674 s/iter. Eval: 0.6387 s/iter. Total: 0.9091 s/iter. ETA=0:00:28
[08/23 08:18:21 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0026 s/iter. Inference: 0.2674 s/iter. Eval: 0.6385 s/iter. Total: 0.9088 s/iter. ETA=0:00:22
[08/23 08:18:26 d2.evaluation.evaluator]: Inference done 125/144. Dataloading: 0.0026 s/iter. Inference: 0.2673 s/iter. Eval: 0.6374 s/iter. Total: 0.9076 s/iter. ETA=0:00:17
[08/23 08:18:31 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0026 s/iter. Inference: 0.2672 s/iter. Eval: 0.6374 s/iter. Total: 0.9075 s/iter. ETA=0:00:11
[08/23 08:18:37 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0026 s/iter. Inference: 0.2673 s/iter. Eval: 0.6390 s/iter. Total: 0.9093 s/iter. ETA=0:00:06
[08/23 08:18:42 d2.evaluation.evaluator]: Inference done 143/144. Dataloading: 0.0026 s/iter. Inference: 0.2672 s/iter. Eval: 0.6386 s/iter. Total: 0.9088 s/iter. ETA=0:00:00
[08/23 08:18:43 d2.evaluation.evaluator]: Total inference time: 0:02:06.397988 (0.909338 s / iter per device, on 1 devices)
[08/23 08:18:43 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:37 (0.267239 s / iter per device, on 1 devices)
[08/23 08:18:44 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 08:18:44 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 08:18:44 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[08/23 08:18:44 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 08:18:44 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.12 seconds.
[08/23 08:18:44 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:18:44 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.231
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.428
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.209
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.257
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.253
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.227
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.454
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.553
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.192
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.554
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.618
[08/23 08:18:44 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 23.074 | 42.820 | 20.879 | 9.985 | 25.711 | 25.325 |
Loading and preparing results...
DONE (t=0.34s)
creating index...
index created!
[08/23 08:18:45 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 08:18:45 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.23 seconds.
[08/23 08:18:45 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:18:45 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.03 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.275
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.450
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.287
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.123
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.231
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.408
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.261
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.530
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.656
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.233
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.639
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.762
[08/23 08:18:45 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 27.453 | 45.032 | 28.686 | 12.331 | 23.057 | 40.846 |
[08/23 08:18:45 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 08:18:45 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 08:18:45 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:18:45 d2.evaluation.testing]: copypaste: 23.0735,42.8197,20.8790,9.9854,25.7107,25.3248
[08/23 08:18:45 d2.evaluation.testing]: copypaste: Task: segm
[08/23 08:18:45 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:18:45 d2.evaluation.testing]: copypaste: 27.4528,45.0319,28.6860,12.3308,23.0571,40.8460
[08/23 08:18:45 d2.utils.events]:  eta: 0:26:59  iter: 139  total_loss: 1.261  loss_cls: 0.28  loss_box_reg: 0.4466  loss_mask: 0.4584  loss_rpn_cls: 0.02105  loss_rpn_loc: 0.008053  time: 1.8883  data_time: 0.0188  lr: 3.4965e-05  max_mem: 10889M
[08/23 08:19:23 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 08:19:23 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 08:19:23 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 08:19:23 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 08:19:23 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 08:19:33 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0023 s/iter. Inference: 0.2652 s/iter. Eval: 0.6212 s/iter. Total: 0.8887 s/iter. ETA=0:01:58
[08/23 08:19:39 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0024 s/iter. Inference: 0.2671 s/iter. Eval: 0.6689 s/iter. Total: 0.9387 s/iter. ETA=0:01:59
[08/23 08:19:45 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0026 s/iter. Inference: 0.2663 s/iter. Eval: 0.6487 s/iter. Total: 0.9179 s/iter. ETA=0:01:51
[08/23 08:19:50 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0026 s/iter. Inference: 0.2661 s/iter. Eval: 0.6473 s/iter. Total: 0.9163 s/iter. ETA=0:01:45
[08/23 08:19:55 d2.evaluation.evaluator]: Inference done 35/144. Dataloading: 0.0026 s/iter. Inference: 0.2660 s/iter. Eval: 0.6390 s/iter. Total: 0.9079 s/iter. ETA=0:01:38
[08/23 08:20:01 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0028 s/iter. Inference: 0.2659 s/iter. Eval: 0.6391 s/iter. Total: 0.9081 s/iter. ETA=0:01:33
[08/23 08:20:06 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0027 s/iter. Inference: 0.2658 s/iter. Eval: 0.6349 s/iter. Total: 0.9038 s/iter. ETA=0:01:27
[08/23 08:20:12 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0027 s/iter. Inference: 0.2662 s/iter. Eval: 0.6421 s/iter. Total: 0.9113 s/iter. ETA=0:01:22
[08/23 08:20:17 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0027 s/iter. Inference: 0.2665 s/iter. Eval: 0.6441 s/iter. Total: 0.9136 s/iter. ETA=0:01:17
[08/23 08:20:23 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0027 s/iter. Inference: 0.2663 s/iter. Eval: 0.6444 s/iter. Total: 0.9138 s/iter. ETA=0:01:12
[08/23 08:20:28 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0026 s/iter. Inference: 0.2663 s/iter. Eval: 0.6423 s/iter. Total: 0.9116 s/iter. ETA=0:01:06
[08/23 08:20:34 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0027 s/iter. Inference: 0.2663 s/iter. Eval: 0.6421 s/iter. Total: 0.9114 s/iter. ETA=0:01:01
[08/23 08:20:39 d2.evaluation.evaluator]: Inference done 83/144. Dataloading: 0.0028 s/iter. Inference: 0.2662 s/iter. Eval: 0.6402 s/iter. Total: 0.9095 s/iter. ETA=0:00:55
[08/23 08:20:45 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0028 s/iter. Inference: 0.2665 s/iter. Eval: 0.6442 s/iter. Total: 0.9139 s/iter. ETA=0:00:50
[08/23 08:20:50 d2.evaluation.evaluator]: Inference done 95/144. Dataloading: 0.0028 s/iter. Inference: 0.2665 s/iter. Eval: 0.6417 s/iter. Total: 0.9113 s/iter. ETA=0:00:44
[08/23 08:20:55 d2.evaluation.evaluator]: Inference done 101/144. Dataloading: 0.0028 s/iter. Inference: 0.2667 s/iter. Eval: 0.6408 s/iter. Total: 0.9106 s/iter. ETA=0:00:39
[08/23 08:21:01 d2.evaluation.evaluator]: Inference done 107/144. Dataloading: 0.0028 s/iter. Inference: 0.2666 s/iter. Eval: 0.6381 s/iter. Total: 0.9079 s/iter. ETA=0:00:33
[08/23 08:21:06 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0028 s/iter. Inference: 0.2665 s/iter. Eval: 0.6386 s/iter. Total: 0.9083 s/iter. ETA=0:00:28
[08/23 08:21:11 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0028 s/iter. Inference: 0.2664 s/iter. Eval: 0.6372 s/iter. Total: 0.9067 s/iter. ETA=0:00:22
[08/23 08:21:17 d2.evaluation.evaluator]: Inference done 125/144. Dataloading: 0.0028 s/iter. Inference: 0.2664 s/iter. Eval: 0.6382 s/iter. Total: 0.9077 s/iter. ETA=0:00:17
[08/23 08:21:23 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0028 s/iter. Inference: 0.2665 s/iter. Eval: 0.6394 s/iter. Total: 0.9090 s/iter. ETA=0:00:11
[08/23 08:21:28 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0027 s/iter. Inference: 0.2664 s/iter. Eval: 0.6397 s/iter. Total: 0.9093 s/iter. ETA=0:00:06
[08/23 08:21:33 d2.evaluation.evaluator]: Inference done 143/144. Dataloading: 0.0028 s/iter. Inference: 0.2663 s/iter. Eval: 0.6385 s/iter. Total: 0.9080 s/iter. ETA=0:00:00
[08/23 08:21:34 d2.evaluation.evaluator]: Total inference time: 0:02:06.261048 (0.908353 s / iter per device, on 1 devices)
[08/23 08:21:34 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:37 (0.266327 s / iter per device, on 1 devices)
[08/23 08:21:34 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 08:21:34 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 08:21:35 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[08/23 08:21:35 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 08:21:35 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.12 seconds.
[08/23 08:21:35 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:21:35 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.265
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.480
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.237
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.293
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.296
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.241
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.480
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.576
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.192
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.577
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.642
[08/23 08:21:35 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 26.497 | 48.004 | 23.734 | 11.978 | 29.273 | 29.626 |
Loading and preparing results...
DONE (t=0.31s)
creating index...
index created!
[08/23 08:21:36 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 08:21:36 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.21 seconds.
[08/23 08:21:36 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:21:36 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.313
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.499
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.346
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.136
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.263
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.464
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.270
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.545
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.672
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.242
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.663
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.767
[08/23 08:21:36 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 31.324 | 49.890 | 34.569 | 13.626 | 26.270 | 46.389 |
[08/23 08:21:36 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 08:21:36 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 08:21:36 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:21:36 d2.evaluation.testing]: copypaste: 26.4966,48.0042,23.7337,11.9779,29.2733,29.6260
[08/23 08:21:36 d2.evaluation.testing]: copypaste: Task: segm
[08/23 08:21:36 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:21:36 d2.evaluation.testing]: copypaste: 31.3238,49.8896,34.5690,13.6257,26.2696,46.3885
[08/23 08:21:36 d2.utils.events]:  eta: 0:26:21  iter: 159  total_loss: 1.186  loss_cls: 0.2548  loss_box_reg: 0.4342  loss_mask: 0.4245  loss_rpn_cls: 0.01966  loss_rpn_loc: 0.008842  time: 1.8882  data_time: 0.0245  lr: 3.996e-05  max_mem: 10889M
[08/23 08:22:14 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 08:22:14 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 08:22:14 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 08:22:14 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 08:22:14 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 08:22:24 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0019 s/iter. Inference: 0.2707 s/iter. Eval: 0.7065 s/iter. Total: 0.9792 s/iter. ETA=0:02:10
[08/23 08:22:30 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0022 s/iter. Inference: 0.2669 s/iter. Eval: 0.6433 s/iter. Total: 0.9127 s/iter. ETA=0:01:55
[08/23 08:22:35 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0023 s/iter. Inference: 0.2663 s/iter. Eval: 0.6465 s/iter. Total: 0.9154 s/iter. ETA=0:01:50
[08/23 08:22:40 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0024 s/iter. Inference: 0.2662 s/iter. Eval: 0.6380 s/iter. Total: 0.9068 s/iter. ETA=0:01:44
[08/23 08:22:46 d2.evaluation.evaluator]: Inference done 35/144. Dataloading: 0.0026 s/iter. Inference: 0.2660 s/iter. Eval: 0.6406 s/iter. Total: 0.9094 s/iter. ETA=0:01:39
[08/23 08:22:51 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0025 s/iter. Inference: 0.2658 s/iter. Eval: 0.6361 s/iter. Total: 0.9047 s/iter. ETA=0:01:33
[08/23 08:22:57 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0025 s/iter. Inference: 0.2662 s/iter. Eval: 0.6376 s/iter. Total: 0.9065 s/iter. ETA=0:01:27
[08/23 08:23:02 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0025 s/iter. Inference: 0.2664 s/iter. Eval: 0.6402 s/iter. Total: 0.9094 s/iter. ETA=0:01:22
[08/23 08:23:08 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0025 s/iter. Inference: 0.2663 s/iter. Eval: 0.6414 s/iter. Total: 0.9105 s/iter. ETA=0:01:17
[08/23 08:23:13 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0025 s/iter. Inference: 0.2662 s/iter. Eval: 0.6386 s/iter. Total: 0.9076 s/iter. ETA=0:01:11
[08/23 08:23:18 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0026 s/iter. Inference: 0.2662 s/iter. Eval: 0.6385 s/iter. Total: 0.9076 s/iter. ETA=0:01:06
[08/23 08:23:24 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0026 s/iter. Inference: 0.2661 s/iter. Eval: 0.6364 s/iter. Total: 0.9054 s/iter. ETA=0:01:00
[08/23 08:23:29 d2.evaluation.evaluator]: Inference done 83/144. Dataloading: 0.0025 s/iter. Inference: 0.2664 s/iter. Eval: 0.6366 s/iter. Total: 0.9058 s/iter. ETA=0:00:55
[08/23 08:23:35 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0026 s/iter. Inference: 0.2667 s/iter. Eval: 0.6389 s/iter. Total: 0.9084 s/iter. ETA=0:00:49
[08/23 08:23:40 d2.evaluation.evaluator]: Inference done 95/144. Dataloading: 0.0026 s/iter. Inference: 0.2669 s/iter. Eval: 0.6384 s/iter. Total: 0.9082 s/iter. ETA=0:00:44
[08/23 08:23:46 d2.evaluation.evaluator]: Inference done 101/144. Dataloading: 0.0026 s/iter. Inference: 0.2668 s/iter. Eval: 0.6400 s/iter. Total: 0.9098 s/iter. ETA=0:00:39
[08/23 08:23:51 d2.evaluation.evaluator]: Inference done 107/144. Dataloading: 0.0026 s/iter. Inference: 0.2666 s/iter. Eval: 0.6367 s/iter. Total: 0.9062 s/iter. ETA=0:00:33
[08/23 08:23:56 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0026 s/iter. Inference: 0.2665 s/iter. Eval: 0.6359 s/iter. Total: 0.9053 s/iter. ETA=0:00:28
[08/23 08:24:02 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0026 s/iter. Inference: 0.2665 s/iter. Eval: 0.6341 s/iter. Total: 0.9035 s/iter. ETA=0:00:22
[08/23 08:24:07 d2.evaluation.evaluator]: Inference done 125/144. Dataloading: 0.0027 s/iter. Inference: 0.2666 s/iter. Eval: 0.6357 s/iter. Total: 0.9053 s/iter. ETA=0:00:17
[08/23 08:24:12 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0027 s/iter. Inference: 0.2667 s/iter. Eval: 0.6343 s/iter. Total: 0.9040 s/iter. ETA=0:00:11
[08/23 08:24:18 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0027 s/iter. Inference: 0.2665 s/iter. Eval: 0.6324 s/iter. Total: 0.9019 s/iter. ETA=0:00:06
[08/23 08:24:23 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0027 s/iter. Inference: 0.2662 s/iter. Eval: 0.6288 s/iter. Total: 0.8979 s/iter. ETA=0:00:00
[08/23 08:24:23 d2.evaluation.evaluator]: Total inference time: 0:02:04.888959 (0.898482 s / iter per device, on 1 devices)
[08/23 08:24:23 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:36 (0.266156 s / iter per device, on 1 devices)
[08/23 08:24:24 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 08:24:24 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 08:24:24 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[08/23 08:24:24 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 08:24:24 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.12 seconds.
[08/23 08:24:24 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:24:24 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.287
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.519
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.253
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.103
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.303
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.331
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.254
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.477
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.564
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.183
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.563
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.635
[08/23 08:24:24 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 28.684 | 51.898 | 25.324 | 10.293 | 30.301 | 33.068 |
Loading and preparing results...
DONE (t=0.29s)
creating index...
index created!
[08/23 08:24:25 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 08:24:25 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.21 seconds.
[08/23 08:24:25 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:24:25 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.338
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.531
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.373
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.129
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.280
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.494
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.283
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.550
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.674
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.292
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.661
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.765
[08/23 08:24:25 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 33.760 | 53.062 | 37.253 | 12.871 | 27.989 | 49.422 |
[08/23 08:24:25 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 08:24:25 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 08:24:25 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:24:25 d2.evaluation.testing]: copypaste: 28.6836,51.8985,25.3242,10.2931,30.3006,33.0678
[08/23 08:24:25 d2.evaluation.testing]: copypaste: Task: segm
[08/23 08:24:25 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:24:25 d2.evaluation.testing]: copypaste: 33.7602,53.0616,37.2529,12.8708,27.9892,49.4224
[08/23 08:24:25 d2.utils.events]:  eta: 0:25:43  iter: 179  total_loss: 1.088  loss_cls: 0.2415  loss_box_reg: 0.3905  loss_mask: 0.362  loss_rpn_cls: 0.01994  loss_rpn_loc: 0.01132  time: 1.8875  data_time: 0.0245  lr: 4.4955e-05  max_mem: 10889M
[08/23 08:25:03 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 08:25:03 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 08:25:03 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 08:25:03 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 08:25:03 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 08:25:14 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0021 s/iter. Inference: 0.2686 s/iter. Eval: 0.6673 s/iter. Total: 0.9380 s/iter. ETA=0:02:04
[08/23 08:25:19 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0024 s/iter. Inference: 0.2661 s/iter. Eval: 0.6249 s/iter. Total: 0.8936 s/iter. ETA=0:01:53
[08/23 08:25:24 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0025 s/iter. Inference: 0.2647 s/iter. Eval: 0.6085 s/iter. Total: 0.8759 s/iter. ETA=0:01:45
[08/23 08:25:29 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0024 s/iter. Inference: 0.2648 s/iter. Eval: 0.6085 s/iter. Total: 0.8760 s/iter. ETA=0:01:40
[08/23 08:25:35 d2.evaluation.evaluator]: Inference done 35/144. Dataloading: 0.0025 s/iter. Inference: 0.2646 s/iter. Eval: 0.6078 s/iter. Total: 0.8751 s/iter. ETA=0:01:35
[08/23 08:25:40 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0025 s/iter. Inference: 0.2643 s/iter. Eval: 0.6139 s/iter. Total: 0.8810 s/iter. ETA=0:01:30
[08/23 08:25:46 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0025 s/iter. Inference: 0.2653 s/iter. Eval: 0.6217 s/iter. Total: 0.8898 s/iter. ETA=0:01:26
[08/23 08:25:51 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0025 s/iter. Inference: 0.2654 s/iter. Eval: 0.6240 s/iter. Total: 0.8921 s/iter. ETA=0:01:21
[08/23 08:25:56 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0025 s/iter. Inference: 0.2652 s/iter. Eval: 0.6216 s/iter. Total: 0.8896 s/iter. ETA=0:01:15
[08/23 08:26:02 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0025 s/iter. Inference: 0.2652 s/iter. Eval: 0.6221 s/iter. Total: 0.8900 s/iter. ETA=0:01:10
[08/23 08:26:07 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0025 s/iter. Inference: 0.2656 s/iter. Eval: 0.6215 s/iter. Total: 0.8898 s/iter. ETA=0:01:04
[08/23 08:26:12 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0025 s/iter. Inference: 0.2654 s/iter. Eval: 0.6207 s/iter. Total: 0.8889 s/iter. ETA=0:00:59
[08/23 08:26:18 d2.evaluation.evaluator]: Inference done 83/144. Dataloading: 0.0025 s/iter. Inference: 0.2658 s/iter. Eval: 0.6251 s/iter. Total: 0.8937 s/iter. ETA=0:00:54
[08/23 08:26:23 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0025 s/iter. Inference: 0.2657 s/iter. Eval: 0.6240 s/iter. Total: 0.8924 s/iter. ETA=0:00:49
[08/23 08:26:29 d2.evaluation.evaluator]: Inference done 95/144. Dataloading: 0.0025 s/iter. Inference: 0.2656 s/iter. Eval: 0.6237 s/iter. Total: 0.8921 s/iter. ETA=0:00:43
[08/23 08:26:34 d2.evaluation.evaluator]: Inference done 101/144. Dataloading: 0.0025 s/iter. Inference: 0.2654 s/iter. Eval: 0.6206 s/iter. Total: 0.8888 s/iter. ETA=0:00:38
[08/23 08:26:39 d2.evaluation.evaluator]: Inference done 108/144. Dataloading: 0.0025 s/iter. Inference: 0.2653 s/iter. Eval: 0.6169 s/iter. Total: 0.8850 s/iter. ETA=0:00:31
[08/23 08:26:45 d2.evaluation.evaluator]: Inference done 114/144. Dataloading: 0.0025 s/iter. Inference: 0.2653 s/iter. Eval: 0.6175 s/iter. Total: 0.8856 s/iter. ETA=0:00:26
[08/23 08:26:50 d2.evaluation.evaluator]: Inference done 120/144. Dataloading: 0.0026 s/iter. Inference: 0.2653 s/iter. Eval: 0.6176 s/iter. Total: 0.8858 s/iter. ETA=0:00:21
[08/23 08:26:55 d2.evaluation.evaluator]: Inference done 126/144. Dataloading: 0.0026 s/iter. Inference: 0.2652 s/iter. Eval: 0.6171 s/iter. Total: 0.8853 s/iter. ETA=0:00:15
[08/23 08:27:01 d2.evaluation.evaluator]: Inference done 133/144. Dataloading: 0.0026 s/iter. Inference: 0.2649 s/iter. Eval: 0.6125 s/iter. Total: 0.8802 s/iter. ETA=0:00:09
[08/23 08:27:06 d2.evaluation.evaluator]: Inference done 140/144. Dataloading: 0.0026 s/iter. Inference: 0.2642 s/iter. Eval: 0.6055 s/iter. Total: 0.8727 s/iter. ETA=0:00:03
[08/23 08:27:10 d2.evaluation.evaluator]: Total inference time: 0:02:01.593945 (0.874777 s / iter per device, on 1 devices)
[08/23 08:27:10 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:36 (0.264254 s / iter per device, on 1 devices)
[08/23 08:27:10 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 08:27:10 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 08:27:10 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[08/23 08:27:10 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 08:27:11 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.35 seconds.
[08/23 08:27:11 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:27:11 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.310
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.558
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.273
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.121
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.318
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.372
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.260
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.499
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.575
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.558
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.673
[08/23 08:27:11 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 31.036 | 55.783 | 27.290 | 12.077 | 31.817 | 37.205 |
Loading and preparing results...
DONE (t=0.29s)
creating index...
index created!
[08/23 08:27:11 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 08:27:12 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.20 seconds.
[08/23 08:27:12 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:27:12 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.362
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.572
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.403
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.124
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.305
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.520
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.285
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.563
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.673
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.292
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.657
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.768
[08/23 08:27:12 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 36.240 | 57.189 | 40.326 | 12.427 | 30.484 | 52.012 |
[08/23 08:27:12 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 08:27:12 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 08:27:12 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:27:12 d2.evaluation.testing]: copypaste: 31.0363,55.7832,27.2900,12.0775,31.8169,37.2047
[08/23 08:27:12 d2.evaluation.testing]: copypaste: Task: segm
[08/23 08:27:12 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:27:12 d2.evaluation.testing]: copypaste: 36.2402,57.1893,40.3261,12.4271,30.4840,52.0120
[08/23 08:27:12 d2.utils.events]:  eta: 0:25:06  iter: 199  total_loss: 1.058  loss_cls: 0.226  loss_box_reg: 0.4968  loss_mask: 0.3046  loss_rpn_cls: 0.01055  loss_rpn_loc: 0.004323  time: 1.8890  data_time: 0.0260  lr: 4.995e-05  max_mem: 10889M
[08/23 08:27:50 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 08:27:50 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 08:27:50 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 08:27:50 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 08:27:50 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 08:28:00 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0021 s/iter. Inference: 0.2648 s/iter. Eval: 0.5987 s/iter. Total: 0.8656 s/iter. ETA=0:01:55
[08/23 08:28:06 d2.evaluation.evaluator]: Inference done 18/144. Dataloading: 0.0023 s/iter. Inference: 0.2599 s/iter. Eval: 0.5691 s/iter. Total: 0.8316 s/iter. ETA=0:01:44
[08/23 08:28:11 d2.evaluation.evaluator]: Inference done 25/144. Dataloading: 0.0023 s/iter. Inference: 0.2569 s/iter. Eval: 0.5316 s/iter. Total: 0.7911 s/iter. ETA=0:01:34
[08/23 08:28:17 d2.evaluation.evaluator]: Inference done 32/144. Dataloading: 0.0024 s/iter. Inference: 0.2576 s/iter. Eval: 0.5398 s/iter. Total: 0.8001 s/iter. ETA=0:01:29
[08/23 08:28:22 d2.evaluation.evaluator]: Inference done 38/144. Dataloading: 0.0024 s/iter. Inference: 0.2584 s/iter. Eval: 0.5477 s/iter. Total: 0.8087 s/iter. ETA=0:01:25
[08/23 08:28:27 d2.evaluation.evaluator]: Inference done 44/144. Dataloading: 0.0024 s/iter. Inference: 0.2600 s/iter. Eval: 0.5623 s/iter. Total: 0.8249 s/iter. ETA=0:01:22
[08/23 08:28:33 d2.evaluation.evaluator]: Inference done 50/144. Dataloading: 0.0024 s/iter. Inference: 0.2612 s/iter. Eval: 0.5694 s/iter. Total: 0.8333 s/iter. ETA=0:01:18
[08/23 08:28:38 d2.evaluation.evaluator]: Inference done 56/144. Dataloading: 0.0024 s/iter. Inference: 0.2614 s/iter. Eval: 0.5731 s/iter. Total: 0.8373 s/iter. ETA=0:01:13
[08/23 08:28:43 d2.evaluation.evaluator]: Inference done 62/144. Dataloading: 0.0024 s/iter. Inference: 0.2618 s/iter. Eval: 0.5767 s/iter. Total: 0.8413 s/iter. ETA=0:01:08
[08/23 08:28:48 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0024 s/iter. Inference: 0.2627 s/iter. Eval: 0.5821 s/iter. Total: 0.8475 s/iter. ETA=0:01:04
[08/23 08:28:54 d2.evaluation.evaluator]: Inference done 75/144. Dataloading: 0.0024 s/iter. Inference: 0.2623 s/iter. Eval: 0.5778 s/iter. Total: 0.8428 s/iter. ETA=0:00:58
[08/23 08:28:59 d2.evaluation.evaluator]: Inference done 81/144. Dataloading: 0.0024 s/iter. Inference: 0.2623 s/iter. Eval: 0.5791 s/iter. Total: 0.8441 s/iter. ETA=0:00:53
[08/23 08:29:05 d2.evaluation.evaluator]: Inference done 88/144. Dataloading: 0.0025 s/iter. Inference: 0.2622 s/iter. Eval: 0.5787 s/iter. Total: 0.8437 s/iter. ETA=0:00:47
[08/23 08:29:10 d2.evaluation.evaluator]: Inference done 94/144. Dataloading: 0.0026 s/iter. Inference: 0.2622 s/iter. Eval: 0.5795 s/iter. Total: 0.8447 s/iter. ETA=0:00:42
[08/23 08:29:16 d2.evaluation.evaluator]: Inference done 101/144. Dataloading: 0.0026 s/iter. Inference: 0.2617 s/iter. Eval: 0.5740 s/iter. Total: 0.8386 s/iter. ETA=0:00:36
[08/23 08:29:21 d2.evaluation.evaluator]: Inference done 108/144. Dataloading: 0.0026 s/iter. Inference: 0.2615 s/iter. Eval: 0.5724 s/iter. Total: 0.8368 s/iter. ETA=0:00:30
[08/23 08:29:26 d2.evaluation.evaluator]: Inference done 114/144. Dataloading: 0.0026 s/iter. Inference: 0.2616 s/iter. Eval: 0.5737 s/iter. Total: 0.8382 s/iter. ETA=0:00:25
[08/23 08:29:32 d2.evaluation.evaluator]: Inference done 121/144. Dataloading: 0.0026 s/iter. Inference: 0.2612 s/iter. Eval: 0.5691 s/iter. Total: 0.8332 s/iter. ETA=0:00:19
[08/23 08:29:37 d2.evaluation.evaluator]: Inference done 127/144. Dataloading: 0.0027 s/iter. Inference: 0.2615 s/iter. Eval: 0.5720 s/iter. Total: 0.8365 s/iter. ETA=0:00:14
[08/23 08:29:42 d2.evaluation.evaluator]: Inference done 134/144. Dataloading: 0.0027 s/iter. Inference: 0.2611 s/iter. Eval: 0.5680 s/iter. Total: 0.8321 s/iter. ETA=0:00:08
[08/23 08:29:48 d2.evaluation.evaluator]: Inference done 142/144. Dataloading: 0.0027 s/iter. Inference: 0.2605 s/iter. Eval: 0.5615 s/iter. Total: 0.8250 s/iter. ETA=0:00:01
[08/23 08:29:50 d2.evaluation.evaluator]: Total inference time: 0:01:54.853697 (0.826286 s / iter per device, on 1 devices)
[08/23 08:29:50 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:36 (0.260560 s / iter per device, on 1 devices)
[08/23 08:29:50 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 08:29:50 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 08:29:50 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/23 08:29:50 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 08:29:50 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[08/23 08:29:50 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:29:50 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.329
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.571
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.307
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.117
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.340
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.385
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.264
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.509
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.591
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.175
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.583
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.680
[08/23 08:29:50 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 32.894 | 57.120 | 30.659 | 11.710 | 33.998 | 38.477 |
Loading and preparing results...
DONE (t=0.26s)
creating index...
index created!
[08/23 08:29:51 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 08:29:52 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.19 seconds.
[08/23 08:29:52 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:29:52 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.383
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.592
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.453
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.124
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.326
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.538
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.293
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.572
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.673
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.267
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.651
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.785
[08/23 08:29:52 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 38.321 | 59.234 | 45.347 | 12.376 | 32.632 | 53.808 |
[08/23 08:29:52 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 08:29:52 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 08:29:52 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:29:52 d2.evaluation.testing]: copypaste: 32.8937,57.1195,30.6594,11.7104,33.9979,38.4771
[08/23 08:29:52 d2.evaluation.testing]: copypaste: Task: segm
[08/23 08:29:52 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:29:52 d2.evaluation.testing]: copypaste: 38.3214,59.2343,45.3467,12.3763,32.6320,53.8076
[08/23 08:29:52 d2.utils.events]:  eta: 0:24:28  iter: 219  total_loss: 0.9132  loss_cls: 0.1951  loss_box_reg: 0.3697  loss_mask: 0.3085  loss_rpn_cls: 0.009033  loss_rpn_loc: 0.006575  time: 1.8888  data_time: 0.0232  lr: 5.4945e-05  max_mem: 10889M
[08/23 08:30:30 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 08:30:30 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 08:30:30 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 08:30:30 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 08:30:30 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 08:30:40 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0032 s/iter. Inference: 0.2672 s/iter. Eval: 0.6092 s/iter. Total: 0.8797 s/iter. ETA=0:01:56
[08/23 08:30:46 d2.evaluation.evaluator]: Inference done 18/144. Dataloading: 0.0031 s/iter. Inference: 0.2599 s/iter. Eval: 0.5639 s/iter. Total: 0.8272 s/iter. ETA=0:01:44
[08/23 08:30:51 d2.evaluation.evaluator]: Inference done 26/144. Dataloading: 0.0029 s/iter. Inference: 0.2553 s/iter. Eval: 0.5157 s/iter. Total: 0.7743 s/iter. ETA=0:01:31
[08/23 08:30:56 d2.evaluation.evaluator]: Inference done 33/144. Dataloading: 0.0028 s/iter. Inference: 0.2552 s/iter. Eval: 0.5138 s/iter. Total: 0.7720 s/iter. ETA=0:01:25
[08/23 08:31:02 d2.evaluation.evaluator]: Inference done 40/144. Dataloading: 0.0029 s/iter. Inference: 0.2553 s/iter. Eval: 0.5186 s/iter. Total: 0.7771 s/iter. ETA=0:01:20
[08/23 08:31:07 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0029 s/iter. Inference: 0.2564 s/iter. Eval: 0.5286 s/iter. Total: 0.7881 s/iter. ETA=0:01:17
[08/23 08:31:13 d2.evaluation.evaluator]: Inference done 52/144. Dataloading: 0.0028 s/iter. Inference: 0.2575 s/iter. Eval: 0.5443 s/iter. Total: 0.8049 s/iter. ETA=0:01:14
[08/23 08:31:18 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0030 s/iter. Inference: 0.2587 s/iter. Eval: 0.5518 s/iter. Total: 0.8139 s/iter. ETA=0:01:09
[08/23 08:31:23 d2.evaluation.evaluator]: Inference done 64/144. Dataloading: 0.0030 s/iter. Inference: 0.2596 s/iter. Eval: 0.5592 s/iter. Total: 0.8221 s/iter. ETA=0:01:05
[08/23 08:31:29 d2.evaluation.evaluator]: Inference done 70/144. Dataloading: 0.0029 s/iter. Inference: 0.2602 s/iter. Eval: 0.5632 s/iter. Total: 0.8266 s/iter. ETA=0:01:01
[08/23 08:31:34 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0029 s/iter. Inference: 0.2592 s/iter. Eval: 0.5549 s/iter. Total: 0.8173 s/iter. ETA=0:00:54
[08/23 08:31:39 d2.evaluation.evaluator]: Inference done 85/144. Dataloading: 0.0028 s/iter. Inference: 0.2582 s/iter. Eval: 0.5439 s/iter. Total: 0.8052 s/iter. ETA=0:00:47
[08/23 08:31:45 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0028 s/iter. Inference: 0.2582 s/iter. Eval: 0.5441 s/iter. Total: 0.8054 s/iter. ETA=0:00:41
[08/23 08:31:50 d2.evaluation.evaluator]: Inference done 100/144. Dataloading: 0.0029 s/iter. Inference: 0.2575 s/iter. Eval: 0.5328 s/iter. Total: 0.7935 s/iter. ETA=0:00:34
[08/23 08:31:55 d2.evaluation.evaluator]: Inference done 107/144. Dataloading: 0.0029 s/iter. Inference: 0.2575 s/iter. Eval: 0.5295 s/iter. Total: 0.7902 s/iter. ETA=0:00:29
[08/23 08:32:01 d2.evaluation.evaluator]: Inference done 114/144. Dataloading: 0.0029 s/iter. Inference: 0.2573 s/iter. Eval: 0.5267 s/iter. Total: 0.7872 s/iter. ETA=0:00:23
[08/23 08:32:06 d2.evaluation.evaluator]: Inference done 122/144. Dataloading: 0.0029 s/iter. Inference: 0.2567 s/iter. Eval: 0.5203 s/iter. Total: 0.7802 s/iter. ETA=0:00:17
[08/23 08:32:11 d2.evaluation.evaluator]: Inference done 129/144. Dataloading: 0.0029 s/iter. Inference: 0.2566 s/iter. Eval: 0.5188 s/iter. Total: 0.7785 s/iter. ETA=0:00:11
[08/23 08:32:16 d2.evaluation.evaluator]: Inference done 136/144. Dataloading: 0.0029 s/iter. Inference: 0.2561 s/iter. Eval: 0.5161 s/iter. Total: 0.7754 s/iter. ETA=0:00:06
[08/23 08:32:22 d2.evaluation.evaluator]: Inference done 143/144. Dataloading: 0.0029 s/iter. Inference: 0.2559 s/iter. Eval: 0.5154 s/iter. Total: 0.7744 s/iter. ETA=0:00:00
[08/23 08:32:23 d2.evaluation.evaluator]: Total inference time: 0:01:47.864118 (0.776001 s / iter per device, on 1 devices)
[08/23 08:32:23 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:35 (0.255957 s / iter per device, on 1 devices)
[08/23 08:32:23 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 08:32:23 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 08:32:23 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/23 08:32:23 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 08:32:23 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.
[08/23 08:32:23 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:32:23 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.352
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.592
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.378
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.117
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.360
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.418
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.282
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.510
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.584
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.192
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.570
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.680
[08/23 08:32:23 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 35.153 | 59.165 | 37.805 | 11.735 | 35.955 | 41.813 |
Loading and preparing results...
DONE (t=0.24s)
creating index...
index created!
[08/23 08:32:24 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 08:32:24 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.18 seconds.
[08/23 08:32:24 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:32:24 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.399
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.612
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.476
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.137
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.337
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.562
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.308
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.570
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.669
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.647
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.773
[08/23 08:32:24 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 39.868 | 61.245 | 47.635 | 13.736 | 33.713 | 56.183 |
[08/23 08:32:24 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 08:32:24 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 08:32:24 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:32:24 d2.evaluation.testing]: copypaste: 35.1533,59.1650,37.8050,11.7347,35.9551,41.8132
[08/23 08:32:24 d2.evaluation.testing]: copypaste: Task: segm
[08/23 08:32:24 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:32:24 d2.evaluation.testing]: copypaste: 39.8684,61.2454,47.6350,13.7355,33.7126,56.1825
[08/23 08:32:24 d2.utils.events]:  eta: 0:23:50  iter: 239  total_loss: 0.862  loss_cls: 0.1798  loss_box_reg: 0.3581  loss_mask: 0.2772  loss_rpn_cls: 0.01833  loss_rpn_loc: 0.006164  time: 1.8904  data_time: 0.0241  lr: 5.994e-05  max_mem: 10889M
[08/23 08:33:02 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 08:33:02 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 08:33:02 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 08:33:02 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 08:33:02 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 08:33:12 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0020 s/iter. Inference: 0.2633 s/iter. Eval: 0.5819 s/iter. Total: 0.8471 s/iter. ETA=0:01:52
[08/23 08:33:17 d2.evaluation.evaluator]: Inference done 19/144. Dataloading: 0.0022 s/iter. Inference: 0.2524 s/iter. Eval: 0.4693 s/iter. Total: 0.7242 s/iter. ETA=0:01:30
[08/23 08:33:23 d2.evaluation.evaluator]: Inference done 27/144. Dataloading: 0.0024 s/iter. Inference: 0.2498 s/iter. Eval: 0.4562 s/iter. Total: 0.7086 s/iter. ETA=0:01:22
[08/23 08:33:28 d2.evaluation.evaluator]: Inference done 34/144. Dataloading: 0.0025 s/iter. Inference: 0.2508 s/iter. Eval: 0.4643 s/iter. Total: 0.7179 s/iter. ETA=0:01:18
[08/23 08:33:33 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0026 s/iter. Inference: 0.2512 s/iter. Eval: 0.4790 s/iter. Total: 0.7330 s/iter. ETA=0:01:15
[08/23 08:33:38 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0026 s/iter. Inference: 0.2527 s/iter. Eval: 0.4921 s/iter. Total: 0.7477 s/iter. ETA=0:01:12
[08/23 08:33:44 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0026 s/iter. Inference: 0.2542 s/iter. Eval: 0.5105 s/iter. Total: 0.7676 s/iter. ETA=0:01:09
[08/23 08:33:50 d2.evaluation.evaluator]: Inference done 60/144. Dataloading: 0.0026 s/iter. Inference: 0.2550 s/iter. Eval: 0.5166 s/iter. Total: 0.7746 s/iter. ETA=0:01:05
[08/23 08:33:55 d2.evaluation.evaluator]: Inference done 66/144. Dataloading: 0.0026 s/iter. Inference: 0.2555 s/iter. Eval: 0.5233 s/iter. Total: 0.7817 s/iter. ETA=0:01:00
[08/23 08:34:00 d2.evaluation.evaluator]: Inference done 73/144. Dataloading: 0.0026 s/iter. Inference: 0.2555 s/iter. Eval: 0.5208 s/iter. Total: 0.7794 s/iter. ETA=0:00:55
[08/23 08:34:05 d2.evaluation.evaluator]: Inference done 80/144. Dataloading: 0.0027 s/iter. Inference: 0.2553 s/iter. Eval: 0.5201 s/iter. Total: 0.7785 s/iter. ETA=0:00:49
[08/23 08:34:11 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0028 s/iter. Inference: 0.2543 s/iter. Eval: 0.5037 s/iter. Total: 0.7611 s/iter. ETA=0:00:41
[08/23 08:34:16 d2.evaluation.evaluator]: Inference done 98/144. Dataloading: 0.0027 s/iter. Inference: 0.2527 s/iter. Eval: 0.4866 s/iter. Total: 0.7425 s/iter. ETA=0:00:34
[08/23 08:34:21 d2.evaluation.evaluator]: Inference done 105/144. Dataloading: 0.0028 s/iter. Inference: 0.2530 s/iter. Eval: 0.4875 s/iter. Total: 0.7437 s/iter. ETA=0:00:29
[08/23 08:34:27 d2.evaluation.evaluator]: Inference done 112/144. Dataloading: 0.0028 s/iter. Inference: 0.2528 s/iter. Eval: 0.4875 s/iter. Total: 0.7434 s/iter. ETA=0:00:23
[08/23 08:34:32 d2.evaluation.evaluator]: Inference done 121/144. Dataloading: 0.0028 s/iter. Inference: 0.2518 s/iter. Eval: 0.4746 s/iter. Total: 0.7295 s/iter. ETA=0:00:16
[08/23 08:34:37 d2.evaluation.evaluator]: Inference done 128/144. Dataloading: 0.0028 s/iter. Inference: 0.2516 s/iter. Eval: 0.4740 s/iter. Total: 0.7287 s/iter. ETA=0:00:11
[08/23 08:34:42 d2.evaluation.evaluator]: Inference done 135/144. Dataloading: 0.0027 s/iter. Inference: 0.2520 s/iter. Eval: 0.4773 s/iter. Total: 0.7324 s/iter. ETA=0:00:06
[08/23 08:34:47 d2.evaluation.evaluator]: Inference done 143/144. Dataloading: 0.0027 s/iter. Inference: 0.2517 s/iter. Eval: 0.4731 s/iter. Total: 0.7279 s/iter. ETA=0:00:00
[08/23 08:34:48 d2.evaluation.evaluator]: Total inference time: 0:01:41.404961 (0.729532 s / iter per device, on 1 devices)
[08/23 08:34:48 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:34 (0.251743 s / iter per device, on 1 devices)
[08/23 08:34:49 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 08:34:49 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 08:34:49 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/23 08:34:49 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 08:34:49 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.
[08/23 08:34:49 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:34:49 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.364
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.611
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.392
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.117
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.364
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.438
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.294
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.527
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.591
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.192
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.572
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.695
[08/23 08:34:49 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 36.354 | 61.051 | 39.217 | 11.700 | 36.387 | 43.846 |
Loading and preparing results...
DONE (t=0.23s)
creating index...
index created!
[08/23 08:34:49 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 08:34:50 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.31 seconds.
[08/23 08:34:50 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:34:50 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.03 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.410
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.624
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.489
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.135
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.353
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.566
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.584
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.673
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.648
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.777
[08/23 08:34:50 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 41.029 | 62.357 | 48.909 | 13.495 | 35.347 | 56.591 |
[08/23 08:34:50 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 08:34:50 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 08:34:50 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:34:50 d2.evaluation.testing]: copypaste: 36.3542,61.0508,39.2175,11.7004,36.3874,43.8463
[08/23 08:34:50 d2.evaluation.testing]: copypaste: Task: segm
[08/23 08:34:50 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:34:50 d2.evaluation.testing]: copypaste: 41.0286,62.3568,48.9091,13.4951,35.3473,56.5906
[08/23 08:34:50 d2.utils.events]:  eta: 0:23:13  iter: 259  total_loss: 0.8212  loss_cls: 0.1644  loss_box_reg: 0.4076  loss_mask: 0.215  loss_rpn_cls: 0.007981  loss_rpn_loc: 0.00384  time: 1.8908  data_time: 0.0249  lr: 6.4935e-05  max_mem: 10889M
[08/23 08:35:28 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 08:35:28 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 08:35:28 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 08:35:28 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 08:35:28 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 08:35:38 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0020 s/iter. Inference: 0.2568 s/iter. Eval: 0.5266 s/iter. Total: 0.7853 s/iter. ETA=0:01:44
[08/23 08:35:43 d2.evaluation.evaluator]: Inference done 20/144. Dataloading: 0.0023 s/iter. Inference: 0.2480 s/iter. Eval: 0.4439 s/iter. Total: 0.6945 s/iter. ETA=0:01:26
[08/23 08:35:48 d2.evaluation.evaluator]: Inference done 28/144. Dataloading: 0.0027 s/iter. Inference: 0.2480 s/iter. Eval: 0.4251 s/iter. Total: 0.6762 s/iter. ETA=0:01:18
[08/23 08:35:54 d2.evaluation.evaluator]: Inference done 36/144. Dataloading: 0.0026 s/iter. Inference: 0.2474 s/iter. Eval: 0.4175 s/iter. Total: 0.6679 s/iter. ETA=0:01:12
[08/23 08:35:59 d2.evaluation.evaluator]: Inference done 43/144. Dataloading: 0.0028 s/iter. Inference: 0.2484 s/iter. Eval: 0.4322 s/iter. Total: 0.6838 s/iter. ETA=0:01:09
[08/23 08:36:05 d2.evaluation.evaluator]: Inference done 50/144. Dataloading: 0.0029 s/iter. Inference: 0.2503 s/iter. Eval: 0.4549 s/iter. Total: 0.7085 s/iter. ETA=0:01:06
[08/23 08:36:10 d2.evaluation.evaluator]: Inference done 56/144. Dataloading: 0.0030 s/iter. Inference: 0.2518 s/iter. Eval: 0.4683 s/iter. Total: 0.7235 s/iter. ETA=0:01:03
[08/23 08:36:15 d2.evaluation.evaluator]: Inference done 63/144. Dataloading: 0.0029 s/iter. Inference: 0.2524 s/iter. Eval: 0.4753 s/iter. Total: 0.7310 s/iter. ETA=0:00:59
[08/23 08:36:21 d2.evaluation.evaluator]: Inference done 69/144. Dataloading: 0.0030 s/iter. Inference: 0.2541 s/iter. Eval: 0.4898 s/iter. Total: 0.7473 s/iter. ETA=0:00:56
[08/23 08:36:26 d2.evaluation.evaluator]: Inference done 78/144. Dataloading: 0.0029 s/iter. Inference: 0.2527 s/iter. Eval: 0.4742 s/iter. Total: 0.7302 s/iter. ETA=0:00:48
[08/23 08:36:32 d2.evaluation.evaluator]: Inference done 88/144. Dataloading: 0.0029 s/iter. Inference: 0.2508 s/iter. Eval: 0.4546 s/iter. Total: 0.7086 s/iter. ETA=0:00:39
[08/23 08:36:37 d2.evaluation.evaluator]: Inference done 99/144. Dataloading: 0.0029 s/iter. Inference: 0.2487 s/iter. Eval: 0.4313 s/iter. Total: 0.6832 s/iter. ETA=0:00:30
[08/23 08:36:43 d2.evaluation.evaluator]: Inference done 107/144. Dataloading: 0.0029 s/iter. Inference: 0.2487 s/iter. Eval: 0.4322 s/iter. Total: 0.6841 s/iter. ETA=0:00:25
[08/23 08:36:48 d2.evaluation.evaluator]: Inference done 115/144. Dataloading: 0.0028 s/iter. Inference: 0.2485 s/iter. Eval: 0.4303 s/iter. Total: 0.6819 s/iter. ETA=0:00:19
[08/23 08:36:53 d2.evaluation.evaluator]: Inference done 124/144. Dataloading: 0.0028 s/iter. Inference: 0.2482 s/iter. Eval: 0.4259 s/iter. Total: 0.6772 s/iter. ETA=0:00:13
[08/23 08:36:59 d2.evaluation.evaluator]: Inference done 133/144. Dataloading: 0.0029 s/iter. Inference: 0.2480 s/iter. Eval: 0.4242 s/iter. Total: 0.6754 s/iter. ETA=0:00:07
[08/23 08:37:05 d2.evaluation.evaluator]: Inference done 142/144. Dataloading: 0.0029 s/iter. Inference: 0.2477 s/iter. Eval: 0.4216 s/iter. Total: 0.6725 s/iter. ETA=0:00:01
[08/23 08:37:07 d2.evaluation.evaluator]: Total inference time: 0:01:33.784066 (0.674706 s / iter per device, on 1 devices)
[08/23 08:37:07 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:34 (0.247794 s / iter per device, on 1 devices)
[08/23 08:37:07 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 08:37:07 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 08:37:07 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/23 08:37:07 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 08:37:07 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.09 seconds.
[08/23 08:37:07 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:37:07 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.375
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.623
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.393
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.378
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.452
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.305
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.525
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.593
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.225
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.570
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.700
[08/23 08:37:07 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 37.484 | 62.332 | 39.296 | 11.991 | 37.772 | 45.237 |
Loading and preparing results...
DONE (t=0.20s)
creating index...
index created!
[08/23 08:37:08 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 08:37:08 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.16 seconds.
[08/23 08:37:08 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:37:08 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.423
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.638
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.507
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.137
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.368
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.577
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.326
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.587
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.676
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.649
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.782
[08/23 08:37:08 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 42.279 | 63.819 | 50.671 | 13.721 | 36.850 | 57.676 |
[08/23 08:37:08 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 08:37:08 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 08:37:08 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:37:08 d2.evaluation.testing]: copypaste: 37.4844,62.3320,39.2956,11.9907,37.7723,45.2366
[08/23 08:37:08 d2.evaluation.testing]: copypaste: Task: segm
[08/23 08:37:08 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:37:08 d2.evaluation.testing]: copypaste: 42.2787,63.8187,50.6713,13.7210,36.8495,57.6757
[08/23 08:37:08 d2.utils.events]:  eta: 0:22:36  iter: 279  total_loss: 0.8358  loss_cls: 0.1543  loss_box_reg: 0.3928  loss_mask: 0.2294  loss_rpn_cls: 0.01225  loss_rpn_loc: 0.008414  time: 1.8919  data_time: 0.0235  lr: 6.993e-05  max_mem: 10889M
[08/23 08:37:46 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 08:37:46 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 08:37:46 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 08:37:46 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 08:37:46 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 08:37:56 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0021 s/iter. Inference: 0.2625 s/iter. Eval: 0.5668 s/iter. Total: 0.8314 s/iter. ETA=0:01:50
[08/23 08:38:01 d2.evaluation.evaluator]: Inference done 20/144. Dataloading: 0.0030 s/iter. Inference: 0.2504 s/iter. Eval: 0.4432 s/iter. Total: 0.6969 s/iter. ETA=0:01:26
[08/23 08:38:07 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0030 s/iter. Inference: 0.2474 s/iter. Eval: 0.4145 s/iter. Total: 0.6651 s/iter. ETA=0:01:16
[08/23 08:38:12 d2.evaluation.evaluator]: Inference done 38/144. Dataloading: 0.0028 s/iter. Inference: 0.2461 s/iter. Eval: 0.3993 s/iter. Total: 0.6485 s/iter. ETA=0:01:08
[08/23 08:38:18 d2.evaluation.evaluator]: Inference done 45/144. Dataloading: 0.0028 s/iter. Inference: 0.2474 s/iter. Eval: 0.4232 s/iter. Total: 0.6736 s/iter. ETA=0:01:06
[08/23 08:38:23 d2.evaluation.evaluator]: Inference done 51/144. Dataloading: 0.0028 s/iter. Inference: 0.2499 s/iter. Eval: 0.4514 s/iter. Total: 0.7043 s/iter. ETA=0:01:05
[08/23 08:38:28 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0028 s/iter. Inference: 0.2512 s/iter. Eval: 0.4677 s/iter. Total: 0.7219 s/iter. ETA=0:01:02
[08/23 08:38:34 d2.evaluation.evaluator]: Inference done 64/144. Dataloading: 0.0028 s/iter. Inference: 0.2516 s/iter. Eval: 0.4723 s/iter. Total: 0.7270 s/iter. ETA=0:00:58
[08/23 08:38:39 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0028 s/iter. Inference: 0.2522 s/iter. Eval: 0.4769 s/iter. Total: 0.7322 s/iter. ETA=0:00:53
[08/23 08:38:45 d2.evaluation.evaluator]: Inference done 81/144. Dataloading: 0.0028 s/iter. Inference: 0.2501 s/iter. Eval: 0.4526 s/iter. Total: 0.7058 s/iter. ETA=0:00:44
[08/23 08:38:50 d2.evaluation.evaluator]: Inference done 91/144. Dataloading: 0.0028 s/iter. Inference: 0.2485 s/iter. Eval: 0.4349 s/iter. Total: 0.6864 s/iter. ETA=0:00:36
[08/23 08:38:55 d2.evaluation.evaluator]: Inference done 101/144. Dataloading: 0.0028 s/iter. Inference: 0.2472 s/iter. Eval: 0.4169 s/iter. Total: 0.6672 s/iter. ETA=0:00:28
[08/23 08:39:00 d2.evaluation.evaluator]: Inference done 109/144. Dataloading: 0.0028 s/iter. Inference: 0.2470 s/iter. Eval: 0.4154 s/iter. Total: 0.6655 s/iter. ETA=0:00:23
[08/23 08:39:05 d2.evaluation.evaluator]: Inference done 117/144. Dataloading: 0.0028 s/iter. Inference: 0.2469 s/iter. Eval: 0.4131 s/iter. Total: 0.6630 s/iter. ETA=0:00:17
[08/23 08:39:10 d2.evaluation.evaluator]: Inference done 127/144. Dataloading: 0.0028 s/iter. Inference: 0.2458 s/iter. Eval: 0.4019 s/iter. Total: 0.6508 s/iter. ETA=0:00:11
[08/23 08:39:16 d2.evaluation.evaluator]: Inference done 135/144. Dataloading: 0.0028 s/iter. Inference: 0.2460 s/iter. Eval: 0.4033 s/iter. Total: 0.6524 s/iter. ETA=0:00:05
[08/23 08:39:21 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0027 s/iter. Inference: 0.2458 s/iter. Eval: 0.4014 s/iter. Total: 0.6503 s/iter. ETA=0:00:00
[08/23 08:39:21 d2.evaluation.evaluator]: Total inference time: 0:01:30.468751 (0.650854 s / iter per device, on 1 devices)
[08/23 08:39:21 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:34 (0.245793 s / iter per device, on 1 devices)
[08/23 08:39:21 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 08:39:21 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 08:39:22 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/23 08:39:22 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 08:39:22 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.09 seconds.
[08/23 08:39:22 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:39:22 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.391
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.637
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.413
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.127
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.384
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.479
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.307
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.540
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.604
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.582
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.712
[08/23 08:39:22 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 39.087 | 63.694 | 41.272 | 12.691 | 38.427 | 47.943 |
Loading and preparing results...
DONE (t=0.18s)
creating index...
index created!
[08/23 08:39:22 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 08:39:22 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.14 seconds.
[08/23 08:39:22 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:39:22 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.435
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.654
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.514
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.142
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.377
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.593
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.324
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.595
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.673
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.375
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.644
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.777
[08/23 08:39:22 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 43.482 | 65.401 | 51.441 | 14.229 | 37.695 | 59.339 |
[08/23 08:39:22 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 08:39:22 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 08:39:22 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:39:22 d2.evaluation.testing]: copypaste: 39.0868,63.6944,41.2717,12.6909,38.4271,47.9428
[08/23 08:39:22 d2.evaluation.testing]: copypaste: Task: segm
[08/23 08:39:22 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:39:22 d2.evaluation.testing]: copypaste: 43.4820,65.4013,51.4412,14.2285,37.6950,59.3392
[08/23 08:39:22 d2.utils.events]:  eta: 0:21:58  iter: 299  total_loss: 0.8825  loss_cls: 0.1706  loss_box_reg: 0.3467  loss_mask: 0.2478  loss_rpn_cls: 0.009106  loss_rpn_loc: 0.008291  time: 1.8928  data_time: 0.0219  lr: 7.4925e-05  max_mem: 10889M
[08/23 08:40:00 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 08:40:00 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 08:40:00 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 08:40:00 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 08:40:00 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 08:40:10 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0038 s/iter. Inference: 0.2614 s/iter. Eval: 0.5141 s/iter. Total: 0.7793 s/iter. ETA=0:01:43
[08/23 08:40:15 d2.evaluation.evaluator]: Inference done 21/144. Dataloading: 0.0031 s/iter. Inference: 0.2461 s/iter. Eval: 0.3831 s/iter. Total: 0.6324 s/iter. ETA=0:01:17
[08/23 08:40:21 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0031 s/iter. Inference: 0.2419 s/iter. Eval: 0.3559 s/iter. Total: 0.6011 s/iter. ETA=0:01:07
[08/23 08:40:26 d2.evaluation.evaluator]: Inference done 40/144. Dataloading: 0.0030 s/iter. Inference: 0.2417 s/iter. Eval: 0.3569 s/iter. Total: 0.6018 s/iter. ETA=0:01:02
[08/23 08:40:32 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0031 s/iter. Inference: 0.2441 s/iter. Eval: 0.3876 s/iter. Total: 0.6349 s/iter. ETA=0:01:01
[08/23 08:40:37 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0030 s/iter. Inference: 0.2464 s/iter. Eval: 0.4115 s/iter. Total: 0.6612 s/iter. ETA=0:01:00
[08/23 08:40:42 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0030 s/iter. Inference: 0.2478 s/iter. Eval: 0.4329 s/iter. Total: 0.6838 s/iter. ETA=0:00:58
[08/23 08:40:48 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0029 s/iter. Inference: 0.2478 s/iter. Eval: 0.4336 s/iter. Total: 0.6846 s/iter. ETA=0:00:52
[08/23 08:40:53 d2.evaluation.evaluator]: Inference done 76/144. Dataloading: 0.0029 s/iter. Inference: 0.2472 s/iter. Eval: 0.4219 s/iter. Total: 0.6724 s/iter. ETA=0:00:45
[08/23 08:40:58 d2.evaluation.evaluator]: Inference done 87/144. Dataloading: 0.0029 s/iter. Inference: 0.2451 s/iter. Eval: 0.3974 s/iter. Total: 0.6456 s/iter. ETA=0:00:36
[08/23 08:41:03 d2.evaluation.evaluator]: Inference done 99/144. Dataloading: 0.0028 s/iter. Inference: 0.2429 s/iter. Eval: 0.3740 s/iter. Total: 0.6199 s/iter. ETA=0:00:27
[08/23 08:41:09 d2.evaluation.evaluator]: Inference done 107/144. Dataloading: 0.0028 s/iter. Inference: 0.2432 s/iter. Eval: 0.3765 s/iter. Total: 0.6227 s/iter. ETA=0:00:23
[08/23 08:41:14 d2.evaluation.evaluator]: Inference done 115/144. Dataloading: 0.0028 s/iter. Inference: 0.2434 s/iter. Eval: 0.3785 s/iter. Total: 0.6250 s/iter. ETA=0:00:18
[08/23 08:41:19 d2.evaluation.evaluator]: Inference done 126/144. Dataloading: 0.0029 s/iter. Inference: 0.2424 s/iter. Eval: 0.3658 s/iter. Total: 0.6113 s/iter. ETA=0:00:11
[08/23 08:41:24 d2.evaluation.evaluator]: Inference done 135/144. Dataloading: 0.0028 s/iter. Inference: 0.2423 s/iter. Eval: 0.3648 s/iter. Total: 0.6101 s/iter. ETA=0:00:05
[08/23 08:41:30 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0029 s/iter. Inference: 0.2422 s/iter. Eval: 0.3646 s/iter. Total: 0.6099 s/iter. ETA=0:00:00
[08/23 08:41:30 d2.evaluation.evaluator]: Total inference time: 0:01:24.860979 (0.610511 s / iter per device, on 1 devices)
[08/23 08:41:30 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:33 (0.242190 s / iter per device, on 1 devices)
[08/23 08:41:30 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 08:41:30 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 08:41:30 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/23 08:41:30 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 08:41:30 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.08 seconds.
[08/23 08:41:30 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:41:30 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.406
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.655
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.459
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.127
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.388
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.506
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.312
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.553
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.607
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.208
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.581
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.724
[08/23 08:41:30 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 40.563 | 65.478 | 45.917 | 12.690 | 38.828 | 50.581 |
Loading and preparing results...
DONE (t=0.16s)
creating index...
index created!
[08/23 08:41:31 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 08:41:31 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.14 seconds.
[08/23 08:41:31 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:41:31 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.446
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.664
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.520
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.127
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.387
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.606
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.328
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.600
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.679
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.656
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.779
[08/23 08:41:31 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 44.605 | 66.442 | 52.008 | 12.691 | 38.695 | 60.624 |
[08/23 08:41:31 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 08:41:31 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 08:41:31 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:41:31 d2.evaluation.testing]: copypaste: 40.5632,65.4781,45.9173,12.6901,38.8278,50.5809
[08/23 08:41:31 d2.evaluation.testing]: copypaste: Task: segm
[08/23 08:41:31 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:41:31 d2.evaluation.testing]: copypaste: 44.6047,66.4422,52.0085,12.6914,38.6948,60.6237
[08/23 08:41:31 d2.utils.events]:  eta: 0:21:21  iter: 319  total_loss: 0.8475  loss_cls: 0.1491  loss_box_reg: 0.4114  loss_mask: 0.212  loss_rpn_cls: 0.005959  loss_rpn_loc: 0.006841  time: 1.8925  data_time: 0.0226  lr: 7.992e-05  max_mem: 10889M
[08/23 08:42:09 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 08:42:09 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 08:42:09 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 08:42:09 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 08:42:09 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 08:42:18 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0020 s/iter. Inference: 0.2538 s/iter. Eval: 0.4678 s/iter. Total: 0.7237 s/iter. ETA=0:01:36
[08/23 08:42:24 d2.evaluation.evaluator]: Inference done 21/144. Dataloading: 0.0026 s/iter. Inference: 0.2441 s/iter. Eval: 0.3559 s/iter. Total: 0.6028 s/iter. ETA=0:01:14
[08/23 08:42:29 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0026 s/iter. Inference: 0.2400 s/iter. Eval: 0.3223 s/iter. Total: 0.5651 s/iter. ETA=0:01:03
[08/23 08:42:34 d2.evaluation.evaluator]: Inference done 40/144. Dataloading: 0.0028 s/iter. Inference: 0.2406 s/iter. Eval: 0.3297 s/iter. Total: 0.5733 s/iter. ETA=0:00:59
[08/23 08:42:40 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0028 s/iter. Inference: 0.2430 s/iter. Eval: 0.3581 s/iter. Total: 0.6041 s/iter. ETA=0:00:58
[08/23 08:42:45 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0029 s/iter. Inference: 0.2453 s/iter. Eval: 0.3894 s/iter. Total: 0.6378 s/iter. ETA=0:00:58
[08/23 08:42:50 d2.evaluation.evaluator]: Inference done 60/144. Dataloading: 0.0028 s/iter. Inference: 0.2465 s/iter. Eval: 0.4003 s/iter. Total: 0.6498 s/iter. ETA=0:00:54
[08/23 08:42:55 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0029 s/iter. Inference: 0.2468 s/iter. Eval: 0.4087 s/iter. Total: 0.6587 s/iter. ETA=0:00:50
[08/23 08:43:00 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0028 s/iter. Inference: 0.2454 s/iter. Eval: 0.3936 s/iter. Total: 0.6420 s/iter. ETA=0:00:43
[08/23 08:43:06 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0027 s/iter. Inference: 0.2432 s/iter. Eval: 0.3685 s/iter. Total: 0.6146 s/iter. ETA=0:00:33
[08/23 08:43:11 d2.evaluation.evaluator]: Inference done 101/144. Dataloading: 0.0027 s/iter. Inference: 0.2414 s/iter. Eval: 0.3483 s/iter. Total: 0.5927 s/iter. ETA=0:00:25
[08/23 08:43:17 d2.evaluation.evaluator]: Inference done 110/144. Dataloading: 0.0029 s/iter. Inference: 0.2415 s/iter. Eval: 0.3500 s/iter. Total: 0.5946 s/iter. ETA=0:00:20
[08/23 08:43:22 d2.evaluation.evaluator]: Inference done 121/144. Dataloading: 0.0029 s/iter. Inference: 0.2405 s/iter. Eval: 0.3388 s/iter. Total: 0.5825 s/iter. ETA=0:00:13
[08/23 08:43:27 d2.evaluation.evaluator]: Inference done 130/144. Dataloading: 0.0029 s/iter. Inference: 0.2405 s/iter. Eval: 0.3395 s/iter. Total: 0.5832 s/iter. ETA=0:00:08
[08/23 08:43:32 d2.evaluation.evaluator]: Inference done 141/144. Dataloading: 0.0029 s/iter. Inference: 0.2398 s/iter. Eval: 0.3322 s/iter. Total: 0.5751 s/iter. ETA=0:00:01
[08/23 08:43:35 d2.evaluation.evaluator]: Total inference time: 0:01:20.661003 (0.580295 s / iter per device, on 1 devices)
[08/23 08:43:35 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:33 (0.240141 s / iter per device, on 1 devices)
[08/23 08:43:35 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 08:43:35 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 08:43:35 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/23 08:43:35 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 08:43:35 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.08 seconds.
[08/23 08:43:35 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:43:35 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.424
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.664
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.496
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.142
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.393
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.543
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.315
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.563
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.242
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.589
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.739
[08/23 08:43:35 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 42.390 | 66.425 | 49.599 | 14.183 | 39.283 | 54.276 |
Loading and preparing results...
DONE (t=0.15s)
creating index...
index created!
[08/23 08:43:36 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 08:43:36 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.13 seconds.
[08/23 08:43:36 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:43:36 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.460
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.672
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.530
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.135
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.403
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.329
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.608
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.682
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.375
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.661
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.774
[08/23 08:43:36 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.013 | 67.183 | 53.048 | 13.530 | 40.250 | 61.929 |
[08/23 08:43:36 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 08:43:36 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 08:43:36 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:43:36 d2.evaluation.testing]: copypaste: 42.3901,66.4252,49.5989,14.1828,39.2826,54.2762
[08/23 08:43:36 d2.evaluation.testing]: copypaste: Task: segm
[08/23 08:43:36 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:43:36 d2.evaluation.testing]: copypaste: 46.0129,67.1825,53.0481,13.5303,40.2501,61.9287
[08/23 08:43:36 d2.utils.events]:  eta: 0:20:43  iter: 339  total_loss: 0.8069  loss_cls: 0.1437  loss_box_reg: 0.3942  loss_mask: 0.197  loss_rpn_cls: 0.01604  loss_rpn_loc: 0.007089  time: 1.8935  data_time: 0.0243  lr: 8.4915e-05  max_mem: 10889M
[08/23 08:44:14 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 08:44:14 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 08:44:14 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 08:44:14 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 08:44:14 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 08:44:22 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0020 s/iter. Inference: 0.2386 s/iter. Eval: 0.3597 s/iter. Total: 0.6003 s/iter. ETA=0:01:19
[08/23 08:44:27 d2.evaluation.evaluator]: Inference done 22/144. Dataloading: 0.0024 s/iter. Inference: 0.2338 s/iter. Eval: 0.2732 s/iter. Total: 0.5097 s/iter. ETA=0:01:02
[08/23 08:44:32 d2.evaluation.evaluator]: Inference done 33/144. Dataloading: 0.0028 s/iter. Inference: 0.2335 s/iter. Eval: 0.2654 s/iter. Total: 0.5020 s/iter. ETA=0:00:55
[08/23 08:44:38 d2.evaluation.evaluator]: Inference done 43/144. Dataloading: 0.0027 s/iter. Inference: 0.2347 s/iter. Eval: 0.2790 s/iter. Total: 0.5167 s/iter. ETA=0:00:52
[08/23 08:44:43 d2.evaluation.evaluator]: Inference done 50/144. Dataloading: 0.0027 s/iter. Inference: 0.2381 s/iter. Eval: 0.3175 s/iter. Total: 0.5585 s/iter. ETA=0:00:52
[08/23 08:44:49 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0027 s/iter. Inference: 0.2398 s/iter. Eval: 0.3360 s/iter. Total: 0.5787 s/iter. ETA=0:00:49
[08/23 08:44:55 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0027 s/iter. Inference: 0.2401 s/iter. Eval: 0.3436 s/iter. Total: 0.5867 s/iter. ETA=0:00:45
[08/23 08:45:00 d2.evaluation.evaluator]: Inference done 78/144. Dataloading: 0.0028 s/iter. Inference: 0.2388 s/iter. Eval: 0.3291 s/iter. Total: 0.5709 s/iter. ETA=0:00:37
[08/23 08:45:05 d2.evaluation.evaluator]: Inference done 91/144. Dataloading: 0.0028 s/iter. Inference: 0.2372 s/iter. Eval: 0.3048 s/iter. Total: 0.5451 s/iter. ETA=0:00:28
[08/23 08:45:10 d2.evaluation.evaluator]: Inference done 103/144. Dataloading: 0.0028 s/iter. Inference: 0.2363 s/iter. Eval: 0.2908 s/iter. Total: 0.5302 s/iter. ETA=0:00:21
[08/23 08:45:15 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0028 s/iter. Inference: 0.2361 s/iter. Eval: 0.2889 s/iter. Total: 0.5281 s/iter. ETA=0:00:16
[08/23 08:45:20 d2.evaluation.evaluator]: Inference done 125/144. Dataloading: 0.0028 s/iter. Inference: 0.2352 s/iter. Eval: 0.2788 s/iter. Total: 0.5170 s/iter. ETA=0:00:09
[08/23 08:45:26 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0028 s/iter. Inference: 0.2346 s/iter. Eval: 0.2731 s/iter. Total: 0.5108 s/iter. ETA=0:00:03
[08/23 08:45:30 d2.evaluation.evaluator]: Total inference time: 0:01:11.372945 (0.513474 s / iter per device, on 1 devices)
[08/23 08:45:30 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:32 (0.234703 s / iter per device, on 1 devices)
[08/23 08:45:30 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 08:45:30 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 08:45:30 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/23 08:45:30 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 08:45:30 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[08/23 08:45:30 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:45:30 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.433
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.674
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.492
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.129
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.402
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.558
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.322
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.574
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.208
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.584
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.753
[08/23 08:45:30 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 43.301 | 67.355 | 49.155 | 12.928 | 40.198 | 55.781 |
Loading and preparing results...
DONE (t=0.12s)
creating index...
index created!
[08/23 08:45:30 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 08:45:30 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[08/23 08:45:30 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:45:30 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.468
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.685
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.539
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.133
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.411
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.331
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.612
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.678
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.375
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.650
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.782
[08/23 08:45:30 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.782 | 68.513 | 53.898 | 13.251 | 41.130 | 62.263 |
[08/23 08:45:30 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 08:45:30 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 08:45:30 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:45:30 d2.evaluation.testing]: copypaste: 43.3014,67.3552,49.1549,12.9275,40.1983,55.7810
[08/23 08:45:30 d2.evaluation.testing]: copypaste: Task: segm
[08/23 08:45:30 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:45:30 d2.evaluation.testing]: copypaste: 46.7815,68.5125,53.8983,13.2508,41.1303,62.2627
[08/23 08:45:30 d2.utils.events]:  eta: 0:20:06  iter: 359  total_loss: 0.8074  loss_cls: 0.1341  loss_box_reg: 0.426  loss_mask: 0.188  loss_rpn_cls: 0.009703  loss_rpn_loc: 0.005584  time: 1.8940  data_time: 0.0265  lr: 8.991e-05  max_mem: 10889M
[08/23 08:46:09 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 08:46:09 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 08:46:09 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 08:46:09 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 08:46:09 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 08:46:16 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0018 s/iter. Inference: 0.2359 s/iter. Eval: 0.2818 s/iter. Total: 0.5194 s/iter. ETA=0:01:09
[08/23 08:46:21 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0023 s/iter. Inference: 0.2298 s/iter. Eval: 0.2246 s/iter. Total: 0.4570 s/iter. ETA=0:00:55
[08/23 08:46:26 d2.evaluation.evaluator]: Inference done 35/144. Dataloading: 0.0026 s/iter. Inference: 0.2292 s/iter. Eval: 0.2136 s/iter. Total: 0.4456 s/iter. ETA=0:00:48
[08/23 08:46:32 d2.evaluation.evaluator]: Inference done 45/144. Dataloading: 0.0028 s/iter. Inference: 0.2310 s/iter. Eval: 0.2347 s/iter. Total: 0.4687 s/iter. ETA=0:00:46
[08/23 08:46:37 d2.evaluation.evaluator]: Inference done 52/144. Dataloading: 0.0027 s/iter. Inference: 0.2351 s/iter. Eval: 0.2764 s/iter. Total: 0.5145 s/iter. ETA=0:00:47
[08/23 08:46:42 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0027 s/iter. Inference: 0.2413 s/iter. Eval: 0.3016 s/iter. Total: 0.5459 s/iter. ETA=0:00:46
[08/23 08:46:48 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0028 s/iter. Inference: 0.2414 s/iter. Eval: 0.3099 s/iter. Total: 0.5543 s/iter. ETA=0:00:42
[08/23 08:46:53 d2.evaluation.evaluator]: Inference done 81/144. Dataloading: 0.0027 s/iter. Inference: 0.2385 s/iter. Eval: 0.2851 s/iter. Total: 0.5266 s/iter. ETA=0:00:33
[08/23 08:46:58 d2.evaluation.evaluator]: Inference done 96/144. Dataloading: 0.0027 s/iter. Inference: 0.2358 s/iter. Eval: 0.2578 s/iter. Total: 0.4965 s/iter. ETA=0:00:23
[08/23 08:47:04 d2.evaluation.evaluator]: Inference done 108/144. Dataloading: 0.0027 s/iter. Inference: 0.2351 s/iter. Eval: 0.2539 s/iter. Total: 0.4919 s/iter. ETA=0:00:17
[08/23 08:47:09 d2.evaluation.evaluator]: Inference done 120/144. Dataloading: 0.0028 s/iter. Inference: 0.2342 s/iter. Eval: 0.2470 s/iter. Total: 0.4842 s/iter. ETA=0:00:11
[08/23 08:47:14 d2.evaluation.evaluator]: Inference done 132/144. Dataloading: 0.0029 s/iter. Inference: 0.2337 s/iter. Eval: 0.2422 s/iter. Total: 0.4790 s/iter. ETA=0:00:05
[08/23 08:47:19 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0029 s/iter. Inference: 0.2334 s/iter. Eval: 0.2421 s/iter. Total: 0.4786 s/iter. ETA=0:00:00
[08/23 08:47:19 d2.evaluation.evaluator]: Total inference time: 0:01:06.608151 (0.479195 s / iter per device, on 1 devices)
[08/23 08:47:19 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:32 (0.233364 s / iter per device, on 1 devices)
[08/23 08:47:20 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 08:47:20 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 08:47:20 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/23 08:47:20 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 08:47:20 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[08/23 08:47:20 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:47:20 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.445
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.677
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.512
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.145
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.411
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.569
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.328
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.578
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.626
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.242
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.590
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.759
[08/23 08:47:20 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 44.479 | 67.663 | 51.167 | 14.493 | 41.123 | 56.851 |
Loading and preparing results...
DONE (t=0.12s)
creating index...
index created!
[08/23 08:47:20 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 08:47:20 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.
[08/23 08:47:20 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:47:20 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.478
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.695
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.544
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.141
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.420
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.637
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.339
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.675
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.342
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.644
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.789
[08/23 08:47:20 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.826 | 69.457 | 54.351 | 14.146 | 41.979 | 63.685 |
[08/23 08:47:20 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 08:47:20 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 08:47:20 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:47:20 d2.evaluation.testing]: copypaste: 44.4789,67.6626,51.1672,14.4925,41.1235,56.8512
[08/23 08:47:20 d2.evaluation.testing]: copypaste: Task: segm
[08/23 08:47:20 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:47:20 d2.evaluation.testing]: copypaste: 47.8260,69.4568,54.3510,14.1462,41.9787,63.6847
[08/23 08:47:20 d2.utils.events]:  eta: 0:19:28  iter: 379  total_loss: 0.565  loss_cls: 0.1131  loss_box_reg: 0.3102  loss_mask: 0.196  loss_rpn_cls: 0.006442  loss_rpn_loc: 0.00414  time: 1.8948  data_time: 0.0231  lr: 9.4905e-05  max_mem: 10889M
[08/23 08:47:58 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 08:47:58 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 08:47:58 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 08:47:58 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 08:47:58 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 08:48:05 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0018 s/iter. Inference: 0.2416 s/iter. Eval: 0.2781 s/iter. Total: 0.5216 s/iter. ETA=0:01:09
[08/23 08:48:11 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0020 s/iter. Inference: 0.2318 s/iter. Eval: 0.2268 s/iter. Total: 0.4608 s/iter. ETA=0:00:55
[08/23 08:48:16 d2.evaluation.evaluator]: Inference done 36/144. Dataloading: 0.0024 s/iter. Inference: 0.2283 s/iter. Eval: 0.2063 s/iter. Total: 0.4372 s/iter. ETA=0:00:47
[08/23 08:48:21 d2.evaluation.evaluator]: Inference done 45/144. Dataloading: 0.0030 s/iter. Inference: 0.2317 s/iter. Eval: 0.2425 s/iter. Total: 0.4774 s/iter. ETA=0:00:47
[08/23 08:48:27 d2.evaluation.evaluator]: Inference done 52/144. Dataloading: 0.0031 s/iter. Inference: 0.2350 s/iter. Eval: 0.2832 s/iter. Total: 0.5215 s/iter. ETA=0:00:47
[08/23 08:48:32 d2.evaluation.evaluator]: Inference done 60/144. Dataloading: 0.0030 s/iter. Inference: 0.2364 s/iter. Eval: 0.2990 s/iter. Total: 0.5387 s/iter. ETA=0:00:45
[08/23 08:48:37 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0030 s/iter. Inference: 0.2372 s/iter. Eval: 0.3101 s/iter. Total: 0.5505 s/iter. ETA=0:00:41
[08/23 08:48:42 d2.evaluation.evaluator]: Inference done 80/144. Dataloading: 0.0029 s/iter. Inference: 0.2354 s/iter. Eval: 0.2911 s/iter. Total: 0.5296 s/iter. ETA=0:00:33
[08/23 08:48:47 d2.evaluation.evaluator]: Inference done 95/144. Dataloading: 0.0029 s/iter. Inference: 0.2331 s/iter. Eval: 0.2628 s/iter. Total: 0.4990 s/iter. ETA=0:00:24
[08/23 08:48:52 d2.evaluation.evaluator]: Inference done 106/144. Dataloading: 0.0029 s/iter. Inference: 0.2328 s/iter. Eval: 0.2603 s/iter. Total: 0.4962 s/iter. ETA=0:00:18
[08/23 08:48:57 d2.evaluation.evaluator]: Inference done 117/144. Dataloading: 0.0029 s/iter. Inference: 0.2327 s/iter. Eval: 0.2578 s/iter. Total: 0.4936 s/iter. ETA=0:00:13
[08/23 08:49:03 d2.evaluation.evaluator]: Inference done 130/144. Dataloading: 0.0029 s/iter. Inference: 0.2318 s/iter. Eval: 0.2485 s/iter. Total: 0.4834 s/iter. ETA=0:00:06
[08/23 08:49:08 d2.evaluation.evaluator]: Inference done 142/144. Dataloading: 0.0029 s/iter. Inference: 0.2314 s/iter. Eval: 0.2438 s/iter. Total: 0.4783 s/iter. ETA=0:00:00
[08/23 08:49:09 d2.evaluation.evaluator]: Total inference time: 0:01:06.977934 (0.481856 s / iter per device, on 1 devices)
[08/23 08:49:09 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:32 (0.231622 s / iter per device, on 1 devices)
[08/23 08:49:09 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 08:49:09 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 08:49:09 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/23 08:49:09 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 08:49:09 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[08/23 08:49:09 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:49:09 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.454
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.679
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.513
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.149
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.415
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.586
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.327
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.588
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.632
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.258
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.597
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.762
[08/23 08:49:09 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.367 | 67.949 | 51.338 | 14.892 | 41.550 | 58.554 |
Loading and preparing results...
DONE (t=0.11s)
creating index...
index created!
[08/23 08:49:10 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 08:49:10 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[08/23 08:49:10 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:49:10 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.479
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.708
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.545
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.157
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.422
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.639
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.334
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.620
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.682
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.657
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.789
[08/23 08:49:10 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.903 | 70.754 | 54.463 | 15.717 | 42.200 | 63.868 |
[08/23 08:49:10 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 08:49:10 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 08:49:10 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:49:10 d2.evaluation.testing]: copypaste: 45.3665,67.9491,51.3376,14.8924,41.5497,58.5540
[08/23 08:49:10 d2.evaluation.testing]: copypaste: Task: segm
[08/23 08:49:10 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:49:10 d2.evaluation.testing]: copypaste: 47.9033,70.7540,54.4634,15.7170,42.2004,63.8679
[08/23 08:49:10 d2.utils.events]:  eta: 0:18:51  iter: 399  total_loss: 0.6134  loss_cls: 0.102  loss_box_reg: 0.3144  loss_mask: 0.1918  loss_rpn_cls: 0.008185  loss_rpn_loc: 0.006772  time: 1.8947  data_time: 0.0255  lr: 9.99e-05  max_mem: 10889M
[08/23 08:49:48 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 08:49:48 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 08:49:48 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 08:49:48 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 08:49:48 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 08:49:55 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0018 s/iter. Inference: 0.2323 s/iter. Eval: 0.2448 s/iter. Total: 0.4789 s/iter. ETA=0:01:03
[08/23 08:50:00 d2.evaluation.evaluator]: Inference done 25/144. Dataloading: 0.0025 s/iter. Inference: 0.2287 s/iter. Eval: 0.1743 s/iter. Total: 0.4056 s/iter. ETA=0:00:48
[08/23 08:50:05 d2.evaluation.evaluator]: Inference done 39/144. Dataloading: 0.0033 s/iter. Inference: 0.2270 s/iter. Eval: 0.1711 s/iter. Total: 0.4016 s/iter. ETA=0:00:42
[08/23 08:50:11 d2.evaluation.evaluator]: Inference done 48/144. Dataloading: 0.0033 s/iter. Inference: 0.2296 s/iter. Eval: 0.2037 s/iter. Total: 0.4368 s/iter. ETA=0:00:41
[08/23 08:50:16 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0032 s/iter. Inference: 0.2314 s/iter. Eval: 0.2269 s/iter. Total: 0.4617 s/iter. ETA=0:00:40
[08/23 08:50:21 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0032 s/iter. Inference: 0.2322 s/iter. Eval: 0.2382 s/iter. Total: 0.4737 s/iter. ETA=0:00:36
[08/23 08:50:26 d2.evaluation.evaluator]: Inference done 80/144. Dataloading: 0.0031 s/iter. Inference: 0.2313 s/iter. Eval: 0.2263 s/iter. Total: 0.4610 s/iter. ETA=0:00:29
[08/23 08:50:31 d2.evaluation.evaluator]: Inference done 96/144. Dataloading: 0.0032 s/iter. Inference: 0.2295 s/iter. Eval: 0.2022 s/iter. Total: 0.4351 s/iter. ETA=0:00:20
[08/23 08:50:36 d2.evaluation.evaluator]: Inference done 108/144. Dataloading: 0.0032 s/iter. Inference: 0.2296 s/iter. Eval: 0.2009 s/iter. Total: 0.4339 s/iter. ETA=0:00:15
[08/23 08:50:42 d2.evaluation.evaluator]: Inference done 122/144. Dataloading: 0.0032 s/iter. Inference: 0.2288 s/iter. Eval: 0.1943 s/iter. Total: 0.4265 s/iter. ETA=0:00:09
[08/23 08:50:47 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0031 s/iter. Inference: 0.2282 s/iter. Eval: 0.1876 s/iter. Total: 0.4191 s/iter. ETA=0:00:02
[08/23 08:50:50 d2.evaluation.evaluator]: Total inference time: 0:00:58.586882 (0.421488 s / iter per device, on 1 devices)
[08/23 08:50:50 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:31 (0.228219 s / iter per device, on 1 devices)
[08/23 08:50:50 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 08:50:50 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 08:50:50 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/23 08:50:50 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 08:50:51 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/23 08:50:51 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:50:51 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.464
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.694
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.535
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.155
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.428
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.597
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.328
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.593
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.638
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.267
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.756
[08/23 08:50:51 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.370 | 69.393 | 53.485 | 15.451 | 42.818 | 59.652 |
Loading and preparing results...
DONE (t=0.09s)
creating index...
index created!
[08/23 08:50:51 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 08:50:51 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.09 seconds.
[08/23 08:50:51 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:50:51 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.483
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.709
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.562
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.158
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.420
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.642
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.337
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.618
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.674
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.643
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.786
[08/23 08:50:51 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.259 | 70.876 | 56.190 | 15.787 | 42.023 | 64.197 |
[08/23 08:50:51 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 08:50:51 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 08:50:51 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:50:51 d2.evaluation.testing]: copypaste: 46.3700,69.3929,53.4848,15.4515,42.8184,59.6523
[08/23 08:50:51 d2.evaluation.testing]: copypaste: Task: segm
[08/23 08:50:51 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:50:51 d2.evaluation.testing]: copypaste: 48.2586,70.8765,56.1895,15.7869,42.0231,64.1968
[08/23 08:50:51 d2.utils.events]:  eta: 0:18:13  iter: 419  total_loss: 0.6371  loss_cls: 0.1002  loss_box_reg: 0.2997  loss_mask: 0.1943  loss_rpn_cls: 0.008872  loss_rpn_loc: 0.0071  time: 1.8954  data_time: 0.0245  lr: 0.0001049  max_mem: 10889M
[08/23 08:51:29 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 08:51:29 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 08:51:29 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 08:51:29 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 08:51:29 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 08:51:36 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0023 s/iter. Inference: 0.2318 s/iter. Eval: 0.2454 s/iter. Total: 0.4796 s/iter. ETA=0:01:03
[08/23 08:51:41 d2.evaluation.evaluator]: Inference done 24/144. Dataloading: 0.0036 s/iter. Inference: 0.2309 s/iter. Eval: 0.1947 s/iter. Total: 0.4295 s/iter. ETA=0:00:51
[08/23 08:51:46 d2.evaluation.evaluator]: Inference done 38/144. Dataloading: 0.0033 s/iter. Inference: 0.2287 s/iter. Eval: 0.1777 s/iter. Total: 0.4099 s/iter. ETA=0:00:43
[08/23 08:51:52 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0032 s/iter. Inference: 0.2324 s/iter. Eval: 0.2246 s/iter. Total: 0.4604 s/iter. ETA=0:00:44
[08/23 08:51:57 d2.evaluation.evaluator]: Inference done 54/144. Dataloading: 0.0031 s/iter. Inference: 0.2351 s/iter. Eval: 0.2608 s/iter. Total: 0.4992 s/iter. ETA=0:00:44
[08/23 08:52:03 d2.evaluation.evaluator]: Inference done 64/144. Dataloading: 0.0031 s/iter. Inference: 0.2354 s/iter. Eval: 0.2675 s/iter. Total: 0.5062 s/iter. ETA=0:00:40
[08/23 08:52:08 d2.evaluation.evaluator]: Inference done 73/144. Dataloading: 0.0030 s/iter. Inference: 0.2360 s/iter. Eval: 0.2775 s/iter. Total: 0.5167 s/iter. ETA=0:00:36
[08/23 08:52:13 d2.evaluation.evaluator]: Inference done 86/144. Dataloading: 0.0030 s/iter. Inference: 0.2348 s/iter. Eval: 0.2608 s/iter. Total: 0.4988 s/iter. ETA=0:00:28
[08/23 08:52:18 d2.evaluation.evaluator]: Inference done 100/144. Dataloading: 0.0031 s/iter. Inference: 0.2333 s/iter. Eval: 0.2432 s/iter. Total: 0.4798 s/iter. ETA=0:00:21
[08/23 08:52:23 d2.evaluation.evaluator]: Inference done 112/144. Dataloading: 0.0030 s/iter. Inference: 0.2327 s/iter. Eval: 0.2384 s/iter. Total: 0.4744 s/iter. ETA=0:00:15
[08/23 08:52:29 d2.evaluation.evaluator]: Inference done 126/144. Dataloading: 0.0031 s/iter. Inference: 0.2320 s/iter. Eval: 0.2277 s/iter. Total: 0.4630 s/iter. ETA=0:00:08
[08/23 08:52:34 d2.evaluation.evaluator]: Inference done 140/144. Dataloading: 0.0031 s/iter. Inference: 0.2310 s/iter. Eval: 0.2189 s/iter. Total: 0.4533 s/iter. ETA=0:00:01
[08/23 08:52:37 d2.evaluation.evaluator]: Total inference time: 0:01:04.158289 (0.461570 s / iter per device, on 1 devices)
[08/23 08:52:37 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:32 (0.231463 s / iter per device, on 1 devices)
[08/23 08:52:37 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 08:52:37 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 08:52:37 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/23 08:52:37 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 08:52:37 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[08/23 08:52:37 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:52:37 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.468
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.699
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.522
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.144
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.426
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.611
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.329
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.594
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.642
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.225
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.607
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.780
[08/23 08:52:37 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.820 | 69.861 | 52.220 | 14.350 | 42.602 | 61.056 |
Loading and preparing results...
DONE (t=0.10s)
creating index...
index created!
[08/23 08:52:37 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 08:52:38 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.09 seconds.
[08/23 08:52:38 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:52:38 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.486
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.717
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.546
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.158
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.424
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.652
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.334
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.676
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.650
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.788
[08/23 08:52:38 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.591 | 71.654 | 54.551 | 15.777 | 42.414 | 65.208 |
[08/23 08:52:38 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 08:52:38 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 08:52:38 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:52:38 d2.evaluation.testing]: copypaste: 46.8197,69.8609,52.2197,14.3504,42.6020,61.0559
[08/23 08:52:38 d2.evaluation.testing]: copypaste: Task: segm
[08/23 08:52:38 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:52:38 d2.evaluation.testing]: copypaste: 48.5910,71.6539,54.5513,15.7772,42.4143,65.2078
[08/23 08:52:38 d2.utils.events]:  eta: 0:17:36  iter: 439  total_loss: 0.6854  loss_cls: 0.1249  loss_box_reg: 0.3396  loss_mask: 0.2057  loss_rpn_cls: 0.01158  loss_rpn_loc: 0.01851  time: 1.8953  data_time: 0.0258  lr: 0.00010989  max_mem: 10889M
[08/23 08:53:15 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 08:53:15 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 08:53:15 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 08:53:15 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 08:53:15 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 08:53:21 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0033 s/iter. Inference: 0.2263 s/iter. Eval: 0.1786 s/iter. Total: 0.4082 s/iter. ETA=0:00:54
[08/23 08:53:27 d2.evaluation.evaluator]: Inference done 27/144. Dataloading: 0.0025 s/iter. Inference: 0.2210 s/iter. Eval: 0.1216 s/iter. Total: 0.3452 s/iter. ETA=0:00:40
[08/23 08:53:32 d2.evaluation.evaluator]: Inference done 42/144. Dataloading: 0.0025 s/iter. Inference: 0.2222 s/iter. Eval: 0.1269 s/iter. Total: 0.3519 s/iter. ETA=0:00:35
[08/23 08:53:37 d2.evaluation.evaluator]: Inference done 50/144. Dataloading: 0.0026 s/iter. Inference: 0.2268 s/iter. Eval: 0.1792 s/iter. Total: 0.4089 s/iter. ETA=0:00:38
[08/23 08:53:43 d2.evaluation.evaluator]: Inference done 61/144. Dataloading: 0.0026 s/iter. Inference: 0.2284 s/iter. Eval: 0.1989 s/iter. Total: 0.4302 s/iter. ETA=0:00:35
[08/23 08:53:48 d2.evaluation.evaluator]: Inference done 73/144. Dataloading: 0.0028 s/iter. Inference: 0.2284 s/iter. Eval: 0.1993 s/iter. Total: 0.4307 s/iter. ETA=0:00:30
[08/23 08:53:53 d2.evaluation.evaluator]: Inference done 88/144. Dataloading: 0.0031 s/iter. Inference: 0.2273 s/iter. Eval: 0.1836 s/iter. Total: 0.4143 s/iter. ETA=0:00:23
[08/23 08:53:59 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0031 s/iter. Inference: 0.2264 s/iter. Eval: 0.1720 s/iter. Total: 0.4018 s/iter. ETA=0:00:16
[08/23 08:54:04 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0030 s/iter. Inference: 0.2255 s/iter. Eval: 0.1642 s/iter. Total: 0.3929 s/iter. ETA=0:00:09
[08/23 08:54:09 d2.evaluation.evaluator]: Inference done 135/144. Dataloading: 0.0031 s/iter. Inference: 0.2251 s/iter. Eval: 0.1570 s/iter. Total: 0.3854 s/iter. ETA=0:00:03
[08/23 08:54:13 d2.evaluation.evaluator]: Total inference time: 0:00:53.935039 (0.388022 s / iter per device, on 1 devices)
[08/23 08:54:13 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:31 (0.225125 s / iter per device, on 1 devices)
[08/23 08:54:13 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 08:54:13 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 08:54:13 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/23 08:54:13 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 08:54:13 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[08/23 08:54:13 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:54:13 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.477
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.706
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.534
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.171
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.450
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.601
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.335
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.600
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.644
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.250
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.764
[08/23 08:54:13 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.748 | 70.577 | 53.408 | 17.110 | 45.009 | 60.054 |
Loading and preparing results...
DONE (t=0.08s)
creating index...
index created!
[08/23 08:54:13 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 08:54:13 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.08 seconds.
[08/23 08:54:13 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:54:13 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.487
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.716
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.560
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.150
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.425
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.653
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.337
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.621
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.671
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.642
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.789
[08/23 08:54:13 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.677 | 71.604 | 56.027 | 14.962 | 42.459 | 65.276 |
[08/23 08:54:13 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 08:54:13 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 08:54:13 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:54:13 d2.evaluation.testing]: copypaste: 47.7484,70.5766,53.4081,17.1099,45.0088,60.0536
[08/23 08:54:13 d2.evaluation.testing]: copypaste: Task: segm
[08/23 08:54:13 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:54:13 d2.evaluation.testing]: copypaste: 48.6769,71.6041,56.0273,14.9617,42.4591,65.2759
[08/23 08:54:13 d2.utils.events]:  eta: 0:16:58  iter: 459  total_loss: 0.5885  loss_cls: 0.1092  loss_box_reg: 0.2706  loss_mask: 0.1963  loss_rpn_cls: 0.01435  loss_rpn_loc: 0.007008  time: 1.8950  data_time: 0.0253  lr: 0.00011489  max_mem: 10889M
[08/23 08:54:51 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 08:54:51 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 08:54:51 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 08:54:51 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 08:54:51 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 08:54:57 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0018 s/iter. Inference: 0.2252 s/iter. Eval: 0.1547 s/iter. Total: 0.3816 s/iter. ETA=0:00:50
[08/23 08:55:02 d2.evaluation.evaluator]: Inference done 26/144. Dataloading: 0.0037 s/iter. Inference: 0.2257 s/iter. Eval: 0.1291 s/iter. Total: 0.3586 s/iter. ETA=0:00:42
[08/23 08:55:07 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0032 s/iter. Inference: 0.2234 s/iter. Eval: 0.1231 s/iter. Total: 0.3499 s/iter. ETA=0:00:36
[08/23 08:55:12 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0032 s/iter. Inference: 0.2274 s/iter. Eval: 0.1755 s/iter. Total: 0.4062 s/iter. ETA=0:00:38
[08/23 08:55:17 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0031 s/iter. Inference: 0.2288 s/iter. Eval: 0.1962 s/iter. Total: 0.4284 s/iter. ETA=0:00:36
[08/23 08:55:23 d2.evaluation.evaluator]: Inference done 70/144. Dataloading: 0.0031 s/iter. Inference: 0.2292 s/iter. Eval: 0.2049 s/iter. Total: 0.4374 s/iter. ETA=0:00:32
[08/23 08:55:28 d2.evaluation.evaluator]: Inference done 87/144. Dataloading: 0.0031 s/iter. Inference: 0.2268 s/iter. Eval: 0.1803 s/iter. Total: 0.4103 s/iter. ETA=0:00:23
[08/23 08:55:33 d2.evaluation.evaluator]: Inference done 103/144. Dataloading: 0.0033 s/iter. Inference: 0.2268 s/iter. Eval: 0.1687 s/iter. Total: 0.3990 s/iter. ETA=0:00:16
[08/23 08:55:39 d2.evaluation.evaluator]: Inference done 118/144. Dataloading: 0.0033 s/iter. Inference: 0.2260 s/iter. Eval: 0.1626 s/iter. Total: 0.3920 s/iter. ETA=0:00:10
[08/23 08:55:44 d2.evaluation.evaluator]: Inference done 134/144. Dataloading: 0.0033 s/iter. Inference: 0.2250 s/iter. Eval: 0.1542 s/iter. Total: 0.3827 s/iter. ETA=0:00:03
[08/23 08:55:48 d2.evaluation.evaluator]: Total inference time: 0:00:53.519174 (0.385030 s / iter per device, on 1 devices)
[08/23 08:55:48 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:31 (0.225264 s / iter per device, on 1 devices)
[08/23 08:55:48 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 08:55:48 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 08:55:48 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/23 08:55:48 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 08:55:48 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[08/23 08:55:48 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:55:48 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.480
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.707
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.558
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.163
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.441
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.331
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.600
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.649
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.250
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.618
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.774
[08/23 08:55:48 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.012 | 70.737 | 55.824 | 16.341 | 44.063 | 61.856 |
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
[08/23 08:55:48 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 08:55:48 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.08 seconds.
[08/23 08:55:48 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:55:48 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.488
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.721
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.560
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.165
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.426
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.655
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.335
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.673
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.642
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.789
[08/23 08:55:48 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.849 | 72.116 | 55.959 | 16.530 | 42.583 | 65.539 |
[08/23 08:55:48 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 08:55:48 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 08:55:48 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:55:48 d2.evaluation.testing]: copypaste: 48.0122,70.7375,55.8238,16.3408,44.0632,61.8563
[08/23 08:55:48 d2.evaluation.testing]: copypaste: Task: segm
[08/23 08:55:48 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:55:48 d2.evaluation.testing]: copypaste: 48.8494,72.1160,55.9591,16.5299,42.5835,65.5385
[08/23 08:55:48 d2.utils.events]:  eta: 0:16:20  iter: 479  total_loss: 0.5452  loss_cls: 0.08396  loss_box_reg: 0.2332  loss_mask: 0.1782  loss_rpn_cls: 0.009544  loss_rpn_loc: 0.008319  time: 1.8946  data_time: 0.0224  lr: 0.00011988  max_mem: 10889M
[08/23 08:56:26 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 08:56:26 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 08:56:26 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 08:56:26 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 08:56:26 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 08:56:31 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0019 s/iter. Inference: 0.2207 s/iter. Eval: 0.1192 s/iter. Total: 0.3418 s/iter. ETA=0:00:45
[08/23 08:56:37 d2.evaluation.evaluator]: Inference done 28/144. Dataloading: 0.0029 s/iter. Inference: 0.2216 s/iter. Eval: 0.0992 s/iter. Total: 0.3238 s/iter. ETA=0:00:37
[08/23 08:56:42 d2.evaluation.evaluator]: Inference done 44/144. Dataloading: 0.0034 s/iter. Inference: 0.2226 s/iter. Eval: 0.0999 s/iter. Total: 0.3261 s/iter. ETA=0:00:32
[08/23 08:56:47 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0032 s/iter. Inference: 0.2262 s/iter. Eval: 0.1480 s/iter. Total: 0.3777 s/iter. ETA=0:00:34
[08/23 08:56:52 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0031 s/iter. Inference: 0.2265 s/iter. Eval: 0.1597 s/iter. Total: 0.3896 s/iter. ETA=0:00:30
[08/23 08:56:58 d2.evaluation.evaluator]: Inference done 78/144. Dataloading: 0.0032 s/iter. Inference: 0.2261 s/iter. Eval: 0.1603 s/iter. Total: 0.3898 s/iter. ETA=0:00:25
[08/23 08:57:03 d2.evaluation.evaluator]: Inference done 96/144. Dataloading: 0.0032 s/iter. Inference: 0.2245 s/iter. Eval: 0.1412 s/iter. Total: 0.3691 s/iter. ETA=0:00:17
[08/23 08:57:08 d2.evaluation.evaluator]: Inference done 112/144. Dataloading: 0.0032 s/iter. Inference: 0.2239 s/iter. Eval: 0.1377 s/iter. Total: 0.3650 s/iter. ETA=0:00:11
[08/23 08:57:13 d2.evaluation.evaluator]: Inference done 128/144. Dataloading: 0.0035 s/iter. Inference: 0.2237 s/iter. Eval: 0.1310 s/iter. Total: 0.3585 s/iter. ETA=0:00:05
[08/23 08:57:19 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0035 s/iter. Inference: 0.2233 s/iter. Eval: 0.1297 s/iter. Total: 0.3568 s/iter. ETA=0:00:00
[08/23 08:57:19 d2.evaluation.evaluator]: Total inference time: 0:00:49.672986 (0.357360 s / iter per device, on 1 devices)
[08/23 08:57:19 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:31 (0.223317 s / iter per device, on 1 devices)
[08/23 08:57:19 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 08:57:19 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 08:57:19 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/23 08:57:19 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 08:57:19 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[08/23 08:57:19 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:57:19 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.490
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.719
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.542
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.181
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.437
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.649
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.609
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.651
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.283
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.612
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.786
[08/23 08:57:19 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.033 | 71.871 | 54.197 | 18.110 | 43.721 | 64.893 |
Loading and preparing results...
DONE (t=0.06s)
creating index...
index created!
[08/23 08:57:19 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 08:57:19 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.08 seconds.
[08/23 08:57:19 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:57:19 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.494
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.726
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.568
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.156
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.433
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.660
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.348
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.621
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.672
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.642
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.788
[08/23 08:57:19 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.407 | 72.647 | 56.763 | 15.585 | 43.330 | 65.960 |
[08/23 08:57:19 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 08:57:19 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 08:57:19 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:57:19 d2.evaluation.testing]: copypaste: 49.0332,71.8709,54.1966,18.1098,43.7207,64.8931
[08/23 08:57:19 d2.evaluation.testing]: copypaste: Task: segm
[08/23 08:57:19 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:57:19 d2.evaluation.testing]: copypaste: 49.4074,72.6472,56.7631,15.5855,43.3301,65.9596
[08/23 08:57:19 d2.utils.events]:  eta: 0:15:42  iter: 499  total_loss: 0.5591  loss_cls: 0.1037  loss_box_reg: 0.2169  loss_mask: 0.2134  loss_rpn_cls: 0.007259  loss_rpn_loc: 0.00496  time: 1.8943  data_time: 0.0253  lr: 0.00012488  max_mem: 10889M
[08/23 08:57:57 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 08:57:57 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 08:57:57 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 08:57:57 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 08:57:57 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 08:58:02 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0019 s/iter. Inference: 0.2206 s/iter. Eval: 0.1225 s/iter. Total: 0.3449 s/iter. ETA=0:00:45
[08/23 08:58:08 d2.evaluation.evaluator]: Inference done 28/144. Dataloading: 0.0030 s/iter. Inference: 0.2220 s/iter. Eval: 0.0982 s/iter. Total: 0.3233 s/iter. ETA=0:00:37
[08/23 08:58:13 d2.evaluation.evaluator]: Inference done 45/144. Dataloading: 0.0029 s/iter. Inference: 0.2210 s/iter. Eval: 0.1045 s/iter. Total: 0.3285 s/iter. ETA=0:00:32
[08/23 08:58:18 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0031 s/iter. Inference: 0.2262 s/iter. Eval: 0.1518 s/iter. Total: 0.3814 s/iter. ETA=0:00:34
[08/23 08:58:23 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0030 s/iter. Inference: 0.2265 s/iter. Eval: 0.1596 s/iter. Total: 0.3894 s/iter. ETA=0:00:30
[08/23 08:58:29 d2.evaluation.evaluator]: Inference done 79/144. Dataloading: 0.0030 s/iter. Inference: 0.2260 s/iter. Eval: 0.1588 s/iter. Total: 0.3881 s/iter. ETA=0:00:25
[08/23 08:58:34 d2.evaluation.evaluator]: Inference done 98/144. Dataloading: 0.0029 s/iter. Inference: 0.2240 s/iter. Eval: 0.1374 s/iter. Total: 0.3645 s/iter. ETA=0:00:16
[08/23 08:58:39 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0029 s/iter. Inference: 0.2234 s/iter. Eval: 0.1339 s/iter. Total: 0.3604 s/iter. ETA=0:00:11
[08/23 08:58:44 d2.evaluation.evaluator]: Inference done 130/144. Dataloading: 0.0029 s/iter. Inference: 0.2229 s/iter. Eval: 0.1263 s/iter. Total: 0.3523 s/iter. ETA=0:00:04
[08/23 08:58:49 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0029 s/iter. Inference: 0.2236 s/iter. Eval: 0.1271 s/iter. Total: 0.3538 s/iter. ETA=0:00:00
[08/23 08:58:49 d2.evaluation.evaluator]: Total inference time: 0:00:49.251257 (0.354326 s / iter per device, on 1 devices)
[08/23 08:58:49 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:31 (0.223596 s / iter per device, on 1 devices)
[08/23 08:58:49 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 08:58:49 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 08:58:49 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/23 08:58:49 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 08:58:49 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[08/23 08:58:49 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:58:50 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.500
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.722
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.558
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.199
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.460
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.639
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.351
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.624
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.664
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.625
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.792
[08/23 08:58:50 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.998 | 72.196 | 55.834 | 19.938 | 45.986 | 63.913 |
Loading and preparing results...
DONE (t=0.06s)
creating index...
index created!
[08/23 08:58:50 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 08:58:50 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[08/23 08:58:50 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 08:58:50 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.500
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.729
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.581
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.154
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.436
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.667
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.346
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.627
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.674
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.641
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.789
[08/23 08:58:50 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.957 | 72.948 | 58.131 | 15.426 | 43.583 | 66.664 |
[08/23 08:58:50 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 08:58:50 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 08:58:50 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:58:50 d2.evaluation.testing]: copypaste: 49.9978,72.1962,55.8342,19.9384,45.9861,63.9134
[08/23 08:58:50 d2.evaluation.testing]: copypaste: Task: segm
[08/23 08:58:50 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 08:58:50 d2.evaluation.testing]: copypaste: 49.9565,72.9483,58.1306,15.4260,43.5830,66.6644
[08/23 08:58:50 d2.utils.events]:  eta: 0:15:04  iter: 519  total_loss: 0.4931  loss_cls: 0.07794  loss_box_reg: 0.1574  loss_mask: 0.1737  loss_rpn_cls: 0.007075  loss_rpn_loc: 0.008663  time: 1.8943  data_time: 0.0204  lr: 0.00012987  max_mem: 10889M
[08/23 08:59:28 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 08:59:28 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 08:59:28 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 08:59:28 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 08:59:28 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 08:59:33 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0021 s/iter. Inference: 0.2186 s/iter. Eval: 0.0924 s/iter. Total: 0.3130 s/iter. ETA=0:00:41
[08/23 08:59:38 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0029 s/iter. Inference: 0.2195 s/iter. Eval: 0.0742 s/iter. Total: 0.2968 s/iter. ETA=0:00:34
[08/23 08:59:44 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0028 s/iter. Inference: 0.2198 s/iter. Eval: 0.0913 s/iter. Total: 0.3141 s/iter. ETA=0:00:30
[08/23 08:59:49 d2.evaluation.evaluator]: Inference done 56/144. Dataloading: 0.0028 s/iter. Inference: 0.2222 s/iter. Eval: 0.1279 s/iter. Total: 0.3531 s/iter. ETA=0:00:31
[08/23 08:59:55 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0030 s/iter. Inference: 0.2253 s/iter. Eval: 0.1453 s/iter. Total: 0.3738 s/iter. ETA=0:00:28
[08/23 09:00:00 d2.evaluation.evaluator]: Inference done 86/144. Dataloading: 0.0031 s/iter. Inference: 0.2236 s/iter. Eval: 0.1262 s/iter. Total: 0.3530 s/iter. ETA=0:00:20
[08/23 09:00:05 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0029 s/iter. Inference: 0.2221 s/iter. Eval: 0.1148 s/iter. Total: 0.3400 s/iter. ETA=0:00:13
[08/23 09:00:10 d2.evaluation.evaluator]: Inference done 122/144. Dataloading: 0.0031 s/iter. Inference: 0.2212 s/iter. Eval: 0.1083 s/iter. Total: 0.3328 s/iter. ETA=0:00:07
[08/23 09:00:15 d2.evaluation.evaluator]: Inference done 141/144. Dataloading: 0.0031 s/iter. Inference: 0.2204 s/iter. Eval: 0.1002 s/iter. Total: 0.3238 s/iter. ETA=0:00:00
[08/23 09:00:17 d2.evaluation.evaluator]: Total inference time: 0:00:45.612153 (0.328145 s / iter per device, on 1 devices)
[08/23 09:00:17 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.220632 s / iter per device, on 1 devices)
[08/23 09:00:17 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 09:00:17 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 09:00:17 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/23 09:00:17 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 09:00:17 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/23 09:00:17 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:00:17 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.499
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.719
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.570
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.195
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.452
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.642
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.352
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.611
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.661
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.325
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.630
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.777
[08/23 09:00:17 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.880 | 71.894 | 56.954 | 19.535 | 45.187 | 64.239 |
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
[08/23 09:00:17 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 09:00:17 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[08/23 09:00:17 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:00:17 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.506
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.729
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.585
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.162
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.445
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.669
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.351
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.621
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.666
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.630
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.788
[08/23 09:00:17 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.601 | 72.862 | 58.502 | 16.192 | 44.478 | 66.922 |
[08/23 09:00:17 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 09:00:17 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 09:00:17 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:00:17 d2.evaluation.testing]: copypaste: 49.8802,71.8941,56.9538,19.5347,45.1870,64.2388
[08/23 09:00:17 d2.evaluation.testing]: copypaste: Task: segm
[08/23 09:00:17 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:00:17 d2.evaluation.testing]: copypaste: 50.6010,72.8619,58.5016,16.1921,44.4780,66.9219
[08/23 09:00:17 d2.utils.events]:  eta: 0:14:27  iter: 539  total_loss: 0.5039  loss_cls: 0.09563  loss_box_reg: 0.2171  loss_mask: 0.1497  loss_rpn_cls: 0.00624  loss_rpn_loc: 0.006826  time: 1.8949  data_time: 0.0265  lr: 0.00013487  max_mem: 10889M
[08/23 09:00:55 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 09:00:55 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 09:00:55 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 09:00:55 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 09:00:55 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 09:01:00 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0048 s/iter. Inference: 0.2279 s/iter. Eval: 0.1485 s/iter. Total: 0.3812 s/iter. ETA=0:00:50
[08/23 09:01:05 d2.evaluation.evaluator]: Inference done 28/144. Dataloading: 0.0034 s/iter. Inference: 0.2213 s/iter. Eval: 0.1050 s/iter. Total: 0.3299 s/iter. ETA=0:00:38
[08/23 09:01:11 d2.evaluation.evaluator]: Inference done 45/144. Dataloading: 0.0032 s/iter. Inference: 0.2202 s/iter. Eval: 0.1016 s/iter. Total: 0.3252 s/iter. ETA=0:00:32
[08/23 09:01:16 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0031 s/iter. Inference: 0.2239 s/iter. Eval: 0.1494 s/iter. Total: 0.3766 s/iter. ETA=0:00:34
[08/23 09:01:21 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0030 s/iter. Inference: 0.2245 s/iter. Eval: 0.1586 s/iter. Total: 0.3864 s/iter. ETA=0:00:30
[08/23 09:01:26 d2.evaluation.evaluator]: Inference done 78/144. Dataloading: 0.0031 s/iter. Inference: 0.2253 s/iter. Eval: 0.1607 s/iter. Total: 0.3893 s/iter. ETA=0:00:25
[08/23 09:01:31 d2.evaluation.evaluator]: Inference done 96/144. Dataloading: 0.0032 s/iter. Inference: 0.2240 s/iter. Eval: 0.1405 s/iter. Total: 0.3678 s/iter. ETA=0:00:17
[08/23 09:01:36 d2.evaluation.evaluator]: Inference done 111/144. Dataloading: 0.0033 s/iter. Inference: 0.2241 s/iter. Eval: 0.1371 s/iter. Total: 0.3646 s/iter. ETA=0:00:12
[08/23 09:01:41 d2.evaluation.evaluator]: Inference done 129/144. Dataloading: 0.0032 s/iter. Inference: 0.2229 s/iter. Eval: 0.1271 s/iter. Total: 0.3533 s/iter. ETA=0:00:05
[08/23 09:01:47 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0031 s/iter. Inference: 0.2226 s/iter. Eval: 0.1268 s/iter. Total: 0.3527 s/iter. ETA=0:00:00
[08/23 09:01:47 d2.evaluation.evaluator]: Total inference time: 0:00:49.165119 (0.353706 s / iter per device, on 1 devices)
[08/23 09:01:47 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.222586 s / iter per device, on 1 devices)
[08/23 09:01:47 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 09:01:47 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 09:01:47 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/23 09:01:47 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 09:01:47 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[08/23 09:01:47 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:01:47 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.499
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.725
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.602
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.203
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.446
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.653
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.342
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.611
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.654
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.617
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.785
[08/23 09:01:47 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.910 | 72.537 | 60.154 | 20.335 | 44.646 | 65.295 |
Loading and preparing results...
DONE (t=0.06s)
creating index...
index created!
[08/23 09:01:47 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 09:01:47 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[08/23 09:01:47 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:01:47 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.509
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.732
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.596
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.188
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.444
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.680
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.340
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.626
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.669
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.342
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.638
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.783
[08/23 09:01:47 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.916 | 73.181 | 59.577 | 18.829 | 44.391 | 67.971 |
[08/23 09:01:47 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 09:01:47 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 09:01:47 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:01:47 d2.evaluation.testing]: copypaste: 49.9103,72.5365,60.1536,20.3352,44.6462,65.2955
[08/23 09:01:47 d2.evaluation.testing]: copypaste: Task: segm
[08/23 09:01:47 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:01:47 d2.evaluation.testing]: copypaste: 50.9162,73.1808,59.5775,18.8291,44.3912,67.9706
[08/23 09:01:47 d2.utils.events]:  eta: 0:13:49  iter: 559  total_loss: 0.4629  loss_cls: 0.0812  loss_box_reg: 0.181  loss_mask: 0.1774  loss_rpn_cls: 0.01415  loss_rpn_loc: 0.005743  time: 1.8945  data_time: 0.0244  lr: 0.00013986  max_mem: 10889M
[08/23 09:02:25 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 09:02:25 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 09:02:25 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 09:02:25 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 09:02:25 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 09:02:30 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0020 s/iter. Inference: 0.2180 s/iter. Eval: 0.0876 s/iter. Total: 0.3077 s/iter. ETA=0:00:40
[08/23 09:02:35 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0034 s/iter. Inference: 0.2180 s/iter. Eval: 0.0706 s/iter. Total: 0.2925 s/iter. ETA=0:00:33
[08/23 09:02:40 d2.evaluation.evaluator]: Inference done 45/144. Dataloading: 0.0035 s/iter. Inference: 0.2203 s/iter. Eval: 0.0765 s/iter. Total: 0.3006 s/iter. ETA=0:00:29
[08/23 09:02:45 d2.evaluation.evaluator]: Inference done 54/144. Dataloading: 0.0033 s/iter. Inference: 0.2240 s/iter. Eval: 0.1231 s/iter. Total: 0.3507 s/iter. ETA=0:00:31
[08/23 09:02:50 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0031 s/iter. Inference: 0.2245 s/iter. Eval: 0.1353 s/iter. Total: 0.3632 s/iter. ETA=0:00:27
[08/23 09:02:56 d2.evaluation.evaluator]: Inference done 85/144. Dataloading: 0.0032 s/iter. Inference: 0.2234 s/iter. Eval: 0.1202 s/iter. Total: 0.3470 s/iter. ETA=0:00:20
[08/23 09:03:01 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0031 s/iter. Inference: 0.2218 s/iter. Eval: 0.1080 s/iter. Total: 0.3331 s/iter. ETA=0:00:13
[08/23 09:03:06 d2.evaluation.evaluator]: Inference done 122/144. Dataloading: 0.0031 s/iter. Inference: 0.2213 s/iter. Eval: 0.1009 s/iter. Total: 0.3255 s/iter. ETA=0:00:07
[08/23 09:03:11 d2.evaluation.evaluator]: Inference done 140/144. Dataloading: 0.0031 s/iter. Inference: 0.2210 s/iter. Eval: 0.0953 s/iter. Total: 0.3196 s/iter. ETA=0:00:01
[08/23 09:03:13 d2.evaluation.evaluator]: Total inference time: 0:00:44.910398 (0.323096 s / iter per device, on 1 devices)
[08/23 09:03:13 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.221205 s / iter per device, on 1 devices)
[08/23 09:03:13 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 09:03:13 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 09:03:13 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/23 09:03:13 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 09:03:13 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/23 09:03:13 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:03:13 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.506
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.720
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.593
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.207
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.452
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.669
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.357
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.620
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.665
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.620
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.806
[08/23 09:03:13 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.642 | 71.984 | 59.343 | 20.690 | 45.224 | 66.889 |
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
[08/23 09:03:13 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 09:03:13 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[08/23 09:03:13 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:03:13 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.504
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.736
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.573
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.161
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.446
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.668
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.353
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.624
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.666
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.325
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.631
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.788
[08/23 09:03:13 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.441 | 73.600 | 57.345 | 16.135 | 44.610 | 66.821 |
[08/23 09:03:13 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 09:03:13 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 09:03:13 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:03:13 d2.evaluation.testing]: copypaste: 50.6423,71.9838,59.3429,20.6897,45.2243,66.8889
[08/23 09:03:13 d2.evaluation.testing]: copypaste: Task: segm
[08/23 09:03:13 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:03:13 d2.evaluation.testing]: copypaste: 50.4410,73.6001,57.3450,16.1348,44.6101,66.8206
[08/23 09:03:13 d2.utils.events]:  eta: 0:13:11  iter: 579  total_loss: 0.4598  loss_cls: 0.09022  loss_box_reg: 0.2226  loss_mask: 0.1611  loss_rpn_cls: 0.005264  loss_rpn_loc: 0.005594  time: 1.8947  data_time: 0.0230  lr: 0.00014486  max_mem: 10889M
[08/23 09:03:51 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 09:03:51 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 09:03:51 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 09:03:51 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 09:03:51 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 09:03:55 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0020 s/iter. Inference: 0.2199 s/iter. Eval: 0.0854 s/iter. Total: 0.3073 s/iter. ETA=0:00:40
[08/23 09:04:00 d2.evaluation.evaluator]: Inference done 30/144. Dataloading: 0.0026 s/iter. Inference: 0.2169 s/iter. Eval: 0.0578 s/iter. Total: 0.2775 s/iter. ETA=0:00:31
[08/23 09:04:05 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0027 s/iter. Inference: 0.2175 s/iter. Eval: 0.0727 s/iter. Total: 0.2931 s/iter. ETA=0:00:28
[08/23 09:04:10 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0028 s/iter. Inference: 0.2207 s/iter. Eval: 0.1040 s/iter. Total: 0.3276 s/iter. ETA=0:00:28
[08/23 09:04:16 d2.evaluation.evaluator]: Inference done 69/144. Dataloading: 0.0028 s/iter. Inference: 0.2219 s/iter. Eval: 0.1221 s/iter. Total: 0.3470 s/iter. ETA=0:00:26
[08/23 09:04:21 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0030 s/iter. Inference: 0.2201 s/iter. Eval: 0.1025 s/iter. Total: 0.3258 s/iter. ETA=0:00:17
[08/23 09:04:26 d2.evaluation.evaluator]: Inference done 108/144. Dataloading: 0.0032 s/iter. Inference: 0.2193 s/iter. Eval: 0.0929 s/iter. Total: 0.3157 s/iter. ETA=0:00:11
[08/23 09:04:31 d2.evaluation.evaluator]: Inference done 128/144. Dataloading: 0.0033 s/iter. Inference: 0.2184 s/iter. Eval: 0.0844 s/iter. Total: 0.3062 s/iter. ETA=0:00:04
[08/23 09:04:36 d2.evaluation.evaluator]: Total inference time: 0:00:42.626544 (0.306666 s / iter per device, on 1 devices)
[08/23 09:04:36 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.218435 s / iter per device, on 1 devices)
[08/23 09:04:36 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 09:04:36 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 09:04:36 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/23 09:04:36 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 09:04:36 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[08/23 09:04:36 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:04:36 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.502
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.723
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.588
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.187
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.454
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.656
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.355
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.652
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.283
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.606
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.798
[08/23 09:04:36 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.230 | 72.343 | 58.771 | 18.683 | 45.412 | 65.649 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[08/23 09:04:36 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 09:04:36 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/23 09:04:36 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:04:36 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.511
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.734
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.586
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.179
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.454
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.671
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.356
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.634
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.667
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.630
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.788
[08/23 09:04:36 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.117 | 73.382 | 58.568 | 17.932 | 45.381 | 67.053 |
[08/23 09:04:36 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 09:04:36 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 09:04:36 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:04:36 d2.evaluation.testing]: copypaste: 50.2297,72.3431,58.7711,18.6832,45.4119,65.6494
[08/23 09:04:36 d2.evaluation.testing]: copypaste: Task: segm
[08/23 09:04:36 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:04:36 d2.evaluation.testing]: copypaste: 51.1174,73.3816,58.5677,17.9325,45.3809,67.0528
[08/23 09:04:36 d2.utils.events]:  eta: 0:12:33  iter: 599  total_loss: 0.5068  loss_cls: 0.07684  loss_box_reg: 0.14  loss_mask: 0.1891  loss_rpn_cls: 0.006177  loss_rpn_loc: 0.007047  time: 1.8946  data_time: 0.0236  lr: 0.00014985  max_mem: 10889M
[08/23 09:05:14 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 09:05:14 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 09:05:14 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 09:05:14 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 09:05:14 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 09:05:19 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0021 s/iter. Inference: 0.2199 s/iter. Eval: 0.1129 s/iter. Total: 0.3349 s/iter. ETA=0:00:44
[08/23 09:05:25 d2.evaluation.evaluator]: Inference done 28/144. Dataloading: 0.0028 s/iter. Inference: 0.2225 s/iter. Eval: 0.0975 s/iter. Total: 0.3229 s/iter. ETA=0:00:37
[08/23 09:05:30 d2.evaluation.evaluator]: Inference done 45/144. Dataloading: 0.0029 s/iter. Inference: 0.2224 s/iter. Eval: 0.0964 s/iter. Total: 0.3218 s/iter. ETA=0:00:31
[08/23 09:05:36 d2.evaluation.evaluator]: Inference done 54/144. Dataloading: 0.0029 s/iter. Inference: 0.2261 s/iter. Eval: 0.1448 s/iter. Total: 0.3740 s/iter. ETA=0:00:33
[08/23 09:05:41 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0029 s/iter. Inference: 0.2267 s/iter. Eval: 0.1584 s/iter. Total: 0.3881 s/iter. ETA=0:00:29
[08/23 09:05:46 d2.evaluation.evaluator]: Inference done 82/144. Dataloading: 0.0028 s/iter. Inference: 0.2255 s/iter. Eval: 0.1495 s/iter. Total: 0.3780 s/iter. ETA=0:00:23
[08/23 09:05:52 d2.evaluation.evaluator]: Inference done 100/144. Dataloading: 0.0030 s/iter. Inference: 0.2240 s/iter. Eval: 0.1327 s/iter. Total: 0.3599 s/iter. ETA=0:00:15
[08/23 09:05:57 d2.evaluation.evaluator]: Inference done 116/144. Dataloading: 0.0030 s/iter. Inference: 0.2240 s/iter. Eval: 0.1281 s/iter. Total: 0.3552 s/iter. ETA=0:00:09
[08/23 09:06:02 d2.evaluation.evaluator]: Inference done 134/144. Dataloading: 0.0030 s/iter. Inference: 0.2231 s/iter. Eval: 0.1192 s/iter. Total: 0.3455 s/iter. ETA=0:00:03
[08/23 09:06:06 d2.evaluation.evaluator]: Total inference time: 0:00:48.206941 (0.346813 s / iter per device, on 1 devices)
[08/23 09:06:06 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.222932 s / iter per device, on 1 devices)
[08/23 09:06:06 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 09:06:06 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 09:06:06 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/23 09:06:06 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 09:06:06 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[08/23 09:06:06 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:06:06 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.502
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.729
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.579
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.210
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.450
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.656
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.348
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.661
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.626
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.785
[08/23 09:06:06 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.177 | 72.899 | 57.897 | 20.989 | 45.002 | 65.558 |
Loading and preparing results...
DONE (t=0.06s)
creating index...
index created!
[08/23 09:06:06 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 09:06:06 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[08/23 09:06:06 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:06:06 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.509
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.736
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.585
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.159
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.447
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.679
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.347
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.628
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.674
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.643
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.786
[08/23 09:06:06 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.943 | 73.605 | 58.548 | 15.945 | 44.725 | 67.905 |
[08/23 09:06:06 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 09:06:06 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 09:06:06 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:06:06 d2.evaluation.testing]: copypaste: 50.1770,72.8995,57.8971,20.9893,45.0024,65.5578
[08/23 09:06:06 d2.evaluation.testing]: copypaste: Task: segm
[08/23 09:06:06 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:06:06 d2.evaluation.testing]: copypaste: 50.9433,73.6051,58.5484,15.9450,44.7248,67.9050
[08/23 09:06:06 d2.utils.events]:  eta: 0:11:55  iter: 619  total_loss: 0.5599  loss_cls: 0.1038  loss_box_reg: 0.2069  loss_mask: 0.1848  loss_rpn_cls: 0.01213  loss_rpn_loc: 0.00835  time: 1.8947  data_time: 0.0269  lr: 0.00015485  max_mem: 10889M
[08/23 09:06:44 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 09:06:44 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 09:06:44 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 09:06:44 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 09:06:44 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 09:06:49 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0019 s/iter. Inference: 0.2181 s/iter. Eval: 0.0834 s/iter. Total: 0.3034 s/iter. ETA=0:00:40
[08/23 09:06:54 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0027 s/iter. Inference: 0.2170 s/iter. Eval: 0.0689 s/iter. Total: 0.2888 s/iter. ETA=0:00:33
[08/23 09:06:59 d2.evaluation.evaluator]: Inference done 45/144. Dataloading: 0.0031 s/iter. Inference: 0.2181 s/iter. Eval: 0.0785 s/iter. Total: 0.2998 s/iter. ETA=0:00:29
[08/23 09:07:04 d2.evaluation.evaluator]: Inference done 54/144. Dataloading: 0.0030 s/iter. Inference: 0.2222 s/iter. Eval: 0.1287 s/iter. Total: 0.3540 s/iter. ETA=0:00:31
[08/23 09:07:10 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0031 s/iter. Inference: 0.2238 s/iter. Eval: 0.1429 s/iter. Total: 0.3699 s/iter. ETA=0:00:28
[08/23 09:07:15 d2.evaluation.evaluator]: Inference done 84/144. Dataloading: 0.0030 s/iter. Inference: 0.2225 s/iter. Eval: 0.1280 s/iter. Total: 0.3537 s/iter. ETA=0:00:21
[08/23 09:07:20 d2.evaluation.evaluator]: Inference done 103/144. Dataloading: 0.0031 s/iter. Inference: 0.2213 s/iter. Eval: 0.1148 s/iter. Total: 0.3394 s/iter. ETA=0:00:13
[08/23 09:07:26 d2.evaluation.evaluator]: Inference done 122/144. Dataloading: 0.0032 s/iter. Inference: 0.2204 s/iter. Eval: 0.1056 s/iter. Total: 0.3294 s/iter. ETA=0:00:07
[08/23 09:07:31 d2.evaluation.evaluator]: Inference done 141/144. Dataloading: 0.0035 s/iter. Inference: 0.2199 s/iter. Eval: 0.0976 s/iter. Total: 0.3212 s/iter. ETA=0:00:00
[08/23 09:07:33 d2.evaluation.evaluator]: Total inference time: 0:00:45.562730 (0.327789 s / iter per device, on 1 devices)
[08/23 09:07:33 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.220288 s / iter per device, on 1 devices)
[08/23 09:07:33 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 09:07:33 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 09:07:33 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/23 09:07:33 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 09:07:33 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/23 09:07:33 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:07:33 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.511
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.730
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.580
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.201
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.456
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.670
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.364
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.621
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.660
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.308
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.617
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.800
[08/23 09:07:33 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.065 | 72.967 | 57.975 | 20.118 | 45.645 | 67.029 |
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
[08/23 09:07:33 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 09:07:33 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/23 09:07:33 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:07:33 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.514
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.744
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.588
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.181
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.456
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.676
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.357
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.627
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.670
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.367
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.637
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.783
[08/23 09:07:33 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.444 | 74.447 | 58.849 | 18.128 | 45.615 | 67.624 |
[08/23 09:07:33 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 09:07:33 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 09:07:33 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:07:33 d2.evaluation.testing]: copypaste: 51.0654,72.9673,57.9752,20.1184,45.6449,67.0293
[08/23 09:07:33 d2.evaluation.testing]: copypaste: Task: segm
[08/23 09:07:33 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:07:33 d2.evaluation.testing]: copypaste: 51.4438,74.4468,58.8492,18.1276,45.6152,67.6236
[08/23 09:07:33 d2.utils.events]:  eta: 0:11:18  iter: 639  total_loss: 0.4417  loss_cls: 0.07573  loss_box_reg: 0.1974  loss_mask: 0.1696  loss_rpn_cls: 0.006887  loss_rpn_loc: 0.005359  time: 1.8951  data_time: 0.0235  lr: 0.00015984  max_mem: 10889M
[08/23 09:08:11 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 09:08:11 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 09:08:11 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 09:08:11 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 09:08:11 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 09:08:16 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0030 s/iter. Inference: 0.2183 s/iter. Eval: 0.0933 s/iter. Total: 0.3146 s/iter. ETA=0:00:41
[08/23 09:08:21 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0031 s/iter. Inference: 0.2163 s/iter. Eval: 0.0686 s/iter. Total: 0.2881 s/iter. ETA=0:00:33
[08/23 09:08:26 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0029 s/iter. Inference: 0.2189 s/iter. Eval: 0.0857 s/iter. Total: 0.3076 s/iter. ETA=0:00:30
[08/23 09:08:32 d2.evaluation.evaluator]: Inference done 56/144. Dataloading: 0.0029 s/iter. Inference: 0.2219 s/iter. Eval: 0.1284 s/iter. Total: 0.3533 s/iter. ETA=0:00:31
[08/23 09:08:37 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0029 s/iter. Inference: 0.2238 s/iter. Eval: 0.1440 s/iter. Total: 0.3709 s/iter. ETA=0:00:28
[08/23 09:08:42 d2.evaluation.evaluator]: Inference done 85/144. Dataloading: 0.0034 s/iter. Inference: 0.2232 s/iter. Eval: 0.1284 s/iter. Total: 0.3552 s/iter. ETA=0:00:20
[08/23 09:08:47 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0035 s/iter. Inference: 0.2221 s/iter. Eval: 0.1148 s/iter. Total: 0.3406 s/iter. ETA=0:00:13
[08/23 09:08:53 d2.evaluation.evaluator]: Inference done 123/144. Dataloading: 0.0033 s/iter. Inference: 0.2210 s/iter. Eval: 0.1046 s/iter. Total: 0.3290 s/iter. ETA=0:00:06
[08/23 09:08:58 d2.evaluation.evaluator]: Inference done 142/144. Dataloading: 0.0032 s/iter. Inference: 0.2206 s/iter. Eval: 0.0981 s/iter. Total: 0.3221 s/iter. ETA=0:00:00
[08/23 09:08:59 d2.evaluation.evaluator]: Total inference time: 0:00:45.214602 (0.325285 s / iter per device, on 1 devices)
[08/23 09:08:59 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.220783 s / iter per device, on 1 devices)
[08/23 09:08:59 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 09:08:59 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 09:08:59 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/23 09:08:59 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 09:08:59 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[08/23 09:08:59 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:08:59 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.510
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.738
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.615
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.207
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.468
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.652
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.362
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.612
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.660
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.292
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.621
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.795
[08/23 09:08:59 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.001 | 73.797 | 61.462 | 20.653 | 46.784 | 65.218 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[08/23 09:08:59 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 09:08:59 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/23 09:08:59 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:08:59 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.524
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.753
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.599
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.164
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.467
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.686
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.363
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.631
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.676
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.342
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.647
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.788
[08/23 09:08:59 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.402 | 75.342 | 59.876 | 16.427 | 46.730 | 68.601 |
[08/23 09:08:59 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 09:08:59 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 09:08:59 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:08:59 d2.evaluation.testing]: copypaste: 51.0013,73.7969,61.4623,20.6533,46.7838,65.2181
[08/23 09:08:59 d2.evaluation.testing]: copypaste: Task: segm
[08/23 09:08:59 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:08:59 d2.evaluation.testing]: copypaste: 52.4021,75.3417,59.8763,16.4274,46.7301,68.6010
[08/23 09:08:59 d2.utils.events]:  eta: 0:10:40  iter: 659  total_loss: 0.5056  loss_cls: 0.09691  loss_box_reg: 0.1781  loss_mask: 0.1895  loss_rpn_cls: 0.005057  loss_rpn_loc: 0.008125  time: 1.8950  data_time: 0.0258  lr: 0.00016484  max_mem: 10889M
[08/23 09:09:37 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 09:09:37 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 09:09:37 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 09:09:37 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 09:09:37 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 09:09:42 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0022 s/iter. Inference: 0.2175 s/iter. Eval: 0.0870 s/iter. Total: 0.3067 s/iter. ETA=0:00:40
[08/23 09:09:47 d2.evaluation.evaluator]: Inference done 28/144. Dataloading: 0.0035 s/iter. Inference: 0.2222 s/iter. Eval: 0.0805 s/iter. Total: 0.3063 s/iter. ETA=0:00:35
[08/23 09:09:52 d2.evaluation.evaluator]: Inference done 45/144. Dataloading: 0.0038 s/iter. Inference: 0.2213 s/iter. Eval: 0.0816 s/iter. Total: 0.3068 s/iter. ETA=0:00:30
[08/23 09:09:58 d2.evaluation.evaluator]: Inference done 54/144. Dataloading: 0.0036 s/iter. Inference: 0.2249 s/iter. Eval: 0.1299 s/iter. Total: 0.3586 s/iter. ETA=0:00:32
[08/23 09:10:03 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0035 s/iter. Inference: 0.2260 s/iter. Eval: 0.1422 s/iter. Total: 0.3719 s/iter. ETA=0:00:28
[08/23 09:10:08 d2.evaluation.evaluator]: Inference done 85/144. Dataloading: 0.0034 s/iter. Inference: 0.2238 s/iter. Eval: 0.1258 s/iter. Total: 0.3531 s/iter. ETA=0:00:20
[08/23 09:10:13 d2.evaluation.evaluator]: Inference done 103/144. Dataloading: 0.0032 s/iter. Inference: 0.2225 s/iter. Eval: 0.1134 s/iter. Total: 0.3393 s/iter. ETA=0:00:13
[08/23 09:10:19 d2.evaluation.evaluator]: Inference done 121/144. Dataloading: 0.0032 s/iter. Inference: 0.2227 s/iter. Eval: 0.1052 s/iter. Total: 0.3313 s/iter. ETA=0:00:07
[08/23 09:10:24 d2.evaluation.evaluator]: Inference done 140/144. Dataloading: 0.0031 s/iter. Inference: 0.2217 s/iter. Eval: 0.0970 s/iter. Total: 0.3220 s/iter. ETA=0:00:01
[08/23 09:10:26 d2.evaluation.evaluator]: Total inference time: 0:00:45.369644 (0.326400 s / iter per device, on 1 devices)
[08/23 09:10:26 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.221947 s / iter per device, on 1 devices)
[08/23 09:10:26 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 09:10:26 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 09:10:26 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/23 09:10:26 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 09:10:26 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/23 09:10:26 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:10:26 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.508
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.734
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.605
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.201
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.465
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.659
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.361
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.661
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.267
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.625
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.794
[08/23 09:10:26 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.821 | 73.423 | 60.488 | 20.066 | 46.495 | 65.921 |
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
[08/23 09:10:26 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 09:10:26 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/23 09:10:26 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:10:26 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.519
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.751
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.576
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.162
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.462
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.684
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.362
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.630
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.674
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.308
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.644
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.791
[08/23 09:10:26 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.863 | 75.132 | 57.608 | 16.185 | 46.226 | 68.373 |
[08/23 09:10:26 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 09:10:26 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 09:10:26 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:10:26 d2.evaluation.testing]: copypaste: 50.8213,73.4229,60.4883,20.0665,46.4948,65.9212
[08/23 09:10:26 d2.evaluation.testing]: copypaste: Task: segm
[08/23 09:10:26 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:10:26 d2.evaluation.testing]: copypaste: 51.8632,75.1322,57.6079,16.1846,46.2261,68.3726
[08/23 09:10:26 d2.utils.events]:  eta: 0:10:03  iter: 679  total_loss: 0.4154  loss_cls: 0.07817  loss_box_reg: 0.1685  loss_mask: 0.1539  loss_rpn_cls: 0.006153  loss_rpn_loc: 0.003788  time: 1.8951  data_time: 0.0255  lr: 0.00016983  max_mem: 10889M
[08/23 09:11:03 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 09:11:03 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 09:11:03 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 09:11:03 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 09:11:03 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 09:11:08 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0024 s/iter. Inference: 0.2176 s/iter. Eval: 0.0784 s/iter. Total: 0.2985 s/iter. ETA=0:00:39
[08/23 09:11:13 d2.evaluation.evaluator]: Inference done 30/144. Dataloading: 0.0024 s/iter. Inference: 0.2163 s/iter. Eval: 0.0579 s/iter. Total: 0.2769 s/iter. ETA=0:00:31
[08/23 09:11:18 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0024 s/iter. Inference: 0.2172 s/iter. Eval: 0.0753 s/iter. Total: 0.2952 s/iter. ETA=0:00:28
[08/23 09:11:23 d2.evaluation.evaluator]: Inference done 56/144. Dataloading: 0.0024 s/iter. Inference: 0.2202 s/iter. Eval: 0.1138 s/iter. Total: 0.3367 s/iter. ETA=0:00:29
[08/23 09:11:28 d2.evaluation.evaluator]: Inference done 69/144. Dataloading: 0.0026 s/iter. Inference: 0.2217 s/iter. Eval: 0.1267 s/iter. Total: 0.3514 s/iter. ETA=0:00:26
[08/23 09:11:34 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0028 s/iter. Inference: 0.2204 s/iter. Eval: 0.1065 s/iter. Total: 0.3299 s/iter. ETA=0:00:18
[08/23 09:11:39 d2.evaluation.evaluator]: Inference done 108/144. Dataloading: 0.0027 s/iter. Inference: 0.2193 s/iter. Eval: 0.0957 s/iter. Total: 0.3179 s/iter. ETA=0:00:11
[08/23 09:11:44 d2.evaluation.evaluator]: Inference done 128/144. Dataloading: 0.0029 s/iter. Inference: 0.2185 s/iter. Eval: 0.0865 s/iter. Total: 0.3081 s/iter. ETA=0:00:04
[08/23 09:11:49 d2.evaluation.evaluator]: Total inference time: 0:00:42.721806 (0.307351 s / iter per device, on 1 devices)
[08/23 09:11:49 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.218273 s / iter per device, on 1 devices)
[08/23 09:11:49 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 09:11:49 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 09:11:49 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/23 09:11:49 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 09:11:49 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/23 09:11:49 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:11:49 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.515
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.733
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.600
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.208
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.470
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.671
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.365
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.621
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.659
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.275
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.805
[08/23 09:11:49 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.478 | 73.300 | 60.048 | 20.830 | 46.956 | 67.061 |
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
[08/23 09:11:49 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 09:11:49 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[08/23 09:11:49 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:11:49 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.521
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.751
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.582
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.158
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.463
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.686
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.363
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.629
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.667
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.632
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.791
[08/23 09:11:49 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.105 | 75.130 | 58.195 | 15.793 | 46.315 | 68.616 |
[08/23 09:11:49 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 09:11:49 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 09:11:49 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:11:49 d2.evaluation.testing]: copypaste: 51.4783,73.3004,60.0482,20.8305,46.9564,67.0606
[08/23 09:11:49 d2.evaluation.testing]: copypaste: Task: segm
[08/23 09:11:49 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:11:49 d2.evaluation.testing]: copypaste: 52.1046,75.1297,58.1953,15.7925,46.3146,68.6162
[08/23 09:11:49 d2.utils.events]:  eta: 0:09:25  iter: 699  total_loss: 0.4084  loss_cls: 0.05594  loss_box_reg: 0.1446  loss_mask: 0.1596  loss_rpn_cls: 0.003326  loss_rpn_loc: 0.009854  time: 1.8944  data_time: 0.0219  lr: 0.00017483  max_mem: 10889M
[08/23 09:12:27 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 09:12:27 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 09:12:27 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 09:12:27 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 09:12:27 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 09:12:32 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0019 s/iter. Inference: 0.2166 s/iter. Eval: 0.0742 s/iter. Total: 0.2928 s/iter. ETA=0:00:38
[08/23 09:12:37 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0031 s/iter. Inference: 0.2177 s/iter. Eval: 0.0637 s/iter. Total: 0.2847 s/iter. ETA=0:00:32
[08/23 09:12:42 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0031 s/iter. Inference: 0.2178 s/iter. Eval: 0.0766 s/iter. Total: 0.2976 s/iter. ETA=0:00:29
[08/23 09:12:47 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0031 s/iter. Inference: 0.2204 s/iter. Eval: 0.1099 s/iter. Total: 0.3336 s/iter. ETA=0:00:29
[08/23 09:12:53 d2.evaluation.evaluator]: Inference done 70/144. Dataloading: 0.0030 s/iter. Inference: 0.2216 s/iter. Eval: 0.1241 s/iter. Total: 0.3488 s/iter. ETA=0:00:25
[08/23 09:12:58 d2.evaluation.evaluator]: Inference done 90/144. Dataloading: 0.0029 s/iter. Inference: 0.2200 s/iter. Eval: 0.1050 s/iter. Total: 0.3281 s/iter. ETA=0:00:17
[08/23 09:13:03 d2.evaluation.evaluator]: Inference done 108/144. Dataloading: 0.0031 s/iter. Inference: 0.2204 s/iter. Eval: 0.0975 s/iter. Total: 0.3212 s/iter. ETA=0:00:11
[08/23 09:13:08 d2.evaluation.evaluator]: Inference done 128/144. Dataloading: 0.0030 s/iter. Inference: 0.2192 s/iter. Eval: 0.0877 s/iter. Total: 0.3100 s/iter. ETA=0:00:04
[08/23 09:13:13 d2.evaluation.evaluator]: Total inference time: 0:00:43.130855 (0.310294 s / iter per device, on 1 devices)
[08/23 09:13:13 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.219100 s / iter per device, on 1 devices)
[08/23 09:13:13 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 09:13:13 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 09:13:13 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/23 09:13:13 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 09:13:13 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/23 09:13:13 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:13:13 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.512
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.743
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.603
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.198
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.466
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.665
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.362
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.614
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.655
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.275
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.618
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.788
[08/23 09:13:13 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.153 | 74.290 | 60.265 | 19.820 | 46.589 | 66.505 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[08/23 09:13:13 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 09:13:13 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/23 09:13:13 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:13:13 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.525
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.754
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.590
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.163
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.469
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.688
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.364
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.636
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.674
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.642
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.792
[08/23 09:13:13 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.483 | 75.443 | 59.039 | 16.316 | 46.945 | 68.751 |
[08/23 09:13:13 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 09:13:13 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 09:13:13 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:13:13 d2.evaluation.testing]: copypaste: 51.1533,74.2899,60.2649,19.8203,46.5893,66.5053
[08/23 09:13:13 d2.evaluation.testing]: copypaste: Task: segm
[08/23 09:13:13 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:13:13 d2.evaluation.testing]: copypaste: 52.4825,75.4428,59.0391,16.3155,46.9451,68.7512
[08/23 09:13:13 d2.utils.events]:  eta: 0:08:47  iter: 719  total_loss: 0.4786  loss_cls: 0.08754  loss_box_reg: 0.1874  loss_mask: 0.1673  loss_rpn_cls: 0.007769  loss_rpn_loc: 0.006182  time: 1.8944  data_time: 0.0228  lr: 0.00017982  max_mem: 10889M
[08/23 09:13:51 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 09:13:51 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 09:13:51 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 09:13:51 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 09:13:51 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 09:13:56 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0024 s/iter. Inference: 0.2175 s/iter. Eval: 0.0763 s/iter. Total: 0.2962 s/iter. ETA=0:00:39
[08/23 09:14:01 d2.evaluation.evaluator]: Inference done 30/144. Dataloading: 0.0022 s/iter. Inference: 0.2145 s/iter. Eval: 0.0585 s/iter. Total: 0.2754 s/iter. ETA=0:00:31
[08/23 09:14:06 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0024 s/iter. Inference: 0.2172 s/iter. Eval: 0.0806 s/iter. Total: 0.3004 s/iter. ETA=0:00:29
[08/23 09:14:11 d2.evaluation.evaluator]: Inference done 56/144. Dataloading: 0.0024 s/iter. Inference: 0.2207 s/iter. Eval: 0.1197 s/iter. Total: 0.3430 s/iter. ETA=0:00:30
[08/23 09:14:17 d2.evaluation.evaluator]: Inference done 69/144. Dataloading: 0.0029 s/iter. Inference: 0.2218 s/iter. Eval: 0.1305 s/iter. Total: 0.3553 s/iter. ETA=0:00:26
[08/23 09:14:22 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0029 s/iter. Inference: 0.2197 s/iter. Eval: 0.1094 s/iter. Total: 0.3322 s/iter. ETA=0:00:18
[08/23 09:14:27 d2.evaluation.evaluator]: Inference done 108/144. Dataloading: 0.0029 s/iter. Inference: 0.2190 s/iter. Eval: 0.0998 s/iter. Total: 0.3219 s/iter. ETA=0:00:11
[08/23 09:14:32 d2.evaluation.evaluator]: Inference done 128/144. Dataloading: 0.0029 s/iter. Inference: 0.2179 s/iter. Eval: 0.0895 s/iter. Total: 0.3105 s/iter. ETA=0:00:04
[08/23 09:14:37 d2.evaluation.evaluator]: Total inference time: 0:00:43.166011 (0.310547 s / iter per device, on 1 devices)
[08/23 09:14:37 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.217773 s / iter per device, on 1 devices)
[08/23 09:14:37 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 09:14:37 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 09:14:37 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/23 09:14:37 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 09:14:37 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/23 09:14:37 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:14:37 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.514
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.756
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.598
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.222
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.465
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.673
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.368
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.661
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.308
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.805
[08/23 09:14:37 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.411 | 75.643 | 59.828 | 22.154 | 46.467 | 67.272 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[08/23 09:14:37 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 09:14:37 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/23 09:14:37 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:14:37 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.526
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.754
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.605
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.186
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.473
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.683
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.364
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.632
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.679
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.392
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.648
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.785
[08/23 09:14:37 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.617 | 75.383 | 60.534 | 18.586 | 47.327 | 68.294 |
[08/23 09:14:37 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 09:14:37 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 09:14:37 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:14:37 d2.evaluation.testing]: copypaste: 51.4105,75.6434,59.8278,22.1542,46.4668,67.2719
[08/23 09:14:37 d2.evaluation.testing]: copypaste: Task: segm
[08/23 09:14:37 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:14:37 d2.evaluation.testing]: copypaste: 52.6172,75.3835,60.5337,18.5857,47.3269,68.2943
[08/23 09:14:38 d2.utils.events]:  eta: 0:08:10  iter: 739  total_loss: 0.442  loss_cls: 0.07658  loss_box_reg: 0.1886  loss_mask: 0.1879  loss_rpn_cls: 0.005303  loss_rpn_loc: 0.007695  time: 1.8945  data_time: 0.0254  lr: 0.00018482  max_mem: 10889M
[08/23 09:15:16 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 09:15:16 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 09:15:16 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 09:15:16 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 09:15:16 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 09:15:20 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0017 s/iter. Inference: 0.2141 s/iter. Eval: 0.0579 s/iter. Total: 0.2737 s/iter. ETA=0:00:36
[08/23 09:15:25 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0029 s/iter. Inference: 0.2163 s/iter. Eval: 0.0403 s/iter. Total: 0.2596 s/iter. ETA=0:00:29
[08/23 09:15:30 d2.evaluation.evaluator]: Inference done 48/144. Dataloading: 0.0026 s/iter. Inference: 0.2165 s/iter. Eval: 0.0586 s/iter. Total: 0.2779 s/iter. ETA=0:00:26
[08/23 09:15:35 d2.evaluation.evaluator]: Inference done 61/144. Dataloading: 0.0029 s/iter. Inference: 0.2186 s/iter. Eval: 0.0821 s/iter. Total: 0.3037 s/iter. ETA=0:00:25
[08/23 09:15:40 d2.evaluation.evaluator]: Inference done 79/144. Dataloading: 0.0028 s/iter. Inference: 0.2179 s/iter. Eval: 0.0795 s/iter. Total: 0.3003 s/iter. ETA=0:00:19
[08/23 09:15:46 d2.evaluation.evaluator]: Inference done 100/144. Dataloading: 0.0029 s/iter. Inference: 0.2176 s/iter. Eval: 0.0703 s/iter. Total: 0.2909 s/iter. ETA=0:00:12
[08/23 09:15:51 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0030 s/iter. Inference: 0.2177 s/iter. Eval: 0.0668 s/iter. Total: 0.2876 s/iter. ETA=0:00:07
[08/23 09:15:56 d2.evaluation.evaluator]: Inference done 139/144. Dataloading: 0.0030 s/iter. Inference: 0.2176 s/iter. Eval: 0.0616 s/iter. Total: 0.2824 s/iter. ETA=0:00:01
[08/23 09:15:57 d2.evaluation.evaluator]: Total inference time: 0:00:39.572081 (0.284691 s / iter per device, on 1 devices)
[08/23 09:15:57 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.217622 s / iter per device, on 1 devices)
[08/23 09:15:57 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 09:15:57 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 09:15:57 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/23 09:15:58 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 09:15:58 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/23 09:15:58 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:15:58 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.497
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.744
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.597
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.225
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.465
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.628
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.599
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.633
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.308
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.594
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.759
[08/23 09:15:58 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.696 | 74.418 | 59.684 | 22.506 | 46.508 | 62.767 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[08/23 09:15:58 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 09:15:58 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[08/23 09:15:58 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:15:58 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.532
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.754
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.605
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.185
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.484
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.686
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.372
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.633
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.664
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.626
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.785
[08/23 09:15:58 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 53.233 | 75.436 | 60.516 | 18.541 | 48.360 | 68.556 |
[08/23 09:15:58 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 09:15:58 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 09:15:58 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:15:58 d2.evaluation.testing]: copypaste: 49.6956,74.4177,59.6836,22.5065,46.5076,62.7674
[08/23 09:15:58 d2.evaluation.testing]: copypaste: Task: segm
[08/23 09:15:58 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:15:58 d2.evaluation.testing]: copypaste: 53.2328,75.4357,60.5155,18.5406,48.3600,68.5557
[08/23 09:15:58 d2.utils.events]:  eta: 0:07:32  iter: 759  total_loss: 0.3375  loss_cls: 0.0591  loss_box_reg: 0.15  loss_mask: 0.1366  loss_rpn_cls: 0.003208  loss_rpn_loc: 0.003611  time: 1.8947  data_time: 0.0260  lr: 0.00018981  max_mem: 10889M
[08/23 09:16:36 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 09:16:36 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 09:16:36 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 09:16:36 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 09:16:36 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 09:16:40 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0019 s/iter. Inference: 0.2156 s/iter. Eval: 0.0650 s/iter. Total: 0.2826 s/iter. ETA=0:00:37
[08/23 09:16:45 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0027 s/iter. Inference: 0.2137 s/iter. Eval: 0.0456 s/iter. Total: 0.2622 s/iter. ETA=0:00:29
[08/23 09:16:51 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0028 s/iter. Inference: 0.2170 s/iter. Eval: 0.0734 s/iter. Total: 0.2934 s/iter. ETA=0:00:28
[08/23 09:16:56 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0030 s/iter. Inference: 0.2212 s/iter. Eval: 0.1078 s/iter. Total: 0.3321 s/iter. ETA=0:00:28
[08/23 09:17:01 d2.evaluation.evaluator]: Inference done 74/144. Dataloading: 0.0032 s/iter. Inference: 0.2214 s/iter. Eval: 0.1078 s/iter. Total: 0.3327 s/iter. ETA=0:00:23
[08/23 09:17:06 d2.evaluation.evaluator]: Inference done 94/144. Dataloading: 0.0031 s/iter. Inference: 0.2196 s/iter. Eval: 0.0914 s/iter. Total: 0.3142 s/iter. ETA=0:00:15
[08/23 09:17:11 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0030 s/iter. Inference: 0.2192 s/iter. Eval: 0.0841 s/iter. Total: 0.3065 s/iter. ETA=0:00:09
[08/23 09:17:17 d2.evaluation.evaluator]: Inference done 134/144. Dataloading: 0.0031 s/iter. Inference: 0.2182 s/iter. Eval: 0.0758 s/iter. Total: 0.2972 s/iter. ETA=0:00:02
[08/23 09:17:20 d2.evaluation.evaluator]: Total inference time: 0:00:41.438637 (0.298120 s / iter per device, on 1 devices)
[08/23 09:17:20 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.218111 s / iter per device, on 1 devices)
[08/23 09:17:20 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 09:17:20 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 09:17:20 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/23 09:17:20 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 09:17:20 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/23 09:17:20 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:17:20 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.515
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.744
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.588
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.212
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.464
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.670
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.367
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.649
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.597
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.803
[08/23 09:17:20 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.471 | 74.426 | 58.793 | 21.247 | 46.409 | 67.047 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[08/23 09:17:20 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 09:17:20 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/23 09:17:20 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:17:20 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.524
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.754
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.585
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.123
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.474
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.683
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.365
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.628
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.660
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.325
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.785
[08/23 09:17:20 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.355 | 75.414 | 58.473 | 12.319 | 47.412 | 68.318 |
[08/23 09:17:20 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 09:17:20 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 09:17:20 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:17:20 d2.evaluation.testing]: copypaste: 51.4707,74.4263,58.7930,21.2471,46.4090,67.0466
[08/23 09:17:20 d2.evaluation.testing]: copypaste: Task: segm
[08/23 09:17:20 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:17:20 d2.evaluation.testing]: copypaste: 52.3550,75.4137,58.4728,12.3194,47.4122,68.3182
[08/23 09:17:20 d2.utils.events]:  eta: 0:06:54  iter: 779  total_loss: 0.5188  loss_cls: 0.1093  loss_box_reg: 0.1941  loss_mask: 0.1935  loss_rpn_cls: 0.005428  loss_rpn_loc: 0.009814  time: 1.8947  data_time: 0.0242  lr: 0.00019481  max_mem: 10889M
[08/23 09:17:58 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 09:17:58 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 09:17:58 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 09:17:58 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 09:17:58 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 09:18:02 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0024 s/iter. Inference: 0.2147 s/iter. Eval: 0.0530 s/iter. Total: 0.2702 s/iter. ETA=0:00:35
[08/23 09:18:08 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0033 s/iter. Inference: 0.2150 s/iter. Eval: 0.0409 s/iter. Total: 0.2593 s/iter. ETA=0:00:29
[08/23 09:18:13 d2.evaluation.evaluator]: Inference done 48/144. Dataloading: 0.0030 s/iter. Inference: 0.2161 s/iter. Eval: 0.0607 s/iter. Total: 0.2799 s/iter. ETA=0:00:26
[08/23 09:18:18 d2.evaluation.evaluator]: Inference done 61/144. Dataloading: 0.0028 s/iter. Inference: 0.2188 s/iter. Eval: 0.0872 s/iter. Total: 0.3090 s/iter. ETA=0:00:25
[08/23 09:18:23 d2.evaluation.evaluator]: Inference done 78/144. Dataloading: 0.0027 s/iter. Inference: 0.2184 s/iter. Eval: 0.0856 s/iter. Total: 0.3068 s/iter. ETA=0:00:20
[08/23 09:18:28 d2.evaluation.evaluator]: Inference done 99/144. Dataloading: 0.0028 s/iter. Inference: 0.2175 s/iter. Eval: 0.0731 s/iter. Total: 0.2935 s/iter. ETA=0:00:13
[08/23 09:18:34 d2.evaluation.evaluator]: Inference done 118/144. Dataloading: 0.0031 s/iter. Inference: 0.2177 s/iter. Eval: 0.0693 s/iter. Total: 0.2903 s/iter. ETA=0:00:07
[08/23 09:18:39 d2.evaluation.evaluator]: Inference done 139/144. Dataloading: 0.0032 s/iter. Inference: 0.2171 s/iter. Eval: 0.0629 s/iter. Total: 0.2834 s/iter. ETA=0:00:01
[08/23 09:18:41 d2.evaluation.evaluator]: Total inference time: 0:00:39.745460 (0.285939 s / iter per device, on 1 devices)
[08/23 09:18:41 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.217252 s / iter per device, on 1 devices)
[08/23 09:18:41 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 09:18:41 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 09:18:41 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/23 09:18:41 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 09:18:41 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/23 09:18:41 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:18:41 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.516
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.746
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.605
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.241
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.468
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.668
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.364
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.624
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.662
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.622
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.794
[08/23 09:18:41 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.576 | 74.584 | 60.460 | 24.082 | 46.804 | 66.766 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[08/23 09:18:41 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 09:18:41 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/23 09:18:41 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:18:41 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.524
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.755
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.595
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.137
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.476
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.679
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.364
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.632
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.667
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.634
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.783
[08/23 09:18:41 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.367 | 75.469 | 59.550 | 13.746 | 47.641 | 67.939 |
[08/23 09:18:41 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 09:18:41 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 09:18:41 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:18:41 d2.evaluation.testing]: copypaste: 51.5756,74.5843,60.4597,24.0815,46.8041,66.7662
[08/23 09:18:41 d2.evaluation.testing]: copypaste: Task: segm
[08/23 09:18:41 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:18:41 d2.evaluation.testing]: copypaste: 52.3667,75.4693,59.5498,13.7460,47.6413,67.9388
[08/23 09:18:41 d2.utils.events]:  eta: 0:06:16  iter: 799  total_loss: 0.3679  loss_cls: 0.06164  loss_box_reg: 0.1265  loss_mask: 0.1545  loss_rpn_cls: 0.007293  loss_rpn_loc: 0.003646  time: 1.8947  data_time: 0.0228  lr: 0.0001998  max_mem: 10889M
[08/23 09:19:19 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 09:19:19 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 09:19:19 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 09:19:19 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 09:19:19 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 09:19:23 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0032 s/iter. Inference: 0.2199 s/iter. Eval: 0.0835 s/iter. Total: 0.3065 s/iter. ETA=0:00:40
[08/23 09:19:28 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0034 s/iter. Inference: 0.2149 s/iter. Eval: 0.0498 s/iter. Total: 0.2682 s/iter. ETA=0:00:30
[08/23 09:19:34 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0031 s/iter. Inference: 0.2170 s/iter. Eval: 0.0771 s/iter. Total: 0.2973 s/iter. ETA=0:00:28
[08/23 09:19:39 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0036 s/iter. Inference: 0.2207 s/iter. Eval: 0.1058 s/iter. Total: 0.3302 s/iter. ETA=0:00:28
[08/23 09:19:44 d2.evaluation.evaluator]: Inference done 72/144. Dataloading: 0.0035 s/iter. Inference: 0.2213 s/iter. Eval: 0.1129 s/iter. Total: 0.3379 s/iter. ETA=0:00:24
[08/23 09:19:49 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0034 s/iter. Inference: 0.2199 s/iter. Eval: 0.0970 s/iter. Total: 0.3205 s/iter. ETA=0:00:16
[08/23 09:19:54 d2.evaluation.evaluator]: Inference done 112/144. Dataloading: 0.0034 s/iter. Inference: 0.2188 s/iter. Eval: 0.0859 s/iter. Total: 0.3082 s/iter. ETA=0:00:09
[08/23 09:20:00 d2.evaluation.evaluator]: Inference done 132/144. Dataloading: 0.0033 s/iter. Inference: 0.2183 s/iter. Eval: 0.0776 s/iter. Total: 0.2994 s/iter. ETA=0:00:03
[08/23 09:20:03 d2.evaluation.evaluator]: Total inference time: 0:00:41.478682 (0.298408 s / iter per device, on 1 devices)
[08/23 09:20:03 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.218019 s / iter per device, on 1 devices)
[08/23 09:20:03 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 09:20:03 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 09:20:03 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/23 09:20:03 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 09:20:03 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[08/23 09:20:03 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:20:03 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.521
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.742
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.617
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.221
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.475
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.676
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.366
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.662
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.308
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.622
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.797
[08/23 09:20:03 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.064 | 74.199 | 61.671 | 22.078 | 47.519 | 67.610 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[08/23 09:20:03 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 09:20:03 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[08/23 09:20:03 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:20:03 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.520
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.752
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.590
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.143
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.476
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.673
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.364
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.624
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.666
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.636
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.777
[08/23 09:20:03 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.014 | 75.241 | 58.956 | 14.313 | 47.560 | 67.274 |
[08/23 09:20:03 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 09:20:03 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 09:20:03 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:20:03 d2.evaluation.testing]: copypaste: 52.0639,74.1989,61.6706,22.0776,47.5194,67.6103
[08/23 09:20:03 d2.evaluation.testing]: copypaste: Task: segm
[08/23 09:20:03 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:20:03 d2.evaluation.testing]: copypaste: 52.0139,75.2407,58.9560,14.3134,47.5596,67.2743
[08/23 09:20:03 d2.utils.events]:  eta: 0:05:39  iter: 819  total_loss: 0.3485  loss_cls: 0.05828  loss_box_reg: 0.1274  loss_mask: 0.1408  loss_rpn_cls: 0.006004  loss_rpn_loc: 0.005855  time: 1.8949  data_time: 0.0243  lr: 0.0002048  max_mem: 10889M
[08/23 09:20:41 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 09:20:41 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 09:20:41 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 09:20:41 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 09:20:41 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 09:20:46 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0047 s/iter. Inference: 0.2303 s/iter. Eval: 0.1030 s/iter. Total: 0.3380 s/iter. ETA=0:00:44
[08/23 09:20:51 d2.evaluation.evaluator]: Inference done 30/144. Dataloading: 0.0031 s/iter. Inference: 0.2180 s/iter. Eval: 0.0607 s/iter. Total: 0.2819 s/iter. ETA=0:00:32
[08/23 09:20:56 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0035 s/iter. Inference: 0.2189 s/iter. Eval: 0.0763 s/iter. Total: 0.2988 s/iter. ETA=0:00:29
[08/23 09:21:01 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0033 s/iter. Inference: 0.2209 s/iter. Eval: 0.1060 s/iter. Total: 0.3303 s/iter. ETA=0:00:28
[08/23 09:21:06 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0035 s/iter. Inference: 0.2214 s/iter. Eval: 0.1183 s/iter. Total: 0.3433 s/iter. ETA=0:00:25
[08/23 09:21:11 d2.evaluation.evaluator]: Inference done 91/144. Dataloading: 0.0032 s/iter. Inference: 0.2196 s/iter. Eval: 0.0991 s/iter. Total: 0.3221 s/iter. ETA=0:00:17
[08/23 09:21:16 d2.evaluation.evaluator]: Inference done 110/144. Dataloading: 0.0033 s/iter. Inference: 0.2189 s/iter. Eval: 0.0893 s/iter. Total: 0.3116 s/iter. ETA=0:00:10
[08/23 09:21:21 d2.evaluation.evaluator]: Inference done 130/144. Dataloading: 0.0033 s/iter. Inference: 0.2188 s/iter. Eval: 0.0818 s/iter. Total: 0.3040 s/iter. ETA=0:00:04
[08/23 09:21:26 d2.evaluation.evaluator]: Total inference time: 0:00:42.255183 (0.303994 s / iter per device, on 1 devices)
[08/23 09:21:26 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.218958 s / iter per device, on 1 devices)
[08/23 09:21:26 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 09:21:26 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 09:21:26 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/23 09:21:26 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 09:21:26 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/23 09:21:26 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:21:26 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.527
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.743
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.620
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.225
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.482
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.683
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.376
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.635
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.674
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.637
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.806
[08/23 09:21:26 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.716 | 74.337 | 61.971 | 22.498 | 48.173 | 68.272 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[08/23 09:21:26 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 09:21:26 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/23 09:21:26 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:21:26 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.528
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.762
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.603
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.144
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.478
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.684
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.373
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.634
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.673
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.643
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.788
[08/23 09:21:26 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.804 | 76.167 | 60.275 | 14.407 | 47.846 | 68.440 |
[08/23 09:21:26 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 09:21:26 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 09:21:26 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:21:26 d2.evaluation.testing]: copypaste: 52.7163,74.3370,61.9712,22.4978,48.1730,68.2717
[08/23 09:21:26 d2.evaluation.testing]: copypaste: Task: segm
[08/23 09:21:26 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:21:26 d2.evaluation.testing]: copypaste: 52.8036,76.1672,60.2747,14.4072,47.8461,68.4397
[08/23 09:21:26 d2.utils.events]:  eta: 0:05:01  iter: 839  total_loss: 0.4749  loss_cls: 0.08871  loss_box_reg: 0.1845  loss_mask: 0.1697  loss_rpn_cls: 0.006887  loss_rpn_loc: 0.006369  time: 1.8946  data_time: 0.0246  lr: 0.00020979  max_mem: 10889M
[08/23 09:22:04 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 09:22:04 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 09:22:04 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 09:22:04 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 09:22:04 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 09:22:08 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0029 s/iter. Inference: 0.2237 s/iter. Eval: 0.0847 s/iter. Total: 0.3114 s/iter. ETA=0:00:41
[08/23 09:22:14 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0028 s/iter. Inference: 0.2162 s/iter. Eval: 0.0542 s/iter. Total: 0.2735 s/iter. ETA=0:00:30
[08/23 09:22:19 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0028 s/iter. Inference: 0.2175 s/iter. Eval: 0.0797 s/iter. Total: 0.3001 s/iter. ETA=0:00:29
[08/23 09:22:24 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0028 s/iter. Inference: 0.2205 s/iter. Eval: 0.1098 s/iter. Total: 0.3333 s/iter. ETA=0:00:28
[08/23 09:22:29 d2.evaluation.evaluator]: Inference done 72/144. Dataloading: 0.0029 s/iter. Inference: 0.2210 s/iter. Eval: 0.1145 s/iter. Total: 0.3385 s/iter. ETA=0:00:24
[08/23 09:22:34 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0029 s/iter. Inference: 0.2200 s/iter. Eval: 0.0972 s/iter. Total: 0.3202 s/iter. ETA=0:00:16
[08/23 09:22:40 d2.evaluation.evaluator]: Inference done 112/144. Dataloading: 0.0028 s/iter. Inference: 0.2188 s/iter. Eval: 0.0864 s/iter. Total: 0.3081 s/iter. ETA=0:00:09
[08/23 09:22:45 d2.evaluation.evaluator]: Inference done 132/144. Dataloading: 0.0028 s/iter. Inference: 0.2184 s/iter. Eval: 0.0783 s/iter. Total: 0.2997 s/iter. ETA=0:00:03
[08/23 09:22:48 d2.evaluation.evaluator]: Total inference time: 0:00:41.691171 (0.299936 s / iter per device, on 1 devices)
[08/23 09:22:48 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.218254 s / iter per device, on 1 devices)
[08/23 09:22:48 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 09:22:48 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 09:22:48 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/23 09:22:48 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 09:22:48 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/23 09:22:48 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:22:48 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.512
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.751
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.607
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.229
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.469
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.661
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.365
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.621
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.658
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.283
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.624
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.783
[08/23 09:22:48 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.238 | 75.107 | 60.681 | 22.890 | 46.917 | 66.113 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[08/23 09:22:49 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 09:22:49 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/23 09:22:49 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:22:49 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.534
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.767
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.605
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.158
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.480
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.691
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.376
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.638
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.675
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.643
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.789
[08/23 09:22:49 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 53.364 | 76.681 | 60.454 | 15.809 | 48.001 | 69.111 |
[08/23 09:22:49 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 09:22:49 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 09:22:49 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:22:49 d2.evaluation.testing]: copypaste: 51.2384,75.1074,60.6809,22.8904,46.9168,66.1132
[08/23 09:22:49 d2.evaluation.testing]: copypaste: Task: segm
[08/23 09:22:49 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:22:49 d2.evaluation.testing]: copypaste: 53.3645,76.6807,60.4536,15.8090,48.0009,69.1111
[08/23 09:22:49 d2.utils.events]:  eta: 0:04:23  iter: 859  total_loss: 0.4314  loss_cls: 0.06532  loss_box_reg: 0.1518  loss_mask: 0.1857  loss_rpn_cls: 0.00229  loss_rpn_loc: 0.003686  time: 1.8948  data_time: 0.0264  lr: 0.00021479  max_mem: 10889M
[08/23 09:23:27 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 09:23:27 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 09:23:27 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 09:23:27 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 09:23:27 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 09:23:31 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0027 s/iter. Inference: 0.2151 s/iter. Eval: 0.0573 s/iter. Total: 0.2751 s/iter. ETA=0:00:36
[08/23 09:23:36 d2.evaluation.evaluator]: Inference done 30/144. Dataloading: 0.0035 s/iter. Inference: 0.2158 s/iter. Eval: 0.0476 s/iter. Total: 0.2671 s/iter. ETA=0:00:30
[08/23 09:23:41 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0037 s/iter. Inference: 0.2170 s/iter. Eval: 0.0635 s/iter. Total: 0.2844 s/iter. ETA=0:00:27
[08/23 09:23:47 d2.evaluation.evaluator]: Inference done 60/144. Dataloading: 0.0034 s/iter. Inference: 0.2192 s/iter. Eval: 0.0880 s/iter. Total: 0.3108 s/iter. ETA=0:00:26
[08/23 09:23:52 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0034 s/iter. Inference: 0.2195 s/iter. Eval: 0.0875 s/iter. Total: 0.3105 s/iter. ETA=0:00:20
[08/23 09:23:57 d2.evaluation.evaluator]: Inference done 98/144. Dataloading: 0.0034 s/iter. Inference: 0.2179 s/iter. Eval: 0.0740 s/iter. Total: 0.2955 s/iter. ETA=0:00:13
[08/23 09:24:02 d2.evaluation.evaluator]: Inference done 115/144. Dataloading: 0.0035 s/iter. Inference: 0.2185 s/iter. Eval: 0.0732 s/iter. Total: 0.2955 s/iter. ETA=0:00:08
[08/23 09:24:07 d2.evaluation.evaluator]: Inference done 136/144. Dataloading: 0.0034 s/iter. Inference: 0.2175 s/iter. Eval: 0.0656 s/iter. Total: 0.2868 s/iter. ETA=0:00:02
[08/23 09:24:10 d2.evaluation.evaluator]: Total inference time: 0:00:40.245800 (0.289538 s / iter per device, on 1 devices)
[08/23 09:24:10 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.217618 s / iter per device, on 1 devices)
[08/23 09:24:10 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 09:24:10 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 09:24:10 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/23 09:24:10 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 09:24:10 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/23 09:24:10 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:24:10 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.513
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.756
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.619
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.212
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.465
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.664
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.368
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.621
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.650
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.292
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.606
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.791
[08/23 09:24:10 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.250 | 75.638 | 61.937 | 21.249 | 46.542 | 66.382 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[08/23 09:24:10 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 09:24:10 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/23 09:24:10 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:24:10 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.530
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.764
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.608
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.173
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.478
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.683
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.373
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.638
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.670
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.367
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.634
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.788
[08/23 09:24:10 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 53.010 | 76.439 | 60.818 | 17.261 | 47.826 | 68.337 |
[08/23 09:24:10 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 09:24:10 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 09:24:10 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:24:10 d2.evaluation.testing]: copypaste: 51.2501,75.6378,61.9368,21.2489,46.5421,66.3817
[08/23 09:24:10 d2.evaluation.testing]: copypaste: Task: segm
[08/23 09:24:10 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:24:10 d2.evaluation.testing]: copypaste: 53.0102,76.4391,60.8177,17.2615,47.8260,68.3368
[08/23 09:24:10 d2.utils.events]:  eta: 0:03:46  iter: 879  total_loss: 0.4524  loss_cls: 0.07535  loss_box_reg: 0.1683  loss_mask: 0.1782  loss_rpn_cls: 0.004656  loss_rpn_loc: 0.007985  time: 1.8949  data_time: 0.0250  lr: 0.00021978  max_mem: 10889M
[08/23 09:24:48 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 09:24:48 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 09:24:48 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 09:24:48 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 09:24:48 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 09:24:52 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0019 s/iter. Inference: 0.2149 s/iter. Eval: 0.0612 s/iter. Total: 0.2780 s/iter. ETA=0:00:36
[08/23 09:24:58 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0025 s/iter. Inference: 0.2146 s/iter. Eval: 0.0465 s/iter. Total: 0.2638 s/iter. ETA=0:00:29
[08/23 09:25:03 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0024 s/iter. Inference: 0.2156 s/iter. Eval: 0.0644 s/iter. Total: 0.2826 s/iter. ETA=0:00:27
[08/23 09:25:08 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0026 s/iter. Inference: 0.2189 s/iter. Eval: 0.0981 s/iter. Total: 0.3198 s/iter. ETA=0:00:27
[08/23 09:25:13 d2.evaluation.evaluator]: Inference done 74/144. Dataloading: 0.0027 s/iter. Inference: 0.2190 s/iter. Eval: 0.0986 s/iter. Total: 0.3206 s/iter. ETA=0:00:22
[08/23 09:25:18 d2.evaluation.evaluator]: Inference done 94/144. Dataloading: 0.0030 s/iter. Inference: 0.2181 s/iter. Eval: 0.0840 s/iter. Total: 0.3053 s/iter. ETA=0:00:15
[08/23 09:25:23 d2.evaluation.evaluator]: Inference done 114/144. Dataloading: 0.0028 s/iter. Inference: 0.2170 s/iter. Eval: 0.0752 s/iter. Total: 0.2953 s/iter. ETA=0:00:08
[08/23 09:25:28 d2.evaluation.evaluator]: Inference done 134/144. Dataloading: 0.0029 s/iter. Inference: 0.2169 s/iter. Eval: 0.0685 s/iter. Total: 0.2885 s/iter. ETA=0:00:02
[08/23 09:25:31 d2.evaluation.evaluator]: Total inference time: 0:00:40.242704 (0.289516 s / iter per device, on 1 devices)
[08/23 09:25:31 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.216811 s / iter per device, on 1 devices)
[08/23 09:25:31 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 09:25:31 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 09:25:31 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/23 09:25:31 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 09:25:31 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/23 09:25:31 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:25:31 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.524
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.752
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.616
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.204
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.474
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.684
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.376
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.632
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.670
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.627
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.814
[08/23 09:25:31 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.397 | 75.190 | 61.590 | 20.449 | 47.353 | 68.400 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[08/23 09:25:31 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 09:25:31 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/23 09:25:31 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:25:31 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.528
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.764
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.607
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.166
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.475
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.682
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.371
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.633
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.673
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.640
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.788
[08/23 09:25:31 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.770 | 76.370 | 60.685 | 16.576 | 47.460 | 68.175 |
[08/23 09:25:31 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 09:25:31 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 09:25:31 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:25:31 d2.evaluation.testing]: copypaste: 52.3971,75.1897,61.5904,20.4486,47.3525,68.3997
[08/23 09:25:31 d2.evaluation.testing]: copypaste: Task: segm
[08/23 09:25:31 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:25:31 d2.evaluation.testing]: copypaste: 52.7699,76.3703,60.6846,16.5762,47.4601,68.1748
[08/23 09:25:31 d2.utils.events]:  eta: 0:03:08  iter: 899  total_loss: 0.3884  loss_cls: 0.06381  loss_box_reg: 0.1588  loss_mask: 0.1637  loss_rpn_cls: 0.004224  loss_rpn_loc: 0.005972  time: 1.8954  data_time: 0.0253  lr: 0.00022478  max_mem: 10889M
[08/23 09:26:09 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 09:26:09 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 09:26:09 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 09:26:09 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 09:26:09 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 09:26:14 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0035 s/iter. Inference: 0.2246 s/iter. Eval: 0.0702 s/iter. Total: 0.2983 s/iter. ETA=0:00:39
[08/23 09:26:19 d2.evaluation.evaluator]: Inference done 32/144. Dataloading: 0.0028 s/iter. Inference: 0.2147 s/iter. Eval: 0.0396 s/iter. Total: 0.2573 s/iter. ETA=0:00:28
[08/23 09:26:24 d2.evaluation.evaluator]: Inference done 48/144. Dataloading: 0.0031 s/iter. Inference: 0.2165 s/iter. Eval: 0.0582 s/iter. Total: 0.2780 s/iter. ETA=0:00:26
[08/23 09:26:29 d2.evaluation.evaluator]: Inference done 62/144. Dataloading: 0.0030 s/iter. Inference: 0.2177 s/iter. Eval: 0.0776 s/iter. Total: 0.2985 s/iter. ETA=0:00:24
[08/23 09:26:34 d2.evaluation.evaluator]: Inference done 79/144. Dataloading: 0.0033 s/iter. Inference: 0.2177 s/iter. Eval: 0.0772 s/iter. Total: 0.2984 s/iter. ETA=0:00:19
[08/23 09:26:39 d2.evaluation.evaluator]: Inference done 100/144. Dataloading: 0.0031 s/iter. Inference: 0.2165 s/iter. Eval: 0.0667 s/iter. Total: 0.2865 s/iter. ETA=0:00:12
[08/23 09:26:45 d2.evaluation.evaluator]: Inference done 120/144. Dataloading: 0.0033 s/iter. Inference: 0.2170 s/iter. Eval: 0.0613 s/iter. Total: 0.2818 s/iter. ETA=0:00:06
[08/23 09:26:50 d2.evaluation.evaluator]: Inference done 141/144. Dataloading: 0.0033 s/iter. Inference: 0.2168 s/iter. Eval: 0.0565 s/iter. Total: 0.2768 s/iter. ETA=0:00:00
[08/23 09:26:51 d2.evaluation.evaluator]: Total inference time: 0:00:38.886078 (0.279756 s / iter per device, on 1 devices)
[08/23 09:26:51 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.216963 s / iter per device, on 1 devices)
[08/23 09:26:51 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 09:26:51 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 09:26:51 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/23 09:26:51 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 09:26:51 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[08/23 09:26:51 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:26:51 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.514
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.756
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.605
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.232
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.471
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.660
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.365
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.622
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.654
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.780
[08/23 09:26:51 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.419 | 75.635 | 60.540 | 23.200 | 47.092 | 65.970 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[08/23 09:26:51 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 09:26:51 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[08/23 09:26:51 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:26:51 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.529
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.764
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.603
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.160
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.475
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.690
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.369
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.634
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.670
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.375
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.630
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.792
[08/23 09:26:51 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.884 | 76.400 | 60.255 | 15.975 | 47.501 | 68.983 |
[08/23 09:26:51 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 09:26:51 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 09:26:51 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:26:51 d2.evaluation.testing]: copypaste: 51.4192,75.6347,60.5400,23.2002,47.0921,65.9702
[08/23 09:26:51 d2.evaluation.testing]: copypaste: Task: segm
[08/23 09:26:51 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:26:51 d2.evaluation.testing]: copypaste: 52.8839,76.3996,60.2555,15.9746,47.5005,68.9829
[08/23 09:26:51 d2.utils.events]:  eta: 0:02:30  iter: 919  total_loss: 0.3883  loss_cls: 0.06057  loss_box_reg: 0.1633  loss_mask: 0.161  loss_rpn_cls: 0.00391  loss_rpn_loc: 0.004965  time: 1.8955  data_time: 0.0239  lr: 0.00022977  max_mem: 10889M
[08/23 09:27:30 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 09:27:30 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 09:27:30 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 09:27:30 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 09:27:30 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 09:27:33 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0018 s/iter. Inference: 0.2135 s/iter. Eval: 0.0453 s/iter. Total: 0.2607 s/iter. ETA=0:00:34
[08/23 09:27:38 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0025 s/iter. Inference: 0.2134 s/iter. Eval: 0.0388 s/iter. Total: 0.2549 s/iter. ETA=0:00:28
[08/23 09:27:44 d2.evaluation.evaluator]: Inference done 48/144. Dataloading: 0.0024 s/iter. Inference: 0.2147 s/iter. Eval: 0.0556 s/iter. Total: 0.2728 s/iter. ETA=0:00:26
[08/23 09:27:49 d2.evaluation.evaluator]: Inference done 62/144. Dataloading: 0.0025 s/iter. Inference: 0.2165 s/iter. Eval: 0.0767 s/iter. Total: 0.2958 s/iter. ETA=0:00:24
[08/23 09:27:54 d2.evaluation.evaluator]: Inference done 78/144. Dataloading: 0.0027 s/iter. Inference: 0.2183 s/iter. Eval: 0.0806 s/iter. Total: 0.3017 s/iter. ETA=0:00:19
[08/23 09:27:59 d2.evaluation.evaluator]: Inference done 100/144. Dataloading: 0.0027 s/iter. Inference: 0.2169 s/iter. Eval: 0.0682 s/iter. Total: 0.2880 s/iter. ETA=0:00:12
[08/23 09:28:04 d2.evaluation.evaluator]: Inference done 121/144. Dataloading: 0.0028 s/iter. Inference: 0.2166 s/iter. Eval: 0.0609 s/iter. Total: 0.2805 s/iter. ETA=0:00:06
[08/23 09:28:09 d2.evaluation.evaluator]: Inference done 142/144. Dataloading: 0.0027 s/iter. Inference: 0.2159 s/iter. Eval: 0.0555 s/iter. Total: 0.2742 s/iter. ETA=0:00:00
[08/23 09:28:10 d2.evaluation.evaluator]: Total inference time: 0:00:38.473052 (0.276785 s / iter per device, on 1 devices)
[08/23 09:28:10 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.215997 s / iter per device, on 1 devices)
[08/23 09:28:10 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 09:28:10 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 09:28:10 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/23 09:28:10 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 09:28:10 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/23 09:28:10 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:28:10 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.530
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.765
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.619
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.244
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.483
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.685
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.373
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.631
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.655
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.603
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.806
[08/23 09:28:10 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.984 | 76.515 | 61.949 | 24.396 | 48.282 | 68.494 |
Loading and preparing results...
DONE (t=0.06s)
creating index...
index created!
[08/23 09:28:11 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 09:28:11 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.09 seconds.
[08/23 09:28:11 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:28:11 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.534
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.766
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.604
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.164
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.482
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.687
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.370
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.637
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.665
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.375
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.622
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.792
[08/23 09:28:11 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 53.356 | 76.647 | 60.449 | 16.404 | 48.203 | 68.728 |
[08/23 09:28:11 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 09:28:11 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 09:28:11 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:28:11 d2.evaluation.testing]: copypaste: 52.9842,76.5155,61.9494,24.3962,48.2821,68.4935
[08/23 09:28:11 d2.evaluation.testing]: copypaste: Task: segm
[08/23 09:28:11 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:28:11 d2.evaluation.testing]: copypaste: 53.3563,76.6466,60.4491,16.4038,48.2025,68.7278
[08/23 09:28:11 d2.utils.events]:  eta: 0:01:53  iter: 939  total_loss: 0.3458  loss_cls: 0.06492  loss_box_reg: 0.1307  loss_mask: 0.1384  loss_rpn_cls: 0.003153  loss_rpn_loc: 0.003781  time: 1.8959  data_time: 0.0236  lr: 0.00023477  max_mem: 10889M
[08/23 09:28:49 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 09:28:49 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 09:28:49 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 09:28:49 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 09:28:49 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 09:28:53 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0022 s/iter. Inference: 0.2146 s/iter. Eval: 0.0627 s/iter. Total: 0.2796 s/iter. ETA=0:00:37
[08/23 09:28:58 d2.evaluation.evaluator]: Inference done 30/144. Dataloading: 0.0033 s/iter. Inference: 0.2165 s/iter. Eval: 0.0537 s/iter. Total: 0.2737 s/iter. ETA=0:00:31
[08/23 09:29:03 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0032 s/iter. Inference: 0.2176 s/iter. Eval: 0.0756 s/iter. Total: 0.2965 s/iter. ETA=0:00:29
[08/23 09:29:08 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0035 s/iter. Inference: 0.2207 s/iter. Eval: 0.1038 s/iter. Total: 0.3282 s/iter. ETA=0:00:28
[08/23 09:29:14 d2.evaluation.evaluator]: Inference done 73/144. Dataloading: 0.0034 s/iter. Inference: 0.2208 s/iter. Eval: 0.1072 s/iter. Total: 0.3316 s/iter. ETA=0:00:23
[08/23 09:29:19 d2.evaluation.evaluator]: Inference done 93/144. Dataloading: 0.0032 s/iter. Inference: 0.2195 s/iter. Eval: 0.0907 s/iter. Total: 0.3136 s/iter. ETA=0:00:15
[08/23 09:29:24 d2.evaluation.evaluator]: Inference done 114/144. Dataloading: 0.0031 s/iter. Inference: 0.2182 s/iter. Eval: 0.0797 s/iter. Total: 0.3011 s/iter. ETA=0:00:09
[08/23 09:29:29 d2.evaluation.evaluator]: Inference done 134/144. Dataloading: 0.0031 s/iter. Inference: 0.2176 s/iter. Eval: 0.0725 s/iter. Total: 0.2933 s/iter. ETA=0:00:02
[08/23 09:29:32 d2.evaluation.evaluator]: Total inference time: 0:00:40.953238 (0.294628 s / iter per device, on 1 devices)
[08/23 09:29:32 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.217592 s / iter per device, on 1 devices)
[08/23 09:29:32 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 09:29:32 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 09:29:32 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/23 09:29:32 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 09:29:32 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/23 09:29:32 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:29:32 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.512
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.766
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.600
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.242
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.466
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.664
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.373
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.626
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.654
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.605
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.797
[08/23 09:29:32 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.241 | 76.554 | 59.984 | 24.161 | 46.630 | 66.360 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[08/23 09:29:32 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 09:29:32 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[08/23 09:29:32 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:29:32 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.526
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.761
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.597
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.158
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.473
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.685
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.374
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.641
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.672
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.367
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.633
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.794
[08/23 09:29:32 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.568 | 76.130 | 59.683 | 15.808 | 47.330 | 68.504 |
[08/23 09:29:32 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 09:29:32 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 09:29:32 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:29:32 d2.evaluation.testing]: copypaste: 51.2412,76.5539,59.9841,24.1606,46.6303,66.3598
[08/23 09:29:32 d2.evaluation.testing]: copypaste: Task: segm
[08/23 09:29:32 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:29:32 d2.evaluation.testing]: copypaste: 52.5677,76.1296,59.6834,15.8076,47.3298,68.5037
[08/23 09:29:32 d2.utils.events]:  eta: 0:01:15  iter: 959  total_loss: 0.4485  loss_cls: 0.08545  loss_box_reg: 0.1553  loss_mask: 0.1686  loss_rpn_cls: 0.004058  loss_rpn_loc: 0.00576  time: 1.8958  data_time: 0.0245  lr: 0.00023976  max_mem: 10889M
[08/23 09:30:11 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 09:30:11 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 09:30:11 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 09:30:11 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 09:30:11 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 09:30:15 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0023 s/iter. Inference: 0.2142 s/iter. Eval: 0.0531 s/iter. Total: 0.2696 s/iter. ETA=0:00:35
[08/23 09:30:20 d2.evaluation.evaluator]: Inference done 32/144. Dataloading: 0.0023 s/iter. Inference: 0.2129 s/iter. Eval: 0.0366 s/iter. Total: 0.2520 s/iter. ETA=0:00:28
[08/23 09:30:25 d2.evaluation.evaluator]: Inference done 48/144. Dataloading: 0.0026 s/iter. Inference: 0.2156 s/iter. Eval: 0.0609 s/iter. Total: 0.2793 s/iter. ETA=0:00:26
[08/23 09:30:30 d2.evaluation.evaluator]: Inference done 62/144. Dataloading: 0.0027 s/iter. Inference: 0.2172 s/iter. Eval: 0.0801 s/iter. Total: 0.3001 s/iter. ETA=0:00:24
[08/23 09:30:35 d2.evaluation.evaluator]: Inference done 79/144. Dataloading: 0.0028 s/iter. Inference: 0.2177 s/iter. Eval: 0.0787 s/iter. Total: 0.2993 s/iter. ETA=0:00:19
[08/23 09:30:40 d2.evaluation.evaluator]: Inference done 100/144. Dataloading: 0.0027 s/iter. Inference: 0.2165 s/iter. Eval: 0.0669 s/iter. Total: 0.2862 s/iter. ETA=0:00:12
[08/23 09:30:45 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0030 s/iter. Inference: 0.2179 s/iter. Eval: 0.0627 s/iter. Total: 0.2837 s/iter. ETA=0:00:07
[08/23 09:30:50 d2.evaluation.evaluator]: Inference done 140/144. Dataloading: 0.0029 s/iter. Inference: 0.2172 s/iter. Eval: 0.0564 s/iter. Total: 0.2767 s/iter. ETA=0:00:01
[08/23 09:30:52 d2.evaluation.evaluator]: Total inference time: 0:00:38.916436 (0.279974 s / iter per device, on 1 devices)
[08/23 09:30:52 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.217377 s / iter per device, on 1 devices)
[08/23 09:30:52 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 09:30:52 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 09:30:52 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/23 09:30:52 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 09:30:52 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/23 09:30:52 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:30:52 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.515
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.744
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.604
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.469
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.676
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.371
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.627
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.650
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.325
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.599
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.798
[08/23 09:30:52 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.521 | 74.426 | 60.450 | 21.653 | 46.857 | 67.623 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[08/23 09:30:52 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 09:30:52 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.28 seconds.
[08/23 09:30:52 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:30:52 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.523
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.760
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.588
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.145
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.471
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.680
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.369
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.636
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.661
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.375
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.617
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.788
[08/23 09:30:52 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.320 | 75.953 | 58.830 | 14.458 | 47.095 | 68.041 |
[08/23 09:30:52 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 09:30:52 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 09:30:52 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:30:52 d2.evaluation.testing]: copypaste: 51.5210,74.4255,60.4497,21.6532,46.8573,67.6225
[08/23 09:30:52 d2.evaluation.testing]: copypaste: Task: segm
[08/23 09:30:52 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:30:52 d2.evaluation.testing]: copypaste: 52.3203,75.9525,58.8297,14.4580,47.0952,68.0408
[08/23 09:30:52 d2.utils.events]:  eta: 0:00:37  iter: 979  total_loss: 0.4613  loss_cls: 0.08415  loss_box_reg: 0.1765  loss_mask: 0.1755  loss_rpn_cls: 0.002753  loss_rpn_loc: 0.006976  time: 1.8961  data_time: 0.0245  lr: 0.00024476  max_mem: 10889M
[08/23 09:31:31 d2.utils.events]:  eta: 0:00:00  iter: 999  total_loss: 0.3472  loss_cls: 0.05894  loss_box_reg: 0.1267  loss_mask: 0.1407  loss_rpn_cls: 0.002361  loss_rpn_loc: 0.005587  time: 1.8961  data_time: 0.0250  lr: 0.00024975  max_mem: 10889M
[08/23 09:31:31 d2.engine.hooks]: Overall training speed: 998 iterations in 0:31:32 (1.8961 s / it)
[08/23 09:31:31 d2.engine.hooks]: Total training time: 1:32:41 (1:01:09 on hooks)
[08/23 09:31:31 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/23 09:31:31 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/23 09:31:31 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/23 09:31:31 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/23 09:31:31 d2.evaluation.evaluator]: Start inference on 144 batches
[08/23 09:31:35 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0018 s/iter. Inference: 0.2128 s/iter. Eval: 0.0427 s/iter. Total: 0.2573 s/iter. ETA=0:00:34
[08/23 09:31:40 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0024 s/iter. Inference: 0.2141 s/iter. Eval: 0.0372 s/iter. Total: 0.2538 s/iter. ETA=0:00:28
[08/23 09:31:45 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0024 s/iter. Inference: 0.2160 s/iter. Eval: 0.0596 s/iter. Total: 0.2781 s/iter. ETA=0:00:26
[08/23 09:31:50 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0025 s/iter. Inference: 0.2195 s/iter. Eval: 0.0887 s/iter. Total: 0.3109 s/iter. ETA=0:00:26
[08/23 09:31:55 d2.evaluation.evaluator]: Inference done 76/144. Dataloading: 0.0027 s/iter. Inference: 0.2194 s/iter. Eval: 0.0860 s/iter. Total: 0.3083 s/iter. ETA=0:00:20
[08/23 09:32:00 d2.evaluation.evaluator]: Inference done 97/144. Dataloading: 0.0026 s/iter. Inference: 0.2176 s/iter. Eval: 0.0720 s/iter. Total: 0.2924 s/iter. ETA=0:00:13
[08/23 09:32:05 d2.evaluation.evaluator]: Inference done 116/144. Dataloading: 0.0028 s/iter. Inference: 0.2187 s/iter. Eval: 0.0666 s/iter. Total: 0.2883 s/iter. ETA=0:00:08
[08/23 09:32:11 d2.evaluation.evaluator]: Inference done 138/144. Dataloading: 0.0028 s/iter. Inference: 0.2175 s/iter. Eval: 0.0589 s/iter. Total: 0.2793 s/iter. ETA=0:00:01
[08/23 09:32:13 d2.evaluation.evaluator]: Total inference time: 0:00:39.167516 (0.281781 s / iter per device, on 1 devices)
[08/23 09:32:13 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.217497 s / iter per device, on 1 devices)
[08/23 09:32:13 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/23 09:32:13 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/23 09:32:13 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/23 09:32:13 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/23 09:32:13 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[08/23 09:32:13 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:32:13 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.522
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.760
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.613
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.231
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.473
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.681
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.380
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.634
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.663
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.797
[08/23 09:32:13 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.166 | 75.960 | 61.279 | 23.100 | 47.332 | 68.128 |
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
[08/23 09:32:13 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/23 09:32:13 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.08 seconds.
[08/23 09:32:13 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/23 09:32:13 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.529
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.757
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.598
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.127
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.471
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.693
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.374
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.637
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.667
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.375
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.627
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.791
[08/23 09:32:13 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.881 | 75.682 | 59.783 | 12.662 | 47.111 | 69.338 |
[08/23 09:32:13 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/23 09:32:13 d2.evaluation.testing]: copypaste: Task: bbox
[08/23 09:32:13 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:32:13 d2.evaluation.testing]: copypaste: 52.1659,75.9600,61.2795,23.0997,47.3317,68.1279
[08/23 09:32:13 d2.evaluation.testing]: copypaste: Task: segm
[08/23 09:32:13 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/23 09:32:13 d2.evaluation.testing]: copypaste: 52.8813,75.6823,59.7835,12.6616,47.1112,69.3379