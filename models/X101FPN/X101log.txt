[09/04 05:28:06 d2.engine.defaults]: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2): Conv2d(
            2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2): Conv2d(
            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2): Conv2d(
            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[09/04 05:28:06 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [RandomBrightness(intensity_min=0.9, intensity_max=1.1), RandomContrast(intensity_min=0.9, intensity_max=1.1), RandomFlip(prob=0.5)]
[09/04 05:28:06 d2.data.datasets.coco]: Loaded 574 images in COCO format from ../input/petbottles/plastic data/annotations/instances_train.json
[09/04 05:28:06 d2.data.build]: Distribution of instances among all 1 categories:
|  category   | #instances   |
|:-----------:|:-------------|
| PET Bottles | 1145         |
|             |              |
[09/04 05:28:06 d2.data.build]: Using training sampler TrainingSampler
[09/04 05:28:06 d2.data.common]: Serializing 574 elements to byte tensors and concatenating them all ...
[09/04 05:28:06 d2.data.common]: Serialized dataset takes 0.45 MiB
model_final_2d9806.pkl: 431MB [00:19, 21.7MB/s]                               
[09/04 05:28:30 d2.engine.train_loop]: Starting training from iteration 0
[09/04 05:29:10 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 05:29:10 d2.data.build]: Distribution of instances among all 1 categories:
|  category   | #instances   |
|:-----------:|:-------------|
| PET Bottles | 193          |
|             |              |
[09/04 05:29:10 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 05:29:10 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 05:29:10 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 05:29:10 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 05:29:20 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.2646 s/iter. Eval: 0.6674 s/iter. Total: 0.9336 s/iter. ETA=0:02:04
[09/04 05:29:26 d2.evaluation.evaluator]: Inference done 16/144. Dataloading: 0.0019 s/iter. Inference: 0.2637 s/iter. Eval: 0.7062 s/iter. Total: 0.9722 s/iter. ETA=0:02:04
[09/04 05:29:31 d2.evaluation.evaluator]: Inference done 22/144. Dataloading: 0.0019 s/iter. Inference: 0.2631 s/iter. Eval: 0.6899 s/iter. Total: 0.9553 s/iter. ETA=0:01:56
[09/04 05:29:37 d2.evaluation.evaluator]: Inference done 28/144. Dataloading: 0.0020 s/iter. Inference: 0.2631 s/iter. Eval: 0.6871 s/iter. Total: 0.9525 s/iter. ETA=0:01:50
[09/04 05:29:42 d2.evaluation.evaluator]: Inference done 34/144. Dataloading: 0.0020 s/iter. Inference: 0.2630 s/iter. Eval: 0.6821 s/iter. Total: 0.9473 s/iter. ETA=0:01:44
[09/04 05:29:48 d2.evaluation.evaluator]: Inference done 40/144. Dataloading: 0.0020 s/iter. Inference: 0.2629 s/iter. Eval: 0.6825 s/iter. Total: 0.9477 s/iter. ETA=0:01:38
[09/04 05:29:54 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0020 s/iter. Inference: 0.2629 s/iter. Eval: 0.6800 s/iter. Total: 0.9451 s/iter. ETA=0:01:32
[09/04 05:29:59 d2.evaluation.evaluator]: Inference done 51/144. Dataloading: 0.0020 s/iter. Inference: 0.2634 s/iter. Eval: 0.6879 s/iter. Total: 0.9536 s/iter. ETA=0:01:28
[09/04 05:30:04 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0020 s/iter. Inference: 0.2633 s/iter. Eval: 0.6848 s/iter. Total: 0.9504 s/iter. ETA=0:01:22
[09/04 05:30:10 d2.evaluation.evaluator]: Inference done 63/144. Dataloading: 0.0020 s/iter. Inference: 0.2633 s/iter. Eval: 0.6862 s/iter. Total: 0.9516 s/iter. ETA=0:01:17
[09/04 05:30:16 d2.evaluation.evaluator]: Inference done 69/144. Dataloading: 0.0020 s/iter. Inference: 0.2631 s/iter. Eval: 0.6837 s/iter. Total: 0.9491 s/iter. ETA=0:01:11
[09/04 05:30:21 d2.evaluation.evaluator]: Inference done 75/144. Dataloading: 0.0020 s/iter. Inference: 0.2633 s/iter. Eval: 0.6834 s/iter. Total: 0.9490 s/iter. ETA=0:01:05
[09/04 05:30:27 d2.evaluation.evaluator]: Inference done 81/144. Dataloading: 0.0020 s/iter. Inference: 0.2632 s/iter. Eval: 0.6819 s/iter. Total: 0.9474 s/iter. ETA=0:00:59
[09/04 05:30:32 d2.evaluation.evaluator]: Inference done 86/144. Dataloading: 0.0020 s/iter. Inference: 0.2638 s/iter. Eval: 0.6853 s/iter. Total: 0.9514 s/iter. ETA=0:00:55
[09/04 05:30:38 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0020 s/iter. Inference: 0.2637 s/iter. Eval: 0.6840 s/iter. Total: 0.9500 s/iter. ETA=0:00:49
[09/04 05:30:43 d2.evaluation.evaluator]: Inference done 98/144. Dataloading: 0.0020 s/iter. Inference: 0.2637 s/iter. Eval: 0.6845 s/iter. Total: 0.9505 s/iter. ETA=0:00:43
[09/04 05:30:49 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0020 s/iter. Inference: 0.2637 s/iter. Eval: 0.6831 s/iter. Total: 0.9491 s/iter. ETA=0:00:37
[09/04 05:30:55 d2.evaluation.evaluator]: Inference done 110/144. Dataloading: 0.0020 s/iter. Inference: 0.2637 s/iter. Eval: 0.6828 s/iter. Total: 0.9488 s/iter. ETA=0:00:32
[09/04 05:31:00 d2.evaluation.evaluator]: Inference done 116/144. Dataloading: 0.0020 s/iter. Inference: 0.2637 s/iter. Eval: 0.6819 s/iter. Total: 0.9478 s/iter. ETA=0:00:26
[09/04 05:31:05 d2.evaluation.evaluator]: Inference done 121/144. Dataloading: 0.0020 s/iter. Inference: 0.2637 s/iter. Eval: 0.6850 s/iter. Total: 0.9510 s/iter. ETA=0:00:21
[09/04 05:31:11 d2.evaluation.evaluator]: Inference done 127/144. Dataloading: 0.0020 s/iter. Inference: 0.2636 s/iter. Eval: 0.6838 s/iter. Total: 0.9497 s/iter. ETA=0:00:16
[09/04 05:31:16 d2.evaluation.evaluator]: Inference done 133/144. Dataloading: 0.0020 s/iter. Inference: 0.2637 s/iter. Eval: 0.6835 s/iter. Total: 0.9495 s/iter. ETA=0:00:10
[09/04 05:31:22 d2.evaluation.evaluator]: Inference done 139/144. Dataloading: 0.0020 s/iter. Inference: 0.2637 s/iter. Eval: 0.6825 s/iter. Total: 0.9484 s/iter. ETA=0:00:04
[09/04 05:31:27 d2.evaluation.evaluator]: Total inference time: 0:02:11.865481 (0.948673 s / iter per device, on 1 devices)
[09/04 05:31:27 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:36 (0.263608 s / iter per device, on 1 devices)
[09/04 05:31:27 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 05:31:27 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 05:31:27 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/04 05:31:27 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 05:31:27 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.
[09/04 05:31:27 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 05:31:27 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.004
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.016
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.152
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.050
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.156
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.165
[09/04 05:31:27 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.076 | 0.414  | 0.005  | 0.007 | 0.165 | 0.077 |
Loading and preparing results...
DONE (t=0.23s)
creating index...
index created!
[09/04 05:31:28 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 05:31:28 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.17 seconds.
[09/04 05:31:28 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 05:31:28 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.03 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.012
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.004
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.013
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.045
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.322
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.133
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.289
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.415
[09/04 05:31:28 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.312 | 1.219  | 0.085  | 0.008 | 0.373 | 1.341 |
[09/04 05:31:28 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 05:31:28 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 05:31:28 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 05:31:28 d2.evaluation.testing]: copypaste: 0.0758,0.4140,0.0046,0.0072,0.1648,0.0773
[09/04 05:31:28 d2.evaluation.testing]: copypaste: Task: segm
[09/04 05:31:28 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 05:31:28 d2.evaluation.testing]: copypaste: 0.3120,1.2195,0.0851,0.0084,0.3734,1.3414
[09/04 05:31:28 d2.utils.events]:  eta: 0:31:42  iter: 19  total_loss: 1.999  loss_cls: 0.7855  loss_box_reg: 0.4953  loss_mask: 0.6821  loss_rpn_cls: 0.006754  loss_rpn_loc: 0.0038  time: 1.9426  data_time: 0.0219  lr: 4.9953e-06  max_mem: 11021M
[09/04 05:32:07 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 05:32:07 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 05:32:07 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 05:32:07 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 05:32:07 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 05:32:18 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.2622 s/iter. Eval: 0.6902 s/iter. Total: 0.9540 s/iter. ETA=0:02:06
[09/04 05:32:24 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0021 s/iter. Inference: 0.2625 s/iter. Eval: 0.6750 s/iter. Total: 0.9398 s/iter. ETA=0:01:59
[09/04 05:32:30 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0021 s/iter. Inference: 0.2626 s/iter. Eval: 0.6754 s/iter. Total: 0.9403 s/iter. ETA=0:01:53
[09/04 05:32:35 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0021 s/iter. Inference: 0.2624 s/iter. Eval: 0.6720 s/iter. Total: 0.9367 s/iter. ETA=0:01:47
[09/04 05:32:41 d2.evaluation.evaluator]: Inference done 35/144. Dataloading: 0.0021 s/iter. Inference: 0.2627 s/iter. Eval: 0.6912 s/iter. Total: 0.9562 s/iter. ETA=0:01:44
[09/04 05:32:47 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0021 s/iter. Inference: 0.2627 s/iter. Eval: 0.6867 s/iter. Total: 0.9518 s/iter. ETA=0:01:38
[09/04 05:32:53 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0021 s/iter. Inference: 0.2629 s/iter. Eval: 0.6863 s/iter. Total: 0.9516 s/iter. ETA=0:01:32
[09/04 05:32:58 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0021 s/iter. Inference: 0.2628 s/iter. Eval: 0.6835 s/iter. Total: 0.9487 s/iter. ETA=0:01:26
[09/04 05:33:04 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0021 s/iter. Inference: 0.2631 s/iter. Eval: 0.6829 s/iter. Total: 0.9483 s/iter. ETA=0:01:20
[09/04 05:33:09 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0021 s/iter. Inference: 0.2630 s/iter. Eval: 0.6812 s/iter. Total: 0.9466 s/iter. ETA=0:01:14
[09/04 05:33:15 d2.evaluation.evaluator]: Inference done 70/144. Dataloading: 0.0021 s/iter. Inference: 0.2630 s/iter. Eval: 0.6898 s/iter. Total: 0.9552 s/iter. ETA=0:01:10
[09/04 05:33:20 d2.evaluation.evaluator]: Inference done 76/144. Dataloading: 0.0021 s/iter. Inference: 0.2630 s/iter. Eval: 0.6877 s/iter. Total: 0.9531 s/iter. ETA=0:01:04
[09/04 05:33:26 d2.evaluation.evaluator]: Inference done 82/144. Dataloading: 0.0021 s/iter. Inference: 0.2630 s/iter. Eval: 0.6872 s/iter. Total: 0.9526 s/iter. ETA=0:00:59
[09/04 05:33:32 d2.evaluation.evaluator]: Inference done 88/144. Dataloading: 0.0022 s/iter. Inference: 0.2630 s/iter. Eval: 0.6853 s/iter. Total: 0.9507 s/iter. ETA=0:00:53
[09/04 05:33:37 d2.evaluation.evaluator]: Inference done 94/144. Dataloading: 0.0022 s/iter. Inference: 0.2629 s/iter. Eval: 0.6852 s/iter. Total: 0.9505 s/iter. ETA=0:00:47
[09/04 05:33:43 d2.evaluation.evaluator]: Inference done 100/144. Dataloading: 0.0022 s/iter. Inference: 0.2628 s/iter. Eval: 0.6843 s/iter. Total: 0.9496 s/iter. ETA=0:00:41
[09/04 05:33:48 d2.evaluation.evaluator]: Inference done 105/144. Dataloading: 0.0023 s/iter. Inference: 0.2631 s/iter. Eval: 0.6876 s/iter. Total: 0.9533 s/iter. ETA=0:00:37
[09/04 05:33:53 d2.evaluation.evaluator]: Inference done 111/144. Dataloading: 0.0023 s/iter. Inference: 0.2631 s/iter. Eval: 0.6861 s/iter. Total: 0.9517 s/iter. ETA=0:00:31
[09/04 05:33:59 d2.evaluation.evaluator]: Inference done 117/144. Dataloading: 0.0023 s/iter. Inference: 0.2631 s/iter. Eval: 0.6862 s/iter. Total: 0.9517 s/iter. ETA=0:00:25
[09/04 05:34:05 d2.evaluation.evaluator]: Inference done 123/144. Dataloading: 0.0023 s/iter. Inference: 0.2630 s/iter. Eval: 0.6849 s/iter. Total: 0.9504 s/iter. ETA=0:00:19
[09/04 05:34:10 d2.evaluation.evaluator]: Inference done 129/144. Dataloading: 0.0023 s/iter. Inference: 0.2630 s/iter. Eval: 0.6846 s/iter. Total: 0.9502 s/iter. ETA=0:00:14
[09/04 05:34:16 d2.evaluation.evaluator]: Inference done 135/144. Dataloading: 0.0023 s/iter. Inference: 0.2630 s/iter. Eval: 0.6837 s/iter. Total: 0.9493 s/iter. ETA=0:00:08
[09/04 05:34:21 d2.evaluation.evaluator]: Inference done 140/144. Dataloading: 0.0024 s/iter. Inference: 0.2630 s/iter. Eval: 0.6870 s/iter. Total: 0.9526 s/iter. ETA=0:00:03
[09/04 05:34:25 d2.evaluation.evaluator]: Total inference time: 0:02:12.335473 (0.952054 s / iter per device, on 1 devices)
[09/04 05:34:25 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:36 (0.262951 s / iter per device, on 1 devices)
[09/04 05:34:25 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 05:34:25 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 05:34:25 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/04 05:34:25 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 05:34:25 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.
[09/04 05:34:25 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 05:34:25 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.011
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.004
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.003
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.032
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.271
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.058
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.256
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.336
[09/04 05:34:25 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.265 | 1.104  | 0.050  | 0.042 | 0.396 | 0.342 |
Loading and preparing results...
DONE (t=0.28s)
creating index...
index created!
[09/04 05:34:26 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 05:34:26 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.19 seconds.
[09/04 05:34:26 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 05:34:26 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.03 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.003
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.008
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.020
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.004
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.074
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.449
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.125
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.404
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.585
[09/04 05:34:26 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.742 | 2.480  | 0.350  | 0.037 | 0.801 | 2.004 |
[09/04 05:34:26 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 05:34:26 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 05:34:26 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 05:34:26 d2.evaluation.testing]: copypaste: 0.2653,1.1036,0.0496,0.0417,0.3960,0.3417
[09/04 05:34:26 d2.evaluation.testing]: copypaste: Task: segm
[09/04 05:34:26 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 05:34:26 d2.evaluation.testing]: copypaste: 0.7423,2.4798,0.3499,0.0369,0.8008,2.0036
[09/04 05:34:26 d2.utils.events]:  eta: 0:31:02  iter: 39  total_loss: 1.791  loss_cls: 0.718  loss_box_reg: 0.3338  loss_mask: 0.6691  loss_rpn_cls: 0.02488  loss_rpn_loc: 0.006031  time: 1.9409  data_time: 0.0061  lr: 9.9902e-06  max_mem: 11021M
[09/04 05:35:05 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 05:35:05 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 05:35:05 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 05:35:05 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 05:35:05 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 05:35:16 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.2632 s/iter. Eval: 0.7357 s/iter. Total: 1.0005 s/iter. ETA=0:02:13
[09/04 05:35:22 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0024 s/iter. Inference: 0.2627 s/iter. Eval: 0.6996 s/iter. Total: 0.9649 s/iter. ETA=0:02:02
[09/04 05:35:27 d2.evaluation.evaluator]: Inference done 22/144. Dataloading: 0.0024 s/iter. Inference: 0.2630 s/iter. Eval: 0.7189 s/iter. Total: 0.9845 s/iter. ETA=0:02:00
[09/04 05:35:33 d2.evaluation.evaluator]: Inference done 28/144. Dataloading: 0.0026 s/iter. Inference: 0.2628 s/iter. Eval: 0.7038 s/iter. Total: 0.9695 s/iter. ETA=0:01:52
[09/04 05:35:38 d2.evaluation.evaluator]: Inference done 34/144. Dataloading: 0.0025 s/iter. Inference: 0.2629 s/iter. Eval: 0.6983 s/iter. Total: 0.9640 s/iter. ETA=0:01:46
[09/04 05:35:44 d2.evaluation.evaluator]: Inference done 40/144. Dataloading: 0.0025 s/iter. Inference: 0.2628 s/iter. Eval: 0.6925 s/iter. Total: 0.9581 s/iter. ETA=0:01:39
[09/04 05:35:50 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0024 s/iter. Inference: 0.2628 s/iter. Eval: 0.6908 s/iter. Total: 0.9563 s/iter. ETA=0:01:33
[09/04 05:35:55 d2.evaluation.evaluator]: Inference done 52/144. Dataloading: 0.0024 s/iter. Inference: 0.2627 s/iter. Eval: 0.6878 s/iter. Total: 0.9532 s/iter. ETA=0:01:27
[09/04 05:36:00 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0024 s/iter. Inference: 0.2629 s/iter. Eval: 0.6976 s/iter. Total: 0.9631 s/iter. ETA=0:01:23
[09/04 05:36:06 d2.evaluation.evaluator]: Inference done 63/144. Dataloading: 0.0024 s/iter. Inference: 0.2629 s/iter. Eval: 0.6938 s/iter. Total: 0.9593 s/iter. ETA=0:01:17
[09/04 05:36:12 d2.evaluation.evaluator]: Inference done 69/144. Dataloading: 0.0024 s/iter. Inference: 0.2632 s/iter. Eval: 0.6923 s/iter. Total: 0.9582 s/iter. ETA=0:01:11
[09/04 05:36:17 d2.evaluation.evaluator]: Inference done 75/144. Dataloading: 0.0024 s/iter. Inference: 0.2631 s/iter. Eval: 0.6896 s/iter. Total: 0.9554 s/iter. ETA=0:01:05
[09/04 05:36:23 d2.evaluation.evaluator]: Inference done 81/144. Dataloading: 0.0024 s/iter. Inference: 0.2631 s/iter. Eval: 0.6893 s/iter. Total: 0.9551 s/iter. ETA=0:01:00
[09/04 05:36:29 d2.evaluation.evaluator]: Inference done 87/144. Dataloading: 0.0024 s/iter. Inference: 0.2631 s/iter. Eval: 0.6877 s/iter. Total: 0.9534 s/iter. ETA=0:00:54
[09/04 05:36:34 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0027 s/iter. Inference: 0.2633 s/iter. Eval: 0.6920 s/iter. Total: 0.9582 s/iter. ETA=0:00:49
[09/04 05:36:39 d2.evaluation.evaluator]: Inference done 98/144. Dataloading: 0.0026 s/iter. Inference: 0.2633 s/iter. Eval: 0.6900 s/iter. Total: 0.9562 s/iter. ETA=0:00:43
[09/04 05:36:45 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0026 s/iter. Inference: 0.2633 s/iter. Eval: 0.6899 s/iter. Total: 0.9561 s/iter. ETA=0:00:38
[09/04 05:36:51 d2.evaluation.evaluator]: Inference done 110/144. Dataloading: 0.0026 s/iter. Inference: 0.2632 s/iter. Eval: 0.6883 s/iter. Total: 0.9544 s/iter. ETA=0:00:32
[09/04 05:36:56 d2.evaluation.evaluator]: Inference done 116/144. Dataloading: 0.0026 s/iter. Inference: 0.2631 s/iter. Eval: 0.6878 s/iter. Total: 0.9537 s/iter. ETA=0:00:26
[09/04 05:37:02 d2.evaluation.evaluator]: Inference done 122/144. Dataloading: 0.0026 s/iter. Inference: 0.2631 s/iter. Eval: 0.6867 s/iter. Total: 0.9526 s/iter. ETA=0:00:20
[09/04 05:37:07 d2.evaluation.evaluator]: Inference done 127/144. Dataloading: 0.0027 s/iter. Inference: 0.2634 s/iter. Eval: 0.6893 s/iter. Total: 0.9555 s/iter. ETA=0:00:16
[09/04 05:37:13 d2.evaluation.evaluator]: Inference done 133/144. Dataloading: 0.0027 s/iter. Inference: 0.2633 s/iter. Eval: 0.6883 s/iter. Total: 0.9545 s/iter. ETA=0:00:10
[09/04 05:37:18 d2.evaluation.evaluator]: Inference done 139/144. Dataloading: 0.0026 s/iter. Inference: 0.2633 s/iter. Eval: 0.6889 s/iter. Total: 0.9551 s/iter. ETA=0:00:04
[09/04 05:37:23 d2.evaluation.evaluator]: Total inference time: 0:02:12.694931 (0.954640 s / iter per device, on 1 devices)
[09/04 05:37:23 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:36 (0.263257 s / iter per device, on 1 devices)
[09/04 05:37:23 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 05:37:23 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 05:37:23 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/04 05:37:23 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 05:37:24 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.
[09/04 05:37:24 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 05:37:24 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.009
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.028
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.003
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.005
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.101
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.391
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.379
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.464
[09/04 05:37:24 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.882 | 2.831  | 0.257  | 0.140 | 0.909 | 1.494 |
Loading and preparing results...
DONE (t=0.29s)
creating index...
index created!
[09/04 05:37:24 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 05:37:25 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.21 seconds.
[09/04 05:37:25 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 05:37:25 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.018
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.050
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.012
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.015
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.063
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.163
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.555
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.150
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.514
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.702
[09/04 05:37:25 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 1.781 | 5.019  | 1.246  | 0.127 | 1.476 | 6.297 |
[09/04 05:37:25 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 05:37:25 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 05:37:25 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 05:37:25 d2.evaluation.testing]: copypaste: 0.8818,2.8305,0.2565,0.1402,0.9093,1.4937
[09/04 05:37:25 d2.evaluation.testing]: copypaste: Task: segm
[09/04 05:37:25 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 05:37:25 d2.evaluation.testing]: copypaste: 1.7807,5.0194,1.2464,0.1268,1.4760,6.2974
[09/04 05:37:25 d2.utils.events]:  eta: 0:30:24  iter: 59  total_loss: 1.638  loss_cls: 0.5591  loss_box_reg: 0.4148  loss_mask: 0.6337  loss_rpn_cls: 0.01039  loss_rpn_loc: 0.004692  time: 1.9423  data_time: 0.0068  lr: 1.4985e-05  max_mem: 11021M
[09/04 05:38:04 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 05:38:04 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 05:38:04 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 05:38:04 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 05:38:04 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 05:38:15 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0017 s/iter. Inference: 0.2686 s/iter. Eval: 0.7499 s/iter. Total: 1.0203 s/iter. ETA=0:02:15
[09/04 05:38:21 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0021 s/iter. Inference: 0.2662 s/iter. Eval: 0.7272 s/iter. Total: 0.9957 s/iter. ETA=0:02:06
[09/04 05:38:26 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0021 s/iter. Inference: 0.2656 s/iter. Eval: 0.7094 s/iter. Total: 0.9774 s/iter. ETA=0:01:58
[09/04 05:38:32 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0021 s/iter. Inference: 0.2650 s/iter. Eval: 0.6996 s/iter. Total: 0.9671 s/iter. ETA=0:01:51
[09/04 05:38:37 d2.evaluation.evaluator]: Inference done 35/144. Dataloading: 0.0021 s/iter. Inference: 0.2649 s/iter. Eval: 0.6949 s/iter. Total: 0.9622 s/iter. ETA=0:01:44
[09/04 05:38:44 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0021 s/iter. Inference: 0.2648 s/iter. Eval: 0.7082 s/iter. Total: 0.9754 s/iter. ETA=0:01:40
[09/04 05:38:49 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0022 s/iter. Inference: 0.2646 s/iter. Eval: 0.7013 s/iter. Total: 0.9684 s/iter. ETA=0:01:33
[09/04 05:38:55 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0021 s/iter. Inference: 0.2644 s/iter. Eval: 0.6985 s/iter. Total: 0.9653 s/iter. ETA=0:01:27
[09/04 05:39:01 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0022 s/iter. Inference: 0.2642 s/iter. Eval: 0.6943 s/iter. Total: 0.9610 s/iter. ETA=0:01:21
[09/04 05:39:06 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0022 s/iter. Inference: 0.2641 s/iter. Eval: 0.6938 s/iter. Total: 0.9604 s/iter. ETA=0:01:15
[09/04 05:39:12 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0022 s/iter. Inference: 0.2639 s/iter. Eval: 0.6916 s/iter. Total: 0.9581 s/iter. ETA=0:01:09
[09/04 05:39:17 d2.evaluation.evaluator]: Inference done 76/144. Dataloading: 0.0024 s/iter. Inference: 0.2643 s/iter. Eval: 0.6974 s/iter. Total: 0.9644 s/iter. ETA=0:01:05
[09/04 05:39:23 d2.evaluation.evaluator]: Inference done 82/144. Dataloading: 0.0024 s/iter. Inference: 0.2642 s/iter. Eval: 0.6950 s/iter. Total: 0.9618 s/iter. ETA=0:00:59
[09/04 05:39:28 d2.evaluation.evaluator]: Inference done 88/144. Dataloading: 0.0024 s/iter. Inference: 0.2641 s/iter. Eval: 0.6944 s/iter. Total: 0.9612 s/iter. ETA=0:00:53
[09/04 05:39:34 d2.evaluation.evaluator]: Inference done 94/144. Dataloading: 0.0024 s/iter. Inference: 0.2641 s/iter. Eval: 0.6921 s/iter. Total: 0.9589 s/iter. ETA=0:00:47
[09/04 05:39:40 d2.evaluation.evaluator]: Inference done 100/144. Dataloading: 0.0024 s/iter. Inference: 0.2642 s/iter. Eval: 0.6912 s/iter. Total: 0.9580 s/iter. ETA=0:00:42
[09/04 05:39:45 d2.evaluation.evaluator]: Inference done 106/144. Dataloading: 0.0023 s/iter. Inference: 0.2641 s/iter. Eval: 0.6895 s/iter. Total: 0.9562 s/iter. ETA=0:00:36
[09/04 05:39:50 d2.evaluation.evaluator]: Inference done 111/144. Dataloading: 0.0024 s/iter. Inference: 0.2642 s/iter. Eval: 0.6939 s/iter. Total: 0.9607 s/iter. ETA=0:00:31
[09/04 05:39:56 d2.evaluation.evaluator]: Inference done 117/144. Dataloading: 0.0024 s/iter. Inference: 0.2641 s/iter. Eval: 0.6929 s/iter. Total: 0.9596 s/iter. ETA=0:00:25
[09/04 05:40:02 d2.evaluation.evaluator]: Inference done 123/144. Dataloading: 0.0024 s/iter. Inference: 0.2642 s/iter. Eval: 0.6925 s/iter. Total: 0.9594 s/iter. ETA=0:00:20
[09/04 05:40:07 d2.evaluation.evaluator]: Inference done 129/144. Dataloading: 0.0024 s/iter. Inference: 0.2641 s/iter. Eval: 0.6911 s/iter. Total: 0.9579 s/iter. ETA=0:00:14
[09/04 05:40:13 d2.evaluation.evaluator]: Inference done 135/144. Dataloading: 0.0024 s/iter. Inference: 0.2641 s/iter. Eval: 0.6910 s/iter. Total: 0.9577 s/iter. ETA=0:00:08
[09/04 05:40:19 d2.evaluation.evaluator]: Inference done 141/144. Dataloading: 0.0024 s/iter. Inference: 0.2640 s/iter. Eval: 0.6899 s/iter. Total: 0.9565 s/iter. ETA=0:00:02
[09/04 05:40:22 d2.evaluation.evaluator]: Total inference time: 0:02:13.337228 (0.959261 s / iter per device, on 1 devices)
[09/04 05:40:22 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:36 (0.263940 s / iter per device, on 1 devices)
[09/04 05:40:22 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 05:40:22 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 05:40:22 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/04 05:40:22 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 05:40:23 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.
[09/04 05:40:23 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 05:40:23 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.020
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.057
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.009
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.018
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.039
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.015
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.217
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.436
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.158
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.441
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.479
[09/04 05:40:23 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 2.045 | 5.658  | 0.936  | 0.340 | 1.819 | 3.868 |
Loading and preparing results...
DONE (t=0.28s)
creating index...
index created!
[09/04 05:40:23 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 05:40:23 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.21 seconds.
[09/04 05:40:23 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 05:40:24 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.034
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.082
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.026
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.025
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.119
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.026
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.283
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.589
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.192
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.563
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.708
[09/04 05:40:24 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 3.389 | 8.153  | 2.590  | 0.352 | 2.466 | 11.882 |
[09/04 05:40:24 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 05:40:24 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 05:40:24 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 05:40:24 d2.evaluation.testing]: copypaste: 2.0453,5.6581,0.9359,0.3399,1.8185,3.8684
[09/04 05:40:24 d2.evaluation.testing]: copypaste: Task: segm
[09/04 05:40:24 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 05:40:24 d2.evaluation.testing]: copypaste: 3.3887,8.1526,2.5897,0.3521,2.4661,11.8820
[09/04 05:40:24 d2.utils.events]:  eta: 0:29:46  iter: 79  total_loss: 1.484  loss_cls: 0.4575  loss_box_reg: 0.4386  loss_mask: 0.5939  loss_rpn_cls: 0.02191  loss_rpn_loc: 0.004689  time: 1.9430  data_time: 0.0064  lr: 1.998e-05  max_mem: 11021M
[09/04 05:41:03 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 05:41:03 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 05:41:03 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 05:41:03 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 05:41:03 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 05:41:13 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.2632 s/iter. Eval: 0.6676 s/iter. Total: 0.9324 s/iter. ETA=0:02:04
[09/04 05:41:19 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0030 s/iter. Inference: 0.2643 s/iter. Eval: 0.6781 s/iter. Total: 0.9456 s/iter. ETA=0:02:00
[09/04 05:41:25 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0027 s/iter. Inference: 0.2637 s/iter. Eval: 0.6746 s/iter. Total: 0.9412 s/iter. ETA=0:01:53
[09/04 05:41:30 d2.evaluation.evaluator]: Inference done 28/144. Dataloading: 0.0026 s/iter. Inference: 0.2651 s/iter. Eval: 0.6975 s/iter. Total: 0.9654 s/iter. ETA=0:01:51
[09/04 05:41:35 d2.evaluation.evaluator]: Inference done 34/144. Dataloading: 0.0026 s/iter. Inference: 0.2645 s/iter. Eval: 0.6896 s/iter. Total: 0.9570 s/iter. ETA=0:01:45
[09/04 05:41:41 d2.evaluation.evaluator]: Inference done 40/144. Dataloading: 0.0026 s/iter. Inference: 0.2643 s/iter. Eval: 0.6893 s/iter. Total: 0.9564 s/iter. ETA=0:01:39
[09/04 05:41:47 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0026 s/iter. Inference: 0.2639 s/iter. Eval: 0.6853 s/iter. Total: 0.9521 s/iter. ETA=0:01:33
[09/04 05:41:52 d2.evaluation.evaluator]: Inference done 52/144. Dataloading: 0.0026 s/iter. Inference: 0.2638 s/iter. Eval: 0.6852 s/iter. Total: 0.9519 s/iter. ETA=0:01:27
[09/04 05:41:58 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0026 s/iter. Inference: 0.2642 s/iter. Eval: 0.6892 s/iter. Total: 0.9561 s/iter. ETA=0:01:22
[09/04 05:42:04 d2.evaluation.evaluator]: Inference done 64/144. Dataloading: 0.0025 s/iter. Inference: 0.2639 s/iter. Eval: 0.6888 s/iter. Total: 0.9555 s/iter. ETA=0:01:16
[09/04 05:42:10 d2.evaluation.evaluator]: Inference done 70/144. Dataloading: 0.0025 s/iter. Inference: 0.2637 s/iter. Eval: 0.6863 s/iter. Total: 0.9527 s/iter. ETA=0:01:10
[09/04 05:42:15 d2.evaluation.evaluator]: Inference done 76/144. Dataloading: 0.0025 s/iter. Inference: 0.2636 s/iter. Eval: 0.6866 s/iter. Total: 0.9529 s/iter. ETA=0:01:04
[09/04 05:42:21 d2.evaluation.evaluator]: Inference done 82/144. Dataloading: 0.0024 s/iter. Inference: 0.2635 s/iter. Eval: 0.6848 s/iter. Total: 0.9510 s/iter. ETA=0:00:58
[09/04 05:42:26 d2.evaluation.evaluator]: Inference done 88/144. Dataloading: 0.0024 s/iter. Inference: 0.2635 s/iter. Eval: 0.6844 s/iter. Total: 0.9506 s/iter. ETA=0:00:53
[09/04 05:42:32 d2.evaluation.evaluator]: Inference done 93/144. Dataloading: 0.0025 s/iter. Inference: 0.2635 s/iter. Eval: 0.6876 s/iter. Total: 0.9538 s/iter. ETA=0:00:48
[09/04 05:42:37 d2.evaluation.evaluator]: Inference done 99/144. Dataloading: 0.0025 s/iter. Inference: 0.2634 s/iter. Eval: 0.6876 s/iter. Total: 0.9537 s/iter. ETA=0:00:42
[09/04 05:42:43 d2.evaluation.evaluator]: Inference done 105/144. Dataloading: 0.0025 s/iter. Inference: 0.2633 s/iter. Eval: 0.6867 s/iter. Total: 0.9527 s/iter. ETA=0:00:37
[09/04 05:42:49 d2.evaluation.evaluator]: Inference done 111/144. Dataloading: 0.0025 s/iter. Inference: 0.2633 s/iter. Eval: 0.6865 s/iter. Total: 0.9525 s/iter. ETA=0:00:31
[09/04 05:42:54 d2.evaluation.evaluator]: Inference done 117/144. Dataloading: 0.0025 s/iter. Inference: 0.2632 s/iter. Eval: 0.6852 s/iter. Total: 0.9511 s/iter. ETA=0:00:25
[09/04 05:43:00 d2.evaluation.evaluator]: Inference done 123/144. Dataloading: 0.0026 s/iter. Inference: 0.2632 s/iter. Eval: 0.6852 s/iter. Total: 0.9512 s/iter. ETA=0:00:19
[09/04 05:43:06 d2.evaluation.evaluator]: Inference done 129/144. Dataloading: 0.0026 s/iter. Inference: 0.2632 s/iter. Eval: 0.6868 s/iter. Total: 0.9528 s/iter. ETA=0:00:14
[09/04 05:43:11 d2.evaluation.evaluator]: Inference done 135/144. Dataloading: 0.0026 s/iter. Inference: 0.2632 s/iter. Eval: 0.6865 s/iter. Total: 0.9525 s/iter. ETA=0:00:08
[09/04 05:43:17 d2.evaluation.evaluator]: Inference done 141/144. Dataloading: 0.0026 s/iter. Inference: 0.2631 s/iter. Eval: 0.6854 s/iter. Total: 0.9514 s/iter. ETA=0:00:02
[09/04 05:43:20 d2.evaluation.evaluator]: Total inference time: 0:02:12.327844 (0.951999 s / iter per device, on 1 devices)
[09/04 05:43:20 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:36 (0.263091 s / iter per device, on 1 devices)
[09/04 05:43:20 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 05:43:20 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 05:43:20 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/04 05:43:20 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 05:43:20 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.
[09/04 05:43:20 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 05:43:20 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.041
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.090
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.027
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.017
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.034
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.075
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.047
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.319
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.501
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.175
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.507
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.548
[09/04 05:43:20 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 4.064 | 9.044  | 2.678  | 1.666 | 3.368 | 7.451 |
Loading and preparing results...
DONE (t=0.27s)
creating index...
index created!
[09/04 05:43:21 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 05:43:21 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.19 seconds.
[09/04 05:43:21 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 05:43:21 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.058
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.125
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.052
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.009
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.039
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.181
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.069
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.378
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.608
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.579
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.733
[09/04 05:43:21 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 5.800 | 12.467 | 5.233  | 0.866 | 3.872 | 18.088 |
[09/04 05:43:21 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 05:43:21 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 05:43:21 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 05:43:21 d2.evaluation.testing]: copypaste: 4.0636,9.0442,2.6784,1.6656,3.3679,7.4506
[09/04 05:43:21 d2.evaluation.testing]: copypaste: Task: segm
[09/04 05:43:21 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 05:43:21 d2.evaluation.testing]: copypaste: 5.8003,12.4666,5.2327,0.8658,3.8716,18.0876
[09/04 05:43:21 d2.utils.events]:  eta: 0:29:07  iter: 99  total_loss: 1.384  loss_cls: 0.3607  loss_box_reg: 0.4348  loss_mask: 0.5523  loss_rpn_cls: 0.01924  loss_rpn_loc: 0.006011  time: 1.9430  data_time: 0.0062  lr: 2.4975e-05  max_mem: 11021M
[09/04 05:44:00 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 05:44:00 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 05:44:00 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 05:44:00 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 05:44:00 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 05:44:11 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0025 s/iter. Inference: 0.2662 s/iter. Eval: 0.7212 s/iter. Total: 0.9899 s/iter. ETA=0:02:11
[09/04 05:44:17 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0026 s/iter. Inference: 0.2645 s/iter. Eval: 0.7115 s/iter. Total: 0.9788 s/iter. ETA=0:02:04
[09/04 05:44:23 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0026 s/iter. Inference: 0.2639 s/iter. Eval: 0.6962 s/iter. Total: 0.9628 s/iter. ETA=0:01:56
[09/04 05:44:28 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0025 s/iter. Inference: 0.2638 s/iter. Eval: 0.6924 s/iter. Total: 0.9589 s/iter. ETA=0:01:50
[09/04 05:44:34 d2.evaluation.evaluator]: Inference done 35/144. Dataloading: 0.0025 s/iter. Inference: 0.2635 s/iter. Eval: 0.6952 s/iter. Total: 0.9614 s/iter. ETA=0:01:44
[09/04 05:44:39 d2.evaluation.evaluator]: Inference done 40/144. Dataloading: 0.0026 s/iter. Inference: 0.2632 s/iter. Eval: 0.7055 s/iter. Total: 0.9715 s/iter. ETA=0:01:41
[09/04 05:44:45 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0026 s/iter. Inference: 0.2635 s/iter. Eval: 0.6998 s/iter. Total: 0.9662 s/iter. ETA=0:01:34
[09/04 05:44:51 d2.evaluation.evaluator]: Inference done 52/144. Dataloading: 0.0026 s/iter. Inference: 0.2637 s/iter. Eval: 0.6973 s/iter. Total: 0.9639 s/iter. ETA=0:01:28
[09/04 05:44:56 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0026 s/iter. Inference: 0.2635 s/iter. Eval: 0.6931 s/iter. Total: 0.9595 s/iter. ETA=0:01:22
[09/04 05:45:02 d2.evaluation.evaluator]: Inference done 64/144. Dataloading: 0.0025 s/iter. Inference: 0.2634 s/iter. Eval: 0.6924 s/iter. Total: 0.9586 s/iter. ETA=0:01:16
[09/04 05:45:07 d2.evaluation.evaluator]: Inference done 70/144. Dataloading: 0.0025 s/iter. Inference: 0.2632 s/iter. Eval: 0.6896 s/iter. Total: 0.9556 s/iter. ETA=0:01:10
[09/04 05:45:13 d2.evaluation.evaluator]: Inference done 75/144. Dataloading: 0.0025 s/iter. Inference: 0.2632 s/iter. Eval: 0.6944 s/iter. Total: 0.9605 s/iter. ETA=0:01:06
[09/04 05:45:18 d2.evaluation.evaluator]: Inference done 81/144. Dataloading: 0.0025 s/iter. Inference: 0.2632 s/iter. Eval: 0.6924 s/iter. Total: 0.9583 s/iter. ETA=0:01:00
[09/04 05:45:24 d2.evaluation.evaluator]: Inference done 87/144. Dataloading: 0.0025 s/iter. Inference: 0.2631 s/iter. Eval: 0.6927 s/iter. Total: 0.9585 s/iter. ETA=0:00:54
[09/04 05:45:29 d2.evaluation.evaluator]: Inference done 93/144. Dataloading: 0.0025 s/iter. Inference: 0.2630 s/iter. Eval: 0.6908 s/iter. Total: 0.9566 s/iter. ETA=0:00:48
[09/04 05:45:35 d2.evaluation.evaluator]: Inference done 99/144. Dataloading: 0.0024 s/iter. Inference: 0.2630 s/iter. Eval: 0.6901 s/iter. Total: 0.9558 s/iter. ETA=0:00:43
[09/04 05:45:41 d2.evaluation.evaluator]: Inference done 105/144. Dataloading: 0.0024 s/iter. Inference: 0.2630 s/iter. Eval: 0.6890 s/iter. Total: 0.9546 s/iter. ETA=0:00:37
[09/04 05:45:46 d2.evaluation.evaluator]: Inference done 110/144. Dataloading: 0.0024 s/iter. Inference: 0.2631 s/iter. Eval: 0.6918 s/iter. Total: 0.9575 s/iter. ETA=0:00:32
[09/04 05:45:51 d2.evaluation.evaluator]: Inference done 116/144. Dataloading: 0.0024 s/iter. Inference: 0.2630 s/iter. Eval: 0.6903 s/iter. Total: 0.9560 s/iter. ETA=0:00:26
[09/04 05:45:57 d2.evaluation.evaluator]: Inference done 122/144. Dataloading: 0.0024 s/iter. Inference: 0.2629 s/iter. Eval: 0.6901 s/iter. Total: 0.9557 s/iter. ETA=0:00:21
[09/04 05:46:03 d2.evaluation.evaluator]: Inference done 128/144. Dataloading: 0.0024 s/iter. Inference: 0.2628 s/iter. Eval: 0.6889 s/iter. Total: 0.9544 s/iter. ETA=0:00:15
[09/04 05:46:08 d2.evaluation.evaluator]: Inference done 134/144. Dataloading: 0.0024 s/iter. Inference: 0.2630 s/iter. Eval: 0.6882 s/iter. Total: 0.9539 s/iter. ETA=0:00:09
[09/04 05:46:14 d2.evaluation.evaluator]: Inference done 140/144. Dataloading: 0.0024 s/iter. Inference: 0.2630 s/iter. Eval: 0.6882 s/iter. Total: 0.9539 s/iter. ETA=0:00:03
[09/04 05:46:18 d2.evaluation.evaluator]: Total inference time: 0:02:12.905101 (0.956152 s / iter per device, on 1 devices)
[09/04 05:46:18 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:36 (0.262989 s / iter per device, on 1 devices)
[09/04 05:46:18 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 05:46:18 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 05:46:19 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/04 05:46:19 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 05:46:19 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.12 seconds.
[09/04 05:46:19 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 05:46:19 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.075
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.143
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.070
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.055
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.055
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.150
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.083
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.418
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.538
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.250
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.506
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.647
[09/04 05:46:19 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 7.541 | 14.336 | 6.995  | 5.521 | 5.505 | 14.958 |
Loading and preparing results...
DONE (t=0.27s)
creating index...
index created!
[09/04 05:46:19 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 05:46:20 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.19 seconds.
[09/04 05:46:20 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 05:46:20 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.093
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.167
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.096
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.029
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.059
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.256
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.107
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.467
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.624
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.267
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.590
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.747
[09/04 05:46:20 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 9.347 | 16.740 | 9.589  | 2.942 | 5.937 | 25.636 |
[09/04 05:46:20 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 05:46:20 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 05:46:20 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 05:46:20 d2.evaluation.testing]: copypaste: 7.5406,14.3361,6.9951,5.5214,5.5046,14.9585
[09/04 05:46:20 d2.evaluation.testing]: copypaste: Task: segm
[09/04 05:46:20 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 05:46:20 d2.evaluation.testing]: copypaste: 9.3472,16.7401,9.5889,2.9416,5.9366,25.6357
[09/04 05:46:20 d2.utils.events]:  eta: 0:28:28  iter: 119  total_loss: 1.07  loss_cls: 0.2941  loss_box_reg: 0.2948  loss_mask: 0.4735  loss_rpn_cls: 0.002971  loss_rpn_loc: 0.002184  time: 1.9422  data_time: 0.0060  lr: 2.997e-05  max_mem: 11021M
[09/04 05:46:59 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 05:46:59 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 05:46:59 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 05:46:59 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 05:46:59 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 05:47:09 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0019 s/iter. Inference: 0.2628 s/iter. Eval: 0.6900 s/iter. Total: 0.9547 s/iter. ETA=0:02:06
[09/04 05:47:15 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0023 s/iter. Inference: 0.2626 s/iter. Eval: 0.6758 s/iter. Total: 0.9410 s/iter. ETA=0:01:59
[09/04 05:47:21 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0022 s/iter. Inference: 0.2628 s/iter. Eval: 0.6781 s/iter. Total: 0.9433 s/iter. ETA=0:01:54
[09/04 05:47:26 d2.evaluation.evaluator]: Inference done 28/144. Dataloading: 0.0022 s/iter. Inference: 0.2635 s/iter. Eval: 0.6909 s/iter. Total: 0.9568 s/iter. ETA=0:01:50
[09/04 05:47:31 d2.evaluation.evaluator]: Inference done 34/144. Dataloading: 0.0022 s/iter. Inference: 0.2634 s/iter. Eval: 0.6914 s/iter. Total: 0.9572 s/iter. ETA=0:01:45
[09/04 05:47:37 d2.evaluation.evaluator]: Inference done 40/144. Dataloading: 0.0022 s/iter. Inference: 0.2632 s/iter. Eval: 0.6862 s/iter. Total: 0.9519 s/iter. ETA=0:01:38
[09/04 05:47:42 d2.evaluation.evaluator]: Inference done 45/144. Dataloading: 0.0022 s/iter. Inference: 0.2632 s/iter. Eval: 0.6929 s/iter. Total: 0.9584 s/iter. ETA=0:01:34
[09/04 05:47:48 d2.evaluation.evaluator]: Inference done 51/144. Dataloading: 0.0022 s/iter. Inference: 0.2636 s/iter. Eval: 0.6893 s/iter. Total: 0.9553 s/iter. ETA=0:01:28
[09/04 05:47:53 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0022 s/iter. Inference: 0.2636 s/iter. Eval: 0.6892 s/iter. Total: 0.9552 s/iter. ETA=0:01:23
[09/04 05:47:58 d2.evaluation.evaluator]: Inference done 62/144. Dataloading: 0.0024 s/iter. Inference: 0.2636 s/iter. Eval: 0.6934 s/iter. Total: 0.9597 s/iter. ETA=0:01:18
[09/04 05:48:04 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0024 s/iter. Inference: 0.2636 s/iter. Eval: 0.6935 s/iter. Total: 0.9597 s/iter. ETA=0:01:12
[09/04 05:48:10 d2.evaluation.evaluator]: Inference done 74/144. Dataloading: 0.0023 s/iter. Inference: 0.2637 s/iter. Eval: 0.6917 s/iter. Total: 0.9580 s/iter. ETA=0:01:07
[09/04 05:48:15 d2.evaluation.evaluator]: Inference done 80/144. Dataloading: 0.0023 s/iter. Inference: 0.2635 s/iter. Eval: 0.6913 s/iter. Total: 0.9574 s/iter. ETA=0:01:01
[09/04 05:48:21 d2.evaluation.evaluator]: Inference done 86/144. Dataloading: 0.0023 s/iter. Inference: 0.2635 s/iter. Eval: 0.6893 s/iter. Total: 0.9554 s/iter. ETA=0:00:55
[09/04 05:48:27 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0023 s/iter. Inference: 0.2635 s/iter. Eval: 0.6887 s/iter. Total: 0.9549 s/iter. ETA=0:00:49
[09/04 05:48:33 d2.evaluation.evaluator]: Inference done 98/144. Dataloading: 0.0023 s/iter. Inference: 0.2637 s/iter. Eval: 0.6903 s/iter. Total: 0.9566 s/iter. ETA=0:00:44
[09/04 05:48:38 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0023 s/iter. Inference: 0.2636 s/iter. Eval: 0.6903 s/iter. Total: 0.9565 s/iter. ETA=0:00:38
[09/04 05:48:44 d2.evaluation.evaluator]: Inference done 110/144. Dataloading: 0.0023 s/iter. Inference: 0.2636 s/iter. Eval: 0.6890 s/iter. Total: 0.9552 s/iter. ETA=0:00:32
[09/04 05:48:50 d2.evaluation.evaluator]: Inference done 116/144. Dataloading: 0.0023 s/iter. Inference: 0.2636 s/iter. Eval: 0.6884 s/iter. Total: 0.9545 s/iter. ETA=0:00:26
[09/04 05:48:55 d2.evaluation.evaluator]: Inference done 122/144. Dataloading: 0.0023 s/iter. Inference: 0.2635 s/iter. Eval: 0.6870 s/iter. Total: 0.9531 s/iter. ETA=0:00:20
[09/04 05:49:01 d2.evaluation.evaluator]: Inference done 128/144. Dataloading: 0.0024 s/iter. Inference: 0.2636 s/iter. Eval: 0.6895 s/iter. Total: 0.9558 s/iter. ETA=0:00:15
[09/04 05:49:07 d2.evaluation.evaluator]: Inference done 134/144. Dataloading: 0.0025 s/iter. Inference: 0.2636 s/iter. Eval: 0.6889 s/iter. Total: 0.9552 s/iter. ETA=0:00:09
[09/04 05:49:13 d2.evaluation.evaluator]: Inference done 140/144. Dataloading: 0.0024 s/iter. Inference: 0.2636 s/iter. Eval: 0.6887 s/iter. Total: 0.9550 s/iter. ETA=0:00:03
[09/04 05:49:16 d2.evaluation.evaluator]: Total inference time: 0:02:12.706218 (0.954721 s / iter per device, on 1 devices)
[09/04 05:49:16 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:36 (0.263604 s / iter per device, on 1 devices)
[09/04 05:49:16 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 05:49:16 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 05:49:17 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/04 05:49:17 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 05:49:17 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.
[09/04 05:49:17 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 05:49:17 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.117
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.227
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.119
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.121
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.092
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.193
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.163
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.449
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.548
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.267
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.517
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.653
[09/04 05:49:17 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm  |  APl   |
|:------:|:------:|:------:|:------:|:-----:|:------:|
| 11.688 | 22.662 | 11.887 | 12.127 | 9.189 | 19.329 |
Loading and preparing results...
DONE (t=0.26s)
creating index...
index created!
[09/04 05:49:17 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 05:49:18 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.19 seconds.
[09/04 05:49:18 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 05:49:18 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.146
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.244
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.155
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.069
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.096
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.315
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.194
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.503
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.644
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.609
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.767
[09/04 05:49:18 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:------:|:------:|:------:|:-----:|:-----:|:------:|
| 14.580 | 24.442 | 15.496 | 6.915 | 9.620 | 31.547 |
[09/04 05:49:18 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 05:49:18 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 05:49:18 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 05:49:18 d2.evaluation.testing]: copypaste: 11.6875,22.6616,11.8870,12.1268,9.1887,19.3291
[09/04 05:49:18 d2.evaluation.testing]: copypaste: Task: segm
[09/04 05:49:18 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 05:49:18 d2.evaluation.testing]: copypaste: 14.5796,24.4415,15.4959,6.9146,9.6202,31.5473
[09/04 05:49:18 d2.utils.events]:  eta: 0:27:49  iter: 139  total_loss: 1.16  loss_cls: 0.276  loss_box_reg: 0.412  loss_mask: 0.4334  loss_rpn_cls: 0.003229  loss_rpn_loc: 0.00585  time: 1.9421  data_time: 0.0063  lr: 3.4965e-05  max_mem: 11021M
[09/04 05:49:57 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 05:49:57 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 05:49:57 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 05:49:57 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 05:49:57 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 05:50:08 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0019 s/iter. Inference: 0.2669 s/iter. Eval: 0.7327 s/iter. Total: 1.0016 s/iter. ETA=0:02:13
[09/04 05:50:13 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0027 s/iter. Inference: 0.2631 s/iter. Eval: 0.6790 s/iter. Total: 0.9450 s/iter. ETA=0:02:00
[09/04 05:50:19 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0024 s/iter. Inference: 0.2635 s/iter. Eval: 0.6702 s/iter. Total: 0.9364 s/iter. ETA=0:01:53
[09/04 05:50:24 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0025 s/iter. Inference: 0.2634 s/iter. Eval: 0.6685 s/iter. Total: 0.9345 s/iter. ETA=0:01:47
[09/04 05:50:30 d2.evaluation.evaluator]: Inference done 35/144. Dataloading: 0.0025 s/iter. Inference: 0.2638 s/iter. Eval: 0.6709 s/iter. Total: 0.9374 s/iter. ETA=0:01:42
[09/04 05:50:35 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0024 s/iter. Inference: 0.2636 s/iter. Eval: 0.6694 s/iter. Total: 0.9357 s/iter. ETA=0:01:36
[09/04 05:50:41 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0026 s/iter. Inference: 0.2638 s/iter. Eval: 0.6807 s/iter. Total: 0.9474 s/iter. ETA=0:01:32
[09/04 05:50:46 d2.evaluation.evaluator]: Inference done 52/144. Dataloading: 0.0026 s/iter. Inference: 0.2638 s/iter. Eval: 0.6794 s/iter. Total: 0.9460 s/iter. ETA=0:01:27
[09/04 05:50:51 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0025 s/iter. Inference: 0.2637 s/iter. Eval: 0.6864 s/iter. Total: 0.9529 s/iter. ETA=0:01:22
[09/04 05:50:57 d2.evaluation.evaluator]: Inference done 63/144. Dataloading: 0.0025 s/iter. Inference: 0.2636 s/iter. Eval: 0.6839 s/iter. Total: 0.9503 s/iter. ETA=0:01:16
[09/04 05:51:02 d2.evaluation.evaluator]: Inference done 69/144. Dataloading: 0.0025 s/iter. Inference: 0.2636 s/iter. Eval: 0.6834 s/iter. Total: 0.9498 s/iter. ETA=0:01:11
[09/04 05:51:08 d2.evaluation.evaluator]: Inference done 75/144. Dataloading: 0.0025 s/iter. Inference: 0.2634 s/iter. Eval: 0.6796 s/iter. Total: 0.9457 s/iter. ETA=0:01:05
[09/04 05:51:13 d2.evaluation.evaluator]: Inference done 80/144. Dataloading: 0.0024 s/iter. Inference: 0.2636 s/iter. Eval: 0.6833 s/iter. Total: 0.9495 s/iter. ETA=0:01:00
[09/04 05:51:19 d2.evaluation.evaluator]: Inference done 86/144. Dataloading: 0.0026 s/iter. Inference: 0.2637 s/iter. Eval: 0.6822 s/iter. Total: 0.9488 s/iter. ETA=0:00:55
[09/04 05:51:24 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0026 s/iter. Inference: 0.2637 s/iter. Eval: 0.6831 s/iter. Total: 0.9497 s/iter. ETA=0:00:49
[09/04 05:51:30 d2.evaluation.evaluator]: Inference done 98/144. Dataloading: 0.0026 s/iter. Inference: 0.2635 s/iter. Eval: 0.6808 s/iter. Total: 0.9472 s/iter. ETA=0:00:43
[09/04 05:51:35 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0026 s/iter. Inference: 0.2635 s/iter. Eval: 0.6807 s/iter. Total: 0.9471 s/iter. ETA=0:00:37
[09/04 05:51:41 d2.evaluation.evaluator]: Inference done 110/144. Dataloading: 0.0027 s/iter. Inference: 0.2632 s/iter. Eval: 0.6761 s/iter. Total: 0.9422 s/iter. ETA=0:00:32
[09/04 05:51:46 d2.evaluation.evaluator]: Inference done 115/144. Dataloading: 0.0027 s/iter. Inference: 0.2631 s/iter. Eval: 0.6788 s/iter. Total: 0.9449 s/iter. ETA=0:00:27
[09/04 05:51:51 d2.evaluation.evaluator]: Inference done 121/144. Dataloading: 0.0027 s/iter. Inference: 0.2634 s/iter. Eval: 0.6773 s/iter. Total: 0.9436 s/iter. ETA=0:00:21
[09/04 05:51:57 d2.evaluation.evaluator]: Inference done 127/144. Dataloading: 0.0027 s/iter. Inference: 0.2635 s/iter. Eval: 0.6774 s/iter. Total: 0.9438 s/iter. ETA=0:00:16
[09/04 05:52:02 d2.evaluation.evaluator]: Inference done 133/144. Dataloading: 0.0027 s/iter. Inference: 0.2634 s/iter. Eval: 0.6766 s/iter. Total: 0.9429 s/iter. ETA=0:00:10
[09/04 05:52:08 d2.evaluation.evaluator]: Inference done 139/144. Dataloading: 0.0026 s/iter. Inference: 0.2633 s/iter. Eval: 0.6760 s/iter. Total: 0.9422 s/iter. ETA=0:00:04
[09/04 05:52:12 d2.evaluation.evaluator]: Total inference time: 0:02:10.646581 (0.939903 s / iter per device, on 1 devices)
[09/04 05:52:12 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:36 (0.263034 s / iter per device, on 1 devices)
[09/04 05:52:12 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 05:52:12 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 05:52:13 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/04 05:52:13 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 05:52:13 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.
[09/04 05:52:13 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 05:52:13 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.190
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.318
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.204
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.104
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.146
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.297
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.217
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.475
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.568
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.225
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.553
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.658
[09/04 05:52:13 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 19.013 | 31.794 | 20.432 | 10.409 | 14.560 | 29.686 |
Loading and preparing results...
DONE (t=0.26s)
creating index...
index created!
[09/04 05:52:13 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 05:52:14 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.18 seconds.
[09/04 05:52:14 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 05:52:14 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.216
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.324
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.243
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.063
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.142
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.404
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.245
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.528
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.658
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.267
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.634
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.770
[09/04 05:52:14 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 21.602 | 32.401 | 24.343 | 6.290 | 14.196 | 40.363 |
[09/04 05:52:14 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 05:52:14 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 05:52:14 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 05:52:14 d2.evaluation.testing]: copypaste: 19.0127,31.7942,20.4319,10.4094,14.5603,29.6859
[09/04 05:52:14 d2.evaluation.testing]: copypaste: Task: segm
[09/04 05:52:14 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 05:52:14 d2.evaluation.testing]: copypaste: 21.6019,32.4013,24.3430,6.2900,14.1957,40.3634
[09/04 05:52:14 d2.utils.events]:  eta: 0:27:11  iter: 159  total_loss: 1.169  loss_cls: 0.2583  loss_box_reg: 0.453  loss_mask: 0.3935  loss_rpn_cls: 0.01237  loss_rpn_loc: 0.008233  time: 1.9421  data_time: 0.0061  lr: 3.996e-05  max_mem: 11021M
[09/04 05:52:53 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 05:52:53 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 05:52:53 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 05:52:53 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 05:52:53 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 05:53:03 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0021 s/iter. Inference: 0.2638 s/iter. Eval: 0.6986 s/iter. Total: 0.9645 s/iter. ETA=0:02:08
[09/04 05:53:08 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0023 s/iter. Inference: 0.2595 s/iter. Eval: 0.6399 s/iter. Total: 0.9021 s/iter. ETA=0:01:54
[09/04 05:53:14 d2.evaluation.evaluator]: Inference done 24/144. Dataloading: 0.0025 s/iter. Inference: 0.2577 s/iter. Eval: 0.6127 s/iter. Total: 0.8731 s/iter. ETA=0:01:44
[09/04 05:53:19 d2.evaluation.evaluator]: Inference done 30/144. Dataloading: 0.0023 s/iter. Inference: 0.2577 s/iter. Eval: 0.6131 s/iter. Total: 0.8733 s/iter. ETA=0:01:39
[09/04 05:53:25 d2.evaluation.evaluator]: Inference done 36/144. Dataloading: 0.0022 s/iter. Inference: 0.2589 s/iter. Eval: 0.6383 s/iter. Total: 0.8997 s/iter. ETA=0:01:37
[09/04 05:53:31 d2.evaluation.evaluator]: Inference done 42/144. Dataloading: 0.0023 s/iter. Inference: 0.2588 s/iter. Eval: 0.6362 s/iter. Total: 0.8975 s/iter. ETA=0:01:31
[09/04 05:53:36 d2.evaluation.evaluator]: Inference done 48/144. Dataloading: 0.0024 s/iter. Inference: 0.2596 s/iter. Eval: 0.6421 s/iter. Total: 0.9042 s/iter. ETA=0:01:26
[09/04 05:53:42 d2.evaluation.evaluator]: Inference done 54/144. Dataloading: 0.0024 s/iter. Inference: 0.2599 s/iter. Eval: 0.6452 s/iter. Total: 0.9077 s/iter. ETA=0:01:21
[09/04 05:53:48 d2.evaluation.evaluator]: Inference done 60/144. Dataloading: 0.0025 s/iter. Inference: 0.2604 s/iter. Eval: 0.6488 s/iter. Total: 0.9119 s/iter. ETA=0:01:16
[09/04 05:53:53 d2.evaluation.evaluator]: Inference done 66/144. Dataloading: 0.0024 s/iter. Inference: 0.2607 s/iter. Eval: 0.6500 s/iter. Total: 0.9134 s/iter. ETA=0:01:11
[09/04 05:53:58 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0024 s/iter. Inference: 0.2608 s/iter. Eval: 0.6576 s/iter. Total: 0.9210 s/iter. ETA=0:01:07
[09/04 05:54:04 d2.evaluation.evaluator]: Inference done 78/144. Dataloading: 0.0026 s/iter. Inference: 0.2599 s/iter. Eval: 0.6474 s/iter. Total: 0.9102 s/iter. ETA=0:01:00
[09/04 05:54:10 d2.evaluation.evaluator]: Inference done 85/144. Dataloading: 0.0025 s/iter. Inference: 0.2592 s/iter. Eval: 0.6387 s/iter. Total: 0.9007 s/iter. ETA=0:00:53
[09/04 05:54:15 d2.evaluation.evaluator]: Inference done 91/144. Dataloading: 0.0025 s/iter. Inference: 0.2593 s/iter. Eval: 0.6388 s/iter. Total: 0.9008 s/iter. ETA=0:00:47
[09/04 05:54:20 d2.evaluation.evaluator]: Inference done 97/144. Dataloading: 0.0025 s/iter. Inference: 0.2595 s/iter. Eval: 0.6387 s/iter. Total: 0.9009 s/iter. ETA=0:00:42
[09/04 05:54:25 d2.evaluation.evaluator]: Inference done 103/144. Dataloading: 0.0025 s/iter. Inference: 0.2592 s/iter. Eval: 0.6348 s/iter. Total: 0.8968 s/iter. ETA=0:00:36
[09/04 05:54:31 d2.evaluation.evaluator]: Inference done 109/144. Dataloading: 0.0025 s/iter. Inference: 0.2590 s/iter. Eval: 0.6346 s/iter. Total: 0.8963 s/iter. ETA=0:00:31
[09/04 05:54:36 d2.evaluation.evaluator]: Inference done 115/144. Dataloading: 0.0025 s/iter. Inference: 0.2593 s/iter. Eval: 0.6366 s/iter. Total: 0.8986 s/iter. ETA=0:00:26
[09/04 05:54:41 d2.evaluation.evaluator]: Inference done 121/144. Dataloading: 0.0025 s/iter. Inference: 0.2590 s/iter. Eval: 0.6339 s/iter. Total: 0.8957 s/iter. ETA=0:00:20
[09/04 05:54:47 d2.evaluation.evaluator]: Inference done 127/144. Dataloading: 0.0025 s/iter. Inference: 0.2591 s/iter. Eval: 0.6347 s/iter. Total: 0.8965 s/iter. ETA=0:00:15
[09/04 05:54:52 d2.evaluation.evaluator]: Inference done 133/144. Dataloading: 0.0025 s/iter. Inference: 0.2589 s/iter. Eval: 0.6335 s/iter. Total: 0.8951 s/iter. ETA=0:00:09
[09/04 05:54:58 d2.evaluation.evaluator]: Inference done 140/144. Dataloading: 0.0025 s/iter. Inference: 0.2584 s/iter. Eval: 0.6273 s/iter. Total: 0.8884 s/iter. ETA=0:00:03
[09/04 05:55:01 d2.evaluation.evaluator]: Total inference time: 0:02:03.709555 (0.889997 s / iter per device, on 1 devices)
[09/04 05:55:01 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:35 (0.258467 s / iter per device, on 1 devices)
[09/04 05:55:01 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 05:55:01 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 05:55:02 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/04 05:55:02 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 05:55:02 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[09/04 05:55:02 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 05:55:02 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.03 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.239
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.388
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.244
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.109
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.211
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.341
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.272
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.485
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.582
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.570
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.670
[09/04 05:55:02 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 23.938 | 38.795 | 24.434 | 10.920 | 21.075 | 34.144 |
Loading and preparing results...
DONE (t=0.25s)
creating index...
index created!
[09/04 05:55:03 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 05:55:03 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.17 seconds.
[09/04 05:55:03 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 05:55:03 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.270
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.394
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.305
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.101
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.195
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.457
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.299
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.531
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.662
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.275
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.641
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.768
[09/04 05:55:03 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 27.000 | 39.447 | 30.480 | 10.069 | 19.487 | 45.697 |
[09/04 05:55:03 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 05:55:03 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 05:55:03 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 05:55:03 d2.evaluation.testing]: copypaste: 23.9382,38.7948,24.4343,10.9203,21.0754,34.1445
[09/04 05:55:03 d2.evaluation.testing]: copypaste: Task: segm
[09/04 05:55:03 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 05:55:03 d2.evaluation.testing]: copypaste: 27.0000,39.4470,30.4802,10.0686,19.4869,45.6975
[09/04 05:55:03 d2.utils.events]:  eta: 0:26:32  iter: 179  total_loss: 1.054  loss_cls: 0.2244  loss_box_reg: 0.4151  loss_mask: 0.3357  loss_rpn_cls: 0.005951  loss_rpn_loc: 0.00497  time: 1.9420  data_time: 0.0060  lr: 4.4955e-05  max_mem: 11021M
[09/04 05:55:42 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 05:55:42 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 05:55:42 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 05:55:42 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 05:55:42 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 05:55:52 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0017 s/iter. Inference: 0.2620 s/iter. Eval: 0.6654 s/iter. Total: 0.9291 s/iter. ETA=0:02:03
[09/04 05:55:58 d2.evaluation.evaluator]: Inference done 18/144. Dataloading: 0.0031 s/iter. Inference: 0.2576 s/iter. Eval: 0.6148 s/iter. Total: 0.8757 s/iter. ETA=0:01:50
[09/04 05:56:04 d2.evaluation.evaluator]: Inference done 26/144. Dataloading: 0.0029 s/iter. Inference: 0.2534 s/iter. Eval: 0.5625 s/iter. Total: 0.8189 s/iter. ETA=0:01:36
[09/04 05:56:09 d2.evaluation.evaluator]: Inference done 32/144. Dataloading: 0.0027 s/iter. Inference: 0.2539 s/iter. Eval: 0.5654 s/iter. Total: 0.8222 s/iter. ETA=0:01:32
[09/04 05:56:15 d2.evaluation.evaluator]: Inference done 38/144. Dataloading: 0.0027 s/iter. Inference: 0.2549 s/iter. Eval: 0.5875 s/iter. Total: 0.8454 s/iter. ETA=0:01:29
[09/04 05:56:20 d2.evaluation.evaluator]: Inference done 44/144. Dataloading: 0.0026 s/iter. Inference: 0.2554 s/iter. Eval: 0.5950 s/iter. Total: 0.8533 s/iter. ETA=0:01:25
[09/04 05:56:26 d2.evaluation.evaluator]: Inference done 50/144. Dataloading: 0.0026 s/iter. Inference: 0.2562 s/iter. Eval: 0.6041 s/iter. Total: 0.8631 s/iter. ETA=0:01:21
[09/04 05:56:31 d2.evaluation.evaluator]: Inference done 56/144. Dataloading: 0.0025 s/iter. Inference: 0.2566 s/iter. Eval: 0.6106 s/iter. Total: 0.8700 s/iter. ETA=0:01:16
[09/04 05:56:37 d2.evaluation.evaluator]: Inference done 62/144. Dataloading: 0.0025 s/iter. Inference: 0.2570 s/iter. Eval: 0.6143 s/iter. Total: 0.8740 s/iter. ETA=0:01:11
[09/04 05:56:42 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0025 s/iter. Inference: 0.2573 s/iter. Eval: 0.6221 s/iter. Total: 0.8822 s/iter. ETA=0:01:07
[09/04 05:56:48 d2.evaluation.evaluator]: Inference done 75/144. Dataloading: 0.0025 s/iter. Inference: 0.2567 s/iter. Eval: 0.6136 s/iter. Total: 0.8730 s/iter. ETA=0:01:00
[09/04 05:56:53 d2.evaluation.evaluator]: Inference done 83/144. Dataloading: 0.0025 s/iter. Inference: 0.2553 s/iter. Eval: 0.5970 s/iter. Total: 0.8552 s/iter. ETA=0:00:52
[09/04 05:56:59 d2.evaluation.evaluator]: Inference done 90/144. Dataloading: 0.0025 s/iter. Inference: 0.2546 s/iter. Eval: 0.5872 s/iter. Total: 0.8446 s/iter. ETA=0:00:45
[09/04 05:57:04 d2.evaluation.evaluator]: Inference done 97/144. Dataloading: 0.0025 s/iter. Inference: 0.2541 s/iter. Eval: 0.5812 s/iter. Total: 0.8381 s/iter. ETA=0:00:39
[09/04 05:57:10 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0024 s/iter. Inference: 0.2541 s/iter. Eval: 0.5803 s/iter. Total: 0.8371 s/iter. ETA=0:00:33
[09/04 05:57:15 d2.evaluation.evaluator]: Inference done 110/144. Dataloading: 0.0024 s/iter. Inference: 0.2544 s/iter. Eval: 0.5801 s/iter. Total: 0.8373 s/iter. ETA=0:00:28
[09/04 05:57:20 d2.evaluation.evaluator]: Inference done 116/144. Dataloading: 0.0024 s/iter. Inference: 0.2546 s/iter. Eval: 0.5827 s/iter. Total: 0.8401 s/iter. ETA=0:00:23
[09/04 05:57:26 d2.evaluation.evaluator]: Inference done 123/144. Dataloading: 0.0024 s/iter. Inference: 0.2544 s/iter. Eval: 0.5798 s/iter. Total: 0.8369 s/iter. ETA=0:00:17
[09/04 05:57:31 d2.evaluation.evaluator]: Inference done 129/144. Dataloading: 0.0024 s/iter. Inference: 0.2543 s/iter. Eval: 0.5814 s/iter. Total: 0.8384 s/iter. ETA=0:00:12
[09/04 05:57:36 d2.evaluation.evaluator]: Inference done 136/144. Dataloading: 0.0024 s/iter. Inference: 0.2542 s/iter. Eval: 0.5780 s/iter. Total: 0.8349 s/iter. ETA=0:00:06
[09/04 05:57:42 d2.evaluation.evaluator]: Inference done 143/144. Dataloading: 0.0024 s/iter. Inference: 0.2541 s/iter. Eval: 0.5761 s/iter. Total: 0.8330 s/iter. ETA=0:00:00
[09/04 05:57:43 d2.evaluation.evaluator]: Total inference time: 0:01:55.928222 (0.834016 s / iter per device, on 1 devices)
[09/04 05:57:43 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:35 (0.254175 s / iter per device, on 1 devices)
[09/04 05:57:43 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 05:57:43 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 05:57:43 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/04 05:57:43 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 05:57:43 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.09 seconds.
[09/04 05:57:43 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 05:57:43 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.273
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.445
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.293
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.105
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.252
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.365
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.281
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.496
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.575
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.208
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.554
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.677
[09/04 05:57:43 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 27.313 | 44.464 | 29.330 | 10.510 | 25.182 | 36.544 |
Loading and preparing results...
DONE (t=0.21s)
creating index...
index created!
[09/04 05:57:44 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 05:57:44 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.16 seconds.
[09/04 05:57:44 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 05:57:44 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.307
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.449
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.352
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.237
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.474
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.312
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.544
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.664
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.267
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.641
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.776
[09/04 05:57:44 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 30.727 | 44.943 | 35.203 | 10.008 | 23.709 | 47.379 |
[09/04 05:57:44 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 05:57:44 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 05:57:44 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 05:57:44 d2.evaluation.testing]: copypaste: 27.3132,44.4644,29.3297,10.5104,25.1818,36.5441
[09/04 05:57:44 d2.evaluation.testing]: copypaste: Task: segm
[09/04 05:57:44 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 05:57:44 d2.evaluation.testing]: copypaste: 30.7274,44.9428,35.2035,10.0076,23.7090,47.3795
[09/04 05:57:44 d2.utils.events]:  eta: 0:25:53  iter: 199  total_loss: 0.8583  loss_cls: 0.1649  loss_box_reg: 0.399  loss_mask: 0.2684  loss_rpn_cls: 0.001051  loss_rpn_loc: 0.00197  time: 1.9417  data_time: 0.0058  lr: 4.995e-05  max_mem: 11021M
[09/04 05:58:23 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 05:58:23 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 05:58:23 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 05:58:23 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 05:58:23 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 05:58:34 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0021 s/iter. Inference: 0.2616 s/iter. Eval: 0.6695 s/iter. Total: 0.9332 s/iter. ETA=0:02:04
[09/04 05:58:39 d2.evaluation.evaluator]: Inference done 18/144. Dataloading: 0.0022 s/iter. Inference: 0.2540 s/iter. Eval: 0.5776 s/iter. Total: 0.8340 s/iter. ETA=0:01:45
[09/04 05:58:44 d2.evaluation.evaluator]: Inference done 26/144. Dataloading: 0.0025 s/iter. Inference: 0.2499 s/iter. Eval: 0.5258 s/iter. Total: 0.7784 s/iter. ETA=0:01:31
[09/04 05:58:50 d2.evaluation.evaluator]: Inference done 33/144. Dataloading: 0.0023 s/iter. Inference: 0.2499 s/iter. Eval: 0.5270 s/iter. Total: 0.7795 s/iter. ETA=0:01:26
[09/04 05:58:55 d2.evaluation.evaluator]: Inference done 39/144. Dataloading: 0.0026 s/iter. Inference: 0.2515 s/iter. Eval: 0.5509 s/iter. Total: 0.8052 s/iter. ETA=0:01:24
[09/04 05:59:01 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0025 s/iter. Inference: 0.2522 s/iter. Eval: 0.5569 s/iter. Total: 0.8118 s/iter. ETA=0:01:19
[09/04 05:59:07 d2.evaluation.evaluator]: Inference done 52/144. Dataloading: 0.0026 s/iter. Inference: 0.2535 s/iter. Eval: 0.5732 s/iter. Total: 0.8295 s/iter. ETA=0:01:16
[09/04 05:59:12 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0025 s/iter. Inference: 0.2538 s/iter. Eval: 0.5747 s/iter. Total: 0.8312 s/iter. ETA=0:01:11
[09/04 05:59:17 d2.evaluation.evaluator]: Inference done 64/144. Dataloading: 0.0026 s/iter. Inference: 0.2540 s/iter. Eval: 0.5789 s/iter. Total: 0.8358 s/iter. ETA=0:01:06
[09/04 05:59:23 d2.evaluation.evaluator]: Inference done 70/144. Dataloading: 0.0026 s/iter. Inference: 0.2546 s/iter. Eval: 0.5845 s/iter. Total: 0.8419 s/iter. ETA=0:01:02
[09/04 05:59:28 d2.evaluation.evaluator]: Inference done 78/144. Dataloading: 0.0025 s/iter. Inference: 0.2530 s/iter. Eval: 0.5657 s/iter. Total: 0.8215 s/iter. ETA=0:00:54
[09/04 05:59:34 d2.evaluation.evaluator]: Inference done 88/144. Dataloading: 0.0026 s/iter. Inference: 0.2513 s/iter. Eval: 0.5396 s/iter. Total: 0.7937 s/iter. ETA=0:00:44
[09/04 05:59:39 d2.evaluation.evaluator]: Inference done 96/144. Dataloading: 0.0026 s/iter. Inference: 0.2506 s/iter. Eval: 0.5289 s/iter. Total: 0.7823 s/iter. ETA=0:00:37
[09/04 05:59:44 d2.evaluation.evaluator]: Inference done 103/144. Dataloading: 0.0025 s/iter. Inference: 0.2503 s/iter. Eval: 0.5247 s/iter. Total: 0.7778 s/iter. ETA=0:00:31
[09/04 05:59:50 d2.evaluation.evaluator]: Inference done 110/144. Dataloading: 0.0025 s/iter. Inference: 0.2506 s/iter. Eval: 0.5286 s/iter. Total: 0.7819 s/iter. ETA=0:00:26
[09/04 05:59:55 d2.evaluation.evaluator]: Inference done 118/144. Dataloading: 0.0025 s/iter. Inference: 0.2499 s/iter. Eval: 0.5206 s/iter. Total: 0.7732 s/iter. ETA=0:00:20
[09/04 06:00:01 d2.evaluation.evaluator]: Inference done 124/144. Dataloading: 0.0025 s/iter. Inference: 0.2501 s/iter. Eval: 0.5257 s/iter. Total: 0.7785 s/iter. ETA=0:00:15
[09/04 06:00:06 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0025 s/iter. Inference: 0.2504 s/iter. Eval: 0.5271 s/iter. Total: 0.7802 s/iter. ETA=0:00:10
[09/04 06:00:12 d2.evaluation.evaluator]: Inference done 139/144. Dataloading: 0.0025 s/iter. Inference: 0.2500 s/iter. Eval: 0.5225 s/iter. Total: 0.7752 s/iter. ETA=0:00:03
[09/04 06:00:16 d2.evaluation.evaluator]: Total inference time: 0:01:48.087775 (0.777610 s / iter per device, on 1 devices)
[09/04 06:00:16 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:34 (0.250098 s / iter per device, on 1 devices)
[09/04 06:00:16 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:00:16 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:00:16 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/04 06:00:16 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:00:16 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.08 seconds.
[09/04 06:00:16 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:00:16 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.304
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.485
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.339
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.097
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.270
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.426
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.293
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.498
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.580
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.183
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.557
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.692
[09/04 06:00:16 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 30.447 | 48.547 | 33.863 | 9.669 | 26.987 | 42.593 |
Loading and preparing results...
DONE (t=0.20s)
creating index...
index created!
[09/04 06:00:17 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:00:17 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.15 seconds.
[09/04 06:00:17 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:00:17 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.346
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.494
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.397
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.104
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.257
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.538
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.326
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.551
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.657
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.267
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.630
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.774
[09/04 06:00:17 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 34.623 | 49.373 | 39.686 | 10.376 | 25.657 | 53.760 |
[09/04 06:00:17 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:00:17 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:00:17 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:00:17 d2.evaluation.testing]: copypaste: 30.4467,48.5467,33.8627,9.6692,26.9871,42.5932
[09/04 06:00:17 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:00:17 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:00:17 d2.evaluation.testing]: copypaste: 34.6229,49.3730,39.6858,10.3758,25.6565,53.7604
[09/04 06:00:17 d2.utils.events]:  eta: 0:25:15  iter: 219  total_loss: 1.066  loss_cls: 0.2127  loss_box_reg: 0.5748  loss_mask: 0.2724  loss_rpn_cls: 0.003784  loss_rpn_loc: 0.007575  time: 1.9424  data_time: 0.0064  lr: 5.4945e-05  max_mem: 11021M
[09/04 06:00:56 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:00:56 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:00:56 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:00:56 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:00:56 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:01:07 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0019 s/iter. Inference: 0.2641 s/iter. Eval: 0.6817 s/iter. Total: 0.9477 s/iter. ETA=0:02:06
[09/04 06:01:12 d2.evaluation.evaluator]: Inference done 19/144. Dataloading: 0.0022 s/iter. Inference: 0.2503 s/iter. Eval: 0.5182 s/iter. Total: 0.7708 s/iter. ETA=0:01:36
[09/04 06:01:17 d2.evaluation.evaluator]: Inference done 26/144. Dataloading: 0.0022 s/iter. Inference: 0.2493 s/iter. Eval: 0.5011 s/iter. Total: 0.7528 s/iter. ETA=0:01:28
[09/04 06:01:22 d2.evaluation.evaluator]: Inference done 33/144. Dataloading: 0.0022 s/iter. Inference: 0.2491 s/iter. Eval: 0.5015 s/iter. Total: 0.7531 s/iter. ETA=0:01:23
[09/04 06:01:27 d2.evaluation.evaluator]: Inference done 39/144. Dataloading: 0.0022 s/iter. Inference: 0.2499 s/iter. Eval: 0.5157 s/iter. Total: 0.7680 s/iter. ETA=0:01:20
[09/04 06:01:33 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0022 s/iter. Inference: 0.2505 s/iter. Eval: 0.5230 s/iter. Total: 0.7759 s/iter. ETA=0:01:16
[09/04 06:01:39 d2.evaluation.evaluator]: Inference done 52/144. Dataloading: 0.0023 s/iter. Inference: 0.2521 s/iter. Eval: 0.5563 s/iter. Total: 0.8109 s/iter. ETA=0:01:14
[09/04 06:01:44 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0023 s/iter. Inference: 0.2525 s/iter. Eval: 0.5588 s/iter. Total: 0.8138 s/iter. ETA=0:01:09
[09/04 06:01:49 d2.evaluation.evaluator]: Inference done 64/144. Dataloading: 0.0023 s/iter. Inference: 0.2526 s/iter. Eval: 0.5624 s/iter. Total: 0.8176 s/iter. ETA=0:01:05
[09/04 06:01:55 d2.evaluation.evaluator]: Inference done 70/144. Dataloading: 0.0022 s/iter. Inference: 0.2531 s/iter. Eval: 0.5669 s/iter. Total: 0.8225 s/iter. ETA=0:01:00
[09/04 06:02:00 d2.evaluation.evaluator]: Inference done 79/144. Dataloading: 0.0022 s/iter. Inference: 0.2508 s/iter. Eval: 0.5400 s/iter. Total: 0.7933 s/iter. ETA=0:00:51
[09/04 06:02:05 d2.evaluation.evaluator]: Inference done 88/144. Dataloading: 0.0023 s/iter. Inference: 0.2492 s/iter. Eval: 0.5167 s/iter. Total: 0.7684 s/iter. ETA=0:00:43
[09/04 06:02:10 d2.evaluation.evaluator]: Inference done 97/144. Dataloading: 0.0022 s/iter. Inference: 0.2478 s/iter. Eval: 0.5001 s/iter. Total: 0.7504 s/iter. ETA=0:00:35
[09/04 06:02:16 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0023 s/iter. Inference: 0.2489 s/iter. Eval: 0.5028 s/iter. Total: 0.7542 s/iter. ETA=0:00:30
[09/04 06:02:21 d2.evaluation.evaluator]: Inference done 111/144. Dataloading: 0.0023 s/iter. Inference: 0.2489 s/iter. Eval: 0.5035 s/iter. Total: 0.7550 s/iter. ETA=0:00:24
[09/04 06:02:26 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0023 s/iter. Inference: 0.2481 s/iter. Eval: 0.4958 s/iter. Total: 0.7464 s/iter. ETA=0:00:18
[09/04 06:02:31 d2.evaluation.evaluator]: Inference done 125/144. Dataloading: 0.0024 s/iter. Inference: 0.2484 s/iter. Eval: 0.5006 s/iter. Total: 0.7516 s/iter. ETA=0:00:14
[09/04 06:02:37 d2.evaluation.evaluator]: Inference done 133/144. Dataloading: 0.0024 s/iter. Inference: 0.2483 s/iter. Eval: 0.5000 s/iter. Total: 0.7509 s/iter. ETA=0:00:08
[09/04 06:02:43 d2.evaluation.evaluator]: Inference done 141/144. Dataloading: 0.0024 s/iter. Inference: 0.2478 s/iter. Eval: 0.4974 s/iter. Total: 0.7478 s/iter. ETA=0:00:02
[09/04 06:02:46 d2.evaluation.evaluator]: Total inference time: 0:01:44.593805 (0.752473 s / iter per device, on 1 devices)
[09/04 06:02:46 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:34 (0.248126 s / iter per device, on 1 devices)
[09/04 06:02:46 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:02:46 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:02:46 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/04 06:02:46 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:02:46 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.08 seconds.
[09/04 06:02:46 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:02:46 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.317
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.522
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.328
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.085
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.291
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.434
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.284
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.502
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.580
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.561
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.688
[09/04 06:02:46 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 31.687 | 52.227 | 32.826 | 8.464 | 29.146 | 43.357 |
Loading and preparing results...
DONE (t=0.18s)
creating index...
index created!
[09/04 06:02:47 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:02:47 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.14 seconds.
[09/04 06:02:47 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:02:47 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.367
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.528
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.419
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.098
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.282
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.556
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.325
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.563
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.667
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.250
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.645
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.780
[09/04 06:02:47 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 36.721 | 52.844 | 41.935 | 9.763 | 28.227 | 55.577 |
[09/04 06:02:47 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:02:47 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:02:47 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:02:47 d2.evaluation.testing]: copypaste: 31.6866,52.2270,32.8262,8.4635,29.1459,43.3566
[09/04 06:02:47 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:02:47 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:02:47 d2.evaluation.testing]: copypaste: 36.7206,52.8443,41.9345,9.7634,28.2272,55.5767
[09/04 06:02:47 d2.utils.events]:  eta: 0:24:36  iter: 239  total_loss: 0.9301  loss_cls: 0.1955  loss_box_reg: 0.4463  loss_mask: 0.2604  loss_rpn_cls: 0.003035  loss_rpn_loc: 0.003394  time: 1.9423  data_time: 0.0059  lr: 5.994e-05  max_mem: 11021M
[09/04 06:03:26 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:03:26 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:03:26 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:03:26 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:03:26 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:03:36 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0023 s/iter. Inference: 0.2530 s/iter. Eval: 0.5506 s/iter. Total: 0.8059 s/iter. ETA=0:01:47
[09/04 06:03:41 d2.evaluation.evaluator]: Inference done 20/144. Dataloading: 0.0028 s/iter. Inference: 0.2454 s/iter. Eval: 0.4576 s/iter. Total: 0.7060 s/iter. ETA=0:01:27
[09/04 06:03:47 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0026 s/iter. Inference: 0.2436 s/iter. Eval: 0.4374 s/iter. Total: 0.6837 s/iter. ETA=0:01:18
[09/04 06:03:52 d2.evaluation.evaluator]: Inference done 36/144. Dataloading: 0.0027 s/iter. Inference: 0.2438 s/iter. Eval: 0.4485 s/iter. Total: 0.6951 s/iter. ETA=0:01:15
[09/04 06:03:58 d2.evaluation.evaluator]: Inference done 43/144. Dataloading: 0.0025 s/iter. Inference: 0.2447 s/iter. Eval: 0.4585 s/iter. Total: 0.7058 s/iter. ETA=0:01:11
[09/04 06:04:03 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0024 s/iter. Inference: 0.2466 s/iter. Eval: 0.4805 s/iter. Total: 0.7297 s/iter. ETA=0:01:09
[09/04 06:04:08 d2.evaluation.evaluator]: Inference done 55/144. Dataloading: 0.0024 s/iter. Inference: 0.2477 s/iter. Eval: 0.4930 s/iter. Total: 0.7434 s/iter. ETA=0:01:06
[09/04 06:04:13 d2.evaluation.evaluator]: Inference done 61/144. Dataloading: 0.0024 s/iter. Inference: 0.2486 s/iter. Eval: 0.5053 s/iter. Total: 0.7564 s/iter. ETA=0:01:02
[09/04 06:04:18 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0024 s/iter. Inference: 0.2486 s/iter. Eval: 0.5059 s/iter. Total: 0.7570 s/iter. ETA=0:00:57
[09/04 06:04:24 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0025 s/iter. Inference: 0.2474 s/iter. Eval: 0.4898 s/iter. Total: 0.7399 s/iter. ETA=0:00:49
[09/04 06:04:29 d2.evaluation.evaluator]: Inference done 88/144. Dataloading: 0.0025 s/iter. Inference: 0.2447 s/iter. Eval: 0.4580 s/iter. Total: 0.7054 s/iter. ETA=0:00:39
[09/04 06:04:35 d2.evaluation.evaluator]: Inference done 99/144. Dataloading: 0.0025 s/iter. Inference: 0.2431 s/iter. Eval: 0.4329 s/iter. Total: 0.6786 s/iter. ETA=0:00:30
[09/04 06:04:40 d2.evaluation.evaluator]: Inference done 106/144. Dataloading: 0.0025 s/iter. Inference: 0.2435 s/iter. Eval: 0.4369 s/iter. Total: 0.6830 s/iter. ETA=0:00:25
[09/04 06:04:45 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0024 s/iter. Inference: 0.2439 s/iter. Eval: 0.4425 s/iter. Total: 0.6890 s/iter. ETA=0:00:21
[09/04 06:04:50 d2.evaluation.evaluator]: Inference done 122/144. Dataloading: 0.0024 s/iter. Inference: 0.2432 s/iter. Eval: 0.4338 s/iter. Total: 0.6796 s/iter. ETA=0:00:14
[09/04 06:04:55 d2.evaluation.evaluator]: Inference done 129/144. Dataloading: 0.0024 s/iter. Inference: 0.2430 s/iter. Eval: 0.4368 s/iter. Total: 0.6824 s/iter. ETA=0:00:10
[09/04 06:05:01 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0024 s/iter. Inference: 0.2432 s/iter. Eval: 0.4393 s/iter. Total: 0.6851 s/iter. ETA=0:00:04
[09/04 06:05:06 d2.evaluation.evaluator]: Total inference time: 0:01:35.280908 (0.685474 s / iter per device, on 1 devices)
[09/04 06:05:06 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:33 (0.243125 s / iter per device, on 1 devices)
[09/04 06:05:06 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:05:06 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:05:06 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/04 06:05:06 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:05:06 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.08 seconds.
[09/04 06:05:06 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:05:06 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.333
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.555
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.350
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.084
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.317
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.443
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.303
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.505
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.582
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.150
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.569
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.685
[09/04 06:05:06 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 33.327 | 55.488 | 35.021 | 8.428 | 31.672 | 44.348 |
Loading and preparing results...
DONE (t=0.25s)
creating index...
index created!
[09/04 06:05:07 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:05:07 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.22 seconds.
[09/04 06:05:07 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:05:07 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.383
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.556
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.435
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.095
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.301
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.571
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.332
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.565
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.662
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.242
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.637
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.782
[09/04 06:05:07 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 38.315 | 55.557 | 43.524 | 9.540 | 30.078 | 57.076 |
[09/04 06:05:07 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:05:07 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:05:07 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:05:07 d2.evaluation.testing]: copypaste: 33.3274,55.4877,35.0213,8.4283,31.6716,44.3476
[09/04 06:05:07 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:05:07 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:05:07 d2.evaluation.testing]: copypaste: 38.3145,55.5574,43.5237,9.5397,30.0779,57.0763
[09/04 06:05:07 d2.utils.events]:  eta: 0:23:57  iter: 259  total_loss: 0.7607  loss_cls: 0.1554  loss_box_reg: 0.396  loss_mask: 0.1834  loss_rpn_cls: 0.001275  loss_rpn_loc: 0.002446  time: 1.9421  data_time: 0.0058  lr: 6.4935e-05  max_mem: 11021M
[09/04 06:05:46 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:05:46 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:05:46 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:05:46 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:05:46 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:05:56 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0018 s/iter. Inference: 0.2513 s/iter. Eval: 0.5250 s/iter. Total: 0.7781 s/iter. ETA=0:01:43
[09/04 06:06:02 d2.evaluation.evaluator]: Inference done 20/144. Dataloading: 0.0019 s/iter. Inference: 0.2420 s/iter. Eval: 0.4450 s/iter. Total: 0.6892 s/iter. ETA=0:01:25
[09/04 06:06:07 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0020 s/iter. Inference: 0.2404 s/iter. Eval: 0.4223 s/iter. Total: 0.6649 s/iter. ETA=0:01:16
[09/04 06:06:12 d2.evaluation.evaluator]: Inference done 37/144. Dataloading: 0.0021 s/iter. Inference: 0.2399 s/iter. Eval: 0.4132 s/iter. Total: 0.6553 s/iter. ETA=0:01:10
[09/04 06:06:17 d2.evaluation.evaluator]: Inference done 44/144. Dataloading: 0.0022 s/iter. Inference: 0.2412 s/iter. Eval: 0.4277 s/iter. Total: 0.6713 s/iter. ETA=0:01:07
[09/04 06:06:23 d2.evaluation.evaluator]: Inference done 50/144. Dataloading: 0.0022 s/iter. Inference: 0.2436 s/iter. Eval: 0.4553 s/iter. Total: 0.7012 s/iter. ETA=0:01:05
[09/04 06:06:28 d2.evaluation.evaluator]: Inference done 56/144. Dataloading: 0.0023 s/iter. Inference: 0.2450 s/iter. Eval: 0.4717 s/iter. Total: 0.7191 s/iter. ETA=0:01:03
[09/04 06:06:33 d2.evaluation.evaluator]: Inference done 63/144. Dataloading: 0.0023 s/iter. Inference: 0.2451 s/iter. Eval: 0.4724 s/iter. Total: 0.7199 s/iter. ETA=0:00:58
[09/04 06:06:39 d2.evaluation.evaluator]: Inference done 70/144. Dataloading: 0.0023 s/iter. Inference: 0.2462 s/iter. Eval: 0.4851 s/iter. Total: 0.7337 s/iter. ETA=0:00:54
[09/04 06:06:44 d2.evaluation.evaluator]: Inference done 82/144. Dataloading: 0.0023 s/iter. Inference: 0.2428 s/iter. Eval: 0.4445 s/iter. Total: 0.6898 s/iter. ETA=0:00:42
[09/04 06:06:49 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0024 s/iter. Inference: 0.2414 s/iter. Eval: 0.4256 s/iter. Total: 0.6695 s/iter. ETA=0:00:34
[09/04 06:06:55 d2.evaluation.evaluator]: Inference done 102/144. Dataloading: 0.0024 s/iter. Inference: 0.2403 s/iter. Eval: 0.4106 s/iter. Total: 0.6534 s/iter. ETA=0:00:27
[09/04 06:07:00 d2.evaluation.evaluator]: Inference done 109/144. Dataloading: 0.0023 s/iter. Inference: 0.2407 s/iter. Eval: 0.4166 s/iter. Total: 0.6599 s/iter. ETA=0:00:23
[09/04 06:07:05 d2.evaluation.evaluator]: Inference done 118/144. Dataloading: 0.0023 s/iter. Inference: 0.2403 s/iter. Eval: 0.4118 s/iter. Total: 0.6547 s/iter. ETA=0:00:17
[09/04 06:07:10 d2.evaluation.evaluator]: Inference done 126/144. Dataloading: 0.0024 s/iter. Inference: 0.2402 s/iter. Eval: 0.4109 s/iter. Total: 0.6536 s/iter. ETA=0:00:11
[09/04 06:07:16 d2.evaluation.evaluator]: Inference done 134/144. Dataloading: 0.0024 s/iter. Inference: 0.2403 s/iter. Eval: 0.4119 s/iter. Total: 0.6548 s/iter. ETA=0:00:06
[09/04 06:07:21 d2.evaluation.evaluator]: Inference done 142/144. Dataloading: 0.0024 s/iter. Inference: 0.2402 s/iter. Eval: 0.4107 s/iter. Total: 0.6535 s/iter. ETA=0:00:01
[09/04 06:07:22 d2.evaluation.evaluator]: Total inference time: 0:01:31.245404 (0.656442 s / iter per device, on 1 devices)
[09/04 06:07:22 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:33 (0.240442 s / iter per device, on 1 devices)
[09/04 06:07:23 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:07:23 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:07:23 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/04 06:07:23 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:07:23 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[09/04 06:07:23 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:07:23 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.362
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.581
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.391
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.095
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.334
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.492
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.314
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.512
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.584
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.175
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.562
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.697
[09/04 06:07:23 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 36.242 | 58.094 | 39.069 | 9.532 | 33.444 | 49.201 |
Loading and preparing results...
DONE (t=0.15s)
creating index...
index created!
[09/04 06:07:23 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:07:23 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.13 seconds.
[09/04 06:07:23 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:07:23 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.405
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.584
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.456
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.093
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.317
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.603
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.346
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.566
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.659
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.242
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.631
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.783
[09/04 06:07:23 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 40.459 | 58.438 | 45.582 | 9.269 | 31.684 | 60.258 |
[09/04 06:07:23 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:07:23 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:07:23 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:07:23 d2.evaluation.testing]: copypaste: 36.2424,58.0939,39.0693,9.5323,33.4439,49.2013
[09/04 06:07:23 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:07:23 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:07:23 d2.evaluation.testing]: copypaste: 40.4586,58.4381,45.5825,9.2686,31.6840,60.2576
[09/04 06:07:23 d2.utils.events]:  eta: 0:23:18  iter: 279  total_loss: 0.7203  loss_cls: 0.1503  loss_box_reg: 0.3478  loss_mask: 0.1877  loss_rpn_cls: 0.003282  loss_rpn_loc: 0.004361  time: 1.9420  data_time: 0.0062  lr: 6.993e-05  max_mem: 11021M
[09/04 06:08:02 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:08:02 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:08:02 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:08:02 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:08:02 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:08:11 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0020 s/iter. Inference: 0.2460 s/iter. Eval: 0.4437 s/iter. Total: 0.6918 s/iter. ETA=0:01:32
[09/04 06:08:16 d2.evaluation.evaluator]: Inference done 20/144. Dataloading: 0.0028 s/iter. Inference: 0.2382 s/iter. Eval: 0.3732 s/iter. Total: 0.6144 s/iter. ETA=0:01:16
[09/04 06:08:22 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0026 s/iter. Inference: 0.2339 s/iter. Eval: 0.3247 s/iter. Total: 0.5614 s/iter. ETA=0:01:03
[09/04 06:08:27 d2.evaluation.evaluator]: Inference done 39/144. Dataloading: 0.0025 s/iter. Inference: 0.2356 s/iter. Eval: 0.3413 s/iter. Total: 0.5795 s/iter. ETA=0:01:00
[09/04 06:08:32 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0024 s/iter. Inference: 0.2368 s/iter. Eval: 0.3640 s/iter. Total: 0.6034 s/iter. ETA=0:00:59
[09/04 06:08:38 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0024 s/iter. Inference: 0.2388 s/iter. Eval: 0.3901 s/iter. Total: 0.6314 s/iter. ETA=0:00:57
[09/04 06:08:43 d2.evaluation.evaluator]: Inference done 61/144. Dataloading: 0.0024 s/iter. Inference: 0.2397 s/iter. Eval: 0.4008 s/iter. Total: 0.6430 s/iter. ETA=0:00:53
[09/04 06:08:48 d2.evaluation.evaluator]: Inference done 69/144. Dataloading: 0.0023 s/iter. Inference: 0.2395 s/iter. Eval: 0.4031 s/iter. Total: 0.6450 s/iter. ETA=0:00:48
[09/04 06:08:54 d2.evaluation.evaluator]: Inference done 81/144. Dataloading: 0.0024 s/iter. Inference: 0.2369 s/iter. Eval: 0.3710 s/iter. Total: 0.6105 s/iter. ETA=0:00:38
[09/04 06:08:59 d2.evaluation.evaluator]: Inference done 93/144. Dataloading: 0.0023 s/iter. Inference: 0.2351 s/iter. Eval: 0.3497 s/iter. Total: 0.5873 s/iter. ETA=0:00:29
[09/04 06:09:05 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0023 s/iter. Inference: 0.2345 s/iter. Eval: 0.3422 s/iter. Total: 0.5791 s/iter. ETA=0:00:23
[09/04 06:09:10 d2.evaluation.evaluator]: Inference done 112/144. Dataloading: 0.0023 s/iter. Inference: 0.2349 s/iter. Eval: 0.3465 s/iter. Total: 0.5839 s/iter. ETA=0:00:18
[09/04 06:09:15 d2.evaluation.evaluator]: Inference done 123/144. Dataloading: 0.0022 s/iter. Inference: 0.2342 s/iter. Eval: 0.3374 s/iter. Total: 0.5740 s/iter. ETA=0:00:12
[09/04 06:09:20 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0022 s/iter. Inference: 0.2344 s/iter. Eval: 0.3438 s/iter. Total: 0.5806 s/iter. ETA=0:00:07
[09/04 06:09:25 d2.evaluation.evaluator]: Inference done 141/144. Dataloading: 0.0023 s/iter. Inference: 0.2340 s/iter. Eval: 0.3389 s/iter. Total: 0.5753 s/iter. ETA=0:00:01
[09/04 06:09:28 d2.evaluation.evaluator]: Total inference time: 0:01:20.525836 (0.579323 s / iter per device, on 1 devices)
[09/04 06:09:28 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:32 (0.234239 s / iter per device, on 1 devices)
[09/04 06:09:28 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:09:28 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:09:28 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/04 06:09:28 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:09:28 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[09/04 06:09:28 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:09:28 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.376
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.588
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.423
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.097
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.351
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.514
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.512
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.578
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.142
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.555
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.698
[09/04 06:09:28 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 37.575 | 58.822 | 42.279 | 9.741 | 35.085 | 51.375 |
Loading and preparing results...
DONE (t=0.12s)
creating index...
index created!
[09/04 06:09:28 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:09:28 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[09/04 06:09:28 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:09:28 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.418
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.594
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.479
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.103
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.338
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.607
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.346
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.568
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.654
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.233
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.625
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.780
[09/04 06:09:28 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 41.761 | 59.381 | 47.945 | 10.264 | 33.814 | 60.708 |
[09/04 06:09:28 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:09:28 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:09:28 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:09:28 d2.evaluation.testing]: copypaste: 37.5754,58.8223,42.2786,9.7407,35.0845,51.3755
[09/04 06:09:28 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:09:28 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:09:28 d2.evaluation.testing]: copypaste: 41.7606,59.3805,47.9449,10.2636,33.8135,60.7083
[09/04 06:09:28 d2.utils.events]:  eta: 0:22:39  iter: 299  total_loss: 0.6483  loss_cls: 0.1022  loss_box_reg: 0.328  loss_mask: 0.1638  loss_rpn_cls: 0.002163  loss_rpn_loc: 0.002261  time: 1.9422  data_time: 0.0072  lr: 7.4925e-05  max_mem: 11021M
[09/04 06:10:07 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:10:07 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:10:07 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:10:07 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:10:07 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:10:16 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0015 s/iter. Inference: 0.2385 s/iter. Eval: 0.3807 s/iter. Total: 0.6207 s/iter. ETA=0:01:22
[09/04 06:10:21 d2.evaluation.evaluator]: Inference done 22/144. Dataloading: 0.0018 s/iter. Inference: 0.2302 s/iter. Eval: 0.2814 s/iter. Total: 0.5135 s/iter. ETA=0:01:02
[09/04 06:10:26 d2.evaluation.evaluator]: Inference done 33/144. Dataloading: 0.0021 s/iter. Inference: 0.2311 s/iter. Eval: 0.2770 s/iter. Total: 0.5103 s/iter. ETA=0:00:56
[09/04 06:10:32 d2.evaluation.evaluator]: Inference done 43/144. Dataloading: 0.0020 s/iter. Inference: 0.2318 s/iter. Eval: 0.2892 s/iter. Total: 0.5232 s/iter. ETA=0:00:52
[09/04 06:10:37 d2.evaluation.evaluator]: Inference done 50/144. Dataloading: 0.0021 s/iter. Inference: 0.2342 s/iter. Eval: 0.3214 s/iter. Total: 0.5579 s/iter. ETA=0:00:52
[09/04 06:10:43 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0022 s/iter. Inference: 0.2351 s/iter. Eval: 0.3336 s/iter. Total: 0.5711 s/iter. ETA=0:00:48
[09/04 06:10:48 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0023 s/iter. Inference: 0.2354 s/iter. Eval: 0.3395 s/iter. Total: 0.5774 s/iter. ETA=0:00:43
[09/04 06:10:53 d2.evaluation.evaluator]: Inference done 81/144. Dataloading: 0.0025 s/iter. Inference: 0.2328 s/iter. Eval: 0.3099 s/iter. Total: 0.5454 s/iter. ETA=0:00:34
[09/04 06:10:59 d2.evaluation.evaluator]: Inference done 94/144. Dataloading: 0.0025 s/iter. Inference: 0.2313 s/iter. Eval: 0.2895 s/iter. Total: 0.5235 s/iter. ETA=0:00:26
[09/04 06:11:04 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0026 s/iter. Inference: 0.2315 s/iter. Eval: 0.2890 s/iter. Total: 0.5233 s/iter. ETA=0:00:20
[09/04 06:11:09 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0026 s/iter. Inference: 0.2318 s/iter. Eval: 0.2924 s/iter. Total: 0.5269 s/iter. ETA=0:00:16
[09/04 06:11:14 d2.evaluation.evaluator]: Inference done 124/144. Dataloading: 0.0026 s/iter. Inference: 0.2312 s/iter. Eval: 0.2872 s/iter. Total: 0.5211 s/iter. ETA=0:00:10
[09/04 06:11:19 d2.evaluation.evaluator]: Inference done 135/144. Dataloading: 0.0025 s/iter. Inference: 0.2310 s/iter. Eval: 0.2855 s/iter. Total: 0.5192 s/iter. ETA=0:00:04
[09/04 06:11:24 d2.evaluation.evaluator]: Total inference time: 0:01:12.206572 (0.519472 s / iter per device, on 1 devices)
[09/04 06:11:24 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:32 (0.230925 s / iter per device, on 1 devices)
[09/04 06:11:24 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:11:24 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:11:24 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/04 06:11:24 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:11:24 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[09/04 06:11:24 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:11:24 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.402
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.608
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.448
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.377
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.545
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.323
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.532
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.591
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.142
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.571
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.708
[09/04 06:11:24 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 40.184 | 60.824 | 44.848 | 9.992 | 37.730 | 54.548 |
Loading and preparing results...
DONE (t=0.11s)
creating index...
index created!
[09/04 06:11:25 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:11:25 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.
[09/04 06:11:25 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:11:25 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.433
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.617
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.492
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.097
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.361
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.618
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.352
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.575
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.649
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.233
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.620
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.776
[09/04 06:11:25 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 43.304 | 61.732 | 49.199 | 9.670 | 36.138 | 61.782 |
[09/04 06:11:25 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:11:25 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:11:25 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:11:25 d2.evaluation.testing]: copypaste: 40.1835,60.8245,44.8480,9.9917,37.7298,54.5477
[09/04 06:11:25 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:11:25 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:11:25 d2.evaluation.testing]: copypaste: 43.3039,61.7323,49.1991,9.6703,36.1377,61.7824
[09/04 06:11:25 d2.utils.events]:  eta: 0:22:00  iter: 319  total_loss: 0.5976  loss_cls: 0.1284  loss_box_reg: 0.3079  loss_mask: 0.1606  loss_rpn_cls: 0.001814  loss_rpn_loc: 0.002283  time: 1.9425  data_time: 0.0070  lr: 7.992e-05  max_mem: 11021M
[09/04 06:12:04 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:12:04 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:12:04 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:12:04 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:12:04 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:12:11 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0017 s/iter. Inference: 0.2302 s/iter. Eval: 0.2928 s/iter. Total: 0.5248 s/iter. ETA=0:01:09
[09/04 06:12:17 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0026 s/iter. Inference: 0.2258 s/iter. Eval: 0.2334 s/iter. Total: 0.4620 s/iter. ETA=0:00:55
[09/04 06:12:22 d2.evaluation.evaluator]: Inference done 36/144. Dataloading: 0.0023 s/iter. Inference: 0.2239 s/iter. Eval: 0.2119 s/iter. Total: 0.4384 s/iter. ETA=0:00:47
[09/04 06:12:28 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0026 s/iter. Inference: 0.2266 s/iter. Eval: 0.2463 s/iter. Total: 0.4756 s/iter. ETA=0:00:46
[09/04 06:12:33 d2.evaluation.evaluator]: Inference done 55/144. Dataloading: 0.0026 s/iter. Inference: 0.2282 s/iter. Eval: 0.2653 s/iter. Total: 0.4963 s/iter. ETA=0:00:44
[09/04 06:12:38 d2.evaluation.evaluator]: Inference done 64/144. Dataloading: 0.0025 s/iter. Inference: 0.2290 s/iter. Eval: 0.2763 s/iter. Total: 0.5080 s/iter. ETA=0:00:40
[09/04 06:12:44 d2.evaluation.evaluator]: Inference done 75/144. Dataloading: 0.0025 s/iter. Inference: 0.2288 s/iter. Eval: 0.2733 s/iter. Total: 0.5048 s/iter. ETA=0:00:34
[09/04 06:12:49 d2.evaluation.evaluator]: Inference done 91/144. Dataloading: 0.0025 s/iter. Inference: 0.2262 s/iter. Eval: 0.2433 s/iter. Total: 0.4722 s/iter. ETA=0:00:25
[09/04 06:12:55 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0026 s/iter. Inference: 0.2262 s/iter. Eval: 0.2387 s/iter. Total: 0.4676 s/iter. ETA=0:00:18
[09/04 06:13:00 d2.evaluation.evaluator]: Inference done 114/144. Dataloading: 0.0025 s/iter. Inference: 0.2264 s/iter. Eval: 0.2433 s/iter. Total: 0.4724 s/iter. ETA=0:00:14
[09/04 06:13:05 d2.evaluation.evaluator]: Inference done 127/144. Dataloading: 0.0025 s/iter. Inference: 0.2260 s/iter. Eval: 0.2361 s/iter. Total: 0.4648 s/iter. ETA=0:00:07
[09/04 06:13:10 d2.evaluation.evaluator]: Inference done 139/144. Dataloading: 0.0025 s/iter. Inference: 0.2259 s/iter. Eval: 0.2330 s/iter. Total: 0.4616 s/iter. ETA=0:00:02
[09/04 06:13:13 d2.evaluation.evaluator]: Total inference time: 0:01:04.705433 (0.465507 s / iter per device, on 1 devices)
[09/04 06:13:13 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:31 (0.226088 s / iter per device, on 1 devices)
[09/04 06:13:13 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:13:13 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:13:13 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 06:13:13 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:13:13 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/04 06:13:13 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:13:13 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.420
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.635
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.465
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.112
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.395
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.564
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.337
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.540
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.594
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.158
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.568
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.718
[09/04 06:13:13 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 42.028 | 63.483 | 46.507 | 11.188 | 39.460 | 56.401 |
Loading and preparing results...
DONE (t=0.09s)
creating index...
index created!
[09/04 06:13:13 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:13:13 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.08 seconds.
[09/04 06:13:13 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:13:14 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.447
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.639
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.502
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.102
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.375
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.634
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.354
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.580
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.649
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.233
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.617
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.782
[09/04 06:13:14 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 44.726 | 63.913 | 50.245 | 10.225 | 37.492 | 63.368 |
[09/04 06:13:14 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:13:14 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:13:14 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:13:14 d2.evaluation.testing]: copypaste: 42.0284,63.4834,46.5074,11.1881,39.4600,56.4010
[09/04 06:13:14 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:13:14 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:13:14 d2.evaluation.testing]: copypaste: 44.7257,63.9134,50.2448,10.2253,37.4920,63.3678
[09/04 06:13:14 d2.utils.events]:  eta: 0:21:21  iter: 339  total_loss: 0.7654  loss_cls: 0.1226  loss_box_reg: 0.3705  loss_mask: 0.186  loss_rpn_cls: 0.00199  loss_rpn_loc: 0.005988  time: 1.9429  data_time: 0.0086  lr: 8.4915e-05  max_mem: 11021M
[09/04 06:13:53 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:13:53 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:13:53 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:13:53 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:13:53 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:14:00 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0019 s/iter. Inference: 0.2338 s/iter. Eval: 0.3257 s/iter. Total: 0.5614 s/iter. ETA=0:01:14
[09/04 06:14:06 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0020 s/iter. Inference: 0.2277 s/iter. Eval: 0.2522 s/iter. Total: 0.4821 s/iter. ETA=0:00:58
[09/04 06:14:11 d2.evaluation.evaluator]: Inference done 34/144. Dataloading: 0.0025 s/iter. Inference: 0.2278 s/iter. Eval: 0.2419 s/iter. Total: 0.4723 s/iter. ETA=0:00:51
[09/04 06:14:16 d2.evaluation.evaluator]: Inference done 44/144. Dataloading: 0.0025 s/iter. Inference: 0.2291 s/iter. Eval: 0.2638 s/iter. Total: 0.4955 s/iter. ETA=0:00:49
[09/04 06:14:22 d2.evaluation.evaluator]: Inference done 51/144. Dataloading: 0.0026 s/iter. Inference: 0.2327 s/iter. Eval: 0.3062 s/iter. Total: 0.5416 s/iter. ETA=0:00:50
[09/04 06:14:27 d2.evaluation.evaluator]: Inference done 60/144. Dataloading: 0.0026 s/iter. Inference: 0.2334 s/iter. Eval: 0.3154 s/iter. Total: 0.5516 s/iter. ETA=0:00:46
[09/04 06:14:33 d2.evaluation.evaluator]: Inference done 69/144. Dataloading: 0.0026 s/iter. Inference: 0.2336 s/iter. Eval: 0.3208 s/iter. Total: 0.5573 s/iter. ETA=0:00:41
[09/04 06:14:38 d2.evaluation.evaluator]: Inference done 83/144. Dataloading: 0.0026 s/iter. Inference: 0.2310 s/iter. Eval: 0.2888 s/iter. Total: 0.5226 s/iter. ETA=0:00:31
[09/04 06:14:43 d2.evaluation.evaluator]: Inference done 98/144. Dataloading: 0.0026 s/iter. Inference: 0.2289 s/iter. Eval: 0.2615 s/iter. Total: 0.4932 s/iter. ETA=0:00:22
[09/04 06:14:48 d2.evaluation.evaluator]: Inference done 107/144. Dataloading: 0.0026 s/iter. Inference: 0.2293 s/iter. Eval: 0.2670 s/iter. Total: 0.4991 s/iter. ETA=0:00:18
[09/04 06:14:53 d2.evaluation.evaluator]: Inference done 116/144. Dataloading: 0.0026 s/iter. Inference: 0.2299 s/iter. Eval: 0.2736 s/iter. Total: 0.5063 s/iter. ETA=0:00:14
[09/04 06:14:59 d2.evaluation.evaluator]: Inference done 129/144. Dataloading: 0.0026 s/iter. Inference: 0.2291 s/iter. Eval: 0.2632 s/iter. Total: 0.4951 s/iter. ETA=0:00:07
[09/04 06:15:04 d2.evaluation.evaluator]: Inference done 141/144. Dataloading: 0.0026 s/iter. Inference: 0.2290 s/iter. Eval: 0.2600 s/iter. Total: 0.4918 s/iter. ETA=0:00:01
[09/04 06:15:06 d2.evaluation.evaluator]: Total inference time: 0:01:08.990802 (0.496337 s / iter per device, on 1 devices)
[09/04 06:15:06 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:31 (0.229314 s / iter per device, on 1 devices)
[09/04 06:15:06 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:15:06 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:15:06 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/04 06:15:06 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:15:06 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[09/04 06:15:06 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:15:06 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.433
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.653
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.500
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.115
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.401
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.577
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.335
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.552
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.611
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.577
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.742
[09/04 06:15:06 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 43.262 | 65.299 | 50.028 | 11.480 | 40.132 | 57.670 |
Loading and preparing results...
DONE (t=0.10s)
creating index...
index created!
[09/04 06:15:07 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:15:07 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.09 seconds.
[09/04 06:15:07 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:15:07 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.468
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.669
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.526
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.109
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.398
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.643
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.356
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.598
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.670
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.342
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.637
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.786
[09/04 06:15:07 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.828 | 66.934 | 52.589 | 10.928 | 39.825 | 64.322 |
[09/04 06:15:07 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:15:07 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:15:07 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:15:07 d2.evaluation.testing]: copypaste: 43.2618,65.2986,50.0282,11.4800,40.1319,57.6705
[09/04 06:15:07 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:15:07 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:15:07 d2.evaluation.testing]: copypaste: 46.8281,66.9341,52.5885,10.9281,39.8247,64.3224
[09/04 06:15:07 d2.utils.events]:  eta: 0:20:43  iter: 359  total_loss: 0.7135  loss_cls: 0.1073  loss_box_reg: 0.4396  loss_mask: 0.1578  loss_rpn_cls: 0.001637  loss_rpn_loc: 0.003734  time: 1.9434  data_time: 0.0085  lr: 8.991e-05  max_mem: 11021M
[09/04 06:15:46 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:15:46 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:15:46 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:15:46 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:15:46 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:15:53 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0018 s/iter. Inference: 0.2329 s/iter. Eval: 0.3095 s/iter. Total: 0.5442 s/iter. ETA=0:01:12
[09/04 06:15:58 d2.evaluation.evaluator]: Inference done 22/144. Dataloading: 0.0028 s/iter. Inference: 0.2297 s/iter. Eval: 0.2647 s/iter. Total: 0.4973 s/iter. ETA=0:01:00
[09/04 06:16:04 d2.evaluation.evaluator]: Inference done 34/144. Dataloading: 0.0028 s/iter. Inference: 0.2275 s/iter. Eval: 0.2444 s/iter. Total: 0.4748 s/iter. ETA=0:00:52
[09/04 06:16:09 d2.evaluation.evaluator]: Inference done 44/144. Dataloading: 0.0027 s/iter. Inference: 0.2283 s/iter. Eval: 0.2552 s/iter. Total: 0.4864 s/iter. ETA=0:00:48
[09/04 06:16:14 d2.evaluation.evaluator]: Inference done 51/144. Dataloading: 0.0027 s/iter. Inference: 0.2317 s/iter. Eval: 0.2955 s/iter. Total: 0.5300 s/iter. ETA=0:00:49
[09/04 06:16:20 d2.evaluation.evaluator]: Inference done 60/144. Dataloading: 0.0026 s/iter. Inference: 0.2328 s/iter. Eval: 0.3048 s/iter. Total: 0.5404 s/iter. ETA=0:00:45
[09/04 06:16:25 d2.evaluation.evaluator]: Inference done 69/144. Dataloading: 0.0026 s/iter. Inference: 0.2330 s/iter. Eval: 0.3090 s/iter. Total: 0.5448 s/iter. ETA=0:00:40
[09/04 06:16:30 d2.evaluation.evaluator]: Inference done 82/144. Dataloading: 0.0027 s/iter. Inference: 0.2317 s/iter. Eval: 0.2852 s/iter. Total: 0.5198 s/iter. ETA=0:00:32
[09/04 06:16:35 d2.evaluation.evaluator]: Inference done 98/144. Dataloading: 0.0027 s/iter. Inference: 0.2291 s/iter. Eval: 0.2546 s/iter. Total: 0.4865 s/iter. ETA=0:00:22
[09/04 06:16:41 d2.evaluation.evaluator]: Inference done 108/144. Dataloading: 0.0028 s/iter. Inference: 0.2294 s/iter. Eval: 0.2607 s/iter. Total: 0.4930 s/iter. ETA=0:00:17
[09/04 06:16:46 d2.evaluation.evaluator]: Inference done 120/144. Dataloading: 0.0028 s/iter. Inference: 0.2288 s/iter. Eval: 0.2554 s/iter. Total: 0.4871 s/iter. ETA=0:00:11
[09/04 06:16:51 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0027 s/iter. Inference: 0.2287 s/iter. Eval: 0.2555 s/iter. Total: 0.4870 s/iter. ETA=0:00:06
[09/04 06:16:56 d2.evaluation.evaluator]: Inference done 143/144. Dataloading: 0.0026 s/iter. Inference: 0.2282 s/iter. Eval: 0.2501 s/iter. Total: 0.4811 s/iter. ETA=0:00:00
[09/04 06:16:57 d2.evaluation.evaluator]: Total inference time: 0:01:07.368970 (0.484669 s / iter per device, on 1 devices)
[09/04 06:16:57 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:31 (0.228410 s / iter per device, on 1 devices)
[09/04 06:16:57 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:16:57 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:16:57 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/04 06:16:57 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:16:57 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/04 06:16:57 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:16:57 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.451
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.677
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.536
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.112
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.416
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.599
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.345
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.576
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.628
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.594
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.762
[09/04 06:16:57 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.084 | 67.719 | 53.576 | 11.176 | 41.582 | 59.947 |
Loading and preparing results...
DONE (t=0.09s)
creating index...
index created!
[09/04 06:16:58 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:16:58 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.08 seconds.
[09/04 06:16:58 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:16:58 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.479
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.689
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.544
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.123
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.406
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.656
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.359
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.608
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.675
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.644
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.791
[09/04 06:16:58 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.888 | 68.908 | 54.444 | 12.301 | 40.621 | 65.561 |
[09/04 06:16:58 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:16:58 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:16:58 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:16:58 d2.evaluation.testing]: copypaste: 45.0840,67.7191,53.5762,11.1760,41.5815,59.9466
[09/04 06:16:58 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:16:58 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:16:58 d2.evaluation.testing]: copypaste: 47.8881,68.9078,54.4444,12.3007,40.6207,65.5614
[09/04 06:16:58 d2.utils.events]:  eta: 0:20:04  iter: 379  total_loss: 0.6629  loss_cls: 0.07802  loss_box_reg: 0.2973  loss_mask: 0.1702  loss_rpn_cls: 0.002408  loss_rpn_loc: 0.002712  time: 1.9436  data_time: 0.0074  lr: 9.4905e-05  max_mem: 11021M
[09/04 06:17:37 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:17:37 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:17:37 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:17:37 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:17:37 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:17:43 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0022 s/iter. Inference: 0.2222 s/iter. Eval: 0.1990 s/iter. Total: 0.4233 s/iter. ETA=0:00:56
[09/04 06:17:48 d2.evaluation.evaluator]: Inference done 26/144. Dataloading: 0.0023 s/iter. Inference: 0.2189 s/iter. Eval: 0.1481 s/iter. Total: 0.3695 s/iter. ETA=0:00:43
[09/04 06:17:53 d2.evaluation.evaluator]: Inference done 40/144. Dataloading: 0.0024 s/iter. Inference: 0.2185 s/iter. Eval: 0.1458 s/iter. Total: 0.3670 s/iter. ETA=0:00:38
[09/04 06:17:59 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0026 s/iter. Inference: 0.2220 s/iter. Eval: 0.1914 s/iter. Total: 0.4162 s/iter. ETA=0:00:39
[09/04 06:18:04 d2.evaluation.evaluator]: Inference done 60/144. Dataloading: 0.0026 s/iter. Inference: 0.2230 s/iter. Eval: 0.2032 s/iter. Total: 0.4290 s/iter. ETA=0:00:36
[09/04 06:18:09 d2.evaluation.evaluator]: Inference done 70/144. Dataloading: 0.0025 s/iter. Inference: 0.2238 s/iter. Eval: 0.2159 s/iter. Total: 0.4425 s/iter. ETA=0:00:32
[09/04 06:18:14 d2.evaluation.evaluator]: Inference done 87/144. Dataloading: 0.0025 s/iter. Inference: 0.2247 s/iter. Eval: 0.1848 s/iter. Total: 0.4121 s/iter. ETA=0:00:23
[09/04 06:18:19 d2.evaluation.evaluator]: Inference done 103/144. Dataloading: 0.0024 s/iter. Inference: 0.2232 s/iter. Eval: 0.1736 s/iter. Total: 0.3994 s/iter. ETA=0:00:16
[09/04 06:18:25 d2.evaluation.evaluator]: Inference done 116/144. Dataloading: 0.0023 s/iter. Inference: 0.2231 s/iter. Eval: 0.1748 s/iter. Total: 0.4003 s/iter. ETA=0:00:11
[09/04 06:18:30 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0024 s/iter. Inference: 0.2222 s/iter. Eval: 0.1688 s/iter. Total: 0.3935 s/iter. ETA=0:00:05
[09/04 06:18:35 d2.evaluation.evaluator]: Total inference time: 0:00:54.547801 (0.392430 s / iter per device, on 1 devices)
[09/04 06:18:35 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.222079 s / iter per device, on 1 devices)
[09/04 06:18:35 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:18:35 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:18:35 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 06:18:35 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:18:35 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 06:18:35 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:18:35 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.460
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.689
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.527
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.124
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.428
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.348
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.571
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.629
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.192
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.596
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.767
[09/04 06:18:35 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.994 | 68.901 | 52.658 | 12.423 | 42.789 | 61.567 |
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
[09/04 06:18:35 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:18:35 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[09/04 06:18:35 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:18:35 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.484
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.698
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.550
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.123
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.416
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.658
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.603
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.666
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.632
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.791
[09/04 06:18:35 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.391 | 69.821 | 54.979 | 12.293 | 41.628 | 65.768 |
[09/04 06:18:35 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:18:35 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:18:35 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:18:35 d2.evaluation.testing]: copypaste: 45.9939,68.9006,52.6575,12.4225,42.7885,61.5669
[09/04 06:18:35 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:18:35 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:18:35 d2.evaluation.testing]: copypaste: 48.3912,69.8210,54.9787,12.2933,41.6280,65.7684
[09/04 06:18:35 d2.utils.events]:  eta: 0:19:25  iter: 399  total_loss: 0.6081  loss_cls: 0.1069  loss_box_reg: 0.2964  loss_mask: 0.1413  loss_rpn_cls: 0.002999  loss_rpn_loc: 0.004286  time: 1.9439  data_time: 0.0080  lr: 9.99e-05  max_mem: 11021M
[09/04 06:19:14 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:19:14 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:19:14 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:19:14 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:19:14 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:19:20 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0018 s/iter. Inference: 0.2212 s/iter. Eval: 0.1712 s/iter. Total: 0.3941 s/iter. ETA=0:00:52
[09/04 06:19:25 d2.evaluation.evaluator]: Inference done 27/144. Dataloading: 0.0025 s/iter. Inference: 0.2181 s/iter. Eval: 0.1269 s/iter. Total: 0.3477 s/iter. ETA=0:00:40
[09/04 06:19:30 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0024 s/iter. Inference: 0.2189 s/iter. Eval: 0.1360 s/iter. Total: 0.3575 s/iter. ETA=0:00:36
[09/04 06:19:35 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0023 s/iter. Inference: 0.2226 s/iter. Eval: 0.1818 s/iter. Total: 0.4069 s/iter. ETA=0:00:38
[09/04 06:19:41 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0024 s/iter. Inference: 0.2241 s/iter. Eval: 0.2027 s/iter. Total: 0.4294 s/iter. ETA=0:00:36
[09/04 06:19:46 d2.evaluation.evaluator]: Inference done 70/144. Dataloading: 0.0025 s/iter. Inference: 0.2250 s/iter. Eval: 0.2117 s/iter. Total: 0.4394 s/iter. ETA=0:00:32
[09/04 06:19:51 d2.evaluation.evaluator]: Inference done 88/144. Dataloading: 0.0026 s/iter. Inference: 0.2230 s/iter. Eval: 0.1811 s/iter. Total: 0.4069 s/iter. ETA=0:00:22
[09/04 06:19:57 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0026 s/iter. Inference: 0.2222 s/iter. Eval: 0.1722 s/iter. Total: 0.3972 s/iter. ETA=0:00:15
[09/04 06:20:02 d2.evaluation.evaluator]: Inference done 118/144. Dataloading: 0.0026 s/iter. Inference: 0.2219 s/iter. Eval: 0.1695 s/iter. Total: 0.3941 s/iter. ETA=0:00:10
[09/04 06:20:07 d2.evaluation.evaluator]: Inference done 133/144. Dataloading: 0.0026 s/iter. Inference: 0.2213 s/iter. Eval: 0.1638 s/iter. Total: 0.3879 s/iter. ETA=0:00:04
[09/04 06:20:12 d2.evaluation.evaluator]: Total inference time: 0:00:54.105943 (0.389251 s / iter per device, on 1 devices)
[09/04 06:20:12 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.221534 s / iter per device, on 1 devices)
[09/04 06:20:12 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:20:12 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:20:12 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 06:20:12 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:20:12 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 06:20:12 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:20:12 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.449
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.700
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.541
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.129
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.421
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.597
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.334
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.573
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.225
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.587
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.745
[09/04 06:20:12 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 44.918 | 69.989 | 54.051 | 12.862 | 42.141 | 59.656 |
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
[09/04 06:20:12 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:20:12 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[09/04 06:20:12 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:20:12 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.488
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.706
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.549
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.131
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.419
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.662
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.354
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.614
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.670
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.634
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.795
[09/04 06:20:12 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.753 | 70.648 | 54.941 | 13.078 | 41.900 | 66.223 |
[09/04 06:20:12 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:20:12 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:20:12 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:20:12 d2.evaluation.testing]: copypaste: 44.9185,69.9895,54.0507,12.8621,42.1414,59.6564
[09/04 06:20:12 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:20:12 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:20:12 d2.evaluation.testing]: copypaste: 48.7529,70.6477,54.9414,13.0782,41.8995,66.2229
[09/04 06:20:12 d2.utils.events]:  eta: 0:18:47  iter: 419  total_loss: 0.6573  loss_cls: 0.1163  loss_box_reg: 0.2763  loss_mask: 0.2148  loss_rpn_cls: 0.008028  loss_rpn_loc: 0.005815  time: 1.9442  data_time: 0.0075  lr: 0.0001049  max_mem: 11021M
[09/04 06:20:51 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:20:51 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:20:51 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:20:51 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:20:51 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:20:56 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0023 s/iter. Inference: 0.2165 s/iter. Eval: 0.1241 s/iter. Total: 0.3429 s/iter. ETA=0:00:45
[09/04 06:21:02 d2.evaluation.evaluator]: Inference done 28/144. Dataloading: 0.0026 s/iter. Inference: 0.2149 s/iter. Eval: 0.0988 s/iter. Total: 0.3164 s/iter. ETA=0:00:36
[09/04 06:21:07 d2.evaluation.evaluator]: Inference done 44/144. Dataloading: 0.0029 s/iter. Inference: 0.2155 s/iter. Eval: 0.1044 s/iter. Total: 0.3230 s/iter. ETA=0:00:32
[09/04 06:21:12 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0029 s/iter. Inference: 0.2188 s/iter. Eval: 0.1465 s/iter. Total: 0.3684 s/iter. ETA=0:00:33
[09/04 06:21:17 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0028 s/iter. Inference: 0.2195 s/iter. Eval: 0.1576 s/iter. Total: 0.3801 s/iter. ETA=0:00:30
[09/04 06:21:22 d2.evaluation.evaluator]: Inference done 79/144. Dataloading: 0.0027 s/iter. Inference: 0.2194 s/iter. Eval: 0.1559 s/iter. Total: 0.3782 s/iter. ETA=0:00:24
[09/04 06:21:27 d2.evaluation.evaluator]: Inference done 97/144. Dataloading: 0.0027 s/iter. Inference: 0.2186 s/iter. Eval: 0.1383 s/iter. Total: 0.3597 s/iter. ETA=0:00:16
[09/04 06:21:33 d2.evaluation.evaluator]: Inference done 112/144. Dataloading: 0.0027 s/iter. Inference: 0.2185 s/iter. Eval: 0.1373 s/iter. Total: 0.3586 s/iter. ETA=0:00:11
[09/04 06:21:38 d2.evaluation.evaluator]: Inference done 129/144. Dataloading: 0.0027 s/iter. Inference: 0.2181 s/iter. Eval: 0.1296 s/iter. Total: 0.3505 s/iter. ETA=0:00:05
[09/04 06:21:43 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0026 s/iter. Inference: 0.2180 s/iter. Eval: 0.1293 s/iter. Total: 0.3501 s/iter. ETA=0:00:00
[09/04 06:21:43 d2.evaluation.evaluator]: Total inference time: 0:00:48.719383 (0.350499 s / iter per device, on 1 devices)
[09/04 06:21:43 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.217991 s / iter per device, on 1 devices)
[09/04 06:21:43 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:21:43 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:21:43 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 06:21:43 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:21:43 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 06:21:43 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:21:43 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.467
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.692
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.547
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.146
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.446
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.629
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.330
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.592
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.636
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.225
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.597
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.779
[09/04 06:21:43 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.746 | 69.170 | 54.662 | 14.640 | 44.569 | 62.908 |
Loading and preparing results...
DONE (t=0.06s)
creating index...
index created!
[09/04 06:21:43 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:21:43 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[09/04 06:21:43 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:21:43 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.487
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.705
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.552
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.122
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.424
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.662
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.342
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.668
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.275
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.637
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.794
[09/04 06:21:43 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.696 | 70.539 | 55.243 | 12.195 | 42.403 | 66.164 |
[09/04 06:21:43 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:21:43 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:21:43 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:21:43 d2.evaluation.testing]: copypaste: 46.7458,69.1697,54.6620,14.6401,44.5694,62.9075
[09/04 06:21:43 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:21:43 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:21:43 d2.evaluation.testing]: copypaste: 48.6958,70.5388,55.2433,12.1952,42.4028,66.1635
[09/04 06:21:43 d2.utils.events]:  eta: 0:18:08  iter: 439  total_loss: 0.5451  loss_cls: 0.09681  loss_box_reg: 0.3012  loss_mask: 0.1472  loss_rpn_cls: 0.005761  loss_rpn_loc: 0.002996  time: 1.9445  data_time: 0.0072  lr: 0.00010989  max_mem: 11021M
[09/04 06:22:23 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:22:23 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:22:23 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:22:23 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:22:23 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:22:27 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.2165 s/iter. Eval: 0.1092 s/iter. Total: 0.3273 s/iter. ETA=0:00:43
[09/04 06:22:32 d2.evaluation.evaluator]: Inference done 28/144. Dataloading: 0.0026 s/iter. Inference: 0.2183 s/iter. Eval: 0.0956 s/iter. Total: 0.3166 s/iter. ETA=0:00:36
[09/04 06:22:38 d2.evaluation.evaluator]: Inference done 45/144. Dataloading: 0.0027 s/iter. Inference: 0.2172 s/iter. Eval: 0.0988 s/iter. Total: 0.3187 s/iter. ETA=0:00:31
[09/04 06:22:43 d2.evaluation.evaluator]: Inference done 55/144. Dataloading: 0.0028 s/iter. Inference: 0.2202 s/iter. Eval: 0.1373 s/iter. Total: 0.3605 s/iter. ETA=0:00:32
[09/04 06:22:49 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0027 s/iter. Inference: 0.2217 s/iter. Eval: 0.1541 s/iter. Total: 0.3786 s/iter. ETA=0:00:29
[09/04 06:22:54 d2.evaluation.evaluator]: Inference done 85/144. Dataloading: 0.0026 s/iter. Inference: 0.2199 s/iter. Eval: 0.1365 s/iter. Total: 0.3591 s/iter. ETA=0:00:21
[09/04 06:22:59 d2.evaluation.evaluator]: Inference done 103/144. Dataloading: 0.0026 s/iter. Inference: 0.2191 s/iter. Eval: 0.1248 s/iter. Total: 0.3467 s/iter. ETA=0:00:14
[09/04 06:23:04 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0026 s/iter. Inference: 0.2187 s/iter. Eval: 0.1211 s/iter. Total: 0.3425 s/iter. ETA=0:00:08
[09/04 06:23:09 d2.evaluation.evaluator]: Inference done 135/144. Dataloading: 0.0027 s/iter. Inference: 0.2188 s/iter. Eval: 0.1186 s/iter. Total: 0.3403 s/iter. ETA=0:00:03
[09/04 06:23:13 d2.evaluation.evaluator]: Total inference time: 0:00:47.432376 (0.341240 s / iter per device, on 1 devices)
[09/04 06:23:13 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.218715 s / iter per device, on 1 devices)
[09/04 06:23:13 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:23:13 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:23:13 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 06:23:13 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:23:13 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 06:23:13 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:23:13 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.469
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.718
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.544
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.155
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.417
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.640
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.334
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.583
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.250
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.576
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.774
[09/04 06:23:13 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.885 | 71.830 | 54.366 | 15.513 | 41.652 | 63.992 |
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
[09/04 06:23:13 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:23:13 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[09/04 06:23:13 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:23:13 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.491
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.714
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.580
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.136
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.421
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.663
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.345
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.608
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.663
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.292
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.632
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.783
[09/04 06:23:13 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.089 | 71.417 | 57.951 | 13.595 | 42.083 | 66.293 |
[09/04 06:23:13 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:23:13 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:23:13 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:23:13 d2.evaluation.testing]: copypaste: 46.8847,71.8299,54.3660,15.5126,41.6516,63.9919
[09/04 06:23:13 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:23:13 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:23:13 d2.evaluation.testing]: copypaste: 49.0892,71.4173,57.9508,13.5953,42.0835,66.2927
[09/04 06:23:13 d2.utils.events]:  eta: 0:17:29  iter: 459  total_loss: 0.6061  loss_cls: 0.1253  loss_box_reg: 0.224  loss_mask: 0.1649  loss_rpn_cls: 0.005545  loss_rpn_loc: 0.01051  time: 1.9449  data_time: 0.0087  lr: 0.00011489  max_mem: 11021M
[09/04 06:23:52 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:23:52 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:23:52 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:23:52 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:23:52 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:23:56 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0015 s/iter. Inference: 0.2146 s/iter. Eval: 0.0794 s/iter. Total: 0.2955 s/iter. ETA=0:00:39
[09/04 06:24:01 d2.evaluation.evaluator]: Inference done 30/144. Dataloading: 0.0023 s/iter. Inference: 0.2136 s/iter. Eval: 0.0619 s/iter. Total: 0.2780 s/iter. ETA=0:00:31
[09/04 06:24:06 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0026 s/iter. Inference: 0.2142 s/iter. Eval: 0.0756 s/iter. Total: 0.2926 s/iter. ETA=0:00:28
[09/04 06:24:11 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0030 s/iter. Inference: 0.2168 s/iter. Eval: 0.1059 s/iter. Total: 0.3258 s/iter. ETA=0:00:28
[09/04 06:24:17 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0029 s/iter. Inference: 0.2177 s/iter. Eval: 0.1205 s/iter. Total: 0.3412 s/iter. ETA=0:00:24
[09/04 06:24:22 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0026 s/iter. Inference: 0.2159 s/iter. Eval: 0.1004 s/iter. Total: 0.3190 s/iter. ETA=0:00:16
[09/04 06:24:27 d2.evaluation.evaluator]: Inference done 110/144. Dataloading: 0.0027 s/iter. Inference: 0.2156 s/iter. Eval: 0.0958 s/iter. Total: 0.3142 s/iter. ETA=0:00:10
[09/04 06:24:32 d2.evaluation.evaluator]: Inference done 129/144. Dataloading: 0.0026 s/iter. Inference: 0.2150 s/iter. Eval: 0.0892 s/iter. Total: 0.3069 s/iter. ETA=0:00:04
[09/04 06:24:37 d2.evaluation.evaluator]: Total inference time: 0:00:42.776727 (0.307746 s / iter per device, on 1 devices)
[09/04 06:24:37 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:29 (0.215105 s / iter per device, on 1 devices)
[09/04 06:24:37 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:24:37 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:24:37 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 06:24:37 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:24:37 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 06:24:37 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:24:37 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.480
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.704
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.554
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.157
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.442
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.645
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.344
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.600
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.637
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.250
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.593
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.783
[09/04 06:24:37 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.014 | 70.428 | 55.391 | 15.689 | 44.248 | 64.476 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[09/04 06:24:37 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:24:37 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/04 06:24:37 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:24:37 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.495
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.713
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.562
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.140
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.426
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.674
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.658
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.789
[09/04 06:24:37 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.524 | 71.290 | 56.195 | 13.968 | 42.581 | 67.372 |
[09/04 06:24:37 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:24:37 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:24:37 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:24:37 d2.evaluation.testing]: copypaste: 48.0137,70.4278,55.3907,15.6895,44.2476,64.4757
[09/04 06:24:37 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:24:37 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:24:37 d2.evaluation.testing]: copypaste: 49.5239,71.2902,56.1948,13.9679,42.5814,67.3719
[09/04 06:24:37 d2.utils.events]:  eta: 0:16:50  iter: 479  total_loss: 0.5151  loss_cls: 0.09828  loss_box_reg: 0.1808  loss_mask: 0.1477  loss_rpn_cls: 0.002803  loss_rpn_loc: 0.002763  time: 1.9449  data_time: 0.0071  lr: 0.00011988  max_mem: 11021M
[09/04 06:25:16 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:25:16 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:25:16 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:25:16 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:25:16 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:25:21 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0023 s/iter. Inference: 0.2140 s/iter. Eval: 0.0840 s/iter. Total: 0.3004 s/iter. ETA=0:00:39
[09/04 06:25:26 d2.evaluation.evaluator]: Inference done 30/144. Dataloading: 0.0021 s/iter. Inference: 0.2120 s/iter. Eval: 0.0632 s/iter. Total: 0.2774 s/iter. ETA=0:00:31
[09/04 06:25:31 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0023 s/iter. Inference: 0.2142 s/iter. Eval: 0.0866 s/iter. Total: 0.3032 s/iter. ETA=0:00:29
[09/04 06:25:36 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0022 s/iter. Inference: 0.2161 s/iter. Eval: 0.1110 s/iter. Total: 0.3294 s/iter. ETA=0:00:28
[09/04 06:25:42 d2.evaluation.evaluator]: Inference done 70/144. Dataloading: 0.0022 s/iter. Inference: 0.2175 s/iter. Eval: 0.1284 s/iter. Total: 0.3483 s/iter. ETA=0:00:25
[09/04 06:25:47 d2.evaluation.evaluator]: Inference done 90/144. Dataloading: 0.0024 s/iter. Inference: 0.2160 s/iter. Eval: 0.1073 s/iter. Total: 0.3258 s/iter. ETA=0:00:17
[09/04 06:25:52 d2.evaluation.evaluator]: Inference done 108/144. Dataloading: 0.0024 s/iter. Inference: 0.2164 s/iter. Eval: 0.1011 s/iter. Total: 0.3200 s/iter. ETA=0:00:11
[09/04 06:25:57 d2.evaluation.evaluator]: Inference done 127/144. Dataloading: 0.0024 s/iter. Inference: 0.2156 s/iter. Eval: 0.0940 s/iter. Total: 0.3121 s/iter. ETA=0:00:05
[09/04 06:26:02 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0024 s/iter. Inference: 0.2154 s/iter. Eval: 0.0934 s/iter. Total: 0.3113 s/iter. ETA=0:00:00
[09/04 06:26:02 d2.evaluation.evaluator]: Total inference time: 0:00:43.316954 (0.311633 s / iter per device, on 1 devices)
[09/04 06:26:02 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:29 (0.215409 s / iter per device, on 1 devices)
[09/04 06:26:02 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:26:02 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:26:02 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 06:26:02 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:26:02 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 06:26:02 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:26:02 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.479
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.705
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.543
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.166
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.444
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.645
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.339
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.599
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.631
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.250
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.586
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.777
[09/04 06:26:02 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.860 | 70.520 | 54.262 | 16.622 | 44.379 | 64.535 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[09/04 06:26:03 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:26:03 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/04 06:26:03 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:26:03 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.490
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.711
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.561
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.125
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.425
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.672
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.347
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.653
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.267
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.618
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.783
[09/04 06:26:03 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.037 | 71.121 | 56.128 | 12.512 | 42.461 | 67.211 |
[09/04 06:26:03 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:26:03 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:26:03 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:26:03 d2.evaluation.testing]: copypaste: 47.8597,70.5204,54.2619,16.6224,44.3791,64.5348
[09/04 06:26:03 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:26:03 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:26:03 d2.evaluation.testing]: copypaste: 49.0370,71.1213,56.1281,12.5122,42.4612,67.2107
[09/04 06:26:03 d2.utils.events]:  eta: 0:16:11  iter: 499  total_loss: 0.4178  loss_cls: 0.09448  loss_box_reg: 0.2029  loss_mask: 0.1378  loss_rpn_cls: 0.001874  loss_rpn_loc: 0.00343  time: 1.9452  data_time: 0.0085  lr: 0.00012488  max_mem: 11021M
[09/04 06:26:42 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:26:42 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:26:42 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:26:42 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:26:42 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:26:46 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0060 s/iter. Inference: 0.2137 s/iter. Eval: 0.0720 s/iter. Total: 0.2917 s/iter. ETA=0:00:38
[09/04 06:26:51 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0035 s/iter. Inference: 0.2114 s/iter. Eval: 0.0476 s/iter. Total: 0.2626 s/iter. ETA=0:00:29
[09/04 06:26:56 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0033 s/iter. Inference: 0.2144 s/iter. Eval: 0.0726 s/iter. Total: 0.2905 s/iter. ETA=0:00:28
[09/04 06:27:01 d2.evaluation.evaluator]: Inference done 60/144. Dataloading: 0.0031 s/iter. Inference: 0.2161 s/iter. Eval: 0.0956 s/iter. Total: 0.3150 s/iter. ETA=0:00:26
[09/04 06:27:07 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0030 s/iter. Inference: 0.2155 s/iter. Eval: 0.0944 s/iter. Total: 0.3131 s/iter. ETA=0:00:20
[09/04 06:27:12 d2.evaluation.evaluator]: Inference done 99/144. Dataloading: 0.0030 s/iter. Inference: 0.2142 s/iter. Eval: 0.0780 s/iter. Total: 0.2953 s/iter. ETA=0:00:13
[09/04 06:27:17 d2.evaluation.evaluator]: Inference done 117/144. Dataloading: 0.0029 s/iter. Inference: 0.2138 s/iter. Eval: 0.0761 s/iter. Total: 0.2930 s/iter. ETA=0:00:07
[09/04 06:27:22 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0029 s/iter. Inference: 0.2136 s/iter. Eval: 0.0713 s/iter. Total: 0.2879 s/iter. ETA=0:00:02
[09/04 06:27:24 d2.evaluation.evaluator]: Total inference time: 0:00:40.388943 (0.290568 s / iter per device, on 1 devices)
[09/04 06:27:24 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:29 (0.213669 s / iter per device, on 1 devices)
[09/04 06:27:24 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:27:24 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:27:24 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 06:27:24 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:27:24 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 06:27:24 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:27:24 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.487
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.710
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.572
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.161
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.445
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.658
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.337
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.594
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.629
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.267
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.587
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.768
[09/04 06:27:24 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.723 | 71.011 | 57.162 | 16.138 | 44.455 | 65.805 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[09/04 06:27:25 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:27:25 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/04 06:27:25 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:27:25 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.495
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.719
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.564
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.128
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.431
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.671
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.344
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.607
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.642
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.292
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.600
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.779
[09/04 06:27:25 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.479 | 71.934 | 56.442 | 12.790 | 43.072 | 67.105 |
[09/04 06:27:25 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:27:25 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:27:25 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:27:25 d2.evaluation.testing]: copypaste: 48.7235,71.0114,57.1622,16.1380,44.4555,65.8051
[09/04 06:27:25 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:27:25 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:27:25 d2.evaluation.testing]: copypaste: 49.4794,71.9339,56.4416,12.7900,43.0718,67.1045
[09/04 06:27:25 d2.utils.events]:  eta: 0:15:33  iter: 519  total_loss: 0.4427  loss_cls: 0.09088  loss_box_reg: 0.1897  loss_mask: 0.1368  loss_rpn_cls: 0.002688  loss_rpn_loc: 0.003363  time: 1.9453  data_time: 0.0082  lr: 0.00012987  max_mem: 11021M
[09/04 06:28:04 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:28:04 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:28:04 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:28:04 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:28:04 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:28:08 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0017 s/iter. Inference: 0.2149 s/iter. Eval: 0.1033 s/iter. Total: 0.3199 s/iter. ETA=0:00:42
[09/04 06:28:13 d2.evaluation.evaluator]: Inference done 28/144. Dataloading: 0.0019 s/iter. Inference: 0.2143 s/iter. Eval: 0.0883 s/iter. Total: 0.3047 s/iter. ETA=0:00:35
[09/04 06:28:19 d2.evaluation.evaluator]: Inference done 45/144. Dataloading: 0.0019 s/iter. Inference: 0.2148 s/iter. Eval: 0.0951 s/iter. Total: 0.3119 s/iter. ETA=0:00:30
[09/04 06:28:24 d2.evaluation.evaluator]: Inference done 54/144. Dataloading: 0.0020 s/iter. Inference: 0.2182 s/iter. Eval: 0.1390 s/iter. Total: 0.3594 s/iter. ETA=0:00:32
[09/04 06:28:29 d2.evaluation.evaluator]: Inference done 66/144. Dataloading: 0.0026 s/iter. Inference: 0.2198 s/iter. Eval: 0.1482 s/iter. Total: 0.3708 s/iter. ETA=0:00:28
[09/04 06:28:34 d2.evaluation.evaluator]: Inference done 81/144. Dataloading: 0.0027 s/iter. Inference: 0.2193 s/iter. Eval: 0.1436 s/iter. Total: 0.3657 s/iter. ETA=0:00:23
[09/04 06:28:39 d2.evaluation.evaluator]: Inference done 100/144. Dataloading: 0.0026 s/iter. Inference: 0.2179 s/iter. Eval: 0.1271 s/iter. Total: 0.3477 s/iter. ETA=0:00:15
[09/04 06:28:44 d2.evaluation.evaluator]: Inference done 117/144. Dataloading: 0.0026 s/iter. Inference: 0.2172 s/iter. Eval: 0.1203 s/iter. Total: 0.3402 s/iter. ETA=0:00:09
[09/04 06:28:50 d2.evaluation.evaluator]: Inference done 135/144. Dataloading: 0.0026 s/iter. Inference: 0.2166 s/iter. Eval: 0.1134 s/iter. Total: 0.3327 s/iter. ETA=0:00:02
[09/04 06:28:53 d2.evaluation.evaluator]: Total inference time: 0:00:46.398286 (0.333801 s / iter per device, on 1 devices)
[09/04 06:28:53 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.216587 s / iter per device, on 1 devices)
[09/04 06:28:53 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:28:53 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:28:53 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 06:28:53 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:28:53 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 06:28:53 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:28:53 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.502
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.722
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.580
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.146
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.468
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.662
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.353
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.607
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.656
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.634
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.774
[09/04 06:28:53 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.196 | 72.187 | 58.030 | 14.566 | 46.844 | 66.203 |
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
[09/04 06:28:53 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:28:53 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/04 06:28:53 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:28:53 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.509
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.737
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.573
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.132
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.444
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.680
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.354
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.667
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.275
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.642
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.783
[09/04 06:28:53 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.894 | 73.736 | 57.319 | 13.197 | 44.413 | 68.049 |
[09/04 06:28:53 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:28:53 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:28:53 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:28:53 d2.evaluation.testing]: copypaste: 50.1959,72.1869,58.0297,14.5663,46.8437,66.2028
[09/04 06:28:53 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:28:53 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:28:53 d2.evaluation.testing]: copypaste: 50.8942,73.7355,57.3191,13.1969,44.4134,68.0493
[09/04 06:28:53 d2.utils.events]:  eta: 0:14:54  iter: 539  total_loss: 0.4246  loss_cls: 0.07127  loss_box_reg: 0.2098  loss_mask: 0.1455  loss_rpn_cls: 0.005268  loss_rpn_loc: 0.004884  time: 1.9455  data_time: 0.0075  lr: 0.00013487  max_mem: 11021M
[09/04 06:29:32 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:29:32 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:29:32 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:29:32 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:29:32 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:29:36 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0019 s/iter. Inference: 0.2135 s/iter. Eval: 0.0801 s/iter. Total: 0.2956 s/iter. ETA=0:00:39
[09/04 06:29:41 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0027 s/iter. Inference: 0.2132 s/iter. Eval: 0.0664 s/iter. Total: 0.2825 s/iter. ETA=0:00:32
[09/04 06:29:47 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0027 s/iter. Inference: 0.2139 s/iter. Eval: 0.0807 s/iter. Total: 0.2975 s/iter. ETA=0:00:29
[09/04 06:29:52 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0026 s/iter. Inference: 0.2160 s/iter. Eval: 0.1063 s/iter. Total: 0.3250 s/iter. ETA=0:00:27
[09/04 06:29:57 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0025 s/iter. Inference: 0.2172 s/iter. Eval: 0.1207 s/iter. Total: 0.3406 s/iter. ETA=0:00:24
[09/04 06:30:02 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0023 s/iter. Inference: 0.2153 s/iter. Eval: 0.0991 s/iter. Total: 0.3168 s/iter. ETA=0:00:16
[09/04 06:30:07 d2.evaluation.evaluator]: Inference done 110/144. Dataloading: 0.0025 s/iter. Inference: 0.2156 s/iter. Eval: 0.0940 s/iter. Total: 0.3123 s/iter. ETA=0:00:10
[09/04 06:30:13 d2.evaluation.evaluator]: Inference done 130/144. Dataloading: 0.0025 s/iter. Inference: 0.2148 s/iter. Eval: 0.0864 s/iter. Total: 0.3038 s/iter. ETA=0:00:04
[09/04 06:30:17 d2.evaluation.evaluator]: Total inference time: 0:00:42.172730 (0.303401 s / iter per device, on 1 devices)
[09/04 06:30:17 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:29 (0.214930 s / iter per device, on 1 devices)
[09/04 06:30:17 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:30:17 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:30:17 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 06:30:17 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:30:17 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 06:30:17 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:30:17 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.507
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.723
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.578
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.162
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.456
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.685
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.359
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.617
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.661
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.258
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.622
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.803
[09/04 06:30:17 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.736 | 72.333 | 57.813 | 16.228 | 45.626 | 68.546 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[09/04 06:30:17 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:30:17 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 06:30:17 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:30:17 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.510
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.733
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.579
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.131
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.441
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.686
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.622
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.672
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.642
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.792
[09/04 06:30:17 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.971 | 73.299 | 57.872 | 13.129 | 44.134 | 68.573 |
[09/04 06:30:17 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:30:17 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:30:17 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:30:17 d2.evaluation.testing]: copypaste: 50.7357,72.3335,57.8131,16.2276,45.6261,68.5458
[09/04 06:30:17 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:30:17 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:30:17 d2.evaluation.testing]: copypaste: 50.9712,73.2991,57.8721,13.1288,44.1339,68.5728
[09/04 06:30:17 d2.utils.events]:  eta: 0:14:15  iter: 559  total_loss: 0.3433  loss_cls: 0.07466  loss_box_reg: 0.1214  loss_mask: 0.1334  loss_rpn_cls: 0.004978  loss_rpn_loc: 0.002718  time: 1.9455  data_time: 0.0081  lr: 0.00013986  max_mem: 11021M
[09/04 06:30:56 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:30:56 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:30:56 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:30:56 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:30:56 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:31:01 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0014 s/iter. Inference: 0.2143 s/iter. Eval: 0.0928 s/iter. Total: 0.3085 s/iter. ETA=0:00:41
[09/04 06:31:06 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0025 s/iter. Inference: 0.2131 s/iter. Eval: 0.0766 s/iter. Total: 0.2923 s/iter. ETA=0:00:33
[09/04 06:31:11 d2.evaluation.evaluator]: Inference done 45/144. Dataloading: 0.0034 s/iter. Inference: 0.2153 s/iter. Eval: 0.0902 s/iter. Total: 0.3090 s/iter. ETA=0:00:30
[09/04 06:31:16 d2.evaluation.evaluator]: Inference done 55/144. Dataloading: 0.0032 s/iter. Inference: 0.2184 s/iter. Eval: 0.1299 s/iter. Total: 0.3516 s/iter. ETA=0:00:31
[09/04 06:31:22 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0030 s/iter. Inference: 0.2197 s/iter. Eval: 0.1472 s/iter. Total: 0.3702 s/iter. ETA=0:00:28
[09/04 06:31:27 d2.evaluation.evaluator]: Inference done 85/144. Dataloading: 0.0029 s/iter. Inference: 0.2179 s/iter. Eval: 0.1289 s/iter. Total: 0.3499 s/iter. ETA=0:00:20
[09/04 06:31:32 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0028 s/iter. Inference: 0.2167 s/iter. Eval: 0.1148 s/iter. Total: 0.3344 s/iter. ETA=0:00:13
[09/04 06:31:37 d2.evaluation.evaluator]: Inference done 123/144. Dataloading: 0.0028 s/iter. Inference: 0.2159 s/iter. Eval: 0.1058 s/iter. Total: 0.3246 s/iter. ETA=0:00:06
[09/04 06:31:42 d2.evaluation.evaluator]: Inference done 142/144. Dataloading: 0.0028 s/iter. Inference: 0.2154 s/iter. Eval: 0.1005 s/iter. Total: 0.3187 s/iter. ETA=0:00:00
[09/04 06:31:44 d2.evaluation.evaluator]: Total inference time: 0:00:44.828419 (0.322507 s / iter per device, on 1 devices)
[09/04 06:31:44 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:29 (0.215562 s / iter per device, on 1 devices)
[09/04 06:31:44 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:31:44 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:31:44 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 06:31:44 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:31:44 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 06:31:44 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:31:44 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.498
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.728
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.575
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.161
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.443
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.673
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.356
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.604
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.644
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.242
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.606
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.783
[09/04 06:31:44 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.837 | 72.759 | 57.482 | 16.117 | 44.323 | 67.302 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[09/04 06:31:44 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:31:44 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/04 06:31:44 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:31:44 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.510
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.740
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.582
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.137
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.443
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.684
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.360
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.618
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.665
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.275
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.637
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.785
[09/04 06:31:44 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.952 | 73.979 | 58.150 | 13.700 | 44.339 | 68.432 |
[09/04 06:31:44 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:31:44 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:31:44 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:31:44 d2.evaluation.testing]: copypaste: 49.8368,72.7589,57.4822,16.1171,44.3228,67.3024
[09/04 06:31:44 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:31:44 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:31:44 d2.evaluation.testing]: copypaste: 50.9521,73.9794,58.1501,13.6997,44.3391,68.4323
[09/04 06:31:44 d2.utils.events]:  eta: 0:13:36  iter: 579  total_loss: 0.3067  loss_cls: 0.05084  loss_box_reg: 0.1274  loss_mask: 0.1488  loss_rpn_cls: 0.001865  loss_rpn_loc: 0.003587  time: 1.9456  data_time: 0.0072  lr: 0.00014486  max_mem: 11021M
[09/04 06:32:23 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:32:23 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:32:23 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:32:23 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:32:23 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:32:27 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0021 s/iter. Inference: 0.2147 s/iter. Eval: 0.0765 s/iter. Total: 0.2934 s/iter. ETA=0:00:39
[09/04 06:32:32 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0031 s/iter. Inference: 0.2114 s/iter. Eval: 0.0520 s/iter. Total: 0.2666 s/iter. ETA=0:00:30
[09/04 06:32:37 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0033 s/iter. Inference: 0.2133 s/iter. Eval: 0.0740 s/iter. Total: 0.2908 s/iter. ETA=0:00:28
[09/04 06:32:43 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0033 s/iter. Inference: 0.2155 s/iter. Eval: 0.1014 s/iter. Total: 0.3203 s/iter. ETA=0:00:27
[09/04 06:32:48 d2.evaluation.evaluator]: Inference done 76/144. Dataloading: 0.0030 s/iter. Inference: 0.2151 s/iter. Eval: 0.0982 s/iter. Total: 0.3164 s/iter. ETA=0:00:21
[09/04 06:32:53 d2.evaluation.evaluator]: Inference done 96/144. Dataloading: 0.0032 s/iter. Inference: 0.2149 s/iter. Eval: 0.0842 s/iter. Total: 0.3025 s/iter. ETA=0:00:14
[09/04 06:32:58 d2.evaluation.evaluator]: Inference done 116/144. Dataloading: 0.0030 s/iter. Inference: 0.2141 s/iter. Eval: 0.0778 s/iter. Total: 0.2950 s/iter. ETA=0:00:08
[09/04 06:33:03 d2.evaluation.evaluator]: Inference done 136/144. Dataloading: 0.0032 s/iter. Inference: 0.2135 s/iter. Eval: 0.0716 s/iter. Total: 0.2885 s/iter. ETA=0:00:02
[09/04 06:33:05 d2.evaluation.evaluator]: Total inference time: 0:00:40.136783 (0.288754 s / iter per device, on 1 devices)
[09/04 06:33:05 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:29 (0.213426 s / iter per device, on 1 devices)
[09/04 06:33:05 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:33:05 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:33:05 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 06:33:05 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:33:05 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 06:33:05 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:33:05 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.469
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.702
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.552
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.131
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.434
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.631
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.339
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.574
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.603
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.562
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.753
[09/04 06:33:05 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.861 | 70.163 | 55.210 | 13.083 | 43.415 | 63.070 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[09/04 06:33:06 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:33:06 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 06:33:06 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:33:06 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.505
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.730
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.571
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.121
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.434
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.690
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.357
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.611
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.650
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.225
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.792
[09/04 06:33:06 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.520 | 73.041 | 57.095 | 12.127 | 43.405 | 69.006 |
[09/04 06:33:06 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:33:06 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:33:06 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:33:06 d2.evaluation.testing]: copypaste: 46.8611,70.1631,55.2098,13.0833,43.4145,63.0697
[09/04 06:33:06 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:33:06 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:33:06 d2.evaluation.testing]: copypaste: 50.5203,73.0413,57.0949,12.1274,43.4054,69.0062
[09/04 06:33:06 d2.utils.events]:  eta: 0:12:57  iter: 599  total_loss: 0.3812  loss_cls: 0.05833  loss_box_reg: 0.1665  loss_mask: 0.1459  loss_rpn_cls: 0.002425  loss_rpn_loc: 0.003832  time: 1.9459  data_time: 0.0081  lr: 0.00014985  max_mem: 11021M
[09/04 06:33:45 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:33:45 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:33:45 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:33:45 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:33:45 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:33:49 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.2140 s/iter. Eval: 0.0702 s/iter. Total: 0.2858 s/iter. ETA=0:00:38
[09/04 06:33:54 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0024 s/iter. Inference: 0.2119 s/iter. Eval: 0.0539 s/iter. Total: 0.2683 s/iter. ETA=0:00:30
[09/04 06:33:59 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0026 s/iter. Inference: 0.2155 s/iter. Eval: 0.0763 s/iter. Total: 0.2945 s/iter. ETA=0:00:28
[09/04 06:34:05 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0026 s/iter. Inference: 0.2179 s/iter. Eval: 0.1149 s/iter. Total: 0.3356 s/iter. ETA=0:00:28
[09/04 06:34:10 d2.evaluation.evaluator]: Inference done 75/144. Dataloading: 0.0025 s/iter. Inference: 0.2173 s/iter. Eval: 0.1116 s/iter. Total: 0.3316 s/iter. ETA=0:00:22
[09/04 06:34:15 d2.evaluation.evaluator]: Inference done 97/144. Dataloading: 0.0025 s/iter. Inference: 0.2151 s/iter. Eval: 0.0903 s/iter. Total: 0.3081 s/iter. ETA=0:00:14
[09/04 06:34:20 d2.evaluation.evaluator]: Inference done 115/144. Dataloading: 0.0024 s/iter. Inference: 0.2151 s/iter. Eval: 0.0857 s/iter. Total: 0.3034 s/iter. ETA=0:00:08
[09/04 06:34:25 d2.evaluation.evaluator]: Inference done 135/144. Dataloading: 0.0025 s/iter. Inference: 0.2143 s/iter. Eval: 0.0782 s/iter. Total: 0.2952 s/iter. ETA=0:00:02
[09/04 06:34:28 d2.evaluation.evaluator]: Total inference time: 0:00:41.389881 (0.297769 s / iter per device, on 1 devices)
[09/04 06:34:28 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:29 (0.214309 s / iter per device, on 1 devices)
[09/04 06:34:28 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:34:28 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:34:28 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 06:34:28 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:34:29 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.02 seconds.
[09/04 06:34:29 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:34:29 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.492
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.719
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.572
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.147
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.441
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.660
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.351
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.594
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.630
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.267
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.583
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.776
[09/04 06:34:29 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.245 | 71.885 | 57.181 | 14.674 | 44.060 | 66.015 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[09/04 06:34:29 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:34:29 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/04 06:34:29 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:34:29 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.510
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.737
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.586
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.136
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.439
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.689
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.355
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.612
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.652
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.785
[09/04 06:34:29 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.987 | 73.726 | 58.601 | 13.649 | 43.946 | 68.883 |
[09/04 06:34:29 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:34:29 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:34:29 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:34:29 d2.evaluation.testing]: copypaste: 49.2450,71.8847,57.1806,14.6743,44.0599,66.0151
[09/04 06:34:29 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:34:29 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:34:29 d2.evaluation.testing]: copypaste: 50.9868,73.7262,58.6011,13.6488,43.9456,68.8826
[09/04 06:34:29 d2.utils.events]:  eta: 0:12:19  iter: 619  total_loss: 0.3726  loss_cls: 0.07009  loss_box_reg: 0.1928  loss_mask: 0.1166  loss_rpn_cls: 0.00168  loss_rpn_loc: 0.004425  time: 1.9461  data_time: 0.0081  lr: 0.00015485  max_mem: 11021M
[09/04 06:35:08 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:35:08 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:35:08 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:35:08 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:35:08 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:35:12 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0028 s/iter. Inference: 0.2128 s/iter. Eval: 0.0716 s/iter. Total: 0.2873 s/iter. ETA=0:00:38
[09/04 06:35:17 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0032 s/iter. Inference: 0.2108 s/iter. Eval: 0.0494 s/iter. Total: 0.2635 s/iter. ETA=0:00:29
[09/04 06:35:22 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0027 s/iter. Inference: 0.2127 s/iter. Eval: 0.0701 s/iter. Total: 0.2857 s/iter. ETA=0:00:27
[09/04 06:35:27 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0029 s/iter. Inference: 0.2156 s/iter. Eval: 0.1006 s/iter. Total: 0.3192 s/iter. ETA=0:00:27
[09/04 06:35:32 d2.evaluation.evaluator]: Inference done 76/144. Dataloading: 0.0027 s/iter. Inference: 0.2152 s/iter. Eval: 0.0977 s/iter. Total: 0.3158 s/iter. ETA=0:00:21
[09/04 06:35:38 d2.evaluation.evaluator]: Inference done 96/144. Dataloading: 0.0029 s/iter. Inference: 0.2154 s/iter. Eval: 0.0834 s/iter. Total: 0.3018 s/iter. ETA=0:00:14
[09/04 06:35:43 d2.evaluation.evaluator]: Inference done 116/144. Dataloading: 0.0028 s/iter. Inference: 0.2146 s/iter. Eval: 0.0770 s/iter. Total: 0.2945 s/iter. ETA=0:00:08
[09/04 06:35:48 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0027 s/iter. Inference: 0.2140 s/iter. Eval: 0.0704 s/iter. Total: 0.2873 s/iter. ETA=0:00:02
[09/04 06:35:50 d2.evaluation.evaluator]: Total inference time: 0:00:40.040004 (0.288058 s / iter per device, on 1 devices)
[09/04 06:35:50 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:29 (0.213963 s / iter per device, on 1 devices)
[09/04 06:35:50 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:35:50 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:35:50 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 06:35:50 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:35:50 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 06:35:50 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:35:50 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.511
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.726
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.609
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.150
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.458
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.686
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.354
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.620
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.653
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.250
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.802
[09/04 06:35:50 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.139 | 72.641 | 60.867 | 14.994 | 45.822 | 68.585 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[09/04 06:35:50 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:35:50 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 06:35:50 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:35:50 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.520
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.742
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.592
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.139
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.458
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.694
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.354
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.659
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.794
[09/04 06:35:50 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.029 | 74.174 | 59.210 | 13.886 | 45.764 | 69.417 |
[09/04 06:35:50 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:35:50 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:35:50 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:35:50 d2.evaluation.testing]: copypaste: 51.1386,72.6406,60.8666,14.9945,45.8218,68.5852
[09/04 06:35:50 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:35:50 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:35:50 d2.evaluation.testing]: copypaste: 52.0288,74.1737,59.2099,13.8865,45.7636,69.4173
[09/04 06:35:50 d2.utils.events]:  eta: 0:11:40  iter: 639  total_loss: 0.4495  loss_cls: 0.06115  loss_box_reg: 0.1868  loss_mask: 0.1456  loss_rpn_cls: 0.000912  loss_rpn_loc: 0.003807  time: 1.9463  data_time: 0.0075  lr: 0.00015984  max_mem: 11021M
[09/04 06:36:29 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:36:29 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:36:29 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:36:29 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:36:29 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:36:33 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0018 s/iter. Inference: 0.2122 s/iter. Eval: 0.0645 s/iter. Total: 0.2785 s/iter. ETA=0:00:37
[09/04 06:36:39 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0020 s/iter. Inference: 0.2113 s/iter. Eval: 0.0518 s/iter. Total: 0.2652 s/iter. ETA=0:00:29
[09/04 06:36:44 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0035 s/iter. Inference: 0.2169 s/iter. Eval: 0.0773 s/iter. Total: 0.2978 s/iter. ETA=0:00:29
[09/04 06:36:49 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0032 s/iter. Inference: 0.2184 s/iter. Eval: 0.1057 s/iter. Total: 0.3275 s/iter. ETA=0:00:28
[09/04 06:36:54 d2.evaluation.evaluator]: Inference done 70/144. Dataloading: 0.0032 s/iter. Inference: 0.2210 s/iter. Eval: 0.1239 s/iter. Total: 0.3482 s/iter. ETA=0:00:25
[09/04 06:37:00 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0029 s/iter. Inference: 0.2178 s/iter. Eval: 0.0984 s/iter. Total: 0.3193 s/iter. ETA=0:00:16
[09/04 06:37:05 d2.evaluation.evaluator]: Inference done 112/144. Dataloading: 0.0029 s/iter. Inference: 0.2169 s/iter. Eval: 0.0887 s/iter. Total: 0.3086 s/iter. ETA=0:00:09
[09/04 06:37:10 d2.evaluation.evaluator]: Inference done 133/144. Dataloading: 0.0028 s/iter. Inference: 0.2157 s/iter. Eval: 0.0802 s/iter. Total: 0.2989 s/iter. ETA=0:00:03
[09/04 06:37:13 d2.evaluation.evaluator]: Total inference time: 0:00:41.668244 (0.299772 s / iter per device, on 1 devices)
[09/04 06:37:13 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:29 (0.215698 s / iter per device, on 1 devices)
[09/04 06:37:13 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:37:13 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:37:13 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 06:37:13 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:37:13 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 06:37:13 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:37:14 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.492
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.729
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.573
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.159
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.463
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.641
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.349
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.601
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.639
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.275
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.605
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.764
[09/04 06:37:14 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.176 | 72.871 | 57.336 | 15.947 | 46.326 | 64.123 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[09/04 06:37:14 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:37:14 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 06:37:14 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:37:14 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.521
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.748
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.582
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.127
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.460
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.692
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.361
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.622
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.665
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.308
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.630
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.792
[09/04 06:37:14 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.076 | 74.834 | 58.187 | 12.719 | 46.022 | 69.206 |
[09/04 06:37:14 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:37:14 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:37:14 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:37:14 d2.evaluation.testing]: copypaste: 49.1761,72.8712,57.3363,15.9473,46.3260,64.1227
[09/04 06:37:14 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:37:14 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:37:14 d2.evaluation.testing]: copypaste: 52.0756,74.8339,58.1870,12.7195,46.0218,69.2060
[09/04 06:37:14 d2.utils.events]:  eta: 0:11:01  iter: 659  total_loss: 0.534  loss_cls: 0.1037  loss_box_reg: 0.1744  loss_mask: 0.171  loss_rpn_cls: 0.001894  loss_rpn_loc: 0.009233  time: 1.9465  data_time: 0.0081  lr: 0.00016484  max_mem: 11021M
[09/04 06:37:53 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:37:53 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:37:53 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:37:53 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:37:53 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:37:57 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0041 s/iter. Inference: 0.2125 s/iter. Eval: 0.0851 s/iter. Total: 0.3017 s/iter. ETA=0:00:40
[09/04 06:38:02 d2.evaluation.evaluator]: Inference done 30/144. Dataloading: 0.0032 s/iter. Inference: 0.2119 s/iter. Eval: 0.0641 s/iter. Total: 0.2793 s/iter. ETA=0:00:31
[09/04 06:38:07 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0030 s/iter. Inference: 0.2133 s/iter. Eval: 0.0861 s/iter. Total: 0.3025 s/iter. ETA=0:00:29
[09/04 06:38:13 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0028 s/iter. Inference: 0.2157 s/iter. Eval: 0.1159 s/iter. Total: 0.3345 s/iter. ETA=0:00:28
[09/04 06:38:18 d2.evaluation.evaluator]: Inference done 70/144. Dataloading: 0.0027 s/iter. Inference: 0.2171 s/iter. Eval: 0.1311 s/iter. Total: 0.3510 s/iter. ETA=0:00:25
[09/04 06:38:23 d2.evaluation.evaluator]: Inference done 91/144. Dataloading: 0.0030 s/iter. Inference: 0.2163 s/iter. Eval: 0.1067 s/iter. Total: 0.3262 s/iter. ETA=0:00:17
[09/04 06:38:28 d2.evaluation.evaluator]: Inference done 111/144. Dataloading: 0.0030 s/iter. Inference: 0.2151 s/iter. Eval: 0.0948 s/iter. Total: 0.3130 s/iter. ETA=0:00:10
[09/04 06:38:33 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0030 s/iter. Inference: 0.2143 s/iter. Eval: 0.0865 s/iter. Total: 0.3039 s/iter. ETA=0:00:03
[09/04 06:38:37 d2.evaluation.evaluator]: Total inference time: 0:00:41.860458 (0.301154 s / iter per device, on 1 devices)
[09/04 06:38:37 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:29 (0.213929 s / iter per device, on 1 devices)
[09/04 06:38:37 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:38:37 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:38:37 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 06:38:37 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:38:37 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 06:38:37 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:38:37 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.509
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.742
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.602
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.180
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.468
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.669
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.351
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.650
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.258
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.782
[09/04 06:38:37 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.944 | 74.166 | 60.214 | 17.996 | 46.811 | 66.887 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[09/04 06:38:37 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:38:37 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/04 06:38:37 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:38:37 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.521
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.744
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.591
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.140
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.460
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.692
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.351
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.665
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.283
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.634
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.788
[09/04 06:38:37 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.135 | 74.427 | 59.140 | 14.024 | 46.024 | 69.239 |
[09/04 06:38:37 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:38:37 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:38:37 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:38:37 d2.evaluation.testing]: copypaste: 50.9443,74.1663,60.2136,17.9955,46.8113,66.8869
[09/04 06:38:37 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:38:37 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:38:37 d2.evaluation.testing]: copypaste: 52.1346,74.4270,59.1400,14.0241,46.0235,69.2385
[09/04 06:38:37 d2.utils.events]:  eta: 0:10:22  iter: 679  total_loss: 0.3327  loss_cls: 0.05808  loss_box_reg: 0.1236  loss_mask: 0.1471  loss_rpn_cls: 0.002272  loss_rpn_loc: 0.001739  time: 1.9465  data_time: 0.0081  lr: 0.00016983  max_mem: 11021M
[09/04 06:39:16 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:39:16 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:39:16 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:39:16 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:39:16 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:39:20 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0021 s/iter. Inference: 0.2144 s/iter. Eval: 0.0748 s/iter. Total: 0.2913 s/iter. ETA=0:00:38
[09/04 06:39:25 d2.evaluation.evaluator]: Inference done 28/144. Dataloading: 0.0029 s/iter. Inference: 0.2178 s/iter. Eval: 0.0751 s/iter. Total: 0.2960 s/iter. ETA=0:00:34
[09/04 06:39:31 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0028 s/iter. Inference: 0.2162 s/iter. Eval: 0.0854 s/iter. Total: 0.3046 s/iter. ETA=0:00:29
[09/04 06:39:36 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0028 s/iter. Inference: 0.2180 s/iter. Eval: 0.1143 s/iter. Total: 0.3353 s/iter. ETA=0:00:28
[09/04 06:39:41 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0028 s/iter. Inference: 0.2187 s/iter. Eval: 0.1265 s/iter. Total: 0.3481 s/iter. ETA=0:00:25
[09/04 06:39:47 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0027 s/iter. Inference: 0.2165 s/iter. Eval: 0.1039 s/iter. Total: 0.3232 s/iter. ETA=0:00:16
[09/04 06:39:52 d2.evaluation.evaluator]: Inference done 112/144. Dataloading: 0.0027 s/iter. Inference: 0.2153 s/iter. Eval: 0.0927 s/iter. Total: 0.3108 s/iter. ETA=0:00:09
[09/04 06:39:57 d2.evaluation.evaluator]: Inference done 132/144. Dataloading: 0.0027 s/iter. Inference: 0.2144 s/iter. Eval: 0.0845 s/iter. Total: 0.3018 s/iter. ETA=0:00:03
[09/04 06:40:01 d2.evaluation.evaluator]: Total inference time: 0:00:42.184789 (0.303488 s / iter per device, on 1 devices)
[09/04 06:40:01 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:29 (0.215068 s / iter per device, on 1 devices)
[09/04 06:40:01 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:40:01 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:40:01 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 06:40:01 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:40:01 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 06:40:01 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:40:01 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.518
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.750
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.597
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.171
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.471
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.680
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.365
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.615
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.659
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.267
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.624
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.789
[09/04 06:40:01 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.833 | 74.989 | 59.727 | 17.105 | 47.129 | 67.991 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[09/04 06:40:01 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:40:01 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/04 06:40:01 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:40:01 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.530
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.753
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.599
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.142
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.473
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.692
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.364
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.672
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.643
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.788
[09/04 06:40:01 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 53.008 | 75.349 | 59.895 | 14.247 | 47.316 | 69.223 |
[09/04 06:40:01 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:40:01 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:40:01 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:40:01 d2.evaluation.testing]: copypaste: 51.8328,74.9888,59.7270,17.1054,47.1286,67.9909
[09/04 06:40:01 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:40:01 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:40:01 d2.evaluation.testing]: copypaste: 53.0082,75.3493,59.8954,14.2469,47.3164,69.2229
[09/04 06:40:01 d2.utils.events]:  eta: 0:09:43  iter: 699  total_loss: 0.5814  loss_cls: 0.1447  loss_box_reg: 0.2028  loss_mask: 0.1637  loss_rpn_cls: 0.004258  loss_rpn_loc: 0.005622  time: 1.9467  data_time: 0.0075  lr: 0.00017483  max_mem: 11021M
[09/04 06:40:40 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:40:40 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:40:40 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:40:40 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:40:40 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:40:44 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.2119 s/iter. Eval: 0.0575 s/iter. Total: 0.2711 s/iter. ETA=0:00:36
[09/04 06:40:49 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0021 s/iter. Inference: 0.2108 s/iter. Eval: 0.0440 s/iter. Total: 0.2570 s/iter. ETA=0:00:29
[09/04 06:40:54 d2.evaluation.evaluator]: Inference done 48/144. Dataloading: 0.0023 s/iter. Inference: 0.2129 s/iter. Eval: 0.0611 s/iter. Total: 0.2765 s/iter. ETA=0:00:26
[09/04 06:40:59 d2.evaluation.evaluator]: Inference done 61/144. Dataloading: 0.0023 s/iter. Inference: 0.2149 s/iter. Eval: 0.0876 s/iter. Total: 0.3049 s/iter. ETA=0:00:25
[09/04 06:41:04 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0030 s/iter. Inference: 0.2168 s/iter. Eval: 0.0887 s/iter. Total: 0.3086 s/iter. ETA=0:00:20
[09/04 06:41:10 d2.evaluation.evaluator]: Inference done 99/144. Dataloading: 0.0028 s/iter. Inference: 0.2148 s/iter. Eval: 0.0728 s/iter. Total: 0.2905 s/iter. ETA=0:00:13
[09/04 06:41:15 d2.evaluation.evaluator]: Inference done 118/144. Dataloading: 0.0028 s/iter. Inference: 0.2145 s/iter. Eval: 0.0688 s/iter. Total: 0.2863 s/iter. ETA=0:00:07
[09/04 06:41:20 d2.evaluation.evaluator]: Inference done 139/144. Dataloading: 0.0027 s/iter. Inference: 0.2137 s/iter. Eval: 0.0631 s/iter. Total: 0.2796 s/iter. ETA=0:00:01
[09/04 06:41:21 d2.evaluation.evaluator]: Total inference time: 0:00:39.116312 (0.281412 s / iter per device, on 1 devices)
[09/04 06:41:21 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:29 (0.213742 s / iter per device, on 1 devices)
[09/04 06:41:21 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:41:21 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:41:21 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 06:41:21 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:41:21 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 06:41:21 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:41:21 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.522
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.760
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.604
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.179
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.486
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.675
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.365
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.650
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.258
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.791
[09/04 06:41:21 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.198 | 76.013 | 60.355 | 17.934 | 48.645 | 67.531 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[09/04 06:41:22 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:41:22 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 06:41:22 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:41:22 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.534
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.765
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.598
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.148
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.478
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.697
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.366
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.626
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.665
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.628
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.794
[09/04 06:41:22 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 53.361 | 76.462 | 59.840 | 14.796 | 47.791 | 69.708 |
[09/04 06:41:22 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:41:22 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:41:22 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:41:22 d2.evaluation.testing]: copypaste: 52.1983,76.0134,60.3554,17.9342,48.6453,67.5313
[09/04 06:41:22 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:41:22 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:41:22 d2.evaluation.testing]: copypaste: 53.3605,76.4617,59.8401,14.7964,47.7909,69.7075
[09/04 06:41:22 d2.utils.events]:  eta: 0:09:04  iter: 719  total_loss: 0.5317  loss_cls: 0.07766  loss_box_reg: 0.199  loss_mask: 0.1848  loss_rpn_cls: 0.002343  loss_rpn_loc: 0.01033  time: 1.9468  data_time: 0.0071  lr: 0.00017982  max_mem: 11021M
[09/04 06:42:01 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:42:01 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:42:01 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:42:01 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:42:01 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:42:05 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0015 s/iter. Inference: 0.2124 s/iter. Eval: 0.0658 s/iter. Total: 0.2796 s/iter. ETA=0:00:37
[09/04 06:42:10 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0026 s/iter. Inference: 0.2127 s/iter. Eval: 0.0745 s/iter. Total: 0.2899 s/iter. ETA=0:00:33
[09/04 06:42:15 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0032 s/iter. Inference: 0.2133 s/iter. Eval: 0.0756 s/iter. Total: 0.2922 s/iter. ETA=0:00:28
[09/04 06:42:20 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0031 s/iter. Inference: 0.2158 s/iter. Eval: 0.1023 s/iter. Total: 0.3213 s/iter. ETA=0:00:27
[09/04 06:42:25 d2.evaluation.evaluator]: Inference done 72/144. Dataloading: 0.0029 s/iter. Inference: 0.2165 s/iter. Eval: 0.1101 s/iter. Total: 0.3297 s/iter. ETA=0:00:23
[09/04 06:42:30 d2.evaluation.evaluator]: Inference done 93/144. Dataloading: 0.0028 s/iter. Inference: 0.2147 s/iter. Eval: 0.0910 s/iter. Total: 0.3087 s/iter. ETA=0:00:15
[09/04 06:42:35 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0029 s/iter. Inference: 0.2142 s/iter. Eval: 0.0814 s/iter. Total: 0.2987 s/iter. ETA=0:00:09
[09/04 06:42:40 d2.evaluation.evaluator]: Inference done 134/144. Dataloading: 0.0028 s/iter. Inference: 0.2135 s/iter. Eval: 0.0737 s/iter. Total: 0.2902 s/iter. ETA=0:00:02
[09/04 06:42:44 d2.evaluation.evaluator]: Total inference time: 0:00:40.773773 (0.293336 s / iter per device, on 1 devices)
[09/04 06:42:44 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:29 (0.213945 s / iter per device, on 1 devices)
[09/04 06:42:44 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:42:44 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:42:44 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 06:42:44 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:42:44 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 06:42:44 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:42:44 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.529
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.760
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.602
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.184
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.480
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.697
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.361
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.621
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.667
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.242
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.631
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.808
[09/04 06:42:44 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.875 | 76.005 | 60.241 | 18.381 | 48.009 | 69.702 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[09/04 06:42:44 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:42:44 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 06:42:44 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:42:44 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.535
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.766
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.599
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.153
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.473
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.701
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.628
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.673
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.308
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.643
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.791
[09/04 06:42:44 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 53.456 | 76.580 | 59.937 | 15.315 | 47.284 | 70.128 |
[09/04 06:42:44 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:42:44 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:42:44 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:42:44 d2.evaluation.testing]: copypaste: 52.8751,76.0049,60.2410,18.3812,48.0093,69.7018
[09/04 06:42:44 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:42:44 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:42:44 d2.evaluation.testing]: copypaste: 53.4563,76.5804,59.9375,15.3146,47.2836,70.1280
[09/04 06:42:44 d2.utils.events]:  eta: 0:08:25  iter: 739  total_loss: 0.432  loss_cls: 0.0764  loss_box_reg: 0.1672  loss_mask: 0.1238  loss_rpn_cls: 0.002858  loss_rpn_loc: 0.004128  time: 1.9470  data_time: 0.0076  lr: 0.00018482  max_mem: 11021M
[09/04 06:43:23 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:43:23 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:43:23 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:43:23 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:43:23 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:43:27 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0018 s/iter. Inference: 0.2167 s/iter. Eval: 0.0590 s/iter. Total: 0.2775 s/iter. ETA=0:00:36
[09/04 06:43:32 d2.evaluation.evaluator]: Inference done 33/144. Dataloading: 0.0022 s/iter. Inference: 0.2105 s/iter. Eval: 0.0320 s/iter. Total: 0.2448 s/iter. ETA=0:00:27
[09/04 06:43:37 d2.evaluation.evaluator]: Inference done 50/144. Dataloading: 0.0021 s/iter. Inference: 0.2119 s/iter. Eval: 0.0513 s/iter. Total: 0.2655 s/iter. ETA=0:00:24
[09/04 06:43:42 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0021 s/iter. Inference: 0.2131 s/iter. Eval: 0.0622 s/iter. Total: 0.2775 s/iter. ETA=0:00:21
[09/04 06:43:47 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0022 s/iter. Inference: 0.2120 s/iter. Eval: 0.0520 s/iter. Total: 0.2663 s/iter. ETA=0:00:14
[09/04 06:43:53 d2.evaluation.evaluator]: Inference done 109/144. Dataloading: 0.0024 s/iter. Inference: 0.2126 s/iter. Eval: 0.0500 s/iter. Total: 0.2651 s/iter. ETA=0:00:09
[09/04 06:43:58 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0024 s/iter. Inference: 0.2120 s/iter. Eval: 0.0453 s/iter. Total: 0.2598 s/iter. ETA=0:00:03
[09/04 06:44:01 d2.evaluation.evaluator]: Total inference time: 0:00:36.194261 (0.260390 s / iter per device, on 1 devices)
[09/04 06:44:01 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:29 (0.212077 s / iter per device, on 1 devices)
[09/04 06:44:01 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:44:01 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:44:01 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 06:44:01 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:44:01 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 06:44:01 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:44:01 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.527
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.746
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.582
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.153
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.483
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.700
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.363
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.621
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.648
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.183
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.602
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.812
[09/04 06:44:01 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.697 | 74.650 | 58.198 | 15.330 | 48.282 | 69.969 |
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/04 06:44:01 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:44:01 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 06:44:01 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:44:01 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.528
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.759
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.588
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.126
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.466
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.702
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.360
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.621
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.651
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.233
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.611
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.797
[09/04 06:44:01 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.765 | 75.894 | 58.805 | 12.612 | 46.571 | 70.212 |
[09/04 06:44:01 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:44:01 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:44:01 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:44:01 d2.evaluation.testing]: copypaste: 52.6973,74.6499,58.1975,15.3300,48.2824,69.9686
[09/04 06:44:01 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:44:01 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:44:01 d2.evaluation.testing]: copypaste: 52.7649,75.8941,58.8045,12.6122,46.5705,70.2116
[09/04 06:44:01 d2.utils.events]:  eta: 0:07:46  iter: 759  total_loss: 0.3592  loss_cls: 0.08441  loss_box_reg: 0.15  loss_mask: 0.1364  loss_rpn_cls: 0.003515  loss_rpn_loc: 0.007127  time: 1.9471  data_time: 0.0104  lr: 0.00018981  max_mem: 11021M
[09/04 06:44:40 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:44:40 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:44:40 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:44:40 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:44:40 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:44:44 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0025 s/iter. Inference: 0.2148 s/iter. Eval: 0.0583 s/iter. Total: 0.2757 s/iter. ETA=0:00:36
[09/04 06:44:49 d2.evaluation.evaluator]: Inference done 32/144. Dataloading: 0.0028 s/iter. Inference: 0.2101 s/iter. Eval: 0.0345 s/iter. Total: 0.2476 s/iter. ETA=0:00:27
[09/04 06:44:55 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0030 s/iter. Inference: 0.2133 s/iter. Eval: 0.0605 s/iter. Total: 0.2769 s/iter. ETA=0:00:26
[09/04 06:45:00 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0028 s/iter. Inference: 0.2137 s/iter. Eval: 0.0706 s/iter. Total: 0.2872 s/iter. ETA=0:00:22
[09/04 06:45:05 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0027 s/iter. Inference: 0.2128 s/iter. Eval: 0.0587 s/iter. Total: 0.2743 s/iter. ETA=0:00:15
[09/04 06:45:10 d2.evaluation.evaluator]: Inference done 110/144. Dataloading: 0.0026 s/iter. Inference: 0.2120 s/iter. Eval: 0.0533 s/iter. Total: 0.2680 s/iter. ETA=0:00:09
[09/04 06:45:16 d2.evaluation.evaluator]: Inference done 132/144. Dataloading: 0.0025 s/iter. Inference: 0.2114 s/iter. Eval: 0.0487 s/iter. Total: 0.2627 s/iter. ETA=0:00:03
[09/04 06:45:19 d2.evaluation.evaluator]: Total inference time: 0:00:36.632316 (0.263542 s / iter per device, on 1 devices)
[09/04 06:45:19 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:29 (0.211521 s / iter per device, on 1 devices)
[09/04 06:45:19 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:45:19 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:45:19 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 06:45:19 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:45:19 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 06:45:19 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:45:19 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.519
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.758
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.590
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.144
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.487
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.687
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.366
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.606
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.632
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.586
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.797
[09/04 06:45:19 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.935 | 75.754 | 59.024 | 14.365 | 48.727 | 68.698 |
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/04 06:45:19 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:45:19 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 06:45:19 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:45:19 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.536
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.769
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.594
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.137
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.476
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.710
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.369
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.624
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.654
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.242
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.800
[09/04 06:45:19 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 53.561 | 76.901 | 59.395 | 13.727 | 47.604 | 71.020 |
[09/04 06:45:19 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:45:19 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:45:19 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:45:19 d2.evaluation.testing]: copypaste: 51.9348,75.7540,59.0237,14.3647,48.7267,68.6981
[09/04 06:45:19 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:45:19 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:45:19 d2.evaluation.testing]: copypaste: 53.5607,76.9009,59.3955,13.7266,47.6044,71.0205
[09/04 06:45:19 d2.utils.events]:  eta: 0:07:08  iter: 779  total_loss: 0.2666  loss_cls: 0.03915  loss_box_reg: 0.1112  loss_mask: 0.126  loss_rpn_cls: 0.0004391  loss_rpn_loc: 0.00149  time: 1.9471  data_time: 0.0085  lr: 0.00019481  max_mem: 11021M
[09/04 06:45:58 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:45:58 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:45:58 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:45:58 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:45:58 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:46:02 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0024 s/iter. Inference: 0.2102 s/iter. Eval: 0.0416 s/iter. Total: 0.2542 s/iter. ETA=0:00:33
[09/04 06:46:07 d2.evaluation.evaluator]: Inference done 32/144. Dataloading: 0.0030 s/iter. Inference: 0.2087 s/iter. Eval: 0.0307 s/iter. Total: 0.2425 s/iter. ETA=0:00:27
[09/04 06:46:12 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0025 s/iter. Inference: 0.2111 s/iter. Eval: 0.0533 s/iter. Total: 0.2671 s/iter. ETA=0:00:25
[09/04 06:46:18 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0027 s/iter. Inference: 0.2121 s/iter. Eval: 0.0656 s/iter. Total: 0.2805 s/iter. ETA=0:00:21
[09/04 06:46:23 d2.evaluation.evaluator]: Inference done 88/144. Dataloading: 0.0029 s/iter. Inference: 0.2113 s/iter. Eval: 0.0562 s/iter. Total: 0.2706 s/iter. ETA=0:00:15
[09/04 06:46:28 d2.evaluation.evaluator]: Inference done 110/144. Dataloading: 0.0026 s/iter. Inference: 0.2106 s/iter. Eval: 0.0500 s/iter. Total: 0.2634 s/iter. ETA=0:00:08
[09/04 06:46:33 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0026 s/iter. Inference: 0.2112 s/iter. Eval: 0.0475 s/iter. Total: 0.2614 s/iter. ETA=0:00:03
[09/04 06:46:37 d2.evaluation.evaluator]: Total inference time: 0:00:36.314422 (0.261255 s / iter per device, on 1 devices)
[09/04 06:46:37 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:29 (0.211036 s / iter per device, on 1 devices)
[09/04 06:46:37 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:46:37 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:46:37 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 06:46:37 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:46:37 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.02 seconds.
[09/04 06:46:37 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:46:37 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.523
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.748
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.608
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.154
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.485
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.701
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.368
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.615
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.645
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.175
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.595
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.817
[09/04 06:46:37 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.325 | 74.834 | 60.763 | 15.434 | 48.526 | 70.124 |
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/04 06:46:37 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:46:37 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 06:46:37 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:46:37 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.531
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.762
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.597
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.142
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.467
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.709
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.368
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.628
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.658
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.250
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.618
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.800
[09/04 06:46:37 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 53.066 | 76.218 | 59.733 | 14.215 | 46.718 | 70.923 |
[09/04 06:46:37 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:46:37 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:46:37 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:46:37 d2.evaluation.testing]: copypaste: 52.3249,74.8345,60.7626,15.4338,48.5258,70.1244
[09/04 06:46:37 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:46:37 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:46:37 d2.evaluation.testing]: copypaste: 53.0663,76.2184,59.7327,14.2147,46.7182,70.9225
[09/04 06:46:37 d2.utils.events]:  eta: 0:06:29  iter: 799  total_loss: 0.3323  loss_cls: 0.05898  loss_box_reg: 0.1011  loss_mask: 0.1329  loss_rpn_cls: 0.0006192  loss_rpn_loc: 0.002614  time: 1.9472  data_time: 0.0072  lr: 0.0001998  max_mem: 11021M
[09/04 06:47:16 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:47:16 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:47:16 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:47:16 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:47:16 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:47:20 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0021 s/iter. Inference: 0.2123 s/iter. Eval: 0.0670 s/iter. Total: 0.2814 s/iter. ETA=0:00:37
[09/04 06:47:25 d2.evaluation.evaluator]: Inference done 32/144. Dataloading: 0.0028 s/iter. Inference: 0.2100 s/iter. Eval: 0.0429 s/iter. Total: 0.2559 s/iter. ETA=0:00:28
[09/04 06:47:31 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0027 s/iter. Inference: 0.2126 s/iter. Eval: 0.0732 s/iter. Total: 0.2886 s/iter. ETA=0:00:27
[09/04 06:47:36 d2.evaluation.evaluator]: Inference done 64/144. Dataloading: 0.0026 s/iter. Inference: 0.2134 s/iter. Eval: 0.0846 s/iter. Total: 0.3006 s/iter. ETA=0:00:24
[09/04 06:47:41 d2.evaluation.evaluator]: Inference done 80/144. Dataloading: 0.0028 s/iter. Inference: 0.2142 s/iter. Eval: 0.0883 s/iter. Total: 0.3054 s/iter. ETA=0:00:19
[09/04 06:47:46 d2.evaluation.evaluator]: Inference done 101/144. Dataloading: 0.0027 s/iter. Inference: 0.2130 s/iter. Eval: 0.0765 s/iter. Total: 0.2923 s/iter. ETA=0:00:12
[09/04 06:47:51 d2.evaluation.evaluator]: Inference done 122/144. Dataloading: 0.0028 s/iter. Inference: 0.2126 s/iter. Eval: 0.0690 s/iter. Total: 0.2845 s/iter. ETA=0:00:06
[09/04 06:47:56 d2.evaluation.evaluator]: Inference done 143/144. Dataloading: 0.0027 s/iter. Inference: 0.2120 s/iter. Eval: 0.0640 s/iter. Total: 0.2789 s/iter. ETA=0:00:00
[09/04 06:47:57 d2.evaluation.evaluator]: Total inference time: 0:00:39.117275 (0.281419 s / iter per device, on 1 devices)
[09/04 06:47:57 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:29 (0.212191 s / iter per device, on 1 devices)
[09/04 06:47:57 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:47:57 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:47:57 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 06:47:57 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:47:57 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 06:47:57 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:47:57 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.517
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.760
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.590
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.185
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.475
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.680
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.374
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.612
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.641
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.233
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.595
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.795
[09/04 06:47:57 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.675 | 76.033 | 58.999 | 18.457 | 47.493 | 67.969 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[09/04 06:47:57 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:47:57 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 06:47:57 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:47:57 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.542
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.775
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.608
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.156
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.483
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.707
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.380
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.633
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.670
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.308
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.634
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.800
[09/04 06:47:57 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 54.163 | 77.547 | 60.762 | 15.596 | 48.322 | 70.700 |
[09/04 06:47:57 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:47:57 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:47:57 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:47:57 d2.evaluation.testing]: copypaste: 51.6751,76.0327,58.9988,18.4573,47.4927,67.9692
[09/04 06:47:57 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:47:57 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:47:57 d2.evaluation.testing]: copypaste: 54.1628,77.5471,60.7622,15.5964,48.3224,70.7003
[09/04 06:47:57 d2.utils.events]:  eta: 0:05:50  iter: 819  total_loss: 0.4382  loss_cls: 0.06557  loss_box_reg: 0.1654  loss_mask: 0.1715  loss_rpn_cls: 0.002941  loss_rpn_loc: 0.00299  time: 1.9471  data_time: 0.0081  lr: 0.0002048  max_mem: 11021M
[09/04 06:48:36 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:48:36 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:48:36 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:48:36 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:48:36 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:48:40 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0021 s/iter. Inference: 0.2108 s/iter. Eval: 0.0407 s/iter. Total: 0.2536 s/iter. ETA=0:00:33
[09/04 06:48:45 d2.evaluation.evaluator]: Inference done 32/144. Dataloading: 0.0031 s/iter. Inference: 0.2122 s/iter. Eval: 0.0335 s/iter. Total: 0.2489 s/iter. ETA=0:00:27
[09/04 06:48:50 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0029 s/iter. Inference: 0.2136 s/iter. Eval: 0.0527 s/iter. Total: 0.2694 s/iter. ETA=0:00:25
[09/04 06:48:55 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0028 s/iter. Inference: 0.2138 s/iter. Eval: 0.0621 s/iter. Total: 0.2789 s/iter. ETA=0:00:21
[09/04 06:49:00 d2.evaluation.evaluator]: Inference done 88/144. Dataloading: 0.0028 s/iter. Inference: 0.2127 s/iter. Eval: 0.0536 s/iter. Total: 0.2693 s/iter. ETA=0:00:15
[09/04 06:49:06 d2.evaluation.evaluator]: Inference done 110/144. Dataloading: 0.0027 s/iter. Inference: 0.2119 s/iter. Eval: 0.0478 s/iter. Total: 0.2626 s/iter. ETA=0:00:08
[09/04 06:49:11 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0028 s/iter. Inference: 0.2115 s/iter. Eval: 0.0441 s/iter. Total: 0.2585 s/iter. ETA=0:00:03
[09/04 06:49:14 d2.evaluation.evaluator]: Total inference time: 0:00:35.884132 (0.258159 s / iter per device, on 1 devices)
[09/04 06:49:14 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:29 (0.211351 s / iter per device, on 1 devices)
[09/04 06:49:14 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:49:14 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:49:14 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 06:49:14 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:49:14 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 06:49:14 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:49:14 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.523
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.758
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.580
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.172
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.479
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.684
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.380
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.642
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.242
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.592
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.803
[09/04 06:49:14 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.270 | 75.815 | 57.968 | 17.170 | 47.900 | 68.438 |
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/04 06:49:14 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:49:14 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 06:49:14 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:49:14 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.538
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.769
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.599
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.153
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.490
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.702
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.380
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.624
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.653
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.608
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.795
[09/04 06:49:14 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 53.840 | 76.916 | 59.851 | 15.310 | 48.957 | 70.207 |
[09/04 06:49:14 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:49:14 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:49:14 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:49:14 d2.evaluation.testing]: copypaste: 52.2700,75.8148,57.9681,17.1702,47.8999,68.4379
[09/04 06:49:14 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:49:14 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:49:14 d2.evaluation.testing]: copypaste: 53.8398,76.9160,59.8509,15.3105,48.9568,70.2072
[09/04 06:49:14 d2.utils.events]:  eta: 0:05:11  iter: 839  total_loss: 0.2869  loss_cls: 0.05637  loss_box_reg: 0.1128  loss_mask: 0.09718  loss_rpn_cls: 0.002147  loss_rpn_loc: 0.001978  time: 1.9471  data_time: 0.0064  lr: 0.00020979  max_mem: 11021M
[09/04 06:49:53 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:49:53 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:49:53 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:49:53 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:49:53 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:49:57 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0018 s/iter. Inference: 0.2133 s/iter. Eval: 0.0707 s/iter. Total: 0.2859 s/iter. ETA=0:00:38
[09/04 06:50:02 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0032 s/iter. Inference: 0.2121 s/iter. Eval: 0.0647 s/iter. Total: 0.2801 s/iter. ETA=0:00:32
[09/04 06:50:08 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0029 s/iter. Inference: 0.2135 s/iter. Eval: 0.0791 s/iter. Total: 0.2956 s/iter. ETA=0:00:28
[09/04 06:50:13 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0027 s/iter. Inference: 0.2163 s/iter. Eval: 0.1107 s/iter. Total: 0.3299 s/iter. ETA=0:00:28
[09/04 06:50:18 d2.evaluation.evaluator]: Inference done 69/144. Dataloading: 0.0028 s/iter. Inference: 0.2178 s/iter. Eval: 0.1286 s/iter. Total: 0.3493 s/iter. ETA=0:00:26
[09/04 06:50:23 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0029 s/iter. Inference: 0.2179 s/iter. Eval: 0.1068 s/iter. Total: 0.3277 s/iter. ETA=0:00:18
[09/04 06:50:28 d2.evaluation.evaluator]: Inference done 109/144. Dataloading: 0.0029 s/iter. Inference: 0.2168 s/iter. Eval: 0.0949 s/iter. Total: 0.3148 s/iter. ETA=0:00:11
[09/04 06:50:33 d2.evaluation.evaluator]: Inference done 130/144. Dataloading: 0.0028 s/iter. Inference: 0.2156 s/iter. Eval: 0.0851 s/iter. Total: 0.3037 s/iter. ETA=0:00:04
[09/04 06:50:38 d2.evaluation.evaluator]: Total inference time: 0:00:42.279610 (0.304170 s / iter per device, on 1 devices)
[09/04 06:50:38 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:29 (0.215475 s / iter per device, on 1 devices)
[09/04 06:50:38 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:50:38 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:50:38 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 06:50:38 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:50:38 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 06:50:38 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:50:38 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.515
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.742
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.592
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.193
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.457
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.706
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.369
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.615
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.647
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.283
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.590
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.812
[09/04 06:50:38 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.546 | 74.241 | 59.226 | 19.281 | 45.694 | 70.578 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[09/04 06:50:38 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:50:38 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/04 06:50:38 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:50:38 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.526
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.758
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.597
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.134
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.470
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.705
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.371
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.625
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.654
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.283
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.611
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.797
[09/04 06:50:38 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.610 | 75.759 | 59.718 | 13.447 | 47.020 | 70.512 |
[09/04 06:50:38 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:50:38 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:50:38 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:50:38 d2.evaluation.testing]: copypaste: 51.5457,74.2414,59.2262,19.2809,45.6943,70.5785
[09/04 06:50:38 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:50:38 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:50:38 d2.evaluation.testing]: copypaste: 52.6101,75.7585,59.7184,13.4469,47.0195,70.5120
[09/04 06:50:38 d2.utils.events]:  eta: 0:04:32  iter: 859  total_loss: 0.3319  loss_cls: 0.05249  loss_box_reg: 0.1061  loss_mask: 0.1241  loss_rpn_cls: 0.002747  loss_rpn_loc: 0.002628  time: 1.9471  data_time: 0.0083  lr: 0.00021479  max_mem: 11021M
[09/04 06:51:17 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:51:17 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:51:17 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:51:17 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:51:17 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:51:20 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0026 s/iter. Inference: 0.2140 s/iter. Eval: 0.0379 s/iter. Total: 0.2546 s/iter. ETA=0:00:33
[09/04 06:51:25 d2.evaluation.evaluator]: Inference done 33/144. Dataloading: 0.0025 s/iter. Inference: 0.2089 s/iter. Eval: 0.0254 s/iter. Total: 0.2369 s/iter. ETA=0:00:26
[09/04 06:51:30 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0026 s/iter. Inference: 0.2126 s/iter. Eval: 0.0506 s/iter. Total: 0.2659 s/iter. ETA=0:00:25
[09/04 06:51:36 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0024 s/iter. Inference: 0.2129 s/iter. Eval: 0.0598 s/iter. Total: 0.2753 s/iter. ETA=0:00:21
[09/04 06:51:41 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0022 s/iter. Inference: 0.2117 s/iter. Eval: 0.0497 s/iter. Total: 0.2637 s/iter. ETA=0:00:14
[09/04 06:51:46 d2.evaluation.evaluator]: Inference done 111/144. Dataloading: 0.0023 s/iter. Inference: 0.2111 s/iter. Eval: 0.0442 s/iter. Total: 0.2577 s/iter. ETA=0:00:08
[09/04 06:51:51 d2.evaluation.evaluator]: Inference done 133/144. Dataloading: 0.0023 s/iter. Inference: 0.2105 s/iter. Eval: 0.0402 s/iter. Total: 0.2531 s/iter. ETA=0:00:02
[09/04 06:51:54 d2.evaluation.evaluator]: Total inference time: 0:00:35.250331 (0.253600 s / iter per device, on 1 devices)
[09/04 06:51:54 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:29 (0.210584 s / iter per device, on 1 devices)
[09/04 06:51:54 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:51:54 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:51:54 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 06:51:54 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:51:54 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.02 seconds.
[09/04 06:51:54 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:51:54 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.534
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.778
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.585
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.174
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.485
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.709
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.378
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.617
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.636
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.192
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.585
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.806
[09/04 06:51:54 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 53.429 | 77.767 | 58.535 | 17.385 | 48.500 | 70.935 |
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/04 06:51:54 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:51:54 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 06:51:54 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:51:54 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.541
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.774
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.601
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.157
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.489
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.703
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.376
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.642
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.242
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.601
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.788
[09/04 06:51:54 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 54.077 | 77.435 | 60.145 | 15.711 | 48.938 | 70.279 |
[09/04 06:51:54 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:51:54 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:51:54 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:51:54 d2.evaluation.testing]: copypaste: 53.4288,77.7671,58.5350,17.3846,48.5003,70.9346
[09/04 06:51:54 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:51:54 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:51:54 d2.evaluation.testing]: copypaste: 54.0770,77.4351,60.1450,15.7106,48.9376,70.2789
[09/04 06:51:54 d2.utils.events]:  eta: 0:03:53  iter: 879  total_loss: 0.3225  loss_cls: 0.08087  loss_box_reg: 0.1479  loss_mask: 0.1281  loss_rpn_cls: 0.00358  loss_rpn_loc: 0.004241  time: 1.9471  data_time: 0.0078  lr: 0.00021978  max_mem: 11021M
[09/04 06:52:33 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:52:33 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:52:33 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:52:33 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:52:33 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:52:38 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0020 s/iter. Inference: 0.2151 s/iter. Eval: 0.0606 s/iter. Total: 0.2776 s/iter. ETA=0:00:36
[09/04 06:52:43 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0027 s/iter. Inference: 0.2110 s/iter. Eval: 0.0441 s/iter. Total: 0.2579 s/iter. ETA=0:00:29
[09/04 06:52:48 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0027 s/iter. Inference: 0.2126 s/iter. Eval: 0.0640 s/iter. Total: 0.2794 s/iter. ETA=0:00:27
[09/04 06:52:53 d2.evaluation.evaluator]: Inference done 60/144. Dataloading: 0.0025 s/iter. Inference: 0.2146 s/iter. Eval: 0.0887 s/iter. Total: 0.3059 s/iter. ETA=0:00:25
[09/04 06:52:58 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0025 s/iter. Inference: 0.2145 s/iter. Eval: 0.0884 s/iter. Total: 0.3056 s/iter. ETA=0:00:20
[09/04 06:53:03 d2.evaluation.evaluator]: Inference done 99/144. Dataloading: 0.0026 s/iter. Inference: 0.2132 s/iter. Eval: 0.0727 s/iter. Total: 0.2887 s/iter. ETA=0:00:12
[09/04 06:53:08 d2.evaluation.evaluator]: Inference done 118/144. Dataloading: 0.0027 s/iter. Inference: 0.2135 s/iter. Eval: 0.0692 s/iter. Total: 0.2855 s/iter. ETA=0:00:07
[09/04 06:53:13 d2.evaluation.evaluator]: Inference done 139/144. Dataloading: 0.0029 s/iter. Inference: 0.2130 s/iter. Eval: 0.0634 s/iter. Total: 0.2794 s/iter. ETA=0:00:01
[09/04 06:53:15 d2.evaluation.evaluator]: Total inference time: 0:00:39.086868 (0.281200 s / iter per device, on 1 devices)
[09/04 06:53:15 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:29 (0.213062 s / iter per device, on 1 devices)
[09/04 06:53:15 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:53:15 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:53:15 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 06:53:15 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:53:15 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 06:53:15 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:53:15 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.530
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.785
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.601
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.184
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.463
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.715
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.378
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.620
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.657
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.292
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.609
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.808
[09/04 06:53:15 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 53.014 | 78.471 | 60.096 | 18.417 | 46.308 | 71.483 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[09/04 06:53:15 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:53:15 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 06:53:15 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:53:15 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.547
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.777
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.619
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.155
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.483
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.720
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.381
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.637
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.677
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.640
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.800
[09/04 06:53:15 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 54.652 | 77.726 | 61.898 | 15.475 | 48.341 | 71.991 |
[09/04 06:53:15 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:53:15 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:53:15 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:53:15 d2.evaluation.testing]: copypaste: 53.0143,78.4713,60.0956,18.4170,46.3083,71.4832
[09/04 06:53:15 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:53:15 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:53:15 d2.evaluation.testing]: copypaste: 54.6518,77.7263,61.8985,15.4748,48.3408,71.9906
[09/04 06:53:15 d2.utils.events]:  eta: 0:03:14  iter: 899  total_loss: 0.4053  loss_cls: 0.05028  loss_box_reg: 0.1723  loss_mask: 0.1335  loss_rpn_cls: 0.00103  loss_rpn_loc: 0.003664  time: 1.9473  data_time: 0.0092  lr: 0.00022478  max_mem: 11021M
[09/04 06:53:54 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:53:54 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:53:54 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:53:54 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:53:54 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:53:58 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0015 s/iter. Inference: 0.2098 s/iter. Eval: 0.0367 s/iter. Total: 0.2481 s/iter. ETA=0:00:32
[09/04 06:54:03 d2.evaluation.evaluator]: Inference done 33/144. Dataloading: 0.0020 s/iter. Inference: 0.2088 s/iter. Eval: 0.0267 s/iter. Total: 0.2376 s/iter. ETA=0:00:26
[09/04 06:54:08 d2.evaluation.evaluator]: Inference done 50/144. Dataloading: 0.0022 s/iter. Inference: 0.2117 s/iter. Eval: 0.0512 s/iter. Total: 0.2653 s/iter. ETA=0:00:24
[09/04 06:54:14 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0025 s/iter. Inference: 0.2138 s/iter. Eval: 0.0659 s/iter. Total: 0.2822 s/iter. ETA=0:00:21
[09/04 06:54:19 d2.evaluation.evaluator]: Inference done 88/144. Dataloading: 0.0028 s/iter. Inference: 0.2129 s/iter. Eval: 0.0558 s/iter. Total: 0.2716 s/iter. ETA=0:00:15
[09/04 06:54:24 d2.evaluation.evaluator]: Inference done 110/144. Dataloading: 0.0028 s/iter. Inference: 0.2120 s/iter. Eval: 0.0490 s/iter. Total: 0.2638 s/iter. ETA=0:00:08
[09/04 06:54:29 d2.evaluation.evaluator]: Inference done 132/144. Dataloading: 0.0028 s/iter. Inference: 0.2116 s/iter. Eval: 0.0444 s/iter. Total: 0.2589 s/iter. ETA=0:00:03
[09/04 06:54:32 d2.evaluation.evaluator]: Total inference time: 0:00:35.909729 (0.258343 s / iter per device, on 1 devices)
[09/04 06:54:32 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:29 (0.211323 s / iter per device, on 1 devices)
[09/04 06:54:32 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:54:32 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:54:32 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 06:54:32 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:54:32 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 06:54:32 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:54:32 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.525
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.754
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.591
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.149
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.479
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.707
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.372
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.611
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.638
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.587
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.814
[09/04 06:54:32 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.456 | 75.397 | 59.070 | 14.925 | 47.932 | 70.679 |
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/04 06:54:32 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:54:32 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 06:54:32 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:54:32 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.532
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.765
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.595
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.465
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.716
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.371
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.612
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.642
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.208
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.601
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.792
[09/04 06:54:32 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 53.179 | 76.466 | 59.502 | 11.951 | 46.462 | 71.571 |
[09/04 06:54:32 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:54:32 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:54:32 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:54:32 d2.evaluation.testing]: copypaste: 52.4560,75.3966,59.0697,14.9254,47.9320,70.6791
[09/04 06:54:32 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:54:32 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:54:32 d2.evaluation.testing]: copypaste: 53.1787,76.4656,59.5023,11.9508,46.4615,71.5706
[09/04 06:54:32 d2.utils.events]:  eta: 0:02:35  iter: 919  total_loss: 0.296  loss_cls: 0.03964  loss_box_reg: 0.09516  loss_mask: 0.1182  loss_rpn_cls: 0.0002694  loss_rpn_loc: 0.002171  time: 1.9473  data_time: 0.0078  lr: 0.00022977  max_mem: 11021M
[09/04 06:55:11 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:55:11 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:55:11 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:55:11 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:55:11 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:55:15 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0018 s/iter. Inference: 0.2105 s/iter. Eval: 0.0553 s/iter. Total: 0.2676 s/iter. ETA=0:00:35
[09/04 06:55:20 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0031 s/iter. Inference: 0.2112 s/iter. Eval: 0.0447 s/iter. Total: 0.2593 s/iter. ETA=0:00:29
[09/04 06:55:26 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0031 s/iter. Inference: 0.2128 s/iter. Eval: 0.0669 s/iter. Total: 0.2830 s/iter. ETA=0:00:26
[09/04 06:55:31 d2.evaluation.evaluator]: Inference done 66/144. Dataloading: 0.0029 s/iter. Inference: 0.2129 s/iter. Eval: 0.0716 s/iter. Total: 0.2875 s/iter. ETA=0:00:22
[09/04 06:55:36 d2.evaluation.evaluator]: Inference done 85/144. Dataloading: 0.0028 s/iter. Inference: 0.2127 s/iter. Eval: 0.0682 s/iter. Total: 0.2838 s/iter. ETA=0:00:16
[09/04 06:55:41 d2.evaluation.evaluator]: Inference done 107/144. Dataloading: 0.0028 s/iter. Inference: 0.2117 s/iter. Eval: 0.0590 s/iter. Total: 0.2736 s/iter. ETA=0:00:10
[09/04 06:55:46 d2.evaluation.evaluator]: Inference done 128/144. Dataloading: 0.0028 s/iter. Inference: 0.2113 s/iter. Eval: 0.0535 s/iter. Total: 0.2677 s/iter. ETA=0:00:04
[09/04 06:55:50 d2.evaluation.evaluator]: Total inference time: 0:00:37.126257 (0.267095 s / iter per device, on 1 devices)
[09/04 06:55:50 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:29 (0.211132 s / iter per device, on 1 devices)
[09/04 06:55:50 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:55:50 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:55:50 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 06:55:50 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:55:50 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 06:55:50 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:55:50 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.500
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.748
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.582
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.154
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.456
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.663
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.354
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.587
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.562
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.774
[09/04 06:55:50 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.994 | 74.825 | 58.207 | 15.396 | 45.639 | 66.321 |
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/04 06:55:51 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:55:51 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 06:55:51 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:55:51 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.549
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.780
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.622
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.151
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.491
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.714
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.374
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.624
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.661
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.267
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.626
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.794
[09/04 06:55:51 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 54.852 | 78.016 | 62.240 | 15.065 | 49.092 | 71.416 |
[09/04 06:55:51 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:55:51 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:55:51 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:55:51 d2.evaluation.testing]: copypaste: 49.9942,74.8249,58.2068,15.3960,45.6389,66.3208
[09/04 06:55:51 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:55:51 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:55:51 d2.evaluation.testing]: copypaste: 54.8525,78.0160,62.2396,15.0645,49.0919,71.4161
[09/04 06:55:51 d2.utils.events]:  eta: 0:01:56  iter: 939  total_loss: 0.473  loss_cls: 0.06113  loss_box_reg: 0.1944  loss_mask: 0.1546  loss_rpn_cls: 0.002072  loss_rpn_loc: 0.005602  time: 1.9474  data_time: 0.0078  lr: 0.00023477  max_mem: 11021M
[09/04 06:56:30 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:56:30 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:56:30 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:56:30 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:56:30 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:56:33 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0019 s/iter. Inference: 0.2106 s/iter. Eval: 0.0548 s/iter. Total: 0.2673 s/iter. ETA=0:00:35
[09/04 06:56:38 d2.evaluation.evaluator]: Inference done 32/144. Dataloading: 0.0027 s/iter. Inference: 0.2099 s/iter. Eval: 0.0364 s/iter. Total: 0.2491 s/iter. ETA=0:00:27
[09/04 06:56:44 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0026 s/iter. Inference: 0.2118 s/iter. Eval: 0.0634 s/iter. Total: 0.2780 s/iter. ETA=0:00:26
[09/04 06:56:49 d2.evaluation.evaluator]: Inference done 66/144. Dataloading: 0.0026 s/iter. Inference: 0.2129 s/iter. Eval: 0.0721 s/iter. Total: 0.2878 s/iter. ETA=0:00:22
[09/04 06:56:54 d2.evaluation.evaluator]: Inference done 85/144. Dataloading: 0.0024 s/iter. Inference: 0.2125 s/iter. Eval: 0.0689 s/iter. Total: 0.2841 s/iter. ETA=0:00:16
[09/04 06:57:00 d2.evaluation.evaluator]: Inference done 106/144. Dataloading: 0.0025 s/iter. Inference: 0.2121 s/iter. Eval: 0.0617 s/iter. Total: 0.2766 s/iter. ETA=0:00:10
[09/04 06:57:05 d2.evaluation.evaluator]: Inference done 128/144. Dataloading: 0.0026 s/iter. Inference: 0.2117 s/iter. Eval: 0.0552 s/iter. Total: 0.2696 s/iter. ETA=0:00:04
[09/04 06:57:09 d2.evaluation.evaluator]: Total inference time: 0:00:37.401709 (0.269077 s / iter per device, on 1 devices)
[09/04 06:57:09 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:29 (0.211495 s / iter per device, on 1 devices)
[09/04 06:57:09 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:57:09 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:57:09 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 06:57:09 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:57:09 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 06:57:09 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:57:09 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.534
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.768
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.621
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.176
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.482
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.709
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.375
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.624
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.650
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.208
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.598
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.821
[09/04 06:57:09 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 53.361 | 76.813 | 62.059 | 17.556 | 48.192 | 70.858 |
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/04 06:57:09 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:57:09 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 06:57:09 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:57:09 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.544
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.783
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.596
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.140
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.484
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.714
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.372
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.628
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.658
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.267
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.795
[09/04 06:57:09 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 54.368 | 78.337 | 59.616 | 14.041 | 48.351 | 71.450 |
[09/04 06:57:09 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:57:09 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:57:09 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:57:09 d2.evaluation.testing]: copypaste: 53.3611,76.8133,62.0591,17.5563,48.1919,70.8585
[09/04 06:57:09 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:57:09 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:57:09 d2.evaluation.testing]: copypaste: 54.3681,78.3375,59.6157,14.0405,48.3509,71.4499
[09/04 06:57:09 d2.utils.events]:  eta: 0:01:17  iter: 959  total_loss: 0.28  loss_cls: 0.04242  loss_box_reg: 0.1069  loss_mask: 0.1327  loss_rpn_cls: 0.001156  loss_rpn_loc: 0.002558  time: 1.9474  data_time: 0.0083  lr: 0.00023976  max_mem: 11021M
[09/04 06:57:48 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:57:48 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:57:48 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:57:48 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:57:48 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:57:52 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0022 s/iter. Inference: 0.2096 s/iter. Eval: 0.0395 s/iter. Total: 0.2518 s/iter. ETA=0:00:33
[09/04 06:57:57 d2.evaluation.evaluator]: Inference done 33/144. Dataloading: 0.0025 s/iter. Inference: 0.2099 s/iter. Eval: 0.0261 s/iter. Total: 0.2388 s/iter. ETA=0:00:26
[09/04 06:58:02 d2.evaluation.evaluator]: Inference done 50/144. Dataloading: 0.0025 s/iter. Inference: 0.2113 s/iter. Eval: 0.0481 s/iter. Total: 0.2621 s/iter. ETA=0:00:24
[09/04 06:58:08 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0030 s/iter. Inference: 0.2126 s/iter. Eval: 0.0649 s/iter. Total: 0.2807 s/iter. ETA=0:00:21
[09/04 06:58:13 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0030 s/iter. Inference: 0.2116 s/iter. Eval: 0.0546 s/iter. Total: 0.2693 s/iter. ETA=0:00:14
[09/04 06:58:18 d2.evaluation.evaluator]: Inference done 110/144. Dataloading: 0.0031 s/iter. Inference: 0.2115 s/iter. Eval: 0.0486 s/iter. Total: 0.2633 s/iter. ETA=0:00:08
[09/04 06:58:23 d2.evaluation.evaluator]: Inference done 132/144. Dataloading: 0.0030 s/iter. Inference: 0.2110 s/iter. Eval: 0.0435 s/iter. Total: 0.2576 s/iter. ETA=0:00:03
[09/04 06:58:26 d2.evaluation.evaluator]: Total inference time: 0:00:35.734840 (0.257085 s / iter per device, on 1 devices)
[09/04 06:58:26 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:29 (0.210801 s / iter per device, on 1 devices)
[09/04 06:58:26 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:58:26 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:58:26 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 06:58:26 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:58:26 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.02 seconds.
[09/04 06:58:26 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:58:26 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.516
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.753
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.573
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.155
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.461
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.694
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.363
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.593
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.183
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.556
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.808
[09/04 06:58:26 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.575 | 75.286 | 57.266 | 15.456 | 46.102 | 69.412 |
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/04 06:58:26 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:58:26 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 06:58:26 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:58:26 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.536
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.772
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.583
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.097
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.479
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.712
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.368
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.608
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.639
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.595
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.792
[09/04 06:58:26 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 53.618 | 77.151 | 58.337 | 9.655 | 47.855 | 71.163 |
[09/04 06:58:26 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:58:26 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:58:26 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:58:26 d2.evaluation.testing]: copypaste: 51.5752,75.2863,57.2665,15.4562,46.1022,69.4123
[09/04 06:58:26 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:58:26 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:58:26 d2.evaluation.testing]: copypaste: 53.6181,77.1511,58.3368,9.6550,47.8552,71.1633
[09/04 06:58:26 d2.utils.events]:  eta: 0:00:38  iter: 979  total_loss: 0.29  loss_cls: 0.0481  loss_box_reg: 0.1128  loss_mask: 0.1357  loss_rpn_cls: 0.0005268  loss_rpn_loc: 0.002663  time: 1.9474  data_time: 0.0072  lr: 0.00024476  max_mem: 11021M
[09/04 06:59:06 d2.utils.events]:  eta: 0:00:00  iter: 999  total_loss: 0.4676  loss_cls: 0.08598  loss_box_reg: 0.1732  loss_mask: 0.1618  loss_rpn_cls: 0.001925  loss_rpn_loc: 0.007645  time: 1.9475  data_time: 0.0083  lr: 0.00024975  max_mem: 11021M
[09/04 06:59:06 d2.engine.hooks]: Overall training speed: 998 iterations in 0:32:23 (1.9475 s / it)
[09/04 06:59:06 d2.engine.hooks]: Total training time: 1:30:31 (0:58:07 on hooks)
[09/04 06:59:06 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 06:59:06 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 06:59:06 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 06:59:06 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 06:59:06 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 06:59:10 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0028 s/iter. Inference: 0.2118 s/iter. Eval: 0.0552 s/iter. Total: 0.2697 s/iter. ETA=0:00:35
[09/04 06:59:15 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0030 s/iter. Inference: 0.2128 s/iter. Eval: 0.0444 s/iter. Total: 0.2604 s/iter. ETA=0:00:29
[09/04 06:59:20 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0027 s/iter. Inference: 0.2134 s/iter. Eval: 0.0646 s/iter. Total: 0.2808 s/iter. ETA=0:00:26
[09/04 06:59:25 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0028 s/iter. Inference: 0.2142 s/iter. Eval: 0.0735 s/iter. Total: 0.2907 s/iter. ETA=0:00:22
[09/04 06:59:31 d2.evaluation.evaluator]: Inference done 84/144. Dataloading: 0.0026 s/iter. Inference: 0.2136 s/iter. Eval: 0.0700 s/iter. Total: 0.2863 s/iter. ETA=0:00:17
[09/04 06:59:36 d2.evaluation.evaluator]: Inference done 105/144. Dataloading: 0.0026 s/iter. Inference: 0.2127 s/iter. Eval: 0.0619 s/iter. Total: 0.2774 s/iter. ETA=0:00:10
[09/04 06:59:41 d2.evaluation.evaluator]: Inference done 126/144. Dataloading: 0.0027 s/iter. Inference: 0.2124 s/iter. Eval: 0.0554 s/iter. Total: 0.2706 s/iter. ETA=0:00:04
[09/04 06:59:46 d2.evaluation.evaluator]: Total inference time: 0:00:37.723465 (0.271392 s / iter per device, on 1 devices)
[09/04 06:59:46 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:29 (0.212618 s / iter per device, on 1 devices)
[09/04 06:59:46 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 06:59:46 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 06:59:46 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 06:59:46 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 06:59:46 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 06:59:46 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:59:46 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.526
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.762
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.600
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.173
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.462
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.710
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.377
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.621
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.650
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.250
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.591
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.824
[09/04 06:59:46 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.604 | 76.171 | 59.994 | 17.272 | 46.239 | 71.036 |
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/04 06:59:46 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 06:59:46 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 06:59:46 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 06:59:46 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.548
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.778
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.614
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.109
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.488
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.725
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.379
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.631
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.670
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.632
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.805
[09/04 06:59:46 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 54.788 | 77.755 | 61.384 | 10.923 | 48.790 | 72.458 |
[09/04 06:59:46 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 06:59:46 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 06:59:46 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:59:46 d2.evaluation.testing]: copypaste: 52.6037,76.1711,59.9940,17.2722,46.2393,71.0356
[09/04 06:59:46 d2.evaluation.testing]: copypaste: Task: segm
[09/04 06:59:46 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 06:59:46 d2.evaluation.testing]: copypaste: 54.7881,77.7553,61.3835,10.9235,48.7901,72.4582