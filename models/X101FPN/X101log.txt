[08/26 13:21:01 d2.engine.defaults]: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2): Conv2d(
            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2): Conv2d(
            2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2): Conv2d(
            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2): Conv2d(
            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[08/26 13:21:01 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [RandomBrightness(intensity_min=0.9, intensity_max=1.1), RandomContrast(intensity_min=0.9, intensity_max=1.1), RandomFlip(prob=0.5), Resize(shape=(720, 1280))]
[08/26 13:21:01 d2.data.datasets.coco]: Loaded 574 images in COCO format from ../input/petbottles/plastic data/annotations/instances_train.json
[08/26 13:21:01 d2.data.build]: Distribution of instances among all 1 categories:
|  category   | #instances   |
|:-----------:|:-------------|
| PET Bottles | 1145         |
|             |              |
[08/26 13:21:01 d2.data.build]: Using training sampler TrainingSampler
[08/26 13:21:01 d2.data.common]: Serializing 574 elements to byte tensors and concatenating them all ...
[08/26 13:21:01 d2.data.common]: Serialized dataset takes 0.45 MiB
model_final_2d9806.pkl: 431MB [00:38, 11.3MB/s]                               
[08/26 13:21:46 d2.engine.train_loop]: Starting training from iteration 0
[08/26 13:22:24 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 13:22:24 d2.data.build]: Distribution of instances among all 1 categories:
|  category   | #instances   |
|:-----------:|:-------------|
| PET Bottles | 193          |
|             |              |
[08/26 13:22:24 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 13:22:24 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 13:22:24 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 13:22:24 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 13:22:35 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0021 s/iter. Inference: 0.2665 s/iter. Eval: 0.6720 s/iter. Total: 0.9406 s/iter. ETA=0:02:05
[08/26 13:22:41 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0025 s/iter. Inference: 0.2670 s/iter. Eval: 0.6875 s/iter. Total: 0.9573 s/iter. ETA=0:02:01
[08/26 13:22:47 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0025 s/iter. Inference: 0.2669 s/iter. Eval: 0.6779 s/iter. Total: 0.9475 s/iter. ETA=0:01:54
[08/26 13:22:52 d2.evaluation.evaluator]: Inference done 28/144. Dataloading: 0.0025 s/iter. Inference: 0.2675 s/iter. Eval: 0.7033 s/iter. Total: 0.9736 s/iter. ETA=0:01:52
[08/26 13:22:57 d2.evaluation.evaluator]: Inference done 34/144. Dataloading: 0.0025 s/iter. Inference: 0.2676 s/iter. Eval: 0.6896 s/iter. Total: 0.9600 s/iter. ETA=0:01:45
[08/26 13:23:03 d2.evaluation.evaluator]: Inference done 40/144. Dataloading: 0.0025 s/iter. Inference: 0.2675 s/iter. Eval: 0.6876 s/iter. Total: 0.9580 s/iter. ETA=0:01:39
[08/26 13:23:08 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0024 s/iter. Inference: 0.2675 s/iter. Eval: 0.6802 s/iter. Total: 0.9505 s/iter. ETA=0:01:33
[08/26 13:23:14 d2.evaluation.evaluator]: Inference done 52/144. Dataloading: 0.0025 s/iter. Inference: 0.2672 s/iter. Eval: 0.6797 s/iter. Total: 0.9498 s/iter. ETA=0:01:27
[08/26 13:23:20 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0025 s/iter. Inference: 0.2672 s/iter. Eval: 0.6779 s/iter. Total: 0.9479 s/iter. ETA=0:01:21
[08/26 13:23:25 d2.evaluation.evaluator]: Inference done 63/144. Dataloading: 0.0025 s/iter. Inference: 0.2673 s/iter. Eval: 0.6857 s/iter. Total: 0.9559 s/iter. ETA=0:01:17
[08/26 13:23:30 d2.evaluation.evaluator]: Inference done 69/144. Dataloading: 0.0025 s/iter. Inference: 0.2673 s/iter. Eval: 0.6808 s/iter. Total: 0.9509 s/iter. ETA=0:01:11
[08/26 13:23:36 d2.evaluation.evaluator]: Inference done 75/144. Dataloading: 0.0025 s/iter. Inference: 0.2674 s/iter. Eval: 0.6801 s/iter. Total: 0.9503 s/iter. ETA=0:01:05
[08/26 13:23:41 d2.evaluation.evaluator]: Inference done 81/144. Dataloading: 0.0025 s/iter. Inference: 0.2674 s/iter. Eval: 0.6771 s/iter. Total: 0.9473 s/iter. ETA=0:00:59
[08/26 13:23:47 d2.evaluation.evaluator]: Inference done 87/144. Dataloading: 0.0025 s/iter. Inference: 0.2676 s/iter. Eval: 0.6773 s/iter. Total: 0.9478 s/iter. ETA=0:00:54
[08/26 13:23:53 d2.evaluation.evaluator]: Inference done 93/144. Dataloading: 0.0025 s/iter. Inference: 0.2676 s/iter. Eval: 0.6746 s/iter. Total: 0.9450 s/iter. ETA=0:00:48
[08/26 13:23:58 d2.evaluation.evaluator]: Inference done 98/144. Dataloading: 0.0025 s/iter. Inference: 0.2679 s/iter. Eval: 0.6793 s/iter. Total: 0.9501 s/iter. ETA=0:00:43
[08/26 13:24:03 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0025 s/iter. Inference: 0.2679 s/iter. Eval: 0.6766 s/iter. Total: 0.9473 s/iter. ETA=0:00:37
[08/26 13:24:09 d2.evaluation.evaluator]: Inference done 110/144. Dataloading: 0.0025 s/iter. Inference: 0.2679 s/iter. Eval: 0.6767 s/iter. Total: 0.9474 s/iter. ETA=0:00:32
[08/26 13:24:14 d2.evaluation.evaluator]: Inference done 116/144. Dataloading: 0.0025 s/iter. Inference: 0.2679 s/iter. Eval: 0.6745 s/iter. Total: 0.9452 s/iter. ETA=0:00:26
[08/26 13:24:20 d2.evaluation.evaluator]: Inference done 122/144. Dataloading: 0.0025 s/iter. Inference: 0.2679 s/iter. Eval: 0.6748 s/iter. Total: 0.9454 s/iter. ETA=0:00:20
[08/26 13:24:26 d2.evaluation.evaluator]: Inference done 128/144. Dataloading: 0.0025 s/iter. Inference: 0.2678 s/iter. Eval: 0.6737 s/iter. Total: 0.9443 s/iter. ETA=0:00:15
[08/26 13:24:31 d2.evaluation.evaluator]: Inference done 133/144. Dataloading: 0.0025 s/iter. Inference: 0.2681 s/iter. Eval: 0.6777 s/iter. Total: 0.9486 s/iter. ETA=0:00:10
[08/26 13:24:36 d2.evaluation.evaluator]: Inference done 139/144. Dataloading: 0.0025 s/iter. Inference: 0.2682 s/iter. Eval: 0.6764 s/iter. Total: 0.9474 s/iter. ETA=0:00:04
[08/26 13:24:41 d2.evaluation.evaluator]: Total inference time: 0:02:11.852972 (0.948583 s / iter per device, on 1 devices)
[08/26 13:24:41 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:37 (0.268098 s / iter per device, on 1 devices)
[08/26 13:24:42 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 13:24:42 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 13:24:42 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[08/26 13:24:42 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 13:24:42 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.13 seconds.
[08/26 13:24:42 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 13:24:42 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.03 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.006
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.006
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.007
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.028
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.258
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.042
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.275
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.267
[08/26 13:24:42 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.191 | 0.584  | 0.040  | 0.557 | 0.346 | 0.154 |
Loading and preparing results...
DONE (t=0.46s)
creating index...
index created!
[08/26 13:24:43 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 13:24:44 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.37 seconds.
[08/26 13:24:44 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 13:24:44 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.03 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.010
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.006
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.006
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.006
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.053
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.410
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.083
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.409
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.471
[08/26 13:24:44 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.402 | 1.039  | 0.242  | 0.114 | 0.558 | 0.644 |
[08/26 13:24:44 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 13:24:44 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 13:24:44 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 13:24:44 d2.evaluation.testing]: copypaste: 0.1914,0.5840,0.0404,0.5569,0.3459,0.1542
[08/26 13:24:44 d2.evaluation.testing]: copypaste: Task: segm
[08/26 13:24:44 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 13:24:44 d2.evaluation.testing]: copypaste: 0.4023,1.0390,0.2424,0.1142,0.5580,0.6440
[08/26 13:24:44 d2.utils.events]:  eta: 0:30:35  iter: 19  total_loss: 1.838  loss_cls: 0.6953  loss_box_reg: 0.3659  loss_mask: 0.6946  loss_rpn_cls: 0.04403  loss_rpn_loc: 0.008618  time: 1.8727  data_time: 0.0515  lr: 4.9953e-06  max_mem: 10070M
[08/26 13:25:22 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 13:25:22 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 13:25:22 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 13:25:22 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 13:25:22 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 13:25:32 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0026 s/iter. Inference: 0.2654 s/iter. Eval: 0.6295 s/iter. Total: 0.8975 s/iter. ETA=0:01:59
[08/26 13:25:38 d2.evaluation.evaluator]: Inference done 16/144. Dataloading: 0.0035 s/iter. Inference: 0.2723 s/iter. Eval: 0.6876 s/iter. Total: 0.9637 s/iter. ETA=0:02:03
[08/26 13:25:43 d2.evaluation.evaluator]: Inference done 22/144. Dataloading: 0.0034 s/iter. Inference: 0.2700 s/iter. Eval: 0.6680 s/iter. Total: 0.9416 s/iter. ETA=0:01:54
[08/26 13:25:49 d2.evaluation.evaluator]: Inference done 28/144. Dataloading: 0.0031 s/iter. Inference: 0.2692 s/iter. Eval: 0.6773 s/iter. Total: 0.9499 s/iter. ETA=0:01:50
[08/26 13:25:54 d2.evaluation.evaluator]: Inference done 34/144. Dataloading: 0.0030 s/iter. Inference: 0.2684 s/iter. Eval: 0.6682 s/iter. Total: 0.9400 s/iter. ETA=0:01:43
[08/26 13:26:00 d2.evaluation.evaluator]: Inference done 40/144. Dataloading: 0.0029 s/iter. Inference: 0.2679 s/iter. Eval: 0.6688 s/iter. Total: 0.9400 s/iter. ETA=0:01:37
[08/26 13:26:05 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0030 s/iter. Inference: 0.2675 s/iter. Eval: 0.6640 s/iter. Total: 0.9348 s/iter. ETA=0:01:31
[08/26 13:26:10 d2.evaluation.evaluator]: Inference done 51/144. Dataloading: 0.0031 s/iter. Inference: 0.2685 s/iter. Eval: 0.6727 s/iter. Total: 0.9446 s/iter. ETA=0:01:27
[08/26 13:26:16 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0030 s/iter. Inference: 0.2681 s/iter. Eval: 0.6683 s/iter. Total: 0.9398 s/iter. ETA=0:01:21
[08/26 13:26:21 d2.evaluation.evaluator]: Inference done 63/144. Dataloading: 0.0030 s/iter. Inference: 0.2682 s/iter. Eval: 0.6680 s/iter. Total: 0.9395 s/iter. ETA=0:01:16
[08/26 13:26:27 d2.evaluation.evaluator]: Inference done 69/144. Dataloading: 0.0029 s/iter. Inference: 0.2679 s/iter. Eval: 0.6646 s/iter. Total: 0.9357 s/iter. ETA=0:01:10
[08/26 13:26:32 d2.evaluation.evaluator]: Inference done 75/144. Dataloading: 0.0029 s/iter. Inference: 0.2680 s/iter. Eval: 0.6637 s/iter. Total: 0.9350 s/iter. ETA=0:01:04
[08/26 13:26:38 d2.evaluation.evaluator]: Inference done 81/144. Dataloading: 0.0029 s/iter. Inference: 0.2678 s/iter. Eval: 0.6615 s/iter. Total: 0.9326 s/iter. ETA=0:00:58
[08/26 13:26:43 d2.evaluation.evaluator]: Inference done 86/144. Dataloading: 0.0029 s/iter. Inference: 0.2677 s/iter. Eval: 0.6691 s/iter. Total: 0.9402 s/iter. ETA=0:00:54
[08/26 13:26:49 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0029 s/iter. Inference: 0.2677 s/iter. Eval: 0.6670 s/iter. Total: 0.9379 s/iter. ETA=0:00:48
[08/26 13:26:54 d2.evaluation.evaluator]: Inference done 98/144. Dataloading: 0.0030 s/iter. Inference: 0.2677 s/iter. Eval: 0.6673 s/iter. Total: 0.9383 s/iter. ETA=0:00:43
[08/26 13:27:00 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0030 s/iter. Inference: 0.2675 s/iter. Eval: 0.6654 s/iter. Total: 0.9362 s/iter. ETA=0:00:37
[08/26 13:27:05 d2.evaluation.evaluator]: Inference done 110/144. Dataloading: 0.0030 s/iter. Inference: 0.2675 s/iter. Eval: 0.6655 s/iter. Total: 0.9363 s/iter. ETA=0:00:31
[08/26 13:27:11 d2.evaluation.evaluator]: Inference done 116/144. Dataloading: 0.0030 s/iter. Inference: 0.2674 s/iter. Eval: 0.6638 s/iter. Total: 0.9345 s/iter. ETA=0:00:26
[08/26 13:27:16 d2.evaluation.evaluator]: Inference done 121/144. Dataloading: 0.0030 s/iter. Inference: 0.2676 s/iter. Eval: 0.6681 s/iter. Total: 0.9391 s/iter. ETA=0:00:21
[08/26 13:27:21 d2.evaluation.evaluator]: Inference done 127/144. Dataloading: 0.0030 s/iter. Inference: 0.2675 s/iter. Eval: 0.6665 s/iter. Total: 0.9373 s/iter. ETA=0:00:15
[08/26 13:27:27 d2.evaluation.evaluator]: Inference done 133/144. Dataloading: 0.0030 s/iter. Inference: 0.2674 s/iter. Eval: 0.6670 s/iter. Total: 0.9378 s/iter. ETA=0:00:10
[08/26 13:27:32 d2.evaluation.evaluator]: Inference done 139/144. Dataloading: 0.0030 s/iter. Inference: 0.2673 s/iter. Eval: 0.6654 s/iter. Total: 0.9361 s/iter. ETA=0:00:04
[08/26 13:27:37 d2.evaluation.evaluator]: Total inference time: 0:02:10.191663 (0.936631 s / iter per device, on 1 devices)
[08/26 13:27:37 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:37 (0.267217 s / iter per device, on 1 devices)
[08/26 13:27:37 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 13:27:37 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 13:27:38 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[08/26 13:27:38 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 13:27:38 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.12 seconds.
[08/26 13:27:38 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 13:27:38 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.018
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.007
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.007
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.006
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.073
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.391
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.133
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.394
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.432
[08/26 13:27:38 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.607 | 1.790  | 0.161  | 0.662 | 0.860 | 0.684 |
Loading and preparing results...
DONE (t=0.39s)
creating index...
index created!
[08/26 13:27:39 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 13:27:39 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.53 seconds.
[08/26 13:27:39 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 13:27:39 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.012
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.026
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.010
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.014
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.019
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.022
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.143
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.536
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.117
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.507
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.664
[08/26 13:27:39 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 1.183 | 2.605  | 1.050  | 0.229 | 1.395 | 1.946 |
[08/26 13:27:39 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 13:27:39 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 13:27:39 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 13:27:39 d2.evaluation.testing]: copypaste: 0.6073,1.7903,0.1613,0.6623,0.8596,0.6838
[08/26 13:27:39 d2.evaluation.testing]: copypaste: Task: segm
[08/26 13:27:39 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 13:27:39 d2.evaluation.testing]: copypaste: 1.1829,2.6048,1.0497,0.2295,1.3948,1.9458
[08/26 13:27:39 d2.utils.events]:  eta: 0:30:01  iter: 39  total_loss: 1.749  loss_cls: 0.6299  loss_box_reg: 0.3666  loss_mask: 0.6781  loss_rpn_cls: 0.01942  loss_rpn_loc: 0.004741  time: 1.8851  data_time: 0.0144  lr: 9.9902e-06  max_mem: 10070M
[08/26 13:28:17 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 13:28:17 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 13:28:17 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 13:28:17 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 13:28:17 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 13:28:29 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0019 s/iter. Inference: 0.2655 s/iter. Eval: 0.6429 s/iter. Total: 0.9103 s/iter. ETA=0:02:01
[08/26 13:28:34 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0026 s/iter. Inference: 0.2666 s/iter. Eval: 0.6528 s/iter. Total: 0.9223 s/iter. ETA=0:01:57
[08/26 13:28:40 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0025 s/iter. Inference: 0.2661 s/iter. Eval: 0.6446 s/iter. Total: 0.9135 s/iter. ETA=0:01:50
[08/26 13:28:45 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0026 s/iter. Inference: 0.2668 s/iter. Eval: 0.6481 s/iter. Total: 0.9179 s/iter. ETA=0:01:45
[08/26 13:28:51 d2.evaluation.evaluator]: Inference done 35/144. Dataloading: 0.0026 s/iter. Inference: 0.2667 s/iter. Eval: 0.6482 s/iter. Total: 0.9178 s/iter. ETA=0:01:40
[08/26 13:28:56 d2.evaluation.evaluator]: Inference done 40/144. Dataloading: 0.0029 s/iter. Inference: 0.2669 s/iter. Eval: 0.6630 s/iter. Total: 0.9331 s/iter. ETA=0:01:37
[08/26 13:29:01 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0029 s/iter. Inference: 0.2667 s/iter. Eval: 0.6582 s/iter. Total: 0.9282 s/iter. ETA=0:01:30
[08/26 13:29:07 d2.evaluation.evaluator]: Inference done 52/144. Dataloading: 0.0028 s/iter. Inference: 0.2667 s/iter. Eval: 0.6602 s/iter. Total: 0.9301 s/iter. ETA=0:01:25
[08/26 13:29:12 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0028 s/iter. Inference: 0.2666 s/iter. Eval: 0.6573 s/iter. Total: 0.9270 s/iter. ETA=0:01:19
[08/26 13:29:18 d2.evaluation.evaluator]: Inference done 64/144. Dataloading: 0.0028 s/iter. Inference: 0.2665 s/iter. Eval: 0.6604 s/iter. Total: 0.9300 s/iter. ETA=0:01:14
[08/26 13:29:23 d2.evaluation.evaluator]: Inference done 70/144. Dataloading: 0.0028 s/iter. Inference: 0.2665 s/iter. Eval: 0.6576 s/iter. Total: 0.9272 s/iter. ETA=0:01:08
[08/26 13:29:29 d2.evaluation.evaluator]: Inference done 75/144. Dataloading: 0.0028 s/iter. Inference: 0.2676 s/iter. Eval: 0.6642 s/iter. Total: 0.9349 s/iter. ETA=0:01:04
[08/26 13:29:34 d2.evaluation.evaluator]: Inference done 81/144. Dataloading: 0.0028 s/iter. Inference: 0.2674 s/iter. Eval: 0.6616 s/iter. Total: 0.9321 s/iter. ETA=0:00:58
[08/26 13:29:40 d2.evaluation.evaluator]: Inference done 87/144. Dataloading: 0.0029 s/iter. Inference: 0.2674 s/iter. Eval: 0.6621 s/iter. Total: 0.9328 s/iter. ETA=0:00:53
[08/26 13:29:45 d2.evaluation.evaluator]: Inference done 93/144. Dataloading: 0.0029 s/iter. Inference: 0.2673 s/iter. Eval: 0.6601 s/iter. Total: 0.9307 s/iter. ETA=0:00:47
[08/26 13:29:51 d2.evaluation.evaluator]: Inference done 99/144. Dataloading: 0.0029 s/iter. Inference: 0.2673 s/iter. Eval: 0.6606 s/iter. Total: 0.9311 s/iter. ETA=0:00:41
[08/26 13:29:56 d2.evaluation.evaluator]: Inference done 105/144. Dataloading: 0.0029 s/iter. Inference: 0.2673 s/iter. Eval: 0.6588 s/iter. Total: 0.9293 s/iter. ETA=0:00:36
[08/26 13:30:01 d2.evaluation.evaluator]: Inference done 110/144. Dataloading: 0.0029 s/iter. Inference: 0.2675 s/iter. Eval: 0.6644 s/iter. Total: 0.9351 s/iter. ETA=0:00:31
[08/26 13:30:07 d2.evaluation.evaluator]: Inference done 116/144. Dataloading: 0.0029 s/iter. Inference: 0.2673 s/iter. Eval: 0.6627 s/iter. Total: 0.9333 s/iter. ETA=0:00:26
[08/26 13:30:12 d2.evaluation.evaluator]: Inference done 122/144. Dataloading: 0.0029 s/iter. Inference: 0.2675 s/iter. Eval: 0.6625 s/iter. Total: 0.9332 s/iter. ETA=0:00:20
[08/26 13:30:18 d2.evaluation.evaluator]: Inference done 128/144. Dataloading: 0.0029 s/iter. Inference: 0.2674 s/iter. Eval: 0.6611 s/iter. Total: 0.9317 s/iter. ETA=0:00:14
[08/26 13:30:23 d2.evaluation.evaluator]: Inference done 134/144. Dataloading: 0.0029 s/iter. Inference: 0.2675 s/iter. Eval: 0.6617 s/iter. Total: 0.9325 s/iter. ETA=0:00:09
[08/26 13:30:29 d2.evaluation.evaluator]: Inference done 140/144. Dataloading: 0.0029 s/iter. Inference: 0.2675 s/iter. Eval: 0.6608 s/iter. Total: 0.9315 s/iter. ETA=0:00:03
[08/26 13:30:33 d2.evaluation.evaluator]: Total inference time: 0:02:09.919224 (0.934671 s / iter per device, on 1 devices)
[08/26 13:30:33 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:37 (0.267518 s / iter per device, on 1 devices)
[08/26 13:30:33 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 13:30:33 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 13:30:33 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[08/26 13:30:34 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 13:30:34 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.13 seconds.
[08/26 13:30:34 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 13:30:34 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.021
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.048
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.011
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.027
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.024
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.031
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.271
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.451
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.117
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.451
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.511
[08/26 13:30:34 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 2.074 | 4.822  | 1.093  | 0.836 | 2.698 | 2.359 |
Loading and preparing results...
DONE (t=0.38s)
creating index...
index created!
[08/26 13:30:35 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 13:30:35 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.26 seconds.
[08/26 13:30:35 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 13:30:35 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.031
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.057
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.033
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.036
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.043
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.051
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.354
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.572
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.142
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.546
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.694
[08/26 13:30:35 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 3.091 | 5.700  | 3.312  | 0.365 | 3.605 | 4.350 |
[08/26 13:30:35 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 13:30:35 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 13:30:35 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 13:30:35 d2.evaluation.testing]: copypaste: 2.0745,4.8218,1.0931,0.8358,2.6976,2.3590
[08/26 13:30:35 d2.evaluation.testing]: copypaste: Task: segm
[08/26 13:30:35 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 13:30:35 d2.evaluation.testing]: copypaste: 3.0909,5.7000,3.3123,0.3653,3.6048,4.3498
[08/26 13:30:35 d2.utils.events]:  eta: 0:29:25  iter: 59  total_loss: 1.633  loss_cls: 0.4995  loss_box_reg: 0.4025  loss_mask: 0.6438  loss_rpn_cls: 0.02628  loss_rpn_loc: 0.008721  time: 1.8876  data_time: 0.0139  lr: 1.4985e-05  max_mem: 10070M
[08/26 13:31:13 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 13:31:13 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 13:31:13 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 13:31:13 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 13:31:13 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 13:31:23 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0020 s/iter. Inference: 0.2646 s/iter. Eval: 0.6322 s/iter. Total: 0.8988 s/iter. ETA=0:01:59
[08/26 13:31:29 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0022 s/iter. Inference: 0.2650 s/iter. Eval: 0.6544 s/iter. Total: 0.9218 s/iter. ETA=0:01:57
[08/26 13:31:34 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0023 s/iter. Inference: 0.2649 s/iter. Eval: 0.6458 s/iter. Total: 0.9132 s/iter. ETA=0:01:50
[08/26 13:31:39 d2.evaluation.evaluator]: Inference done 28/144. Dataloading: 0.0024 s/iter. Inference: 0.2671 s/iter. Eval: 0.6682 s/iter. Total: 0.9380 s/iter. ETA=0:01:48
[08/26 13:31:45 d2.evaluation.evaluator]: Inference done 34/144. Dataloading: 0.0024 s/iter. Inference: 0.2666 s/iter. Eval: 0.6620 s/iter. Total: 0.9314 s/iter. ETA=0:01:42
[08/26 13:31:50 d2.evaluation.evaluator]: Inference done 40/144. Dataloading: 0.0025 s/iter. Inference: 0.2672 s/iter. Eval: 0.6620 s/iter. Total: 0.9321 s/iter. ETA=0:01:36
[08/26 13:31:56 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0025 s/iter. Inference: 0.2669 s/iter. Eval: 0.6578 s/iter. Total: 0.9275 s/iter. ETA=0:01:30
[08/26 13:32:01 d2.evaluation.evaluator]: Inference done 51/144. Dataloading: 0.0026 s/iter. Inference: 0.2667 s/iter. Eval: 0.6659 s/iter. Total: 0.9355 s/iter. ETA=0:01:27
[08/26 13:32:06 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0026 s/iter. Inference: 0.2665 s/iter. Eval: 0.6619 s/iter. Total: 0.9313 s/iter. ETA=0:01:21
[08/26 13:32:11 d2.evaluation.evaluator]: Inference done 62/144. Dataloading: 0.0026 s/iter. Inference: 0.2666 s/iter. Eval: 0.6690 s/iter. Total: 0.9385 s/iter. ETA=0:01:16
[08/26 13:32:17 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0026 s/iter. Inference: 0.2669 s/iter. Eval: 0.6669 s/iter. Total: 0.9368 s/iter. ETA=0:01:11
[08/26 13:32:22 d2.evaluation.evaluator]: Inference done 74/144. Dataloading: 0.0026 s/iter. Inference: 0.2668 s/iter. Eval: 0.6670 s/iter. Total: 0.9369 s/iter. ETA=0:01:05
[08/26 13:32:28 d2.evaluation.evaluator]: Inference done 80/144. Dataloading: 0.0026 s/iter. Inference: 0.2668 s/iter. Eval: 0.6648 s/iter. Total: 0.9345 s/iter. ETA=0:00:59
[08/26 13:32:33 d2.evaluation.evaluator]: Inference done 86/144. Dataloading: 0.0027 s/iter. Inference: 0.2670 s/iter. Eval: 0.6639 s/iter. Total: 0.9340 s/iter. ETA=0:00:54
[08/26 13:32:39 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0026 s/iter. Inference: 0.2669 s/iter. Eval: 0.6617 s/iter. Total: 0.9315 s/iter. ETA=0:00:48
[08/26 13:32:44 d2.evaluation.evaluator]: Inference done 97/144. Dataloading: 0.0026 s/iter. Inference: 0.2669 s/iter. Eval: 0.6664 s/iter. Total: 0.9363 s/iter. ETA=0:00:44
[08/26 13:32:49 d2.evaluation.evaluator]: Inference done 103/144. Dataloading: 0.0027 s/iter. Inference: 0.2671 s/iter. Eval: 0.6649 s/iter. Total: 0.9351 s/iter. ETA=0:00:38
[08/26 13:32:55 d2.evaluation.evaluator]: Inference done 109/144. Dataloading: 0.0027 s/iter. Inference: 0.2670 s/iter. Eval: 0.6654 s/iter. Total: 0.9354 s/iter. ETA=0:00:32
[08/26 13:33:00 d2.evaluation.evaluator]: Inference done 115/144. Dataloading: 0.0028 s/iter. Inference: 0.2668 s/iter. Eval: 0.6633 s/iter. Total: 0.9333 s/iter. ETA=0:00:27
[08/26 13:33:06 d2.evaluation.evaluator]: Inference done 121/144. Dataloading: 0.0028 s/iter. Inference: 0.2667 s/iter. Eval: 0.6635 s/iter. Total: 0.9334 s/iter. ETA=0:00:21
[08/26 13:33:11 d2.evaluation.evaluator]: Inference done 127/144. Dataloading: 0.0027 s/iter. Inference: 0.2666 s/iter. Eval: 0.6617 s/iter. Total: 0.9314 s/iter. ETA=0:00:15
[08/26 13:33:17 d2.evaluation.evaluator]: Inference done 132/144. Dataloading: 0.0027 s/iter. Inference: 0.2665 s/iter. Eval: 0.6654 s/iter. Total: 0.9350 s/iter. ETA=0:00:11
[08/26 13:33:22 d2.evaluation.evaluator]: Inference done 138/144. Dataloading: 0.0028 s/iter. Inference: 0.2666 s/iter. Eval: 0.6643 s/iter. Total: 0.9342 s/iter. ETA=0:00:05
[08/26 13:33:28 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0027 s/iter. Inference: 0.2666 s/iter. Eval: 0.6638 s/iter. Total: 0.9335 s/iter. ETA=0:00:00
[08/26 13:33:28 d2.evaluation.evaluator]: Total inference time: 0:02:09.831521 (0.934040 s / iter per device, on 1 devices)
[08/26 13:33:28 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:37 (0.266551 s / iter per device, on 1 devices)
[08/26 13:33:28 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 13:33:28 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 13:33:28 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[08/26 13:33:28 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 13:33:28 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.13 seconds.
[08/26 13:33:28 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 13:33:28 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.050
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.098
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.040
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.009
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.069
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.053
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.109
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.379
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.533
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.192
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.535
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.591
[08/26 13:33:28 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 4.985 | 9.778  | 4.030  | 0.871 | 6.868 | 5.337 |
Loading and preparing results...
DONE (t=0.38s)
creating index...
index created!
[08/26 13:33:29 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 13:33:29 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.26 seconds.
[08/26 13:33:29 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 13:33:29 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.063
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.102
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.070
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.006
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.071
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.084
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.133
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.432
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.609
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.579
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.732
[08/26 13:33:29 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 6.324 | 10.204 | 6.975  | 0.603 | 7.095 | 8.447 |
[08/26 13:33:29 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 13:33:29 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 13:33:29 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 13:33:29 d2.evaluation.testing]: copypaste: 4.9852,9.7783,4.0298,0.8708,6.8675,5.3366
[08/26 13:33:29 d2.evaluation.testing]: copypaste: Task: segm
[08/26 13:33:29 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 13:33:29 d2.evaluation.testing]: copypaste: 6.3245,10.2043,6.9747,0.6026,7.0949,8.4474
[08/26 13:33:29 d2.utils.events]:  eta: 0:28:46  iter: 79  total_loss: 1.359  loss_cls: 0.3923  loss_box_reg: 0.3263  loss_mask: 0.6053  loss_rpn_cls: 0.03561  loss_rpn_loc: 0.007021  time: 1.8841  data_time: 0.0125  lr: 1.998e-05  max_mem: 10070M
[08/26 13:34:07 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 13:34:07 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 13:34:07 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 13:34:07 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 13:34:07 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 13:34:18 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0017 s/iter. Inference: 0.2649 s/iter. Eval: 0.6512 s/iter. Total: 0.9178 s/iter. ETA=0:02:02
[08/26 13:34:23 d2.evaluation.evaluator]: Inference done 16/144. Dataloading: 0.0022 s/iter. Inference: 0.2712 s/iter. Eval: 0.7009 s/iter. Total: 0.9746 s/iter. ETA=0:02:04
[08/26 13:34:29 d2.evaluation.evaluator]: Inference done 22/144. Dataloading: 0.0023 s/iter. Inference: 0.2690 s/iter. Eval: 0.6765 s/iter. Total: 0.9482 s/iter. ETA=0:01:55
[08/26 13:34:34 d2.evaluation.evaluator]: Inference done 28/144. Dataloading: 0.0027 s/iter. Inference: 0.2698 s/iter. Eval: 0.6724 s/iter. Total: 0.9452 s/iter. ETA=0:01:49
[08/26 13:34:40 d2.evaluation.evaluator]: Inference done 34/144. Dataloading: 0.0027 s/iter. Inference: 0.2688 s/iter. Eval: 0.6643 s/iter. Total: 0.9361 s/iter. ETA=0:01:42
[08/26 13:34:45 d2.evaluation.evaluator]: Inference done 40/144. Dataloading: 0.0027 s/iter. Inference: 0.2683 s/iter. Eval: 0.6651 s/iter. Total: 0.9365 s/iter. ETA=0:01:37
[08/26 13:34:51 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0026 s/iter. Inference: 0.2678 s/iter. Eval: 0.6598 s/iter. Total: 0.9306 s/iter. ETA=0:01:31
[08/26 13:34:56 d2.evaluation.evaluator]: Inference done 51/144. Dataloading: 0.0028 s/iter. Inference: 0.2686 s/iter. Eval: 0.6726 s/iter. Total: 0.9443 s/iter. ETA=0:01:27
[08/26 13:35:01 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0027 s/iter. Inference: 0.2683 s/iter. Eval: 0.6678 s/iter. Total: 0.9392 s/iter. ETA=0:01:21
[08/26 13:35:07 d2.evaluation.evaluator]: Inference done 63/144. Dataloading: 0.0027 s/iter. Inference: 0.2679 s/iter. Eval: 0.6677 s/iter. Total: 0.9386 s/iter. ETA=0:01:16
[08/26 13:35:13 d2.evaluation.evaluator]: Inference done 69/144. Dataloading: 0.0027 s/iter. Inference: 0.2676 s/iter. Eval: 0.6688 s/iter. Total: 0.9395 s/iter. ETA=0:01:10
[08/26 13:35:18 d2.evaluation.evaluator]: Inference done 75/144. Dataloading: 0.0027 s/iter. Inference: 0.2675 s/iter. Eval: 0.6681 s/iter. Total: 0.9387 s/iter. ETA=0:01:04
[08/26 13:35:24 d2.evaluation.evaluator]: Inference done 81/144. Dataloading: 0.0027 s/iter. Inference: 0.2673 s/iter. Eval: 0.6651 s/iter. Total: 0.9354 s/iter. ETA=0:00:58
[08/26 13:35:29 d2.evaluation.evaluator]: Inference done 86/144. Dataloading: 0.0027 s/iter. Inference: 0.2673 s/iter. Eval: 0.6733 s/iter. Total: 0.9437 s/iter. ETA=0:00:54
[08/26 13:35:34 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0027 s/iter. Inference: 0.2671 s/iter. Eval: 0.6705 s/iter. Total: 0.9406 s/iter. ETA=0:00:48
[08/26 13:35:40 d2.evaluation.evaluator]: Inference done 98/144. Dataloading: 0.0027 s/iter. Inference: 0.2671 s/iter. Eval: 0.6712 s/iter. Total: 0.9413 s/iter. ETA=0:00:43
[08/26 13:35:46 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0027 s/iter. Inference: 0.2670 s/iter. Eval: 0.6700 s/iter. Total: 0.9402 s/iter. ETA=0:00:37
[08/26 13:35:51 d2.evaluation.evaluator]: Inference done 110/144. Dataloading: 0.0027 s/iter. Inference: 0.2671 s/iter. Eval: 0.6694 s/iter. Total: 0.9396 s/iter. ETA=0:00:31
[08/26 13:35:57 d2.evaluation.evaluator]: Inference done 116/144. Dataloading: 0.0027 s/iter. Inference: 0.2670 s/iter. Eval: 0.6673 s/iter. Total: 0.9373 s/iter. ETA=0:00:26
[08/26 13:36:02 d2.evaluation.evaluator]: Inference done 121/144. Dataloading: 0.0027 s/iter. Inference: 0.2671 s/iter. Eval: 0.6719 s/iter. Total: 0.9420 s/iter. ETA=0:00:21
[08/26 13:36:07 d2.evaluation.evaluator]: Inference done 127/144. Dataloading: 0.0028 s/iter. Inference: 0.2669 s/iter. Eval: 0.6699 s/iter. Total: 0.9400 s/iter. ETA=0:00:15
[08/26 13:36:13 d2.evaluation.evaluator]: Inference done 133/144. Dataloading: 0.0028 s/iter. Inference: 0.2668 s/iter. Eval: 0.6697 s/iter. Total: 0.9397 s/iter. ETA=0:00:10
[08/26 13:36:18 d2.evaluation.evaluator]: Inference done 139/144. Dataloading: 0.0028 s/iter. Inference: 0.2668 s/iter. Eval: 0.6682 s/iter. Total: 0.9381 s/iter. ETA=0:00:04
[08/26 13:36:23 d2.evaluation.evaluator]: Total inference time: 0:02:10.453500 (0.938514 s / iter per device, on 1 devices)
[08/26 13:36:23 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:37 (0.266650 s / iter per device, on 1 devices)
[08/26 13:36:23 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 13:36:23 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 13:36:23 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[08/26 13:36:24 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 13:36:24 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.12 seconds.
[08/26 13:36:24 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 13:36:24 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.092
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.167
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.085
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.015
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.130
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.098
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.164
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.416
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.552
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.233
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.552
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.609
[08/26 13:36:24 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |
|:-----:|:------:|:------:|:-----:|:------:|:-----:|
| 9.193 | 16.694 | 8.518  | 1.453 | 12.950 | 9.776 |
Loading and preparing results...
DONE (t=0.37s)
creating index...
index created!
[08/26 13:36:25 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 13:36:25 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.26 seconds.
[08/26 13:36:25 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 13:36:25 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.111
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.175
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.125
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.120
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.144
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.189
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.468
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.628
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.258
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.601
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.742
[08/26 13:36:25 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 11.093 | 17.472 | 12.504 | 0.984 | 11.981 | 14.424 |
[08/26 13:36:25 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 13:36:25 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 13:36:25 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 13:36:25 d2.evaluation.testing]: copypaste: 9.1933,16.6943,8.5178,1.4533,12.9501,9.7762
[08/26 13:36:25 d2.evaluation.testing]: copypaste: Task: segm
[08/26 13:36:25 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 13:36:25 d2.evaluation.testing]: copypaste: 11.0935,17.4717,12.5035,0.9841,11.9809,14.4244
[08/26 13:36:25 d2.utils.events]:  eta: 0:28:09  iter: 99  total_loss: 1.323  loss_cls: 0.3264  loss_box_reg: 0.4019  loss_mask: 0.5492  loss_rpn_cls: 0.02125  loss_rpn_loc: 0.01029  time: 1.8858  data_time: 0.0131  lr: 2.4975e-05  max_mem: 10070M
[08/26 13:37:03 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 13:37:03 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 13:37:03 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 13:37:03 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 13:37:03 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 13:37:14 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0023 s/iter. Inference: 0.2646 s/iter. Eval: 0.6320 s/iter. Total: 0.8989 s/iter. ETA=0:01:59
[08/26 13:37:20 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0027 s/iter. Inference: 0.2668 s/iter. Eval: 0.6436 s/iter. Total: 0.9134 s/iter. ETA=0:01:56
[08/26 13:37:25 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0026 s/iter. Inference: 0.2659 s/iter. Eval: 0.6390 s/iter. Total: 0.9078 s/iter. ETA=0:01:49
[08/26 13:37:31 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0026 s/iter. Inference: 0.2660 s/iter. Eval: 0.6435 s/iter. Total: 0.9123 s/iter. ETA=0:01:44
[08/26 13:37:36 d2.evaluation.evaluator]: Inference done 35/144. Dataloading: 0.0026 s/iter. Inference: 0.2658 s/iter. Eval: 0.6412 s/iter. Total: 0.9099 s/iter. ETA=0:01:39
[08/26 13:37:41 d2.evaluation.evaluator]: Inference done 40/144. Dataloading: 0.0026 s/iter. Inference: 0.2678 s/iter. Eval: 0.6595 s/iter. Total: 0.9303 s/iter. ETA=0:01:36
[08/26 13:37:47 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0026 s/iter. Inference: 0.2675 s/iter. Eval: 0.6561 s/iter. Total: 0.9265 s/iter. ETA=0:01:30
[08/26 13:37:52 d2.evaluation.evaluator]: Inference done 52/144. Dataloading: 0.0025 s/iter. Inference: 0.2671 s/iter. Eval: 0.6576 s/iter. Total: 0.9276 s/iter. ETA=0:01:25
[08/26 13:37:58 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0026 s/iter. Inference: 0.2668 s/iter. Eval: 0.6547 s/iter. Total: 0.9244 s/iter. ETA=0:01:19
[08/26 13:38:03 d2.evaluation.evaluator]: Inference done 64/144. Dataloading: 0.0025 s/iter. Inference: 0.2665 s/iter. Eval: 0.6555 s/iter. Total: 0.9249 s/iter. ETA=0:01:13
[08/26 13:38:09 d2.evaluation.evaluator]: Inference done 70/144. Dataloading: 0.0025 s/iter. Inference: 0.2663 s/iter. Eval: 0.6532 s/iter. Total: 0.9224 s/iter. ETA=0:01:08
[08/26 13:38:14 d2.evaluation.evaluator]: Inference done 76/144. Dataloading: 0.0026 s/iter. Inference: 0.2663 s/iter. Eval: 0.6544 s/iter. Total: 0.9236 s/iter. ETA=0:01:02
[08/26 13:38:20 d2.evaluation.evaluator]: Inference done 82/144. Dataloading: 0.0026 s/iter. Inference: 0.2665 s/iter. Eval: 0.6575 s/iter. Total: 0.9269 s/iter. ETA=0:00:57
[08/26 13:38:25 d2.evaluation.evaluator]: Inference done 87/144. Dataloading: 0.0026 s/iter. Inference: 0.2666 s/iter. Eval: 0.6628 s/iter. Total: 0.9324 s/iter. ETA=0:00:53
[08/26 13:38:31 d2.evaluation.evaluator]: Inference done 93/144. Dataloading: 0.0026 s/iter. Inference: 0.2665 s/iter. Eval: 0.6614 s/iter. Total: 0.9308 s/iter. ETA=0:00:47
[08/26 13:38:36 d2.evaluation.evaluator]: Inference done 99/144. Dataloading: 0.0026 s/iter. Inference: 0.2665 s/iter. Eval: 0.6617 s/iter. Total: 0.9311 s/iter. ETA=0:00:41
[08/26 13:38:42 d2.evaluation.evaluator]: Inference done 105/144. Dataloading: 0.0026 s/iter. Inference: 0.2664 s/iter. Eval: 0.6599 s/iter. Total: 0.9292 s/iter. ETA=0:00:36
[08/26 13:38:47 d2.evaluation.evaluator]: Inference done 111/144. Dataloading: 0.0026 s/iter. Inference: 0.2663 s/iter. Eval: 0.6603 s/iter. Total: 0.9296 s/iter. ETA=0:00:30
[08/26 13:38:53 d2.evaluation.evaluator]: Inference done 117/144. Dataloading: 0.0026 s/iter. Inference: 0.2665 s/iter. Eval: 0.6618 s/iter. Total: 0.9313 s/iter. ETA=0:00:25
[08/26 13:38:58 d2.evaluation.evaluator]: Inference done 123/144. Dataloading: 0.0026 s/iter. Inference: 0.2666 s/iter. Eval: 0.6614 s/iter. Total: 0.9310 s/iter. ETA=0:00:19
[08/26 13:39:04 d2.evaluation.evaluator]: Inference done 129/144. Dataloading: 0.0026 s/iter. Inference: 0.2665 s/iter. Eval: 0.6600 s/iter. Total: 0.9294 s/iter. ETA=0:00:13
[08/26 13:39:09 d2.evaluation.evaluator]: Inference done 135/144. Dataloading: 0.0026 s/iter. Inference: 0.2664 s/iter. Eval: 0.6599 s/iter. Total: 0.9292 s/iter. ETA=0:00:08
[08/26 13:39:15 d2.evaluation.evaluator]: Inference done 141/144. Dataloading: 0.0026 s/iter. Inference: 0.2663 s/iter. Eval: 0.6587 s/iter. Total: 0.9279 s/iter. ETA=0:00:02
[08/26 13:39:18 d2.evaluation.evaluator]: Total inference time: 0:02:08.971726 (0.927854 s / iter per device, on 1 devices)
[08/26 13:39:18 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:37 (0.266261 s / iter per device, on 1 devices)
[08/26 13:39:18 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 13:39:18 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 13:39:18 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[08/26 13:39:18 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 13:39:18 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.13 seconds.
[08/26 13:39:18 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 13:39:18 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.155
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.265
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.157
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.017
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.204
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.167
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.212
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.444
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.568
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.233
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.563
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.636
[08/26 13:39:18 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 15.506 | 26.523 | 15.729 | 1.723 | 20.364 | 16.722 |
Loading and preparing results...
DONE (t=0.45s)
creating index...
index created!
[08/26 13:39:19 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 13:39:20 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.25 seconds.
[08/26 13:39:20 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 13:39:20 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.177
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.271
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.204
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.015
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.185
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.227
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.230
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.494
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.635
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.233
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.611
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.748
[08/26 13:39:20 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 17.749 | 27.106 | 20.388 | 1.471 | 18.482 | 22.667 |
[08/26 13:39:20 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 13:39:20 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 13:39:20 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 13:39:20 d2.evaluation.testing]: copypaste: 15.5060,26.5232,15.7287,1.7234,20.3639,16.7224
[08/26 13:39:20 d2.evaluation.testing]: copypaste: Task: segm
[08/26 13:39:20 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 13:39:20 d2.evaluation.testing]: copypaste: 17.7494,27.1055,20.3879,1.4712,18.4821,22.6669
[08/26 13:39:20 d2.utils.events]:  eta: 0:27:32  iter: 119  total_loss: 1.249  loss_cls: 0.2809  loss_box_reg: 0.4332  loss_mask: 0.4897  loss_rpn_cls: 0.03458  loss_rpn_loc: 0.007088  time: 1.8864  data_time: 0.0129  lr: 2.997e-05  max_mem: 10070M
[08/26 13:39:58 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 13:39:58 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 13:39:58 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 13:39:58 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 13:39:58 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 13:40:09 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0021 s/iter. Inference: 0.2662 s/iter. Eval: 0.6600 s/iter. Total: 0.9283 s/iter. ETA=0:02:03
[08/26 13:40:14 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0025 s/iter. Inference: 0.2657 s/iter. Eval: 0.6646 s/iter. Total: 0.9331 s/iter. ETA=0:01:58
[08/26 13:40:20 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0026 s/iter. Inference: 0.2654 s/iter. Eval: 0.6534 s/iter. Total: 0.9217 s/iter. ETA=0:01:51
[08/26 13:40:25 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0027 s/iter. Inference: 0.2654 s/iter. Eval: 0.6564 s/iter. Total: 0.9247 s/iter. ETA=0:01:46
[08/26 13:40:31 d2.evaluation.evaluator]: Inference done 35/144. Dataloading: 0.0031 s/iter. Inference: 0.2659 s/iter. Eval: 0.6629 s/iter. Total: 0.9322 s/iter. ETA=0:01:41
[08/26 13:40:37 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0030 s/iter. Inference: 0.2663 s/iter. Eval: 0.6623 s/iter. Total: 0.9319 s/iter. ETA=0:01:35
[08/26 13:40:42 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0030 s/iter. Inference: 0.2660 s/iter. Eval: 0.6580 s/iter. Total: 0.9274 s/iter. ETA=0:01:29
[08/26 13:40:48 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0029 s/iter. Inference: 0.2660 s/iter. Eval: 0.6583 s/iter. Total: 0.9276 s/iter. ETA=0:01:24
[08/26 13:40:53 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0029 s/iter. Inference: 0.2659 s/iter. Eval: 0.6548 s/iter. Total: 0.9240 s/iter. ETA=0:01:18
[08/26 13:40:59 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0030 s/iter. Inference: 0.2659 s/iter. Eval: 0.6557 s/iter. Total: 0.9249 s/iter. ETA=0:01:13
[08/26 13:41:04 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0030 s/iter. Inference: 0.2662 s/iter. Eval: 0.6587 s/iter. Total: 0.9282 s/iter. ETA=0:01:07
[08/26 13:41:10 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0030 s/iter. Inference: 0.2661 s/iter. Eval: 0.6594 s/iter. Total: 0.9288 s/iter. ETA=0:01:02
[08/26 13:41:15 d2.evaluation.evaluator]: Inference done 83/144. Dataloading: 0.0030 s/iter. Inference: 0.2660 s/iter. Eval: 0.6577 s/iter. Total: 0.9270 s/iter. ETA=0:00:56
[08/26 13:41:21 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0029 s/iter. Inference: 0.2660 s/iter. Eval: 0.6584 s/iter. Total: 0.9276 s/iter. ETA=0:00:51
[08/26 13:41:26 d2.evaluation.evaluator]: Inference done 95/144. Dataloading: 0.0029 s/iter. Inference: 0.2659 s/iter. Eval: 0.6565 s/iter. Total: 0.9257 s/iter. ETA=0:00:45
[08/26 13:41:32 d2.evaluation.evaluator]: Inference done 101/144. Dataloading: 0.0029 s/iter. Inference: 0.2659 s/iter. Eval: 0.6573 s/iter. Total: 0.9265 s/iter. ETA=0:00:39
[08/26 13:41:37 d2.evaluation.evaluator]: Inference done 106/144. Dataloading: 0.0030 s/iter. Inference: 0.2663 s/iter. Eval: 0.6628 s/iter. Total: 0.9324 s/iter. ETA=0:00:35
[08/26 13:41:43 d2.evaluation.evaluator]: Inference done 112/144. Dataloading: 0.0030 s/iter. Inference: 0.2662 s/iter. Eval: 0.6634 s/iter. Total: 0.9330 s/iter. ETA=0:00:29
[08/26 13:41:48 d2.evaluation.evaluator]: Inference done 118/144. Dataloading: 0.0029 s/iter. Inference: 0.2662 s/iter. Eval: 0.6620 s/iter. Total: 0.9314 s/iter. ETA=0:00:24
[08/26 13:41:54 d2.evaluation.evaluator]: Inference done 124/144. Dataloading: 0.0029 s/iter. Inference: 0.2661 s/iter. Eval: 0.6625 s/iter. Total: 0.9319 s/iter. ETA=0:00:18
[08/26 13:41:59 d2.evaluation.evaluator]: Inference done 130/144. Dataloading: 0.0029 s/iter. Inference: 0.2660 s/iter. Eval: 0.6610 s/iter. Total: 0.9303 s/iter. ETA=0:00:13
[08/26 13:42:05 d2.evaluation.evaluator]: Inference done 136/144. Dataloading: 0.0029 s/iter. Inference: 0.2660 s/iter. Eval: 0.6615 s/iter. Total: 0.9308 s/iter. ETA=0:00:07
[08/26 13:42:11 d2.evaluation.evaluator]: Inference done 142/144. Dataloading: 0.0029 s/iter. Inference: 0.2659 s/iter. Eval: 0.6632 s/iter. Total: 0.9323 s/iter. ETA=0:00:01
[08/26 13:42:13 d2.evaluation.evaluator]: Total inference time: 0:02:09.598227 (0.932361 s / iter per device, on 1 devices)
[08/26 13:42:13 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:36 (0.265913 s / iter per device, on 1 devices)
[08/26 13:42:13 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 13:42:13 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 13:42:13 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[08/26 13:42:13 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 13:42:13 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.12 seconds.
[08/26 13:42:13 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 13:42:13 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.238
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.382
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.249
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.034
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.260
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.283
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.249
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.469
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.572
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.565
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.648
[08/26 13:42:13 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 23.781 | 38.248 | 24.876 | 3.442 | 26.033 | 28.312 |
Loading and preparing results...
DONE (t=0.35s)
creating index...
index created!
[08/26 13:42:14 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 13:42:14 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.24 seconds.
[08/26 13:42:14 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 13:42:14 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.03 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.268
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.392
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.316
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.030
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.247
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.365
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.263
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.521
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.646
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.233
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.627
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.755
[08/26 13:42:14 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 26.764 | 39.216 | 31.628 | 2.984 | 24.692 | 36.464 |
[08/26 13:42:15 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 13:42:15 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 13:42:15 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 13:42:15 d2.evaluation.testing]: copypaste: 23.7813,38.2481,24.8764,3.4418,26.0332,28.3120
[08/26 13:42:15 d2.evaluation.testing]: copypaste: Task: segm
[08/26 13:42:15 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 13:42:15 d2.evaluation.testing]: copypaste: 26.7644,39.2163,31.6276,2.9844,24.6920,36.4636
[08/26 13:42:15 d2.utils.events]:  eta: 0:26:59  iter: 139  total_loss: 1.395  loss_cls: 0.3117  loss_box_reg: 0.5879  loss_mask: 0.4623  loss_rpn_cls: 0.01704  loss_rpn_loc: 0.007908  time: 1.8897  data_time: 0.0149  lr: 3.4965e-05  max_mem: 10070M
[08/26 13:42:52 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 13:42:52 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 13:42:52 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 13:42:52 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 13:42:52 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 13:43:03 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0024 s/iter. Inference: 0.2682 s/iter. Eval: 0.6624 s/iter. Total: 0.9330 s/iter. ETA=0:02:04
[08/26 13:43:08 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0027 s/iter. Inference: 0.2668 s/iter. Eval: 0.6495 s/iter. Total: 0.9193 s/iter. ETA=0:01:56
[08/26 13:43:14 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0026 s/iter. Inference: 0.2678 s/iter. Eval: 0.6518 s/iter. Total: 0.9225 s/iter. ETA=0:01:51
[08/26 13:43:20 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0026 s/iter. Inference: 0.2689 s/iter. Eval: 0.6628 s/iter. Total: 0.9346 s/iter. ETA=0:01:47
[08/26 13:43:25 d2.evaluation.evaluator]: Inference done 35/144. Dataloading: 0.0026 s/iter. Inference: 0.2688 s/iter. Eval: 0.6631 s/iter. Total: 0.9349 s/iter. ETA=0:01:41
[08/26 13:43:31 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0027 s/iter. Inference: 0.2682 s/iter. Eval: 0.6580 s/iter. Total: 0.9292 s/iter. ETA=0:01:35
[08/26 13:43:37 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0026 s/iter. Inference: 0.2681 s/iter. Eval: 0.6601 s/iter. Total: 0.9312 s/iter. ETA=0:01:30
[08/26 13:43:42 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0027 s/iter. Inference: 0.2677 s/iter. Eval: 0.6571 s/iter. Total: 0.9278 s/iter. ETA=0:01:24
[08/26 13:43:48 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0027 s/iter. Inference: 0.2675 s/iter. Eval: 0.6615 s/iter. Total: 0.9320 s/iter. ETA=0:01:19
[08/26 13:43:53 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0027 s/iter. Inference: 0.2675 s/iter. Eval: 0.6629 s/iter. Total: 0.9334 s/iter. ETA=0:01:13
[08/26 13:43:59 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0027 s/iter. Inference: 0.2677 s/iter. Eval: 0.6628 s/iter. Total: 0.9336 s/iter. ETA=0:01:08
[08/26 13:44:04 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0027 s/iter. Inference: 0.2674 s/iter. Eval: 0.6604 s/iter. Total: 0.9309 s/iter. ETA=0:01:02
[08/26 13:44:10 d2.evaluation.evaluator]: Inference done 83/144. Dataloading: 0.0028 s/iter. Inference: 0.2673 s/iter. Eval: 0.6606 s/iter. Total: 0.9311 s/iter. ETA=0:00:56
[08/26 13:44:15 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0028 s/iter. Inference: 0.2671 s/iter. Eval: 0.6590 s/iter. Total: 0.9292 s/iter. ETA=0:00:51
[08/26 13:44:21 d2.evaluation.evaluator]: Inference done 95/144. Dataloading: 0.0027 s/iter. Inference: 0.2671 s/iter. Eval: 0.6591 s/iter. Total: 0.9293 s/iter. ETA=0:00:45
[08/26 13:44:27 d2.evaluation.evaluator]: Inference done 101/144. Dataloading: 0.0028 s/iter. Inference: 0.2671 s/iter. Eval: 0.6642 s/iter. Total: 0.9345 s/iter. ETA=0:00:40
[08/26 13:44:33 d2.evaluation.evaluator]: Inference done 107/144. Dataloading: 0.0028 s/iter. Inference: 0.2669 s/iter. Eval: 0.6621 s/iter. Total: 0.9323 s/iter. ETA=0:00:34
[08/26 13:44:38 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0028 s/iter. Inference: 0.2669 s/iter. Eval: 0.6625 s/iter. Total: 0.9326 s/iter. ETA=0:00:28
[08/26 13:44:44 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0028 s/iter. Inference: 0.2668 s/iter. Eval: 0.6612 s/iter. Total: 0.9312 s/iter. ETA=0:00:23
[08/26 13:44:49 d2.evaluation.evaluator]: Inference done 125/144. Dataloading: 0.0028 s/iter. Inference: 0.2668 s/iter. Eval: 0.6637 s/iter. Total: 0.9336 s/iter. ETA=0:00:17
[08/26 13:44:55 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0028 s/iter. Inference: 0.2667 s/iter. Eval: 0.6627 s/iter. Total: 0.9325 s/iter. ETA=0:00:12
[08/26 13:45:00 d2.evaluation.evaluator]: Inference done 136/144. Dataloading: 0.0027 s/iter. Inference: 0.2668 s/iter. Eval: 0.6654 s/iter. Total: 0.9354 s/iter. ETA=0:00:07
[08/26 13:45:05 d2.evaluation.evaluator]: Inference done 142/144. Dataloading: 0.0027 s/iter. Inference: 0.2667 s/iter. Eval: 0.6631 s/iter. Total: 0.9330 s/iter. ETA=0:00:01
[08/26 13:45:07 d2.evaluation.evaluator]: Total inference time: 0:02:09.681101 (0.932958 s / iter per device, on 1 devices)
[08/26 13:45:07 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:37 (0.266694 s / iter per device, on 1 devices)
[08/26 13:45:07 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 13:45:07 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 13:45:07 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[08/26 13:45:08 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 13:45:08 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.12 seconds.
[08/26 13:45:08 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 13:45:08 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.306
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.480
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.324
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.057
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.303
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.387
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.266
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.481
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.580
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.563
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.677
[08/26 13:45:08 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 30.570 | 48.041 | 32.353 | 5.691 | 30.282 | 38.708 |
Loading and preparing results...
DONE (t=0.34s)
creating index...
index created!
[08/26 13:45:09 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 13:45:09 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.23 seconds.
[08/26 13:45:09 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 13:45:09 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.335
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.490
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.386
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.058
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.289
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.471
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.283
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.522
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.660
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.233
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.644
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.764
[08/26 13:45:09 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 33.517 | 48.976 | 38.601 | 5.779 | 28.909 | 47.142 |
[08/26 13:45:09 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 13:45:09 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 13:45:09 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 13:45:09 d2.evaluation.testing]: copypaste: 30.5698,48.0412,32.3528,5.6909,30.2823,38.7078
[08/26 13:45:09 d2.evaluation.testing]: copypaste: Task: segm
[08/26 13:45:09 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 13:45:09 d2.evaluation.testing]: copypaste: 33.5169,48.9762,38.6011,5.7786,28.9092,47.1420
[08/26 13:45:09 d2.utils.events]:  eta: 0:26:21  iter: 159  total_loss: 1.114  loss_cls: 0.2371  loss_box_reg: 0.4368  loss_mask: 0.3806  loss_rpn_cls: 0.01816  loss_rpn_loc: 0.006043  time: 1.8895  data_time: 0.0248  lr: 3.996e-05  max_mem: 10070M
[08/26 13:45:47 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 13:45:47 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 13:45:47 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 13:45:47 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 13:45:47 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 13:45:57 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0024 s/iter. Inference: 0.2725 s/iter. Eval: 0.6631 s/iter. Total: 0.9380 s/iter. ETA=0:02:04
[08/26 13:46:03 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0035 s/iter. Inference: 0.2688 s/iter. Eval: 0.6616 s/iter. Total: 0.9343 s/iter. ETA=0:01:58
[08/26 13:46:08 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0033 s/iter. Inference: 0.2676 s/iter. Eval: 0.6551 s/iter. Total: 0.9263 s/iter. ETA=0:01:52
[08/26 13:46:14 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0032 s/iter. Inference: 0.2668 s/iter. Eval: 0.6496 s/iter. Total: 0.9198 s/iter. ETA=0:01:45
[08/26 13:46:19 d2.evaluation.evaluator]: Inference done 35/144. Dataloading: 0.0030 s/iter. Inference: 0.2672 s/iter. Eval: 0.6518 s/iter. Total: 0.9223 s/iter. ETA=0:01:40
[08/26 13:46:25 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0031 s/iter. Inference: 0.2667 s/iter. Eval: 0.6488 s/iter. Total: 0.9189 s/iter. ETA=0:01:34
[08/26 13:46:30 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0030 s/iter. Inference: 0.2668 s/iter. Eval: 0.6505 s/iter. Total: 0.9206 s/iter. ETA=0:01:29
[08/26 13:46:36 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0031 s/iter. Inference: 0.2666 s/iter. Eval: 0.6559 s/iter. Total: 0.9259 s/iter. ETA=0:01:24
[08/26 13:46:42 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0031 s/iter. Inference: 0.2664 s/iter. Eval: 0.6576 s/iter. Total: 0.9274 s/iter. ETA=0:01:18
[08/26 13:46:47 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0030 s/iter. Inference: 0.2662 s/iter. Eval: 0.6557 s/iter. Total: 0.9252 s/iter. ETA=0:01:13
[08/26 13:46:53 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0030 s/iter. Inference: 0.2662 s/iter. Eval: 0.6576 s/iter. Total: 0.9271 s/iter. ETA=0:01:07
[08/26 13:46:58 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0029 s/iter. Inference: 0.2662 s/iter. Eval: 0.6561 s/iter. Total: 0.9255 s/iter. ETA=0:01:02
[08/26 13:47:04 d2.evaluation.evaluator]: Inference done 83/144. Dataloading: 0.0029 s/iter. Inference: 0.2660 s/iter. Eval: 0.6573 s/iter. Total: 0.9266 s/iter. ETA=0:00:56
[08/26 13:47:10 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0030 s/iter. Inference: 0.2664 s/iter. Eval: 0.6601 s/iter. Total: 0.9298 s/iter. ETA=0:00:51
[08/26 13:47:15 d2.evaluation.evaluator]: Inference done 95/144. Dataloading: 0.0030 s/iter. Inference: 0.2663 s/iter. Eval: 0.6602 s/iter. Total: 0.9299 s/iter. ETA=0:00:45
[08/26 13:47:21 d2.evaluation.evaluator]: Inference done 101/144. Dataloading: 0.0030 s/iter. Inference: 0.2662 s/iter. Eval: 0.6583 s/iter. Total: 0.9279 s/iter. ETA=0:00:39
[08/26 13:47:26 d2.evaluation.evaluator]: Inference done 107/144. Dataloading: 0.0030 s/iter. Inference: 0.2661 s/iter. Eval: 0.6557 s/iter. Total: 0.9251 s/iter. ETA=0:00:34
[08/26 13:47:31 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0030 s/iter. Inference: 0.2660 s/iter. Eval: 0.6545 s/iter. Total: 0.9239 s/iter. ETA=0:00:28
[08/26 13:47:37 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0029 s/iter. Inference: 0.2658 s/iter. Eval: 0.6529 s/iter. Total: 0.9220 s/iter. ETA=0:00:23
[08/26 13:47:43 d2.evaluation.evaluator]: Inference done 125/144. Dataloading: 0.0030 s/iter. Inference: 0.2659 s/iter. Eval: 0.6550 s/iter. Total: 0.9242 s/iter. ETA=0:00:17
[08/26 13:47:48 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0030 s/iter. Inference: 0.2657 s/iter. Eval: 0.6539 s/iter. Total: 0.9229 s/iter. ETA=0:00:11
[08/26 13:47:53 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0030 s/iter. Inference: 0.2655 s/iter. Eval: 0.6525 s/iter. Total: 0.9213 s/iter. ETA=0:00:06
[08/26 13:47:59 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0029 s/iter. Inference: 0.2651 s/iter. Eval: 0.6484 s/iter. Total: 0.9168 s/iter. ETA=0:00:00
[08/26 13:47:59 d2.evaluation.evaluator]: Total inference time: 0:02:07.511119 (0.917346 s / iter per device, on 1 devices)
[08/26 13:47:59 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:36 (0.265144 s / iter per device, on 1 devices)
[08/26 13:47:59 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 13:47:59 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 13:48:00 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[08/26 13:48:00 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 13:48:00 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.35 seconds.
[08/26 13:48:00 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 13:48:00 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.327
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.525
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.332
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.093
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.325
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.405
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.279
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.493
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.593
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.581
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.682
[08/26 13:48:00 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 32.702 | 52.501 | 33.194 | 9.328 | 32.470 | 40.462 |
Loading and preparing results...
DONE (t=0.32s)
creating index...
index created!
[08/26 13:48:01 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 13:48:01 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.22 seconds.
[08/26 13:48:01 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 13:48:01 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.364
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.537
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.417
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.062
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.314
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.508
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.296
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.535
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.660
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.283
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.636
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.770
[08/26 13:48:01 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 36.388 | 53.660 | 41.739 | 6.232 | 31.399 | 50.796 |
[08/26 13:48:01 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 13:48:01 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 13:48:01 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 13:48:01 d2.evaluation.testing]: copypaste: 32.7021,52.5006,33.1939,9.3282,32.4703,40.4619
[08/26 13:48:01 d2.evaluation.testing]: copypaste: Task: segm
[08/26 13:48:01 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 13:48:01 d2.evaluation.testing]: copypaste: 36.3876,53.6601,41.7393,6.2322,31.3990,50.7957
[08/26 13:48:01 d2.utils.events]:  eta: 0:25:44  iter: 179  total_loss: 1.051  loss_cls: 0.2212  loss_box_reg: 0.4163  loss_mask: 0.3593  loss_rpn_cls: 0.01253  loss_rpn_loc: 0.007137  time: 1.8898  data_time: 0.0245  lr: 4.4955e-05  max_mem: 10070M
[08/26 13:48:39 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 13:48:39 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 13:48:39 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 13:48:39 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 13:48:39 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 13:48:50 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0020 s/iter. Inference: 0.2685 s/iter. Eval: 0.7022 s/iter. Total: 0.9727 s/iter. ETA=0:02:09
[08/26 13:48:55 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0022 s/iter. Inference: 0.2635 s/iter. Eval: 0.6561 s/iter. Total: 0.9221 s/iter. ETA=0:01:57
[08/26 13:49:01 d2.evaluation.evaluator]: Inference done 24/144. Dataloading: 0.0024 s/iter. Inference: 0.2615 s/iter. Eval: 0.6209 s/iter. Total: 0.8851 s/iter. ETA=0:01:46
[08/26 13:49:06 d2.evaluation.evaluator]: Inference done 30/144. Dataloading: 0.0025 s/iter. Inference: 0.2613 s/iter. Eval: 0.6245 s/iter. Total: 0.8886 s/iter. ETA=0:01:41
[08/26 13:49:12 d2.evaluation.evaluator]: Inference done 36/144. Dataloading: 0.0025 s/iter. Inference: 0.2619 s/iter. Eval: 0.6261 s/iter. Total: 0.8908 s/iter. ETA=0:01:36
[08/26 13:49:17 d2.evaluation.evaluator]: Inference done 42/144. Dataloading: 0.0025 s/iter. Inference: 0.2622 s/iter. Eval: 0.6269 s/iter. Total: 0.8919 s/iter. ETA=0:01:30
[08/26 13:49:23 d2.evaluation.evaluator]: Inference done 48/144. Dataloading: 0.0026 s/iter. Inference: 0.2623 s/iter. Eval: 0.6252 s/iter. Total: 0.8904 s/iter. ETA=0:01:25
[08/26 13:49:28 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0027 s/iter. Inference: 0.2640 s/iter. Eval: 0.6392 s/iter. Total: 0.9061 s/iter. ETA=0:01:22
[08/26 13:49:33 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0027 s/iter. Inference: 0.2637 s/iter. Eval: 0.6352 s/iter. Total: 0.9018 s/iter. ETA=0:01:16
[08/26 13:49:39 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0027 s/iter. Inference: 0.2645 s/iter. Eval: 0.6376 s/iter. Total: 0.9051 s/iter. ETA=0:01:11
[08/26 13:49:44 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0027 s/iter. Inference: 0.2644 s/iter. Eval: 0.6377 s/iter. Total: 0.9051 s/iter. ETA=0:01:06
[08/26 13:49:49 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0027 s/iter. Inference: 0.2642 s/iter. Eval: 0.6356 s/iter. Total: 0.9029 s/iter. ETA=0:01:00
[08/26 13:49:54 d2.evaluation.evaluator]: Inference done 83/144. Dataloading: 0.0027 s/iter. Inference: 0.2640 s/iter. Eval: 0.6325 s/iter. Total: 0.8995 s/iter. ETA=0:00:54
[08/26 13:50:00 d2.evaluation.evaluator]: Inference done 88/144. Dataloading: 0.0026 s/iter. Inference: 0.2646 s/iter. Eval: 0.6407 s/iter. Total: 0.9082 s/iter. ETA=0:00:50
[08/26 13:50:05 d2.evaluation.evaluator]: Inference done 94/144. Dataloading: 0.0026 s/iter. Inference: 0.2646 s/iter. Eval: 0.6396 s/iter. Total: 0.9071 s/iter. ETA=0:00:45
[08/26 13:50:10 d2.evaluation.evaluator]: Inference done 100/144. Dataloading: 0.0027 s/iter. Inference: 0.2645 s/iter. Eval: 0.6379 s/iter. Total: 0.9053 s/iter. ETA=0:00:39
[08/26 13:50:15 d2.evaluation.evaluator]: Inference done 106/144. Dataloading: 0.0027 s/iter. Inference: 0.2642 s/iter. Eval: 0.6341 s/iter. Total: 0.9012 s/iter. ETA=0:00:34
[08/26 13:50:21 d2.evaluation.evaluator]: Inference done 112/144. Dataloading: 0.0027 s/iter. Inference: 0.2642 s/iter. Eval: 0.6360 s/iter. Total: 0.9032 s/iter. ETA=0:00:28
[08/26 13:50:26 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0027 s/iter. Inference: 0.2635 s/iter. Eval: 0.6283 s/iter. Total: 0.8949 s/iter. ETA=0:00:22
[08/26 13:50:31 d2.evaluation.evaluator]: Inference done 124/144. Dataloading: 0.0027 s/iter. Inference: 0.2638 s/iter. Eval: 0.6344 s/iter. Total: 0.9013 s/iter. ETA=0:00:18
[08/26 13:50:37 d2.evaluation.evaluator]: Inference done 130/144. Dataloading: 0.0027 s/iter. Inference: 0.2637 s/iter. Eval: 0.6317 s/iter. Total: 0.8984 s/iter. ETA=0:00:12
[08/26 13:50:42 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0026 s/iter. Inference: 0.2633 s/iter. Eval: 0.6283 s/iter. Total: 0.8945 s/iter. ETA=0:00:06
[08/26 13:50:48 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0026 s/iter. Inference: 0.2628 s/iter. Eval: 0.6230 s/iter. Total: 0.8887 s/iter. ETA=0:00:00
[08/26 13:50:48 d2.evaluation.evaluator]: Total inference time: 0:02:03.598215 (0.889196 s / iter per device, on 1 devices)
[08/26 13:50:48 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:36 (0.262785 s / iter per device, on 1 devices)
[08/26 13:50:48 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 13:50:48 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 13:50:48 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[08/26 13:50:48 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 13:50:48 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[08/26 13:50:48 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 13:50:48 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.352
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.564
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.354
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.115
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.341
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.443
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.293
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.504
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.598
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.581
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.698
[08/26 13:50:48 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 35.233 | 56.363 | 35.435 | 11.525 | 34.145 | 44.250 |
Loading and preparing results...
DONE (t=0.30s)
creating index...
index created!
[08/26 13:50:49 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 13:50:50 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.21 seconds.
[08/26 13:50:50 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 13:50:50 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.393
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.582
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.453
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.092
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.337
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.555
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.309
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.558
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.660
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.636
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.768
[08/26 13:50:50 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 39.346 | 58.183 | 45.311 | 9.241 | 33.717 | 55.526 |
[08/26 13:50:50 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 13:50:50 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 13:50:50 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 13:50:50 d2.evaluation.testing]: copypaste: 35.2330,56.3633,35.4352,11.5251,34.1447,44.2503
[08/26 13:50:50 d2.evaluation.testing]: copypaste: Task: segm
[08/26 13:50:50 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 13:50:50 d2.evaluation.testing]: copypaste: 39.3456,58.1831,45.3113,9.2414,33.7170,55.5258
[08/26 13:50:50 d2.utils.events]:  eta: 0:25:05  iter: 199  total_loss: 1.06  loss_cls: 0.2197  loss_box_reg: 0.4312  loss_mask: 0.3153  loss_rpn_cls: 0.0183  loss_rpn_loc: 0.00927  time: 1.8891  data_time: 0.0240  lr: 4.995e-05  max_mem: 10070M
[08/26 13:51:28 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 13:51:28 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 13:51:28 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 13:51:28 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 13:51:28 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 13:51:38 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0036 s/iter. Inference: 0.2732 s/iter. Eval: 0.7183 s/iter. Total: 0.9951 s/iter. ETA=0:02:12
[08/26 13:51:44 d2.evaluation.evaluator]: Inference done 18/144. Dataloading: 0.0033 s/iter. Inference: 0.2658 s/iter. Eval: 0.6326 s/iter. Total: 0.9019 s/iter. ETA=0:01:53
[08/26 13:51:50 d2.evaluation.evaluator]: Inference done 25/144. Dataloading: 0.0031 s/iter. Inference: 0.2625 s/iter. Eval: 0.5990 s/iter. Total: 0.8649 s/iter. ETA=0:01:42
[08/26 13:51:55 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0030 s/iter. Inference: 0.2620 s/iter. Eval: 0.5956 s/iter. Total: 0.8609 s/iter. ETA=0:01:37
[08/26 13:52:00 d2.evaluation.evaluator]: Inference done 37/144. Dataloading: 0.0029 s/iter. Inference: 0.2625 s/iter. Eval: 0.6033 s/iter. Total: 0.8690 s/iter. ETA=0:01:32
[08/26 13:52:06 d2.evaluation.evaluator]: Inference done 43/144. Dataloading: 0.0029 s/iter. Inference: 0.2626 s/iter. Eval: 0.6054 s/iter. Total: 0.8712 s/iter. ETA=0:01:27
[08/26 13:52:11 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0031 s/iter. Inference: 0.2638 s/iter. Eval: 0.6193 s/iter. Total: 0.8864 s/iter. ETA=0:01:24
[08/26 13:52:17 d2.evaluation.evaluator]: Inference done 55/144. Dataloading: 0.0030 s/iter. Inference: 0.2635 s/iter. Eval: 0.6164 s/iter. Total: 0.8832 s/iter. ETA=0:01:18
[08/26 13:52:22 d2.evaluation.evaluator]: Inference done 61/144. Dataloading: 0.0029 s/iter. Inference: 0.2645 s/iter. Eval: 0.6229 s/iter. Total: 0.8906 s/iter. ETA=0:01:13
[08/26 13:52:28 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0029 s/iter. Inference: 0.2645 s/iter. Eval: 0.6245 s/iter. Total: 0.8922 s/iter. ETA=0:01:08
[08/26 13:52:33 d2.evaluation.evaluator]: Inference done 73/144. Dataloading: 0.0030 s/iter. Inference: 0.2646 s/iter. Eval: 0.6242 s/iter. Total: 0.8922 s/iter. ETA=0:01:03
[08/26 13:52:38 d2.evaluation.evaluator]: Inference done 79/144. Dataloading: 0.0030 s/iter. Inference: 0.2644 s/iter. Eval: 0.6223 s/iter. Total: 0.8899 s/iter. ETA=0:00:57
[08/26 13:52:44 d2.evaluation.evaluator]: Inference done 85/144. Dataloading: 0.0030 s/iter. Inference: 0.2643 s/iter. Eval: 0.6221 s/iter. Total: 0.8897 s/iter. ETA=0:00:52
[08/26 13:52:49 d2.evaluation.evaluator]: Inference done 91/144. Dataloading: 0.0029 s/iter. Inference: 0.2643 s/iter. Eval: 0.6232 s/iter. Total: 0.8908 s/iter. ETA=0:00:47
[08/26 13:52:55 d2.evaluation.evaluator]: Inference done 97/144. Dataloading: 0.0029 s/iter. Inference: 0.2643 s/iter. Eval: 0.6239 s/iter. Total: 0.8914 s/iter. ETA=0:00:41
[08/26 13:53:00 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0029 s/iter. Inference: 0.2636 s/iter. Eval: 0.6171 s/iter. Total: 0.8840 s/iter. ETA=0:00:35
[08/26 13:53:05 d2.evaluation.evaluator]: Inference done 110/144. Dataloading: 0.0029 s/iter. Inference: 0.2633 s/iter. Eval: 0.6152 s/iter. Total: 0.8817 s/iter. ETA=0:00:29
[08/26 13:53:10 d2.evaluation.evaluator]: Inference done 117/144. Dataloading: 0.0029 s/iter. Inference: 0.2627 s/iter. Eval: 0.6083 s/iter. Total: 0.8742 s/iter. ETA=0:00:23
[08/26 13:53:16 d2.evaluation.evaluator]: Inference done 123/144. Dataloading: 0.0029 s/iter. Inference: 0.2627 s/iter. Eval: 0.6091 s/iter. Total: 0.8750 s/iter. ETA=0:00:18
[08/26 13:53:22 d2.evaluation.evaluator]: Inference done 130/144. Dataloading: 0.0029 s/iter. Inference: 0.2624 s/iter. Eval: 0.6066 s/iter. Total: 0.8723 s/iter. ETA=0:00:12
[08/26 13:53:27 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0029 s/iter. Inference: 0.2621 s/iter. Eval: 0.6023 s/iter. Total: 0.8677 s/iter. ETA=0:00:06
[08/26 13:53:32 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0029 s/iter. Inference: 0.2616 s/iter. Eval: 0.5974 s/iter. Total: 0.8623 s/iter. ETA=0:00:00
[08/26 13:53:32 d2.evaluation.evaluator]: Total inference time: 0:01:59.927766 (0.862790 s / iter per device, on 1 devices)
[08/26 13:53:32 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:36 (0.261649 s / iter per device, on 1 devices)
[08/26 13:53:33 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 13:53:33 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 13:53:33 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[08/26 13:53:33 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 13:53:33 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.12 seconds.
[08/26 13:53:33 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 13:53:33 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.377
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.592
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.398
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.121
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.356
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.481
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.292
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.535
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.608
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.225
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.579
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.727
[08/26 13:53:33 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 37.727 | 59.185 | 39.824 | 12.109 | 35.641 | 48.103 |
Loading and preparing results...
DONE (t=0.28s)
creating index...
index created!
[08/26 13:53:34 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 13:53:34 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.20 seconds.
[08/26 13:53:34 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 13:53:34 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.414
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.602
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.483
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.081
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.364
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.571
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.310
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.574
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.675
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.650
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.777
[08/26 13:53:34 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 41.441 | 60.243 | 48.345 | 8.121 | 36.445 | 57.136 |
[08/26 13:53:34 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 13:53:34 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 13:53:34 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 13:53:34 d2.evaluation.testing]: copypaste: 37.7273,59.1849,39.8235,12.1094,35.6409,48.1027
[08/26 13:53:34 d2.evaluation.testing]: copypaste: Task: segm
[08/26 13:53:34 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 13:53:34 d2.evaluation.testing]: copypaste: 41.4415,60.2427,48.3453,8.1211,36.4448,57.1362
[08/26 13:53:34 d2.utils.events]:  eta: 0:24:27  iter: 219  total_loss: 0.9147  loss_cls: 0.1772  loss_box_reg: 0.3133  loss_mask: 0.3072  loss_rpn_cls: 0.01381  loss_rpn_loc: 0.009357  time: 1.8891  data_time: 0.0240  lr: 5.4945e-05  max_mem: 10070M
[08/26 13:54:12 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 13:54:12 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 13:54:12 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 13:54:12 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 13:54:12 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 13:54:23 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0033 s/iter. Inference: 0.2668 s/iter. Eval: 0.7112 s/iter. Total: 0.9813 s/iter. ETA=0:02:10
[08/26 13:54:28 d2.evaluation.evaluator]: Inference done 18/144. Dataloading: 0.0032 s/iter. Inference: 0.2604 s/iter. Eval: 0.6089 s/iter. Total: 0.8728 s/iter. ETA=0:01:49
[08/26 13:54:33 d2.evaluation.evaluator]: Inference done 25/144. Dataloading: 0.0029 s/iter. Inference: 0.2560 s/iter. Eval: 0.5582 s/iter. Total: 0.8174 s/iter. ETA=0:01:37
[08/26 13:54:39 d2.evaluation.evaluator]: Inference done 32/144. Dataloading: 0.0030 s/iter. Inference: 0.2564 s/iter. Eval: 0.5578 s/iter. Total: 0.8174 s/iter. ETA=0:01:31
[08/26 13:54:44 d2.evaluation.evaluator]: Inference done 38/144. Dataloading: 0.0030 s/iter. Inference: 0.2576 s/iter. Eval: 0.5643 s/iter. Total: 0.8252 s/iter. ETA=0:01:27
[08/26 13:54:50 d2.evaluation.evaluator]: Inference done 45/144. Dataloading: 0.0028 s/iter. Inference: 0.2580 s/iter. Eval: 0.5662 s/iter. Total: 0.8273 s/iter. ETA=0:01:21
[08/26 13:54:55 d2.evaluation.evaluator]: Inference done 50/144. Dataloading: 0.0030 s/iter. Inference: 0.2599 s/iter. Eval: 0.5852 s/iter. Total: 0.8484 s/iter. ETA=0:01:19
[08/26 13:55:00 d2.evaluation.evaluator]: Inference done 56/144. Dataloading: 0.0029 s/iter. Inference: 0.2600 s/iter. Eval: 0.5840 s/iter. Total: 0.8471 s/iter. ETA=0:01:14
[08/26 13:55:06 d2.evaluation.evaluator]: Inference done 62/144. Dataloading: 0.0028 s/iter. Inference: 0.2605 s/iter. Eval: 0.5925 s/iter. Total: 0.8562 s/iter. ETA=0:01:10
[08/26 13:55:11 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0028 s/iter. Inference: 0.2609 s/iter. Eval: 0.5961 s/iter. Total: 0.8601 s/iter. ETA=0:01:05
[08/26 13:55:17 d2.evaluation.evaluator]: Inference done 75/144. Dataloading: 0.0028 s/iter. Inference: 0.2603 s/iter. Eval: 0.5913 s/iter. Total: 0.8547 s/iter. ETA=0:00:58
[08/26 13:55:22 d2.evaluation.evaluator]: Inference done 82/144. Dataloading: 0.0028 s/iter. Inference: 0.2597 s/iter. Eval: 0.5836 s/iter. Total: 0.8464 s/iter. ETA=0:00:52
[08/26 13:55:28 d2.evaluation.evaluator]: Inference done 88/144. Dataloading: 0.0027 s/iter. Inference: 0.2599 s/iter. Eval: 0.5865 s/iter. Total: 0.8494 s/iter. ETA=0:00:47
[08/26 13:55:33 d2.evaluation.evaluator]: Inference done 94/144. Dataloading: 0.0028 s/iter. Inference: 0.2599 s/iter. Eval: 0.5861 s/iter. Total: 0.8491 s/iter. ETA=0:00:42
[08/26 13:55:38 d2.evaluation.evaluator]: Inference done 101/144. Dataloading: 0.0028 s/iter. Inference: 0.2594 s/iter. Eval: 0.5821 s/iter. Total: 0.8445 s/iter. ETA=0:00:36
[08/26 13:55:44 d2.evaluation.evaluator]: Inference done 108/144. Dataloading: 0.0028 s/iter. Inference: 0.2592 s/iter. Eval: 0.5794 s/iter. Total: 0.8417 s/iter. ETA=0:00:30
[08/26 13:55:49 d2.evaluation.evaluator]: Inference done 115/144. Dataloading: 0.0028 s/iter. Inference: 0.2587 s/iter. Eval: 0.5749 s/iter. Total: 0.8367 s/iter. ETA=0:00:24
[08/26 13:55:55 d2.evaluation.evaluator]: Inference done 123/144. Dataloading: 0.0028 s/iter. Inference: 0.2581 s/iter. Eval: 0.5669 s/iter. Total: 0.8280 s/iter. ETA=0:00:17
[08/26 13:56:00 d2.evaluation.evaluator]: Inference done 129/144. Dataloading: 0.0028 s/iter. Inference: 0.2582 s/iter. Eval: 0.5691 s/iter. Total: 0.8304 s/iter. ETA=0:00:12
[08/26 13:56:05 d2.evaluation.evaluator]: Inference done 136/144. Dataloading: 0.0028 s/iter. Inference: 0.2578 s/iter. Eval: 0.5636 s/iter. Total: 0.8244 s/iter. ETA=0:00:06
[08/26 13:56:10 d2.evaluation.evaluator]: Inference done 143/144. Dataloading: 0.0028 s/iter. Inference: 0.2575 s/iter. Eval: 0.5602 s/iter. Total: 0.8207 s/iter. ETA=0:00:00
[08/26 13:56:11 d2.evaluation.evaluator]: Total inference time: 0:01:54.360966 (0.822741 s / iter per device, on 1 devices)
[08/26 13:56:11 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:35 (0.257583 s / iter per device, on 1 devices)
[08/26 13:56:12 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 13:56:12 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 13:56:12 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/26 13:56:12 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 13:56:12 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[08/26 13:56:12 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 13:56:12 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.382
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.610
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.407
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.115
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.364
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.483
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.288
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.535
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.603
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.225
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.578
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.715
[08/26 13:56:12 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 38.242 | 61.032 | 40.709 | 11.481 | 36.365 | 48.265 |
Loading and preparing results...
DONE (t=0.26s)
creating index...
index created!
[08/26 13:56:13 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 13:56:13 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.19 seconds.
[08/26 13:56:13 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 13:56:13 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.425
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.623
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.487
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.080
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.374
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.581
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.307
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.580
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.676
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.342
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.650
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.782
[08/26 13:56:13 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 42.463 | 62.317 | 48.687 | 8.021 | 37.365 | 58.086 |
[08/26 13:56:13 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 13:56:13 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 13:56:13 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 13:56:13 d2.evaluation.testing]: copypaste: 38.2420,61.0322,40.7086,11.4807,36.3645,48.2650
[08/26 13:56:13 d2.evaluation.testing]: copypaste: Task: segm
[08/26 13:56:13 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 13:56:13 d2.evaluation.testing]: copypaste: 42.4631,62.3172,48.6868,8.0212,37.3650,58.0863
[08/26 13:56:13 d2.utils.events]:  eta: 0:23:50  iter: 239  total_loss: 0.9354  loss_cls: 0.1861  loss_box_reg: 0.4092  loss_mask: 0.2426  loss_rpn_cls: 0.01156  loss_rpn_loc: 0.006749  time: 1.8896  data_time: 0.0252  lr: 5.994e-05  max_mem: 10070M
[08/26 13:56:51 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 13:56:51 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 13:56:51 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 13:56:51 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 13:56:51 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 13:57:01 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0024 s/iter. Inference: 0.2578 s/iter. Eval: 0.5570 s/iter. Total: 0.8172 s/iter. ETA=0:01:48
[08/26 13:57:07 d2.evaluation.evaluator]: Inference done 18/144. Dataloading: 0.0029 s/iter. Inference: 0.2562 s/iter. Eval: 0.5451 s/iter. Total: 0.8044 s/iter. ETA=0:01:41
[08/26 13:57:12 d2.evaluation.evaluator]: Inference done 26/144. Dataloading: 0.0028 s/iter. Inference: 0.2516 s/iter. Eval: 0.4916 s/iter. Total: 0.7463 s/iter. ETA=0:01:28
[08/26 13:57:17 d2.evaluation.evaluator]: Inference done 33/144. Dataloading: 0.0027 s/iter. Inference: 0.2527 s/iter. Eval: 0.5004 s/iter. Total: 0.7560 s/iter. ETA=0:01:23
[08/26 13:57:23 d2.evaluation.evaluator]: Inference done 40/144. Dataloading: 0.0026 s/iter. Inference: 0.2528 s/iter. Eval: 0.5001 s/iter. Total: 0.7558 s/iter. ETA=0:01:18
[08/26 13:57:28 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0026 s/iter. Inference: 0.2538 s/iter. Eval: 0.5146 s/iter. Total: 0.7713 s/iter. ETA=0:01:15
[08/26 13:57:33 d2.evaluation.evaluator]: Inference done 52/144. Dataloading: 0.0029 s/iter. Inference: 0.2552 s/iter. Eval: 0.5299 s/iter. Total: 0.7883 s/iter. ETA=0:01:12
[08/26 13:57:39 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0029 s/iter. Inference: 0.2561 s/iter. Eval: 0.5455 s/iter. Total: 0.8048 s/iter. ETA=0:01:09
[08/26 13:57:44 d2.evaluation.evaluator]: Inference done 64/144. Dataloading: 0.0029 s/iter. Inference: 0.2572 s/iter. Eval: 0.5539 s/iter. Total: 0.8144 s/iter. ETA=0:01:05
[08/26 13:57:50 d2.evaluation.evaluator]: Inference done 70/144. Dataloading: 0.0029 s/iter. Inference: 0.2578 s/iter. Eval: 0.5632 s/iter. Total: 0.8243 s/iter. ETA=0:01:00
[08/26 13:57:55 d2.evaluation.evaluator]: Inference done 78/144. Dataloading: 0.0029 s/iter. Inference: 0.2568 s/iter. Eval: 0.5511 s/iter. Total: 0.8112 s/iter. ETA=0:00:53
[08/26 13:58:02 d2.evaluation.evaluator]: Inference done 87/144. Dataloading: 0.0028 s/iter. Inference: 0.2557 s/iter. Eval: 0.5369 s/iter. Total: 0.7959 s/iter. ETA=0:00:45
[08/26 13:58:07 d2.evaluation.evaluator]: Inference done 94/144. Dataloading: 0.0028 s/iter. Inference: 0.2556 s/iter. Eval: 0.5344 s/iter. Total: 0.7931 s/iter. ETA=0:00:39
[08/26 13:58:12 d2.evaluation.evaluator]: Inference done 101/144. Dataloading: 0.0028 s/iter. Inference: 0.2550 s/iter. Eval: 0.5314 s/iter. Total: 0.7896 s/iter. ETA=0:00:33
[08/26 13:58:17 d2.evaluation.evaluator]: Inference done 108/144. Dataloading: 0.0028 s/iter. Inference: 0.2548 s/iter. Eval: 0.5276 s/iter. Total: 0.7857 s/iter. ETA=0:00:28
[08/26 13:58:23 d2.evaluation.evaluator]: Inference done 116/144. Dataloading: 0.0027 s/iter. Inference: 0.2543 s/iter. Eval: 0.5216 s/iter. Total: 0.7791 s/iter. ETA=0:00:21
[08/26 13:58:28 d2.evaluation.evaluator]: Inference done 124/144. Dataloading: 0.0027 s/iter. Inference: 0.2538 s/iter. Eval: 0.5135 s/iter. Total: 0.7705 s/iter. ETA=0:00:15
[08/26 13:58:33 d2.evaluation.evaluator]: Inference done 132/144. Dataloading: 0.0027 s/iter. Inference: 0.2533 s/iter. Eval: 0.5074 s/iter. Total: 0.7639 s/iter. ETA=0:00:09
[08/26 13:58:38 d2.evaluation.evaluator]: Inference done 139/144. Dataloading: 0.0027 s/iter. Inference: 0.2545 s/iter. Eval: 0.5037 s/iter. Total: 0.7613 s/iter. ETA=0:00:03
[08/26 13:58:43 d2.evaluation.evaluator]: Total inference time: 0:01:46.345303 (0.765074 s / iter per device, on 1 devices)
[08/26 13:58:43 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:35 (0.254555 s / iter per device, on 1 devices)
[08/26 13:58:43 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 13:58:43 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 13:58:43 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/26 13:58:43 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 13:58:43 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[08/26 13:58:43 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 13:58:43 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.391
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.619
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.422
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.114
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.382
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.481
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.298
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.538
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.609
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.590
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.712
[08/26 13:58:43 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 39.103 | 61.861 | 42.221 | 11.419 | 38.184 | 48.069 |
Loading and preparing results...
DONE (t=0.26s)
creating index...
index created!
[08/26 13:58:44 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 13:58:44 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.18 seconds.
[08/26 13:58:44 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 13:58:44 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.432
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.634
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.508
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.073
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.380
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.590
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.592
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.675
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.342
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.652
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.776
[08/26 13:58:44 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 43.230 | 63.379 | 50.763 | 7.262 | 37.968 | 59.005 |
[08/26 13:58:44 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 13:58:44 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 13:58:44 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 13:58:44 d2.evaluation.testing]: copypaste: 39.1032,61.8613,42.2205,11.4193,38.1841,48.0689
[08/26 13:58:44 d2.evaluation.testing]: copypaste: Task: segm
[08/26 13:58:44 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 13:58:44 d2.evaluation.testing]: copypaste: 43.2304,63.3788,50.7634,7.2621,37.9683,59.0045
[08/26 13:58:44 d2.utils.events]:  eta: 0:23:12  iter: 259  total_loss: 0.8573  loss_cls: 0.166  loss_box_reg: 0.3779  loss_mask: 0.2455  loss_rpn_cls: 0.01383  loss_rpn_loc: 0.007376  time: 1.8906  data_time: 0.0261  lr: 6.4935e-05  max_mem: 10070M
[08/26 13:59:22 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 13:59:22 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 13:59:22 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 13:59:22 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 13:59:22 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 13:59:32 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0022 s/iter. Inference: 0.2605 s/iter. Eval: 0.5691 s/iter. Total: 0.8318 s/iter. ETA=0:01:50
[08/26 13:59:37 d2.evaluation.evaluator]: Inference done 19/144. Dataloading: 0.0026 s/iter. Inference: 0.2514 s/iter. Eval: 0.4752 s/iter. Total: 0.7294 s/iter. ETA=0:01:31
[08/26 13:59:42 d2.evaluation.evaluator]: Inference done 26/144. Dataloading: 0.0027 s/iter. Inference: 0.2509 s/iter. Eval: 0.4728 s/iter. Total: 0.7266 s/iter. ETA=0:01:25
[08/26 13:59:48 d2.evaluation.evaluator]: Inference done 33/144. Dataloading: 0.0027 s/iter. Inference: 0.2515 s/iter. Eval: 0.4790 s/iter. Total: 0.7334 s/iter. ETA=0:01:21
[08/26 13:59:53 d2.evaluation.evaluator]: Inference done 39/144. Dataloading: 0.0026 s/iter. Inference: 0.2523 s/iter. Eval: 0.5050 s/iter. Total: 0.7602 s/iter. ETA=0:01:19
[08/26 13:59:58 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0027 s/iter. Inference: 0.2531 s/iter. Eval: 0.5107 s/iter. Total: 0.7667 s/iter. ETA=0:01:15
[08/26 14:00:04 d2.evaluation.evaluator]: Inference done 52/144. Dataloading: 0.0027 s/iter. Inference: 0.2545 s/iter. Eval: 0.5308 s/iter. Total: 0.7883 s/iter. ETA=0:01:12
[08/26 14:00:10 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0026 s/iter. Inference: 0.2552 s/iter. Eval: 0.5367 s/iter. Total: 0.7948 s/iter. ETA=0:01:07
[08/26 14:00:15 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0026 s/iter. Inference: 0.2558 s/iter. Eval: 0.5443 s/iter. Total: 0.8030 s/iter. ETA=0:01:03
[08/26 14:00:20 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0027 s/iter. Inference: 0.2564 s/iter. Eval: 0.5494 s/iter. Total: 0.8088 s/iter. ETA=0:00:59
[08/26 14:00:26 d2.evaluation.evaluator]: Inference done 78/144. Dataloading: 0.0027 s/iter. Inference: 0.2558 s/iter. Eval: 0.5480 s/iter. Total: 0.8068 s/iter. ETA=0:00:53
[08/26 14:00:32 d2.evaluation.evaluator]: Inference done 87/144. Dataloading: 0.0027 s/iter. Inference: 0.2544 s/iter. Eval: 0.5303 s/iter. Total: 0.7877 s/iter. ETA=0:00:44
[08/26 14:00:37 d2.evaluation.evaluator]: Inference done 94/144. Dataloading: 0.0027 s/iter. Inference: 0.2542 s/iter. Eval: 0.5289 s/iter. Total: 0.7861 s/iter. ETA=0:00:39
[08/26 14:00:42 d2.evaluation.evaluator]: Inference done 102/144. Dataloading: 0.0027 s/iter. Inference: 0.2533 s/iter. Eval: 0.5168 s/iter. Total: 0.7731 s/iter. ETA=0:00:32
[08/26 14:00:47 d2.evaluation.evaluator]: Inference done 109/144. Dataloading: 0.0027 s/iter. Inference: 0.2532 s/iter. Eval: 0.5142 s/iter. Total: 0.7704 s/iter. ETA=0:00:26
[08/26 14:00:52 d2.evaluation.evaluator]: Inference done 117/144. Dataloading: 0.0027 s/iter. Inference: 0.2526 s/iter. Eval: 0.5062 s/iter. Total: 0.7618 s/iter. ETA=0:00:20
[08/26 14:00:58 d2.evaluation.evaluator]: Inference done 124/144. Dataloading: 0.0027 s/iter. Inference: 0.2522 s/iter. Eval: 0.5078 s/iter. Total: 0.7630 s/iter. ETA=0:00:15
[08/26 14:01:03 d2.evaluation.evaluator]: Inference done 132/144. Dataloading: 0.0027 s/iter. Inference: 0.2519 s/iter. Eval: 0.5019 s/iter. Total: 0.7569 s/iter. ETA=0:00:09
[08/26 14:01:08 d2.evaluation.evaluator]: Inference done 140/144. Dataloading: 0.0027 s/iter. Inference: 0.2515 s/iter. Eval: 0.4950 s/iter. Total: 0.7496 s/iter. ETA=0:00:02
[08/26 14:01:12 d2.evaluation.evaluator]: Total inference time: 0:01:44.842898 (0.754265 s / iter per device, on 1 devices)
[08/26 14:01:12 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:35 (0.251872 s / iter per device, on 1 devices)
[08/26 14:01:12 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 14:01:12 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 14:01:12 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/26 14:01:12 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 14:01:12 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.
[08/26 14:01:12 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:01:12 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.399
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.632
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.445
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.122
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.386
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.493
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.293
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.546
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.605
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.267
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.583
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.705
[08/26 14:01:12 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 39.945 | 63.200 | 44.493 | 12.187 | 38.551 | 49.257 |
Loading and preparing results...
DONE (t=0.23s)
creating index...
index created!
[08/26 14:01:13 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 14:01:13 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.17 seconds.
[08/26 14:01:13 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:01:13 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.441
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.650
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.516
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.085
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.388
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.594
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.604
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.682
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.660
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.779
[08/26 14:01:13 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 44.084 | 64.980 | 51.560 | 8.453 | 38.832 | 59.368 |
[08/26 14:01:13 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 14:01:13 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 14:01:13 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:01:13 d2.evaluation.testing]: copypaste: 39.9445,63.2000,44.4934,12.1871,38.5505,49.2570
[08/26 14:01:13 d2.evaluation.testing]: copypaste: Task: segm
[08/26 14:01:13 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:01:13 d2.evaluation.testing]: copypaste: 44.0840,64.9801,51.5604,8.4530,38.8322,59.3678
[08/26 14:01:13 d2.utils.events]:  eta: 0:22:35  iter: 279  total_loss: 0.8666  loss_cls: 0.1819  loss_box_reg: 0.4459  loss_mask: 0.2438  loss_rpn_cls: 0.01624  loss_rpn_loc: 0.009294  time: 1.8912  data_time: 0.0268  lr: 6.993e-05  max_mem: 10070M
[08/26 14:01:51 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 14:01:51 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 14:01:51 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 14:01:51 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 14:01:51 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 14:02:01 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0020 s/iter. Inference: 0.2503 s/iter. Eval: 0.4776 s/iter. Total: 0.7299 s/iter. ETA=0:01:37
[08/26 14:02:06 d2.evaluation.evaluator]: Inference done 18/144. Dataloading: 0.0031 s/iter. Inference: 0.2520 s/iter. Eval: 0.4777 s/iter. Total: 0.7331 s/iter. ETA=0:01:32
[08/26 14:02:12 d2.evaluation.evaluator]: Inference done 28/144. Dataloading: 0.0030 s/iter. Inference: 0.2455 s/iter. Eval: 0.4101 s/iter. Total: 0.6588 s/iter. ETA=0:01:16
[08/26 14:02:17 d2.evaluation.evaluator]: Inference done 37/144. Dataloading: 0.0029 s/iter. Inference: 0.2436 s/iter. Eval: 0.3956 s/iter. Total: 0.6423 s/iter. ETA=0:01:08
[08/26 14:02:22 d2.evaluation.evaluator]: Inference done 44/144. Dataloading: 0.0029 s/iter. Inference: 0.2448 s/iter. Eval: 0.4094 s/iter. Total: 0.6574 s/iter. ETA=0:01:05
[08/26 14:02:28 d2.evaluation.evaluator]: Inference done 50/144. Dataloading: 0.0030 s/iter. Inference: 0.2475 s/iter. Eval: 0.4442 s/iter. Total: 0.6949 s/iter. ETA=0:01:05
[08/26 14:02:34 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0030 s/iter. Inference: 0.2489 s/iter. Eval: 0.4601 s/iter. Total: 0.7123 s/iter. ETA=0:01:01
[08/26 14:02:39 d2.evaluation.evaluator]: Inference done 63/144. Dataloading: 0.0030 s/iter. Inference: 0.2499 s/iter. Eval: 0.4749 s/iter. Total: 0.7280 s/iter. ETA=0:00:58
[08/26 14:02:44 d2.evaluation.evaluator]: Inference done 70/144. Dataloading: 0.0029 s/iter. Inference: 0.2508 s/iter. Eval: 0.4834 s/iter. Total: 0.7374 s/iter. ETA=0:00:54
[08/26 14:02:50 d2.evaluation.evaluator]: Inference done 79/144. Dataloading: 0.0029 s/iter. Inference: 0.2492 s/iter. Eval: 0.4660 s/iter. Total: 0.7183 s/iter. ETA=0:00:46
[08/26 14:02:55 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0028 s/iter. Inference: 0.2474 s/iter. Eval: 0.4443 s/iter. Total: 0.6948 s/iter. ETA=0:00:38
[08/26 14:03:00 d2.evaluation.evaluator]: Inference done 99/144. Dataloading: 0.0028 s/iter. Inference: 0.2460 s/iter. Eval: 0.4253 s/iter. Total: 0.6743 s/iter. ETA=0:00:30
[08/26 14:03:05 d2.evaluation.evaluator]: Inference done 107/144. Dataloading: 0.0028 s/iter. Inference: 0.2458 s/iter. Eval: 0.4236 s/iter. Total: 0.6725 s/iter. ETA=0:00:24
[08/26 14:03:10 d2.evaluation.evaluator]: Inference done 114/144. Dataloading: 0.0028 s/iter. Inference: 0.2471 s/iter. Eval: 0.4264 s/iter. Total: 0.6765 s/iter. ETA=0:00:20
[08/26 14:03:16 d2.evaluation.evaluator]: Inference done 124/144. Dataloading: 0.0028 s/iter. Inference: 0.2461 s/iter. Eval: 0.4149 s/iter. Total: 0.6641 s/iter. ETA=0:00:13
[08/26 14:03:21 d2.evaluation.evaluator]: Inference done 133/144. Dataloading: 0.0028 s/iter. Inference: 0.2458 s/iter. Eval: 0.4125 s/iter. Total: 0.6614 s/iter. ETA=0:00:07
[08/26 14:03:26 d2.evaluation.evaluator]: Inference done 142/144. Dataloading: 0.0028 s/iter. Inference: 0.2453 s/iter. Eval: 0.4068 s/iter. Total: 0.6551 s/iter. ETA=0:00:01
[08/26 14:03:28 d2.evaluation.evaluator]: Total inference time: 0:01:31.410440 (0.657629 s / iter per device, on 1 devices)
[08/26 14:03:28 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:34 (0.245468 s / iter per device, on 1 devices)
[08/26 14:03:28 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 14:03:28 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 14:03:28 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/26 14:03:28 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 14:03:28 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.09 seconds.
[08/26 14:03:28 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:03:28 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.402
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.640
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.448
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.116
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.393
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.494
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.299
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.539
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.604
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.225
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.588
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.700
[08/26 14:03:28 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 40.208 | 63.962 | 44.807 | 11.604 | 39.336 | 49.412 |
Loading and preparing results...
DONE (t=0.19s)
creating index...
index created!
[08/26 14:03:29 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 14:03:29 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.15 seconds.
[08/26 14:03:29 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:03:29 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.445
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.661
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.517
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.098
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.393
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.597
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.596
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.677
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.653
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.777
[08/26 14:03:29 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 44.511 | 66.064 | 51.692 | 9.840 | 39.266 | 59.692 |
[08/26 14:03:29 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 14:03:29 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 14:03:29 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:03:29 d2.evaluation.testing]: copypaste: 40.2084,63.9616,44.8071,11.6044,39.3364,49.4120
[08/26 14:03:29 d2.evaluation.testing]: copypaste: Task: segm
[08/26 14:03:29 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:03:29 d2.evaluation.testing]: copypaste: 44.5113,66.0644,51.6924,9.8401,39.2658,59.6918
[08/26 14:03:29 d2.utils.events]:  eta: 0:21:57  iter: 299  total_loss: 0.8243  loss_cls: 0.1476  loss_box_reg: 0.4005  loss_mask: 0.2163  loss_rpn_cls: 0.01292  loss_rpn_loc: 0.01123  time: 1.8911  data_time: 0.0268  lr: 7.4925e-05  max_mem: 10070M
[08/26 14:04:07 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 14:04:07 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 14:04:07 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 14:04:07 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 14:04:07 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 14:04:16 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0020 s/iter. Inference: 0.2522 s/iter. Eval: 0.4612 s/iter. Total: 0.7154 s/iter. ETA=0:01:35
[08/26 14:04:22 d2.evaluation.evaluator]: Inference done 21/144. Dataloading: 0.0024 s/iter. Inference: 0.2429 s/iter. Eval: 0.3844 s/iter. Total: 0.6300 s/iter. ETA=0:01:17
[08/26 14:04:27 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0024 s/iter. Inference: 0.2403 s/iter. Eval: 0.3497 s/iter. Total: 0.5928 s/iter. ETA=0:01:06
[08/26 14:04:32 d2.evaluation.evaluator]: Inference done 40/144. Dataloading: 0.0025 s/iter. Inference: 0.2401 s/iter. Eval: 0.3500 s/iter. Total: 0.5930 s/iter. ETA=0:01:01
[08/26 14:04:38 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0025 s/iter. Inference: 0.2424 s/iter. Eval: 0.3827 s/iter. Total: 0.6280 s/iter. ETA=0:01:00
[08/26 14:04:43 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0025 s/iter. Inference: 0.2449 s/iter. Eval: 0.4106 s/iter. Total: 0.6584 s/iter. ETA=0:00:59
[08/26 14:04:49 d2.evaluation.evaluator]: Inference done 60/144. Dataloading: 0.0025 s/iter. Inference: 0.2461 s/iter. Eval: 0.4227 s/iter. Total: 0.6717 s/iter. ETA=0:00:56
[08/26 14:04:54 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0026 s/iter. Inference: 0.2465 s/iter. Eval: 0.4312 s/iter. Total: 0.6806 s/iter. ETA=0:00:52
[08/26 14:04:59 d2.evaluation.evaluator]: Inference done 75/144. Dataloading: 0.0026 s/iter. Inference: 0.2462 s/iter. Eval: 0.4253 s/iter. Total: 0.6745 s/iter. ETA=0:00:46
[08/26 14:05:04 d2.evaluation.evaluator]: Inference done 86/144. Dataloading: 0.0026 s/iter. Inference: 0.2443 s/iter. Eval: 0.3980 s/iter. Total: 0.6454 s/iter. ETA=0:00:37
[08/26 14:05:09 d2.evaluation.evaluator]: Inference done 97/144. Dataloading: 0.0027 s/iter. Inference: 0.2428 s/iter. Eval: 0.3810 s/iter. Total: 0.6269 s/iter. ETA=0:00:29
[08/26 14:05:15 d2.evaluation.evaluator]: Inference done 106/144. Dataloading: 0.0027 s/iter. Inference: 0.2428 s/iter. Eval: 0.3765 s/iter. Total: 0.6223 s/iter. ETA=0:00:23
[08/26 14:05:20 d2.evaluation.evaluator]: Inference done 115/144. Dataloading: 0.0027 s/iter. Inference: 0.2424 s/iter. Eval: 0.3725 s/iter. Total: 0.6179 s/iter. ETA=0:00:17
[08/26 14:05:25 d2.evaluation.evaluator]: Inference done 126/144. Dataloading: 0.0027 s/iter. Inference: 0.2416 s/iter. Eval: 0.3608 s/iter. Total: 0.6055 s/iter. ETA=0:00:10
[08/26 14:05:30 d2.evaluation.evaluator]: Inference done 135/144. Dataloading: 0.0028 s/iter. Inference: 0.2416 s/iter. Eval: 0.3608 s/iter. Total: 0.6055 s/iter. ETA=0:00:05
[08/26 14:05:36 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0028 s/iter. Inference: 0.2417 s/iter. Eval: 0.3602 s/iter. Total: 0.6051 s/iter. ETA=0:00:00
[08/26 14:05:36 d2.evaluation.evaluator]: Total inference time: 0:01:24.176525 (0.605587 s / iter per device, on 1 devices)
[08/26 14:05:36 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:33 (0.241711 s / iter per device, on 1 devices)
[08/26 14:05:36 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 14:05:36 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 14:05:36 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/26 14:05:36 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 14:05:36 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.08 seconds.
[08/26 14:05:36 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:05:36 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.408
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.642
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.452
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.133
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.400
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.498
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.307
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.545
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.606
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.225
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.597
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.689
[08/26 14:05:36 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 40.831 | 64.222 | 45.156 | 13.266 | 40.015 | 49.815 |
Loading and preparing results...
DONE (t=0.17s)
creating index...
index created!
[08/26 14:05:37 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 14:05:37 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.14 seconds.
[08/26 14:05:37 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:05:37 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.453
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.663
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.523
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.400
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.608
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.327
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.601
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.677
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.375
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.651
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.776
[08/26 14:05:37 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.320 | 66.253 | 52.320 | 10.029 | 39.972 | 60.777 |
[08/26 14:05:37 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 14:05:37 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 14:05:37 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:05:37 d2.evaluation.testing]: copypaste: 40.8310,64.2225,45.1562,13.2655,40.0147,49.8152
[08/26 14:05:37 d2.evaluation.testing]: copypaste: Task: segm
[08/26 14:05:37 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:05:37 d2.evaluation.testing]: copypaste: 45.3196,66.2534,52.3200,10.0292,39.9723,60.7767
[08/26 14:05:37 d2.utils.events]:  eta: 0:21:20  iter: 319  total_loss: 0.829  loss_cls: 0.1515  loss_box_reg: 0.413  loss_mask: 0.2133  loss_rpn_cls: 0.005948  loss_rpn_loc: 0.009117  time: 1.8912  data_time: 0.0276  lr: 7.992e-05  max_mem: 10070M
[08/26 14:06:15 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 14:06:15 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 14:06:15 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 14:06:15 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 14:06:15 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 14:06:23 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0020 s/iter. Inference: 0.2411 s/iter. Eval: 0.3735 s/iter. Total: 0.6165 s/iter. ETA=0:01:22
[08/26 14:06:29 d2.evaluation.evaluator]: Inference done 21/144. Dataloading: 0.0027 s/iter. Inference: 0.2362 s/iter. Eval: 0.3180 s/iter. Total: 0.5571 s/iter. ETA=0:01:08
[08/26 14:06:34 d2.evaluation.evaluator]: Inference done 30/144. Dataloading: 0.0026 s/iter. Inference: 0.2350 s/iter. Eval: 0.3204 s/iter. Total: 0.5583 s/iter. ETA=0:01:03
[08/26 14:06:39 d2.evaluation.evaluator]: Inference done 39/144. Dataloading: 0.0027 s/iter. Inference: 0.2355 s/iter. Eval: 0.3213 s/iter. Total: 0.5598 s/iter. ETA=0:00:58
[08/26 14:06:44 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0031 s/iter. Inference: 0.2384 s/iter. Eval: 0.3494 s/iter. Total: 0.5911 s/iter. ETA=0:00:57
[08/26 14:06:50 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0030 s/iter. Inference: 0.2412 s/iter. Eval: 0.3800 s/iter. Total: 0.6245 s/iter. ETA=0:00:56
[08/26 14:06:55 d2.evaluation.evaluator]: Inference done 61/144. Dataloading: 0.0031 s/iter. Inference: 0.2424 s/iter. Eval: 0.3925 s/iter. Total: 0.6382 s/iter. ETA=0:00:52
[08/26 14:07:01 d2.evaluation.evaluator]: Inference done 69/144. Dataloading: 0.0030 s/iter. Inference: 0.2427 s/iter. Eval: 0.3988 s/iter. Total: 0.6448 s/iter. ETA=0:00:48
[08/26 14:07:06 d2.evaluation.evaluator]: Inference done 79/144. Dataloading: 0.0031 s/iter. Inference: 0.2425 s/iter. Eval: 0.3874 s/iter. Total: 0.6333 s/iter. ETA=0:00:41
[08/26 14:07:12 d2.evaluation.evaluator]: Inference done 90/144. Dataloading: 0.0030 s/iter. Inference: 0.2410 s/iter. Eval: 0.3668 s/iter. Total: 0.6111 s/iter. ETA=0:00:33
[08/26 14:07:17 d2.evaluation.evaluator]: Inference done 102/144. Dataloading: 0.0030 s/iter. Inference: 0.2394 s/iter. Eval: 0.3471 s/iter. Total: 0.5897 s/iter. ETA=0:00:24
[08/26 14:07:22 d2.evaluation.evaluator]: Inference done 111/144. Dataloading: 0.0030 s/iter. Inference: 0.2394 s/iter. Eval: 0.3459 s/iter. Total: 0.5885 s/iter. ETA=0:00:19
[08/26 14:07:27 d2.evaluation.evaluator]: Inference done 122/144. Dataloading: 0.0030 s/iter. Inference: 0.2386 s/iter. Eval: 0.3347 s/iter. Total: 0.5766 s/iter. ETA=0:00:12
[08/26 14:07:32 d2.evaluation.evaluator]: Inference done 132/144. Dataloading: 0.0030 s/iter. Inference: 0.2381 s/iter. Eval: 0.3295 s/iter. Total: 0.5708 s/iter. ETA=0:00:06
[08/26 14:07:37 d2.evaluation.evaluator]: Inference done 142/144. Dataloading: 0.0030 s/iter. Inference: 0.2379 s/iter. Eval: 0.3255 s/iter. Total: 0.5666 s/iter. ETA=0:00:01
[08/26 14:07:39 d2.evaluation.evaluator]: Total inference time: 0:01:19.588680 (0.572580 s / iter per device, on 1 devices)
[08/26 14:07:39 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:33 (0.238143 s / iter per device, on 1 devices)
[08/26 14:07:39 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 14:07:39 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 14:07:39 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/26 14:07:39 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 14:07:40 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.08 seconds.
[08/26 14:07:40 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:07:40 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.419
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.654
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.478
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.133
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.411
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.510
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.309
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.559
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.622
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.250
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.614
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.703
[08/26 14:07:40 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 41.907 | 65.370 | 47.774 | 13.281 | 41.086 | 51.027 |
Loading and preparing results...
DONE (t=0.15s)
creating index...
index created!
[08/26 14:07:40 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 14:07:40 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.13 seconds.
[08/26 14:07:40 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:07:40 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.461
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.676
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.533
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.105
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.408
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.614
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.327
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.608
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.681
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.383
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.656
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.779
[08/26 14:07:40 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.125 | 67.565 | 53.316 | 10.477 | 40.812 | 61.400 |
[08/26 14:07:40 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 14:07:40 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 14:07:40 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:07:40 d2.evaluation.testing]: copypaste: 41.9067,65.3702,47.7737,13.2805,41.0862,51.0268
[08/26 14:07:40 d2.evaluation.testing]: copypaste: Task: segm
[08/26 14:07:40 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:07:40 d2.evaluation.testing]: copypaste: 46.1248,67.5651,53.3163,10.4769,40.8119,61.4003
[08/26 14:07:40 d2.utils.events]:  eta: 0:20:42  iter: 339  total_loss: 0.7483  loss_cls: 0.1092  loss_box_reg: 0.3952  loss_mask: 0.1813  loss_rpn_cls: 0.008517  loss_rpn_loc: 0.006052  time: 1.8909  data_time: 0.0246  lr: 8.4915e-05  max_mem: 10070M
[08/26 14:08:18 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 14:08:18 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 14:08:18 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 14:08:18 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 14:08:18 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 14:08:26 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0020 s/iter. Inference: 0.2419 s/iter. Eval: 0.3787 s/iter. Total: 0.6226 s/iter. ETA=0:01:22
[08/26 14:08:31 d2.evaluation.evaluator]: Inference done 21/144. Dataloading: 0.0027 s/iter. Inference: 0.2359 s/iter. Eval: 0.3086 s/iter. Total: 0.5474 s/iter. ETA=0:01:07
[08/26 14:08:37 d2.evaluation.evaluator]: Inference done 32/144. Dataloading: 0.0026 s/iter. Inference: 0.2340 s/iter. Eval: 0.2830 s/iter. Total: 0.5199 s/iter. ETA=0:00:58
[08/26 14:08:42 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0029 s/iter. Inference: 0.2353 s/iter. Eval: 0.2956 s/iter. Total: 0.5341 s/iter. ETA=0:00:55
[08/26 14:08:47 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0029 s/iter. Inference: 0.2392 s/iter. Eval: 0.3365 s/iter. Total: 0.5789 s/iter. ETA=0:00:56
[08/26 14:08:52 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0028 s/iter. Inference: 0.2422 s/iter. Eval: 0.3666 s/iter. Total: 0.6119 s/iter. ETA=0:00:55
[08/26 14:08:58 d2.evaluation.evaluator]: Inference done 61/144. Dataloading: 0.0028 s/iter. Inference: 0.2431 s/iter. Eval: 0.3793 s/iter. Total: 0.6255 s/iter. ETA=0:00:51
[08/26 14:09:03 d2.evaluation.evaluator]: Inference done 69/144. Dataloading: 0.0029 s/iter. Inference: 0.2440 s/iter. Eval: 0.3873 s/iter. Total: 0.6344 s/iter. ETA=0:00:47
[08/26 14:09:08 d2.evaluation.evaluator]: Inference done 80/144. Dataloading: 0.0028 s/iter. Inference: 0.2421 s/iter. Eval: 0.3670 s/iter. Total: 0.6122 s/iter. ETA=0:00:39
[08/26 14:09:14 d2.evaluation.evaluator]: Inference done 91/144. Dataloading: 0.0028 s/iter. Inference: 0.2405 s/iter. Eval: 0.3499 s/iter. Total: 0.5934 s/iter. ETA=0:00:31
[08/26 14:09:19 d2.evaluation.evaluator]: Inference done 102/144. Dataloading: 0.0028 s/iter. Inference: 0.2395 s/iter. Eval: 0.3371 s/iter. Total: 0.5796 s/iter. ETA=0:00:24
[08/26 14:09:24 d2.evaluation.evaluator]: Inference done 111/144. Dataloading: 0.0027 s/iter. Inference: 0.2396 s/iter. Eval: 0.3372 s/iter. Total: 0.5798 s/iter. ETA=0:00:19
[08/26 14:09:29 d2.evaluation.evaluator]: Inference done 123/144. Dataloading: 0.0028 s/iter. Inference: 0.2386 s/iter. Eval: 0.3256 s/iter. Total: 0.5671 s/iter. ETA=0:00:11
[08/26 14:09:35 d2.evaluation.evaluator]: Inference done 133/144. Dataloading: 0.0028 s/iter. Inference: 0.2383 s/iter. Eval: 0.3220 s/iter. Total: 0.5633 s/iter. ETA=0:00:06
[08/26 14:09:40 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0028 s/iter. Inference: 0.2380 s/iter. Eval: 0.3194 s/iter. Total: 0.5605 s/iter. ETA=0:00:00
[08/26 14:09:41 d2.evaluation.evaluator]: Total inference time: 0:01:17.974931 (0.560971 s / iter per device, on 1 devices)
[08/26 14:09:41 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:33 (0.238032 s / iter per device, on 1 devices)
[08/26 14:09:41 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 14:09:41 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 14:09:41 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/26 14:09:41 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 14:09:41 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.08 seconds.
[08/26 14:09:41 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:09:41 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.428
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.660
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.493
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.127
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.407
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.538
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.321
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.562
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.614
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.233
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.589
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.727
[08/26 14:09:41 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 42.837 | 66.016 | 49.289 | 12.720 | 40.674 | 53.799 |
Loading and preparing results...
DONE (t=0.15s)
creating index...
index created!
[08/26 14:09:41 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 14:09:41 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.13 seconds.
[08/26 14:09:41 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:09:41 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.467
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.684
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.538
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.139
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.410
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.629
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.337
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.611
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.675
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.375
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.645
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.782
[08/26 14:09:41 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.694 | 68.360 | 53.808 | 13.891 | 40.992 | 62.939 |
[08/26 14:09:41 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 14:09:41 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 14:09:41 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:09:41 d2.evaluation.testing]: copypaste: 42.8366,66.0155,49.2887,12.7196,40.6744,53.7989
[08/26 14:09:41 d2.evaluation.testing]: copypaste: Task: segm
[08/26 14:09:41 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:09:41 d2.evaluation.testing]: copypaste: 46.6945,68.3598,53.8075,13.8906,40.9922,62.9390
[08/26 14:09:41 d2.utils.events]:  eta: 0:20:05  iter: 359  total_loss: 0.6987  loss_cls: 0.1109  loss_box_reg: 0.3857  loss_mask: 0.1766  loss_rpn_cls: 0.005993  loss_rpn_loc: 0.006343  time: 1.8906  data_time: 0.0237  lr: 8.991e-05  max_mem: 10070M
[08/26 14:10:19 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 14:10:19 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 14:10:19 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 14:10:19 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 14:10:19 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 14:10:28 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0019 s/iter. Inference: 0.2448 s/iter. Eval: 0.3413 s/iter. Total: 0.5880 s/iter. ETA=0:01:18
[08/26 14:10:33 d2.evaluation.evaluator]: Inference done 22/144. Dataloading: 0.0022 s/iter. Inference: 0.2363 s/iter. Eval: 0.2701 s/iter. Total: 0.5088 s/iter. ETA=0:01:02
[08/26 14:10:38 d2.evaluation.evaluator]: Inference done 33/144. Dataloading: 0.0024 s/iter. Inference: 0.2336 s/iter. Eval: 0.2521 s/iter. Total: 0.4883 s/iter. ETA=0:00:54
[08/26 14:10:44 d2.evaluation.evaluator]: Inference done 43/144. Dataloading: 0.0024 s/iter. Inference: 0.2350 s/iter. Eval: 0.2736 s/iter. Total: 0.5113 s/iter. ETA=0:00:51
[08/26 14:10:50 d2.evaluation.evaluator]: Inference done 50/144. Dataloading: 0.0024 s/iter. Inference: 0.2424 s/iter. Eval: 0.3153 s/iter. Total: 0.5604 s/iter. ETA=0:00:52
[08/26 14:10:55 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0025 s/iter. Inference: 0.2435 s/iter. Eval: 0.3371 s/iter. Total: 0.5833 s/iter. ETA=0:00:50
[08/26 14:11:00 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0025 s/iter. Inference: 0.2437 s/iter. Eval: 0.3465 s/iter. Total: 0.5930 s/iter. ETA=0:00:46
[08/26 14:11:05 d2.evaluation.evaluator]: Inference done 73/144. Dataloading: 0.0025 s/iter. Inference: 0.2437 s/iter. Eval: 0.3509 s/iter. Total: 0.5974 s/iter. ETA=0:00:42
[08/26 14:11:10 d2.evaluation.evaluator]: Inference done 86/144. Dataloading: 0.0025 s/iter. Inference: 0.2407 s/iter. Eval: 0.3227 s/iter. Total: 0.5662 s/iter. ETA=0:00:32
[08/26 14:11:15 d2.evaluation.evaluator]: Inference done 98/144. Dataloading: 0.0025 s/iter. Inference: 0.2388 s/iter. Eval: 0.3057 s/iter. Total: 0.5473 s/iter. ETA=0:00:25
[08/26 14:11:21 d2.evaluation.evaluator]: Inference done 108/144. Dataloading: 0.0026 s/iter. Inference: 0.2384 s/iter. Eval: 0.3037 s/iter. Total: 0.5450 s/iter. ETA=0:00:19
[08/26 14:11:26 d2.evaluation.evaluator]: Inference done 120/144. Dataloading: 0.0026 s/iter. Inference: 0.2375 s/iter. Eval: 0.2938 s/iter. Total: 0.5341 s/iter. ETA=0:00:12
[08/26 14:11:31 d2.evaluation.evaluator]: Inference done 130/144. Dataloading: 0.0027 s/iter. Inference: 0.2374 s/iter. Eval: 0.2915 s/iter. Total: 0.5318 s/iter. ETA=0:00:07
[08/26 14:11:37 d2.evaluation.evaluator]: Inference done 142/144. Dataloading: 0.0026 s/iter. Inference: 0.2371 s/iter. Eval: 0.2871 s/iter. Total: 0.5272 s/iter. ETA=0:00:01
[08/26 14:11:38 d2.evaluation.evaluator]: Total inference time: 0:01:13.726336 (0.530405 s / iter per device, on 1 devices)
[08/26 14:11:38 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:32 (0.237303 s / iter per device, on 1 devices)
[08/26 14:11:38 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 14:11:38 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 14:11:38 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/26 14:11:38 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 14:11:38 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.08 seconds.
[08/26 14:11:38 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:11:38 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.439
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.673
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.498
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.127
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.412
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.560
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.326
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.565
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.622
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.591
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.748
[08/26 14:11:38 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 43.942 | 67.338 | 49.761 | 12.682 | 41.159 | 56.018 |
Loading and preparing results...
DONE (t=0.14s)
creating index...
index created!
[08/26 14:11:39 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 14:11:39 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.13 seconds.
[08/26 14:11:39 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:11:39 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.475
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.696
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.543
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.140
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.416
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.640
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.340
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.677
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.649
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.786
[08/26 14:11:39 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.538 | 69.561 | 54.319 | 14.016 | 41.607 | 63.981 |
[08/26 14:11:39 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 14:11:39 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 14:11:39 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:11:39 d2.evaluation.testing]: copypaste: 43.9421,67.3383,49.7613,12.6824,41.1592,56.0182
[08/26 14:11:39 d2.evaluation.testing]: copypaste: Task: segm
[08/26 14:11:39 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:11:39 d2.evaluation.testing]: copypaste: 47.5381,69.5612,54.3189,14.0164,41.6067,63.9815
[08/26 14:11:39 d2.utils.events]:  eta: 0:19:27  iter: 379  total_loss: 0.7927  loss_cls: 0.1152  loss_box_reg: 0.3447  loss_mask: 0.2215  loss_rpn_cls: 0.01198  loss_rpn_loc: 0.008745  time: 1.8910  data_time: 0.0254  lr: 9.4905e-05  max_mem: 10070M
[08/26 14:12:17 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 14:12:17 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 14:12:17 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 14:12:17 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 14:12:17 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 14:12:25 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0027 s/iter. Inference: 0.2366 s/iter. Eval: 0.3187 s/iter. Total: 0.5581 s/iter. ETA=0:01:14
[08/26 14:12:30 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0026 s/iter. Inference: 0.2310 s/iter. Eval: 0.2502 s/iter. Total: 0.4839 s/iter. ETA=0:00:58
[08/26 14:12:35 d2.evaluation.evaluator]: Inference done 34/144. Dataloading: 0.0029 s/iter. Inference: 0.2299 s/iter. Eval: 0.2456 s/iter. Total: 0.4788 s/iter. ETA=0:00:52
[08/26 14:12:41 d2.evaluation.evaluator]: Inference done 44/144. Dataloading: 0.0029 s/iter. Inference: 0.2323 s/iter. Eval: 0.2649 s/iter. Total: 0.5004 s/iter. ETA=0:00:50
[08/26 14:12:46 d2.evaluation.evaluator]: Inference done 50/144. Dataloading: 0.0029 s/iter. Inference: 0.2369 s/iter. Eval: 0.3108 s/iter. Total: 0.5510 s/iter. ETA=0:00:51
[08/26 14:12:52 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0029 s/iter. Inference: 0.2385 s/iter. Eval: 0.3324 s/iter. Total: 0.5743 s/iter. ETA=0:00:49
[08/26 14:12:57 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0029 s/iter. Inference: 0.2396 s/iter. Eval: 0.3387 s/iter. Total: 0.5816 s/iter. ETA=0:00:44
[08/26 14:13:03 d2.evaluation.evaluator]: Inference done 78/144. Dataloading: 0.0028 s/iter. Inference: 0.2386 s/iter. Eval: 0.3272 s/iter. Total: 0.5690 s/iter. ETA=0:00:37
[08/26 14:13:09 d2.evaluation.evaluator]: Inference done 91/144. Dataloading: 0.0028 s/iter. Inference: 0.2368 s/iter. Eval: 0.3085 s/iter. Total: 0.5485 s/iter. ETA=0:00:29
[08/26 14:13:14 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0028 s/iter. Inference: 0.2362 s/iter. Eval: 0.2958 s/iter. Total: 0.5353 s/iter. ETA=0:00:21
[08/26 14:13:19 d2.evaluation.evaluator]: Inference done 115/144. Dataloading: 0.0028 s/iter. Inference: 0.2355 s/iter. Eval: 0.2895 s/iter. Total: 0.5282 s/iter. ETA=0:00:15
[08/26 14:13:25 d2.evaluation.evaluator]: Inference done 128/144. Dataloading: 0.0028 s/iter. Inference: 0.2343 s/iter. Eval: 0.2768 s/iter. Total: 0.5142 s/iter. ETA=0:00:08
[08/26 14:13:30 d2.evaluation.evaluator]: Inference done 139/144. Dataloading: 0.0028 s/iter. Inference: 0.2340 s/iter. Eval: 0.2736 s/iter. Total: 0.5107 s/iter. ETA=0:00:02
[08/26 14:13:33 d2.evaluation.evaluator]: Total inference time: 0:01:11.734249 (0.516074 s / iter per device, on 1 devices)
[08/26 14:13:33 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:32 (0.234333 s / iter per device, on 1 devices)
[08/26 14:13:33 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 14:13:33 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 14:13:33 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/26 14:13:33 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 14:13:33 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[08/26 14:13:33 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:13:33 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.451
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.677
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.531
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.121
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.415
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.584
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.332
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.581
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.630
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.225
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.593
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.768
[08/26 14:13:33 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.050 | 67.712 | 53.126 | 12.135 | 41.467 | 58.363 |
Loading and preparing results...
DONE (t=0.13s)
creating index...
index created!
[08/26 14:13:34 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 14:13:34 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.12 seconds.
[08/26 14:13:34 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:13:34 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.480
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.699
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.552
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.091
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.415
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.651
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.344
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.615
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.675
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.643
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.788
[08/26 14:13:34 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 48.024 | 69.902 | 55.168 | 9.146 | 41.547 | 65.120 |
[08/26 14:13:34 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 14:13:34 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 14:13:34 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:13:34 d2.evaluation.testing]: copypaste: 45.0505,67.7116,53.1264,12.1352,41.4671,58.3628
[08/26 14:13:34 d2.evaluation.testing]: copypaste: Task: segm
[08/26 14:13:34 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:13:34 d2.evaluation.testing]: copypaste: 48.0236,69.9022,55.1679,9.1462,41.5469,65.1202
[08/26 14:13:34 d2.utils.events]:  eta: 0:18:49  iter: 399  total_loss: 0.7527  loss_cls: 0.1323  loss_box_reg: 0.3366  loss_mask: 0.2071  loss_rpn_cls: 0.009776  loss_rpn_loc: 0.00668  time: 1.8909  data_time: 0.0259  lr: 9.99e-05  max_mem: 10070M
[08/26 14:14:12 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 14:14:12 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 14:14:12 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 14:14:12 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 14:14:12 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 14:14:19 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0020 s/iter. Inference: 0.2289 s/iter. Eval: 0.2183 s/iter. Total: 0.4493 s/iter. ETA=0:00:59
[08/26 14:14:24 d2.evaluation.evaluator]: Inference done 26/144. Dataloading: 0.0026 s/iter. Inference: 0.2230 s/iter. Eval: 0.1545 s/iter. Total: 0.3803 s/iter. ETA=0:00:44
[08/26 14:14:29 d2.evaluation.evaluator]: Inference done 40/144. Dataloading: 0.0028 s/iter. Inference: 0.2231 s/iter. Eval: 0.1556 s/iter. Total: 0.3816 s/iter. ETA=0:00:39
[08/26 14:14:34 d2.evaluation.evaluator]: Inference done 48/144. Dataloading: 0.0028 s/iter. Inference: 0.2268 s/iter. Eval: 0.2011 s/iter. Total: 0.4309 s/iter. ETA=0:00:41
[08/26 14:14:40 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0029 s/iter. Inference: 0.2293 s/iter. Eval: 0.2290 s/iter. Total: 0.4614 s/iter. ETA=0:00:40
[08/26 14:14:45 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0029 s/iter. Inference: 0.2307 s/iter. Eval: 0.2443 s/iter. Total: 0.4781 s/iter. ETA=0:00:36
[08/26 14:14:51 d2.evaluation.evaluator]: Inference done 80/144. Dataloading: 0.0030 s/iter. Inference: 0.2300 s/iter. Eval: 0.2321 s/iter. Total: 0.4653 s/iter. ETA=0:00:29
[08/26 14:14:56 d2.evaluation.evaluator]: Inference done 96/144. Dataloading: 0.0029 s/iter. Inference: 0.2282 s/iter. Eval: 0.2096 s/iter. Total: 0.4409 s/iter. ETA=0:00:21
[08/26 14:15:01 d2.evaluation.evaluator]: Inference done 109/144. Dataloading: 0.0029 s/iter. Inference: 0.2277 s/iter. Eval: 0.2045 s/iter. Total: 0.4353 s/iter. ETA=0:00:15
[08/26 14:15:06 d2.evaluation.evaluator]: Inference done 123/144. Dataloading: 0.0029 s/iter. Inference: 0.2272 s/iter. Eval: 0.1981 s/iter. Total: 0.4285 s/iter. ETA=0:00:08
[08/26 14:15:12 d2.evaluation.evaluator]: Inference done 138/144. Dataloading: 0.0029 s/iter. Inference: 0.2265 s/iter. Eval: 0.1894 s/iter. Total: 0.4190 s/iter. ETA=0:00:02
[08/26 14:15:15 d2.evaluation.evaluator]: Total inference time: 0:00:58.825819 (0.423207 s / iter per device, on 1 devices)
[08/26 14:15:15 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:31 (0.226684 s / iter per device, on 1 devices)
[08/26 14:15:15 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 14:15:15 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 14:15:15 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/26 14:15:15 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 14:15:15 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.35 seconds.
[08/26 14:15:15 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:15:15 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.464
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.688
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.540
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.135
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.426
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.600
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.335
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.575
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.633
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.599
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.768
[08/26 14:15:15 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.370 | 68.799 | 54.024 | 13.488 | 42.596 | 59.991 |
Loading and preparing results...
DONE (t=0.10s)
creating index...
index created!
[08/26 14:15:16 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 14:15:16 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.09 seconds.
[08/26 14:15:16 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:15:16 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.484
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.703
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.553
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.139
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.420
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.652
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.342
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.606
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.664
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.630
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.786
[08/26 14:15:16 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.434 | 70.318 | 55.326 | 13.854 | 41.960 | 65.209 |
[08/26 14:15:16 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 14:15:16 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 14:15:16 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:15:16 d2.evaluation.testing]: copypaste: 46.3695,68.7992,54.0237,13.4877,42.5956,59.9910
[08/26 14:15:16 d2.evaluation.testing]: copypaste: Task: segm
[08/26 14:15:16 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:15:16 d2.evaluation.testing]: copypaste: 48.4341,70.3184,55.3262,13.8539,41.9595,65.2091
[08/26 14:15:16 d2.utils.events]:  eta: 0:18:11  iter: 419  total_loss: 0.6312  loss_cls: 0.123  loss_box_reg: 0.2882  loss_mask: 0.1748  loss_rpn_cls: 0.01224  loss_rpn_loc: 0.01175  time: 1.8906  data_time: 0.0251  lr: 0.0001049  max_mem: 10070M
[08/26 14:15:54 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 14:15:54 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 14:15:54 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 14:15:54 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 14:15:54 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 14:16:00 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0022 s/iter. Inference: 0.2332 s/iter. Eval: 0.2394 s/iter. Total: 0.4747 s/iter. ETA=0:01:03
[08/26 14:16:05 d2.evaluation.evaluator]: Inference done 25/144. Dataloading: 0.0025 s/iter. Inference: 0.2254 s/iter. Eval: 0.1668 s/iter. Total: 0.3949 s/iter. ETA=0:00:46
[08/26 14:16:11 d2.evaluation.evaluator]: Inference done 39/144. Dataloading: 0.0027 s/iter. Inference: 0.2262 s/iter. Eval: 0.1647 s/iter. Total: 0.3938 s/iter. ETA=0:00:41
[08/26 14:16:16 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0027 s/iter. Inference: 0.2295 s/iter. Eval: 0.2059 s/iter. Total: 0.4383 s/iter. ETA=0:00:42
[08/26 14:16:21 d2.evaluation.evaluator]: Inference done 54/144. Dataloading: 0.0027 s/iter. Inference: 0.2323 s/iter. Eval: 0.2466 s/iter. Total: 0.4818 s/iter. ETA=0:00:43
[08/26 14:16:26 d2.evaluation.evaluator]: Inference done 63/144. Dataloading: 0.0029 s/iter. Inference: 0.2333 s/iter. Eval: 0.2618 s/iter. Total: 0.4982 s/iter. ETA=0:00:40
[08/26 14:16:32 d2.evaluation.evaluator]: Inference done 73/144. Dataloading: 0.0029 s/iter. Inference: 0.2337 s/iter. Eval: 0.2662 s/iter. Total: 0.5031 s/iter. ETA=0:00:35
[08/26 14:16:37 d2.evaluation.evaluator]: Inference done 87/144. Dataloading: 0.0028 s/iter. Inference: 0.2321 s/iter. Eval: 0.2460 s/iter. Total: 0.4811 s/iter. ETA=0:00:27
[08/26 14:16:42 d2.evaluation.evaluator]: Inference done 102/144. Dataloading: 0.0028 s/iter. Inference: 0.2304 s/iter. Eval: 0.2266 s/iter. Total: 0.4600 s/iter. ETA=0:00:19
[08/26 14:16:47 d2.evaluation.evaluator]: Inference done 114/144. Dataloading: 0.0028 s/iter. Inference: 0.2302 s/iter. Eval: 0.2246 s/iter. Total: 0.4578 s/iter. ETA=0:00:13
[08/26 14:16:53 d2.evaluation.evaluator]: Inference done 129/144. Dataloading: 0.0028 s/iter. Inference: 0.2291 s/iter. Eval: 0.2136 s/iter. Total: 0.4458 s/iter. ETA=0:00:06
[08/26 14:16:58 d2.evaluation.evaluator]: Inference done 142/144. Dataloading: 0.0029 s/iter. Inference: 0.2291 s/iter. Eval: 0.2123 s/iter. Total: 0.4445 s/iter. ETA=0:00:00
[08/26 14:17:00 d2.evaluation.evaluator]: Total inference time: 0:01:02.475486 (0.449464 s / iter per device, on 1 devices)
[08/26 14:17:00 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:31 (0.229396 s / iter per device, on 1 devices)
[08/26 14:17:00 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 14:17:00 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 14:17:00 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/26 14:17:00 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 14:17:00 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/26 14:17:00 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:17:00 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.462
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.688
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.533
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.157
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.423
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.598
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.593
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.637
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.267
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.602
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.765
[08/26 14:17:00 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.191 | 68.803 | 53.306 | 15.692 | 42.306 | 59.758 |
Loading and preparing results...
DONE (t=0.10s)
creating index...
index created!
[08/26 14:17:01 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 14:17:01 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.09 seconds.
[08/26 14:17:01 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:17:01 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.484
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.707
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.549
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.147
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.420
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.657
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.340
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.617
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.674
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.325
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.645
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.788
[08/26 14:17:01 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.391 | 70.685 | 54.922 | 14.689 | 41.996 | 65.650 |
[08/26 14:17:01 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 14:17:01 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 14:17:01 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:17:01 d2.evaluation.testing]: copypaste: 46.1908,68.8031,53.3057,15.6918,42.3063,59.7584
[08/26 14:17:01 d2.evaluation.testing]: copypaste: Task: segm
[08/26 14:17:01 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:17:01 d2.evaluation.testing]: copypaste: 48.3914,70.6852,54.9224,14.6890,41.9958,65.6500
[08/26 14:17:01 d2.utils.events]:  eta: 0:17:33  iter: 439  total_loss: 0.6863  loss_cls: 0.1249  loss_box_reg: 0.2945  loss_mask: 0.1882  loss_rpn_cls: 0.0102  loss_rpn_loc: 0.01027  time: 1.8914  data_time: 0.0274  lr: 0.00010989  max_mem: 10070M
[08/26 14:17:38 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 14:17:38 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 14:17:38 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 14:17:38 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 14:17:38 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 14:17:44 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0020 s/iter. Inference: 0.2229 s/iter. Eval: 0.1387 s/iter. Total: 0.3637 s/iter. ETA=0:00:48
[08/26 14:17:49 d2.evaluation.evaluator]: Inference done 28/144. Dataloading: 0.0030 s/iter. Inference: 0.2202 s/iter. Eval: 0.1131 s/iter. Total: 0.3365 s/iter. ETA=0:00:39
[08/26 14:17:54 d2.evaluation.evaluator]: Inference done 43/144. Dataloading: 0.0028 s/iter. Inference: 0.2202 s/iter. Eval: 0.1125 s/iter. Total: 0.3357 s/iter. ETA=0:00:33
[08/26 14:18:00 d2.evaluation.evaluator]: Inference done 51/144. Dataloading: 0.0029 s/iter. Inference: 0.2245 s/iter. Eval: 0.1651 s/iter. Total: 0.3928 s/iter. ETA=0:00:36
[08/26 14:18:05 d2.evaluation.evaluator]: Inference done 61/144. Dataloading: 0.0031 s/iter. Inference: 0.2263 s/iter. Eval: 0.1853 s/iter. Total: 0.4150 s/iter. ETA=0:00:34
[08/26 14:18:10 d2.evaluation.evaluator]: Inference done 72/144. Dataloading: 0.0034 s/iter. Inference: 0.2274 s/iter. Eval: 0.1941 s/iter. Total: 0.4252 s/iter. ETA=0:00:30
[08/26 14:18:15 d2.evaluation.evaluator]: Inference done 88/144. Dataloading: 0.0032 s/iter. Inference: 0.2256 s/iter. Eval: 0.1746 s/iter. Total: 0.4037 s/iter. ETA=0:00:22
[08/26 14:18:20 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0031 s/iter. Inference: 0.2245 s/iter. Eval: 0.1631 s/iter. Total: 0.3910 s/iter. ETA=0:00:15
[08/26 14:18:25 d2.evaluation.evaluator]: Inference done 120/144. Dataloading: 0.0031 s/iter. Inference: 0.2240 s/iter. Eval: 0.1551 s/iter. Total: 0.3824 s/iter. ETA=0:00:09
[08/26 14:18:31 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0030 s/iter. Inference: 0.2233 s/iter. Eval: 0.1466 s/iter. Total: 0.3731 s/iter. ETA=0:00:02
[08/26 14:18:34 d2.evaluation.evaluator]: Total inference time: 0:00:52.326991 (0.376453 s / iter per device, on 1 devices)
[08/26 14:18:34 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:31 (0.223425 s / iter per device, on 1 devices)
[08/26 14:18:34 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 14:18:34 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 14:18:34 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/26 14:18:34 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 14:18:34 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[08/26 14:18:34 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:18:34 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.471
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.701
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.545
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.162
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.435
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.607
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.336
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.599
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.639
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.267
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.608
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.761
[08/26 14:18:34 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.077 | 70.126 | 54.464 | 16.229 | 43.453 | 60.699 |
Loading and preparing results...
DONE (t=0.08s)
creating index...
index created!
[08/26 14:18:34 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 14:18:34 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.08 seconds.
[08/26 14:18:34 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:18:34 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.489
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.709
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.568
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.141
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.418
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.670
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.339
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.620
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.666
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.308
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.631
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.792
[08/26 14:18:34 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.853 | 70.870 | 56.795 | 14.127 | 41.827 | 66.996 |
[08/26 14:18:34 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 14:18:34 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 14:18:34 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:18:34 d2.evaluation.testing]: copypaste: 47.0771,70.1263,54.4638,16.2290,43.4526,60.6986
[08/26 14:18:34 d2.evaluation.testing]: copypaste: Task: segm
[08/26 14:18:34 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:18:34 d2.evaluation.testing]: copypaste: 48.8527,70.8700,56.7952,14.1266,41.8267,66.9958
[08/26 14:18:34 d2.utils.events]:  eta: 0:16:56  iter: 459  total_loss: 0.6236  loss_cls: 0.1018  loss_box_reg: 0.2917  loss_mask: 0.195  loss_rpn_cls: 0.01267  loss_rpn_loc: 0.0102  time: 1.8909  data_time: 0.0262  lr: 0.00011489  max_mem: 10070M
[08/26 14:19:12 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 14:19:12 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 14:19:12 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 14:19:12 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 14:19:12 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 14:19:18 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0023 s/iter. Inference: 0.2271 s/iter. Eval: 0.1860 s/iter. Total: 0.4154 s/iter. ETA=0:00:55
[08/26 14:19:23 d2.evaluation.evaluator]: Inference done 26/144. Dataloading: 0.0028 s/iter. Inference: 0.2231 s/iter. Eval: 0.1323 s/iter. Total: 0.3583 s/iter. ETA=0:00:42
[08/26 14:19:28 d2.evaluation.evaluator]: Inference done 42/144. Dataloading: 0.0026 s/iter. Inference: 0.2220 s/iter. Eval: 0.1200 s/iter. Total: 0.3448 s/iter. ETA=0:00:35
[08/26 14:19:33 d2.evaluation.evaluator]: Inference done 50/144. Dataloading: 0.0026 s/iter. Inference: 0.2267 s/iter. Eval: 0.1726 s/iter. Total: 0.4021 s/iter. ETA=0:00:37
[08/26 14:19:39 d2.evaluation.evaluator]: Inference done 61/144. Dataloading: 0.0025 s/iter. Inference: 0.2275 s/iter. Eval: 0.1873 s/iter. Total: 0.4175 s/iter. ETA=0:00:34
[08/26 14:19:44 d2.evaluation.evaluator]: Inference done 72/144. Dataloading: 0.0025 s/iter. Inference: 0.2283 s/iter. Eval: 0.1930 s/iter. Total: 0.4241 s/iter. ETA=0:00:30
[08/26 14:19:49 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0026 s/iter. Inference: 0.2260 s/iter. Eval: 0.1705 s/iter. Total: 0.3993 s/iter. ETA=0:00:21
[08/26 14:19:54 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0029 s/iter. Inference: 0.2266 s/iter. Eval: 0.1634 s/iter. Total: 0.3930 s/iter. ETA=0:00:15
[08/26 14:19:59 d2.evaluation.evaluator]: Inference done 120/144. Dataloading: 0.0028 s/iter. Inference: 0.2254 s/iter. Eval: 0.1539 s/iter. Total: 0.3824 s/iter. ETA=0:00:09
[08/26 14:20:04 d2.evaluation.evaluator]: Inference done 136/144. Dataloading: 0.0029 s/iter. Inference: 0.2247 s/iter. Eval: 0.1467 s/iter. Total: 0.3746 s/iter. ETA=0:00:02
[08/26 14:20:07 d2.evaluation.evaluator]: Total inference time: 0:00:52.338649 (0.376537 s / iter per device, on 1 devices)
[08/26 14:20:07 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:31 (0.224667 s / iter per device, on 1 devices)
[08/26 14:20:08 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 14:20:08 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 14:20:08 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/26 14:20:08 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 14:20:08 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/26 14:20:08 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:20:08 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.479
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.695
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.549
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.166
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.432
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.628
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.349
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.650
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.275
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.605
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.795
[08/26 14:20:08 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.928 | 69.530 | 54.886 | 16.617 | 43.151 | 62.766 |
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
[08/26 14:20:08 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 14:20:08 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.08 seconds.
[08/26 14:20:08 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:20:08 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.486
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.708
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.550
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.142
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.419
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.663
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.618
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.665
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.325
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.628
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.792
[08/26 14:20:08 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.635 | 70.796 | 54.952 | 14.155 | 41.861 | 66.297 |
[08/26 14:20:08 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 14:20:08 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 14:20:08 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:20:08 d2.evaluation.testing]: copypaste: 47.9284,69.5299,54.8859,16.6167,43.1507,62.7663
[08/26 14:20:08 d2.evaluation.testing]: copypaste: Task: segm
[08/26 14:20:08 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:20:08 d2.evaluation.testing]: copypaste: 48.6355,70.7963,54.9519,14.1552,41.8611,66.2971
[08/26 14:20:08 d2.utils.events]:  eta: 0:16:18  iter: 479  total_loss: 0.5112  loss_cls: 0.101  loss_box_reg: 0.2446  loss_mask: 0.1597  loss_rpn_cls: 0.01005  loss_rpn_loc: 0.007799  time: 1.8905  data_time: 0.0231  lr: 0.00011988  max_mem: 10070M
[08/26 14:20:46 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 14:20:46 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 14:20:46 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 14:20:46 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 14:20:46 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 14:20:51 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0018 s/iter. Inference: 0.2200 s/iter. Eval: 0.1238 s/iter. Total: 0.3456 s/iter. ETA=0:00:45
[08/26 14:20:56 d2.evaluation.evaluator]: Inference done 28/144. Dataloading: 0.0027 s/iter. Inference: 0.2214 s/iter. Eval: 0.1000 s/iter. Total: 0.3243 s/iter. ETA=0:00:37
[08/26 14:21:01 d2.evaluation.evaluator]: Inference done 43/144. Dataloading: 0.0036 s/iter. Inference: 0.2236 s/iter. Eval: 0.1036 s/iter. Total: 0.3309 s/iter. ETA=0:00:33
[08/26 14:21:07 d2.evaluation.evaluator]: Inference done 52/144. Dataloading: 0.0034 s/iter. Inference: 0.2267 s/iter. Eval: 0.1507 s/iter. Total: 0.3809 s/iter. ETA=0:00:35
[08/26 14:21:12 d2.evaluation.evaluator]: Inference done 63/144. Dataloading: 0.0034 s/iter. Inference: 0.2270 s/iter. Eval: 0.1650 s/iter. Total: 0.3957 s/iter. ETA=0:00:32
[08/26 14:21:17 d2.evaluation.evaluator]: Inference done 76/144. Dataloading: 0.0033 s/iter. Inference: 0.2265 s/iter. Eval: 0.1645 s/iter. Total: 0.3945 s/iter. ETA=0:00:26
[08/26 14:21:22 d2.evaluation.evaluator]: Inference done 93/144. Dataloading: 0.0032 s/iter. Inference: 0.2251 s/iter. Eval: 0.1472 s/iter. Total: 0.3757 s/iter. ETA=0:00:19
[08/26 14:21:27 d2.evaluation.evaluator]: Inference done 110/144. Dataloading: 0.0031 s/iter. Inference: 0.2240 s/iter. Eval: 0.1390 s/iter. Total: 0.3663 s/iter. ETA=0:00:12
[08/26 14:21:32 d2.evaluation.evaluator]: Inference done 125/144. Dataloading: 0.0031 s/iter. Inference: 0.2242 s/iter. Eval: 0.1360 s/iter. Total: 0.3635 s/iter. ETA=0:00:06
[08/26 14:21:38 d2.evaluation.evaluator]: Inference done 142/144. Dataloading: 0.0030 s/iter. Inference: 0.2232 s/iter. Eval: 0.1300 s/iter. Total: 0.3565 s/iter. ETA=0:00:00
[08/26 14:21:39 d2.evaluation.evaluator]: Total inference time: 0:00:50.109324 (0.360499 s / iter per device, on 1 devices)
[08/26 14:21:39 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:31 (0.223455 s / iter per device, on 1 devices)
[08/26 14:21:39 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 14:21:39 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 14:21:39 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/26 14:21:39 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 14:21:39 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[08/26 14:21:39 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:21:39 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.482
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.703
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.560
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.172
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.430
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.642
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.347
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.652
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.292
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.782
[08/26 14:21:39 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.233 | 70.271 | 55.994 | 17.195 | 42.954 | 64.152 |
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
[08/26 14:21:39 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 14:21:39 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[08/26 14:21:39 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:21:39 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.493
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.709
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.572
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.138
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.423
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.671
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.349
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.662
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.625
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.786
[08/26 14:21:39 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.262 | 70.871 | 57.184 | 13.803 | 42.342 | 67.071 |
[08/26 14:21:39 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 14:21:39 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 14:21:39 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:21:39 d2.evaluation.testing]: copypaste: 48.2332,70.2711,55.9936,17.1950,42.9544,64.1521
[08/26 14:21:39 d2.evaluation.testing]: copypaste: Task: segm
[08/26 14:21:39 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:21:39 d2.evaluation.testing]: copypaste: 49.2623,70.8710,57.1840,13.8027,42.3423,67.0709
[08/26 14:21:39 d2.utils.events]:  eta: 0:15:40  iter: 499  total_loss: 0.4777  loss_cls: 0.1004  loss_box_reg: 0.2096  loss_mask: 0.1744  loss_rpn_cls: 0.009765  loss_rpn_loc: 0.008132  time: 1.8903  data_time: 0.0215  lr: 0.00012488  max_mem: 10070M
[08/26 14:22:17 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 14:22:17 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 14:22:17 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 14:22:17 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 14:22:17 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 14:22:22 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0020 s/iter. Inference: 0.2218 s/iter. Eval: 0.1309 s/iter. Total: 0.3547 s/iter. ETA=0:00:47
[08/26 14:22:28 d2.evaluation.evaluator]: Inference done 28/144. Dataloading: 0.0028 s/iter. Inference: 0.2228 s/iter. Eval: 0.1037 s/iter. Total: 0.3295 s/iter. ETA=0:00:38
[08/26 14:22:33 d2.evaluation.evaluator]: Inference done 44/144. Dataloading: 0.0027 s/iter. Inference: 0.2212 s/iter. Eval: 0.1007 s/iter. Total: 0.3248 s/iter. ETA=0:00:32
[08/26 14:22:38 d2.evaluation.evaluator]: Inference done 51/144. Dataloading: 0.0027 s/iter. Inference: 0.2267 s/iter. Eval: 0.1631 s/iter. Total: 0.3927 s/iter. ETA=0:00:36
[08/26 14:22:44 d2.evaluation.evaluator]: Inference done 62/144. Dataloading: 0.0029 s/iter. Inference: 0.2275 s/iter. Eval: 0.1786 s/iter. Total: 0.4092 s/iter. ETA=0:00:33
[08/26 14:22:49 d2.evaluation.evaluator]: Inference done 74/144. Dataloading: 0.0029 s/iter. Inference: 0.2274 s/iter. Eval: 0.1837 s/iter. Total: 0.4141 s/iter. ETA=0:00:28
[08/26 14:22:54 d2.evaluation.evaluator]: Inference done 91/144. Dataloading: 0.0029 s/iter. Inference: 0.2255 s/iter. Eval: 0.1622 s/iter. Total: 0.3907 s/iter. ETA=0:00:20
[08/26 14:22:59 d2.evaluation.evaluator]: Inference done 107/144. Dataloading: 0.0029 s/iter. Inference: 0.2248 s/iter. Eval: 0.1523 s/iter. Total: 0.3801 s/iter. ETA=0:00:14
[08/26 14:23:04 d2.evaluation.evaluator]: Inference done 123/144. Dataloading: 0.0029 s/iter. Inference: 0.2239 s/iter. Eval: 0.1456 s/iter. Total: 0.3726 s/iter. ETA=0:00:07
[08/26 14:23:09 d2.evaluation.evaluator]: Inference done 140/144. Dataloading: 0.0029 s/iter. Inference: 0.2235 s/iter. Eval: 0.1376 s/iter. Total: 0.3641 s/iter. ETA=0:00:01
[08/26 14:23:12 d2.evaluation.evaluator]: Total inference time: 0:00:51.691744 (0.371883 s / iter per device, on 1 devices)
[08/26 14:23:12 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:31 (0.223872 s / iter per device, on 1 devices)
[08/26 14:23:12 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 14:23:12 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 14:23:12 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/26 14:23:12 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 14:23:12 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[08/26 14:23:12 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:23:12 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.495
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.716
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.572
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.174
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.437
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.659
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.354
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.612
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.659
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.283
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.795
[08/26 14:23:12 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.465 | 71.556 | 57.223 | 17.442 | 43.695 | 65.928 |
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
[08/26 14:23:12 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 14:23:12 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[08/26 14:23:12 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:23:12 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.499
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.716
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.582
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.160
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.431
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.674
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.352
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.669
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.635
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.788
[08/26 14:23:12 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.932 | 71.631 | 58.248 | 16.039 | 43.061 | 67.355 |
[08/26 14:23:12 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 14:23:12 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 14:23:12 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:23:12 d2.evaluation.testing]: copypaste: 49.4646,71.5560,57.2232,17.4420,43.6952,65.9281
[08/26 14:23:12 d2.evaluation.testing]: copypaste: Task: segm
[08/26 14:23:12 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:23:12 d2.evaluation.testing]: copypaste: 49.9316,71.6312,58.2479,16.0390,43.0607,67.3550
[08/26 14:23:12 d2.utils.events]:  eta: 0:15:03  iter: 519  total_loss: 0.4905  loss_cls: 0.09006  loss_box_reg: 0.2062  loss_mask: 0.1663  loss_rpn_cls: 0.00571  loss_rpn_loc: 0.00601  time: 1.8899  data_time: 0.0261  lr: 0.00012987  max_mem: 10070M
[08/26 14:23:51 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 14:23:51 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 14:23:51 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 14:23:51 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 14:23:51 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 14:23:56 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0039 s/iter. Inference: 0.2189 s/iter. Eval: 0.1096 s/iter. Total: 0.3324 s/iter. ETA=0:00:44
[08/26 14:24:01 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0028 s/iter. Inference: 0.2160 s/iter. Eval: 0.0768 s/iter. Total: 0.2958 s/iter. ETA=0:00:34
[08/26 14:24:06 d2.evaluation.evaluator]: Inference done 45/144. Dataloading: 0.0034 s/iter. Inference: 0.2179 s/iter. Eval: 0.0869 s/iter. Total: 0.3084 s/iter. ETA=0:00:30
[08/26 14:24:11 d2.evaluation.evaluator]: Inference done 54/144. Dataloading: 0.0034 s/iter. Inference: 0.2218 s/iter. Eval: 0.1332 s/iter. Total: 0.3585 s/iter. ETA=0:00:32
[08/26 14:24:17 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0033 s/iter. Inference: 0.2239 s/iter. Eval: 0.1559 s/iter. Total: 0.3833 s/iter. ETA=0:00:29
[08/26 14:24:23 d2.evaluation.evaluator]: Inference done 85/144. Dataloading: 0.0032 s/iter. Inference: 0.2221 s/iter. Eval: 0.1377 s/iter. Total: 0.3631 s/iter. ETA=0:00:21
[08/26 14:24:28 d2.evaluation.evaluator]: Inference done 103/144. Dataloading: 0.0031 s/iter. Inference: 0.2215 s/iter. Eval: 0.1249 s/iter. Total: 0.3496 s/iter. ETA=0:00:14
[08/26 14:24:33 d2.evaluation.evaluator]: Inference done 121/144. Dataloading: 0.0031 s/iter. Inference: 0.2206 s/iter. Eval: 0.1173 s/iter. Total: 0.3412 s/iter. ETA=0:00:07
[08/26 14:24:38 d2.evaluation.evaluator]: Inference done 139/144. Dataloading: 0.0032 s/iter. Inference: 0.2203 s/iter. Eval: 0.1108 s/iter. Total: 0.3344 s/iter. ETA=0:00:01
[08/26 14:24:41 d2.evaluation.evaluator]: Total inference time: 0:00:46.924516 (0.337586 s / iter per device, on 1 devices)
[08/26 14:24:41 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.220436 s / iter per device, on 1 devices)
[08/26 14:24:41 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 14:24:41 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 14:24:41 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/26 14:24:41 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 14:24:41 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[08/26 14:24:41 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:24:41 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.496
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.716
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.575
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.172
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.445
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.650
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.356
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.654
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.283
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.621
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.779
[08/26 14:24:41 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.575 | 71.627 | 57.538 | 17.174 | 44.459 | 64.953 |
Loading and preparing results...
DONE (t=0.06s)
creating index...
index created!
[08/26 14:24:41 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 14:24:41 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[08/26 14:24:41 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:24:41 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.500
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.730
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.567
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.148
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.435
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.670
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.355
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.667
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.325
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.632
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.789
[08/26 14:24:41 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.008 | 73.021 | 56.697 | 14.835 | 43.459 | 66.968 |
[08/26 14:24:41 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 14:24:41 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 14:24:41 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:24:41 d2.evaluation.testing]: copypaste: 49.5752,71.6270,57.5376,17.1735,44.4593,64.9529
[08/26 14:24:41 d2.evaluation.testing]: copypaste: Task: segm
[08/26 14:24:41 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:24:41 d2.evaluation.testing]: copypaste: 50.0078,73.0211,56.6973,14.8353,43.4590,66.9675
[08/26 14:24:41 d2.utils.events]:  eta: 0:14:25  iter: 539  total_loss: 0.5358  loss_cls: 0.09954  loss_box_reg: 0.236  loss_mask: 0.1791  loss_rpn_cls: 0.008415  loss_rpn_loc: 0.006699  time: 1.8904  data_time: 0.0245  lr: 0.00013487  max_mem: 10070M
[08/26 14:25:19 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 14:25:19 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 14:25:19 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 14:25:19 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 14:25:19 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 14:25:24 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0032 s/iter. Inference: 0.2266 s/iter. Eval: 0.1306 s/iter. Total: 0.3604 s/iter. ETA=0:00:47
[08/26 14:25:30 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0034 s/iter. Inference: 0.2189 s/iter. Eval: 0.0860 s/iter. Total: 0.3085 s/iter. ETA=0:00:35
[08/26 14:25:35 d2.evaluation.evaluator]: Inference done 45/144. Dataloading: 0.0034 s/iter. Inference: 0.2198 s/iter. Eval: 0.0937 s/iter. Total: 0.3171 s/iter. ETA=0:00:31
[08/26 14:25:40 d2.evaluation.evaluator]: Inference done 54/144. Dataloading: 0.0034 s/iter. Inference: 0.2236 s/iter. Eval: 0.1410 s/iter. Total: 0.3681 s/iter. ETA=0:00:33
[08/26 14:25:45 d2.evaluation.evaluator]: Inference done 66/144. Dataloading: 0.0032 s/iter. Inference: 0.2249 s/iter. Eval: 0.1495 s/iter. Total: 0.3778 s/iter. ETA=0:00:29
[08/26 14:25:50 d2.evaluation.evaluator]: Inference done 80/144. Dataloading: 0.0031 s/iter. Inference: 0.2244 s/iter. Eval: 0.1468 s/iter. Total: 0.3745 s/iter. ETA=0:00:23
[08/26 14:25:56 d2.evaluation.evaluator]: Inference done 99/144. Dataloading: 0.0031 s/iter. Inference: 0.2231 s/iter. Eval: 0.1271 s/iter. Total: 0.3535 s/iter. ETA=0:00:15
[08/26 14:26:01 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0031 s/iter. Inference: 0.2236 s/iter. Eval: 0.1276 s/iter. Total: 0.3545 s/iter. ETA=0:00:10
[08/26 14:26:06 d2.evaluation.evaluator]: Inference done 130/144. Dataloading: 0.0030 s/iter. Inference: 0.2229 s/iter. Eval: 0.1214 s/iter. Total: 0.3475 s/iter. ETA=0:00:04
[08/26 14:26:10 d2.evaluation.evaluator]: Total inference time: 0:00:48.113298 (0.346139 s / iter per device, on 1 devices)
[08/26 14:26:10 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.222548 s / iter per device, on 1 devices)
[08/26 14:26:10 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 14:26:10 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 14:26:11 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/26 14:26:11 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 14:26:11 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/26 14:26:11 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:26:11 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.500
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.723
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.582
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.448
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.656
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.618
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.659
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.292
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.786
[08/26 14:26:11 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.042 | 72.332 | 58.219 | 20.045 | 44.813 | 65.601 |
Loading and preparing results...
DONE (t=0.06s)
creating index...
index created!
[08/26 14:26:11 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 14:26:11 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.08 seconds.
[08/26 14:26:11 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:26:11 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.507
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.730
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.583
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.166
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.446
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.672
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.356
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.625
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.671
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.342
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.639
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.786
[08/26 14:26:11 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.681 | 73.024 | 58.322 | 16.584 | 44.560 | 67.204 |
[08/26 14:26:11 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 14:26:11 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 14:26:11 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:26:11 d2.evaluation.testing]: copypaste: 50.0422,72.3324,58.2190,20.0451,44.8132,65.6005
[08/26 14:26:11 d2.evaluation.testing]: copypaste: Task: segm
[08/26 14:26:11 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:26:11 d2.evaluation.testing]: copypaste: 50.6809,73.0241,58.3218,16.5844,44.5596,67.2039
[08/26 14:26:11 d2.utils.events]:  eta: 0:13:47  iter: 559  total_loss: 0.5577  loss_cls: 0.1088  loss_box_reg: 0.2247  loss_mask: 0.1837  loss_rpn_cls: 0.005915  loss_rpn_loc: 0.006202  time: 1.8905  data_time: 0.0274  lr: 0.00013986  max_mem: 10070M
[08/26 14:26:49 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 14:26:49 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 14:26:49 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 14:26:49 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 14:26:49 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 14:26:54 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0021 s/iter. Inference: 0.2193 s/iter. Eval: 0.1131 s/iter. Total: 0.3345 s/iter. ETA=0:00:44
[08/26 14:26:59 d2.evaluation.evaluator]: Inference done 28/144. Dataloading: 0.0024 s/iter. Inference: 0.2185 s/iter. Eval: 0.0999 s/iter. Total: 0.3210 s/iter. ETA=0:00:37
[08/26 14:27:04 d2.evaluation.evaluator]: Inference done 43/144. Dataloading: 0.0031 s/iter. Inference: 0.2211 s/iter. Eval: 0.1079 s/iter. Total: 0.3323 s/iter. ETA=0:00:33
[08/26 14:27:10 d2.evaluation.evaluator]: Inference done 51/144. Dataloading: 0.0030 s/iter. Inference: 0.2252 s/iter. Eval: 0.1593 s/iter. Total: 0.3876 s/iter. ETA=0:00:36
[08/26 14:27:15 d2.evaluation.evaluator]: Inference done 62/144. Dataloading: 0.0032 s/iter. Inference: 0.2271 s/iter. Eval: 0.1756 s/iter. Total: 0.4061 s/iter. ETA=0:00:33
[08/26 14:27:20 d2.evaluation.evaluator]: Inference done 74/144. Dataloading: 0.0031 s/iter. Inference: 0.2269 s/iter. Eval: 0.1783 s/iter. Total: 0.4086 s/iter. ETA=0:00:28
[08/26 14:27:25 d2.evaluation.evaluator]: Inference done 91/144. Dataloading: 0.0031 s/iter. Inference: 0.2254 s/iter. Eval: 0.1604 s/iter. Total: 0.3891 s/iter. ETA=0:00:20
[08/26 14:27:30 d2.evaluation.evaluator]: Inference done 108/144. Dataloading: 0.0031 s/iter. Inference: 0.2240 s/iter. Eval: 0.1475 s/iter. Total: 0.3748 s/iter. ETA=0:00:13
[08/26 14:27:36 d2.evaluation.evaluator]: Inference done 124/144. Dataloading: 0.0031 s/iter. Inference: 0.2236 s/iter. Eval: 0.1409 s/iter. Total: 0.3677 s/iter. ETA=0:00:07
[08/26 14:27:41 d2.evaluation.evaluator]: Inference done 141/144. Dataloading: 0.0031 s/iter. Inference: 0.2236 s/iter. Eval: 0.1338 s/iter. Total: 0.3607 s/iter. ETA=0:00:01
[08/26 14:27:43 d2.evaluation.evaluator]: Total inference time: 0:00:51.046423 (0.367240 s / iter per device, on 1 devices)
[08/26 14:27:43 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:31 (0.223983 s / iter per device, on 1 devices)
[08/26 14:27:43 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 14:27:43 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 14:27:43 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/26 14:27:43 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 14:27:43 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.08 seconds.
[08/26 14:27:43 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:27:43 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.502
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.724
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.576
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.194
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.445
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.665
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.359
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.659
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.792
[08/26 14:27:43 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.247 | 72.441 | 57.620 | 19.439 | 44.454 | 66.453 |
Loading and preparing results...
DONE (t=0.06s)
creating index...
index created!
[08/26 14:27:43 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 14:27:43 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[08/26 14:27:43 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:27:43 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.508
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.733
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.570
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.146
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.444
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.681
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.354
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.625
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.672
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.325
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.640
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.789
[08/26 14:27:43 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.791 | 73.332 | 56.979 | 14.623 | 44.424 | 68.101 |
[08/26 14:27:43 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 14:27:43 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 14:27:43 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:27:43 d2.evaluation.testing]: copypaste: 50.2470,72.4409,57.6200,19.4388,44.4541,66.4529
[08/26 14:27:43 d2.evaluation.testing]: copypaste: Task: segm
[08/26 14:27:43 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:27:43 d2.evaluation.testing]: copypaste: 50.7910,73.3321,56.9788,14.6225,44.4238,68.1015
[08/26 14:27:43 d2.utils.events]:  eta: 0:13:10  iter: 579  total_loss: 0.6356  loss_cls: 0.1174  loss_box_reg: 0.1919  loss_mask: 0.1885  loss_rpn_cls: 0.009415  loss_rpn_loc: 0.01107  time: 1.8907  data_time: 0.0271  lr: 0.00014486  max_mem: 10070M
[08/26 14:28:21 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 14:28:21 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 14:28:21 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 14:28:21 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 14:28:21 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 14:28:26 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0023 s/iter. Inference: 0.2179 s/iter. Eval: 0.0914 s/iter. Total: 0.3116 s/iter. ETA=0:00:41
[08/26 14:28:31 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0033 s/iter. Inference: 0.2177 s/iter. Eval: 0.0758 s/iter. Total: 0.2970 s/iter. ETA=0:00:34
[08/26 14:28:37 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0031 s/iter. Inference: 0.2189 s/iter. Eval: 0.0937 s/iter. Total: 0.3159 s/iter. ETA=0:00:30
[08/26 14:28:42 d2.evaluation.evaluator]: Inference done 55/144. Dataloading: 0.0034 s/iter. Inference: 0.2221 s/iter. Eval: 0.1344 s/iter. Total: 0.3601 s/iter. ETA=0:00:32
[08/26 14:28:48 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0037 s/iter. Inference: 0.2239 s/iter. Eval: 0.1530 s/iter. Total: 0.3810 s/iter. ETA=0:00:29
[08/26 14:28:53 d2.evaluation.evaluator]: Inference done 83/144. Dataloading: 0.0035 s/iter. Inference: 0.2229 s/iter. Eval: 0.1419 s/iter. Total: 0.3686 s/iter. ETA=0:00:22
[08/26 14:28:58 d2.evaluation.evaluator]: Inference done 102/144. Dataloading: 0.0033 s/iter. Inference: 0.2213 s/iter. Eval: 0.1250 s/iter. Total: 0.3498 s/iter. ETA=0:00:14
[08/26 14:29:03 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0033 s/iter. Inference: 0.2211 s/iter. Eval: 0.1187 s/iter. Total: 0.3434 s/iter. ETA=0:00:08
[08/26 14:29:08 d2.evaluation.evaluator]: Inference done 138/144. Dataloading: 0.0033 s/iter. Inference: 0.2202 s/iter. Eval: 0.1098 s/iter. Total: 0.3335 s/iter. ETA=0:00:02
[08/26 14:29:11 d2.evaluation.evaluator]: Total inference time: 0:00:46.894986 (0.337374 s / iter per device, on 1 devices)
[08/26 14:29:11 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.220314 s / iter per device, on 1 devices)
[08/26 14:29:11 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 14:29:11 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 14:29:11 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/26 14:29:11 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 14:29:11 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/26 14:29:11 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:29:11 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.503
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.722
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.599
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.208
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.448
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.664
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.359
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.614
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.660
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.618
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.798
[08/26 14:29:11 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.346 | 72.169 | 59.937 | 20.793 | 44.845 | 66.359 |
Loading and preparing results...
DONE (t=0.06s)
creating index...
index created!
[08/26 14:29:11 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 14:29:11 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[08/26 14:29:11 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:29:11 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.508
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.730
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.570
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.136
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.448
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.675
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.357
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.618
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.664
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.626
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.786
[08/26 14:29:11 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.793 | 72.954 | 56.984 | 13.569 | 44.839 | 67.506 |
[08/26 14:29:11 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 14:29:11 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 14:29:11 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:29:11 d2.evaluation.testing]: copypaste: 50.3462,72.1685,59.9374,20.7934,44.8452,66.3586
[08/26 14:29:11 d2.evaluation.testing]: copypaste: Task: segm
[08/26 14:29:11 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:29:11 d2.evaluation.testing]: copypaste: 50.7927,72.9538,56.9840,13.5691,44.8387,67.5064
[08/26 14:29:11 d2.utils.events]:  eta: 0:12:32  iter: 599  total_loss: 0.4493  loss_cls: 0.08123  loss_box_reg: 0.1689  loss_mask: 0.1932  loss_rpn_cls: 0.007344  loss_rpn_loc: 0.006342  time: 1.8910  data_time: 0.0235  lr: 0.00014985  max_mem: 10070M
[08/26 14:29:49 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 14:29:49 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 14:29:49 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 14:29:49 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 14:29:49 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 14:29:55 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0020 s/iter. Inference: 0.2250 s/iter. Eval: 0.1165 s/iter. Total: 0.3435 s/iter. ETA=0:00:45
[08/26 14:30:00 d2.evaluation.evaluator]: Inference done 27/144. Dataloading: 0.0038 s/iter. Inference: 0.2244 s/iter. Eval: 0.1014 s/iter. Total: 0.3299 s/iter. ETA=0:00:38
[08/26 14:30:05 d2.evaluation.evaluator]: Inference done 43/144. Dataloading: 0.0033 s/iter. Inference: 0.2224 s/iter. Eval: 0.1069 s/iter. Total: 0.3328 s/iter. ETA=0:00:33
[08/26 14:30:10 d2.evaluation.evaluator]: Inference done 50/144. Dataloading: 0.0032 s/iter. Inference: 0.2266 s/iter. Eval: 0.1626 s/iter. Total: 0.3927 s/iter. ETA=0:00:36
[08/26 14:30:15 d2.evaluation.evaluator]: Inference done 61/144. Dataloading: 0.0031 s/iter. Inference: 0.2275 s/iter. Eval: 0.1803 s/iter. Total: 0.4112 s/iter. ETA=0:00:34
[08/26 14:30:21 d2.evaluation.evaluator]: Inference done 72/144. Dataloading: 0.0030 s/iter. Inference: 0.2279 s/iter. Eval: 0.1884 s/iter. Total: 0.4196 s/iter. ETA=0:00:30
[08/26 14:30:26 d2.evaluation.evaluator]: Inference done 87/144. Dataloading: 0.0030 s/iter. Inference: 0.2262 s/iter. Eval: 0.1746 s/iter. Total: 0.4040 s/iter. ETA=0:00:23
[08/26 14:30:31 d2.evaluation.evaluator]: Inference done 103/144. Dataloading: 0.0030 s/iter. Inference: 0.2262 s/iter. Eval: 0.1634 s/iter. Total: 0.3927 s/iter. ETA=0:00:16
[08/26 14:30:36 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0030 s/iter. Inference: 0.2252 s/iter. Eval: 0.1542 s/iter. Total: 0.3826 s/iter. ETA=0:00:09
[08/26 14:30:41 d2.evaluation.evaluator]: Inference done 135/144. Dataloading: 0.0030 s/iter. Inference: 0.2247 s/iter. Eval: 0.1469 s/iter. Total: 0.3749 s/iter. ETA=0:00:03
[08/26 14:30:45 d2.evaluation.evaluator]: Total inference time: 0:00:52.449624 (0.377335 s / iter per device, on 1 devices)
[08/26 14:30:45 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:31 (0.224638 s / iter per device, on 1 devices)
[08/26 14:30:45 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 14:30:45 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 14:30:45 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/26 14:30:45 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 14:30:45 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[08/26 14:30:45 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:30:45 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.508
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.726
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.582
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.205
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.455
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.663
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.362
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.624
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.672
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.292
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.638
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.800
[08/26 14:30:45 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.805 | 72.552 | 58.176 | 20.495 | 45.539 | 66.329 |
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
[08/26 14:30:45 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 14:30:45 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.08 seconds.
[08/26 14:30:45 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:30:45 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.514
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.736
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.595
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.127
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.457
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.680
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.356
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.628
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.677
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.342
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.650
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.786
[08/26 14:30:45 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.426 | 73.577 | 59.491 | 12.674 | 45.674 | 67.997 |
[08/26 14:30:45 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 14:30:45 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 14:30:45 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:30:45 d2.evaluation.testing]: copypaste: 50.8048,72.5517,58.1758,20.4949,45.5391,66.3292
[08/26 14:30:45 d2.evaluation.testing]: copypaste: Task: segm
[08/26 14:30:45 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:30:45 d2.evaluation.testing]: copypaste: 51.4264,73.5772,59.4912,12.6737,45.6743,67.9966
[08/26 14:30:45 d2.utils.events]:  eta: 0:11:54  iter: 619  total_loss: 0.4711  loss_cls: 0.1017  loss_box_reg: 0.1673  loss_mask: 0.1746  loss_rpn_cls: 0.00868  loss_rpn_loc: 0.0088  time: 1.8911  data_time: 0.0246  lr: 0.00015485  max_mem: 10070M
[08/26 14:31:23 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 14:31:23 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 14:31:23 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 14:31:23 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 14:31:23 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 14:31:27 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0021 s/iter. Inference: 0.2161 s/iter. Eval: 0.0790 s/iter. Total: 0.2972 s/iter. ETA=0:00:39
[08/26 14:31:33 d2.evaluation.evaluator]: Inference done 30/144. Dataloading: 0.0030 s/iter. Inference: 0.2145 s/iter. Eval: 0.0576 s/iter. Total: 0.2753 s/iter. ETA=0:00:31
[08/26 14:31:38 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0030 s/iter. Inference: 0.2179 s/iter. Eval: 0.0781 s/iter. Total: 0.2992 s/iter. ETA=0:00:29
[08/26 14:31:43 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0033 s/iter. Inference: 0.2211 s/iter. Eval: 0.1131 s/iter. Total: 0.3376 s/iter. ETA=0:00:29
[08/26 14:31:48 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0035 s/iter. Inference: 0.2231 s/iter. Eval: 0.1323 s/iter. Total: 0.3590 s/iter. ETA=0:00:27
[08/26 14:31:53 d2.evaluation.evaluator]: Inference done 86/144. Dataloading: 0.0035 s/iter. Inference: 0.2214 s/iter. Eval: 0.1162 s/iter. Total: 0.3412 s/iter. ETA=0:00:19
[08/26 14:31:58 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0034 s/iter. Inference: 0.2208 s/iter. Eval: 0.1060 s/iter. Total: 0.3304 s/iter. ETA=0:00:13
[08/26 14:32:03 d2.evaluation.evaluator]: Inference done 123/144. Dataloading: 0.0034 s/iter. Inference: 0.2197 s/iter. Eval: 0.0968 s/iter. Total: 0.3201 s/iter. ETA=0:00:06
[08/26 14:32:09 d2.evaluation.evaluator]: Inference done 142/144. Dataloading: 0.0033 s/iter. Inference: 0.2195 s/iter. Eval: 0.0916 s/iter. Total: 0.3146 s/iter. ETA=0:00:00
[08/26 14:32:10 d2.evaluation.evaluator]: Total inference time: 0:00:44.147201 (0.317606 s / iter per device, on 1 devices)
[08/26 14:32:10 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.219639 s / iter per device, on 1 devices)
[08/26 14:32:10 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 14:32:10 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 14:32:10 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/26 14:32:10 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 14:32:10 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/26 14:32:10 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:32:10 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.508
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.725
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.602
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.186
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.454
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.670
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.359
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.622
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.661
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.267
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.621
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.802
[08/26 14:32:10 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.845 | 72.457 | 60.205 | 18.635 | 45.411 | 66.975 |
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
[08/26 14:32:10 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 14:32:10 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/26 14:32:10 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:32:10 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.516
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.738
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.592
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.127
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.457
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.687
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.360
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.629
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.675
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.641
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.794
[08/26 14:32:10 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.604 | 73.816 | 59.156 | 12.724 | 45.672 | 68.707 |
[08/26 14:32:10 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 14:32:10 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 14:32:10 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:32:10 d2.evaluation.testing]: copypaste: 50.8453,72.4566,60.2051,18.6352,45.4114,66.9751
[08/26 14:32:10 d2.evaluation.testing]: copypaste: Task: segm
[08/26 14:32:10 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:32:10 d2.evaluation.testing]: copypaste: 51.6037,73.8159,59.1556,12.7242,45.6722,68.7074
[08/26 14:32:10 d2.utils.events]:  eta: 0:11:17  iter: 639  total_loss: 0.5493  loss_cls: 0.111  loss_box_reg: 0.2076  loss_mask: 0.1654  loss_rpn_cls: 0.00914  loss_rpn_loc: 0.009864  time: 1.8909  data_time: 0.0242  lr: 0.00015984  max_mem: 10070M
[08/26 14:32:48 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 14:32:48 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 14:32:48 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 14:32:48 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 14:32:48 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 14:32:53 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0020 s/iter. Inference: 0.2161 s/iter. Eval: 0.0802 s/iter. Total: 0.2983 s/iter. ETA=0:00:39
[08/26 14:32:58 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0027 s/iter. Inference: 0.2156 s/iter. Eval: 0.0649 s/iter. Total: 0.2834 s/iter. ETA=0:00:32
[08/26 14:33:04 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0031 s/iter. Inference: 0.2168 s/iter. Eval: 0.0855 s/iter. Total: 0.3056 s/iter. ETA=0:00:29
[08/26 14:33:09 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0030 s/iter. Inference: 0.2194 s/iter. Eval: 0.1151 s/iter. Total: 0.3378 s/iter. ETA=0:00:29
[08/26 14:33:14 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0030 s/iter. Inference: 0.2212 s/iter. Eval: 0.1350 s/iter. Total: 0.3594 s/iter. ETA=0:00:27
[08/26 14:33:19 d2.evaluation.evaluator]: Inference done 87/144. Dataloading: 0.0029 s/iter. Inference: 0.2196 s/iter. Eval: 0.1165 s/iter. Total: 0.3392 s/iter. ETA=0:00:19
[08/26 14:33:24 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0033 s/iter. Inference: 0.2204 s/iter. Eval: 0.1091 s/iter. Total: 0.3330 s/iter. ETA=0:00:13
[08/26 14:33:29 d2.evaluation.evaluator]: Inference done 123/144. Dataloading: 0.0033 s/iter. Inference: 0.2194 s/iter. Eval: 0.0996 s/iter. Total: 0.3226 s/iter. ETA=0:00:06
[08/26 14:33:35 d2.evaluation.evaluator]: Inference done 142/144. Dataloading: 0.0033 s/iter. Inference: 0.2186 s/iter. Eval: 0.0935 s/iter. Total: 0.3157 s/iter. ETA=0:00:00
[08/26 14:33:36 d2.evaluation.evaluator]: Total inference time: 0:00:44.321619 (0.318861 s / iter per device, on 1 devices)
[08/26 14:33:36 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.218845 s / iter per device, on 1 devices)
[08/26 14:33:36 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 14:33:36 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 14:33:36 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/26 14:33:36 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 14:33:36 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[08/26 14:33:36 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:33:36 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.516
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.723
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.600
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.199
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.466
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.672
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.361
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.627
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.667
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.283
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.630
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.802
[08/26 14:33:36 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.576 | 72.312 | 59.979 | 19.945 | 46.579 | 67.225 |
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
[08/26 14:33:36 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 14:33:36 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/26 14:33:36 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:33:36 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.516
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.740
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.590
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.121
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.459
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.682
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.356
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.628
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.673
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.641
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.789
[08/26 14:33:36 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.570 | 74.033 | 58.963 | 12.143 | 45.931 | 68.222 |
[08/26 14:33:36 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 14:33:36 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 14:33:36 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:33:36 d2.evaluation.testing]: copypaste: 51.5762,72.3118,59.9792,19.9453,46.5789,67.2251
[08/26 14:33:36 d2.evaluation.testing]: copypaste: Task: segm
[08/26 14:33:36 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:33:36 d2.evaluation.testing]: copypaste: 51.5697,74.0329,58.9629,12.1428,45.9309,68.2221
[08/26 14:33:36 d2.utils.events]:  eta: 0:10:39  iter: 659  total_loss: 0.4961  loss_cls: 0.09422  loss_box_reg: 0.2083  loss_mask: 0.1739  loss_rpn_cls: 0.006552  loss_rpn_loc: 0.01099  time: 1.8907  data_time: 0.0267  lr: 0.00016484  max_mem: 10070M
[08/26 14:34:14 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 14:34:14 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 14:34:14 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 14:34:14 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 14:34:14 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 14:34:18 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0023 s/iter. Inference: 0.2153 s/iter. Eval: 0.0581 s/iter. Total: 0.2757 s/iter. ETA=0:00:36
[08/26 14:34:23 d2.evaluation.evaluator]: Inference done 30/144. Dataloading: 0.0040 s/iter. Inference: 0.2161 s/iter. Eval: 0.0467 s/iter. Total: 0.2670 s/iter. ETA=0:00:30
[08/26 14:34:28 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0035 s/iter. Inference: 0.2186 s/iter. Eval: 0.0680 s/iter. Total: 0.2902 s/iter. ETA=0:00:28
[08/26 14:34:33 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0035 s/iter. Inference: 0.2209 s/iter. Eval: 0.0973 s/iter. Total: 0.3218 s/iter. ETA=0:00:27
[08/26 14:34:38 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0034 s/iter. Inference: 0.2215 s/iter. Eval: 0.1107 s/iter. Total: 0.3358 s/iter. ETA=0:00:24
[08/26 14:34:43 d2.evaluation.evaluator]: Inference done 91/144. Dataloading: 0.0034 s/iter. Inference: 0.2199 s/iter. Eval: 0.0924 s/iter. Total: 0.3159 s/iter. ETA=0:00:16
[08/26 14:34:48 d2.evaluation.evaluator]: Inference done 111/144. Dataloading: 0.0033 s/iter. Inference: 0.2189 s/iter. Eval: 0.0834 s/iter. Total: 0.3057 s/iter. ETA=0:00:10
[08/26 14:34:54 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0033 s/iter. Inference: 0.2185 s/iter. Eval: 0.0766 s/iter. Total: 0.2986 s/iter. ETA=0:00:03
[08/26 14:34:57 d2.evaluation.evaluator]: Total inference time: 0:00:41.288085 (0.297037 s / iter per device, on 1 devices)
[08/26 14:34:57 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.218165 s / iter per device, on 1 devices)
[08/26 14:34:57 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 14:34:57 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 14:34:57 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/26 14:34:57 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 14:34:57 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/26 14:34:57 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:34:57 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.520
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.728
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.595
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.196
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.469
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.679
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.374
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.635
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.665
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.622
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.803
[08/26 14:34:57 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.964 | 72.754 | 59.465 | 19.564 | 46.919 | 67.899 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[08/26 14:34:57 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 14:34:58 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/26 14:34:58 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:34:58 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.515
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.737
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.574
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.460
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.678
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.370
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.631
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.662
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.629
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.780
[08/26 14:34:58 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.542 | 73.694 | 57.402 | 11.965 | 45.981 | 67.756 |
[08/26 14:34:58 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 14:34:58 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 14:34:58 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:34:58 d2.evaluation.testing]: copypaste: 51.9641,72.7543,59.4654,19.5645,46.9188,67.8990
[08/26 14:34:58 d2.evaluation.testing]: copypaste: Task: segm
[08/26 14:34:58 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:34:58 d2.evaluation.testing]: copypaste: 51.5420,73.6944,57.4015,11.9646,45.9807,67.7557
[08/26 14:34:58 d2.utils.events]:  eta: 0:10:02  iter: 679  total_loss: 0.3801  loss_cls: 0.05477  loss_box_reg: 0.151  loss_mask: 0.1518  loss_rpn_cls: 0.006488  loss_rpn_loc: 0.003717  time: 1.8902  data_time: 0.0270  lr: 0.00016983  max_mem: 10070M
[08/26 14:35:35 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 14:35:35 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 14:35:35 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 14:35:35 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 14:35:35 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 14:35:41 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0025 s/iter. Inference: 0.2162 s/iter. Eval: 0.0763 s/iter. Total: 0.2950 s/iter. ETA=0:00:39
[08/26 14:35:46 d2.evaluation.evaluator]: Inference done 30/144. Dataloading: 0.0031 s/iter. Inference: 0.2163 s/iter. Eval: 0.0590 s/iter. Total: 0.2786 s/iter. ETA=0:00:31
[08/26 14:35:51 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0033 s/iter. Inference: 0.2183 s/iter. Eval: 0.0806 s/iter. Total: 0.3023 s/iter. ETA=0:00:29
[08/26 14:35:56 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0032 s/iter. Inference: 0.2206 s/iter. Eval: 0.1117 s/iter. Total: 0.3356 s/iter. ETA=0:00:29
[08/26 14:36:01 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0032 s/iter. Inference: 0.2226 s/iter. Eval: 0.1313 s/iter. Total: 0.3573 s/iter. ETA=0:00:27
[08/26 14:36:06 d2.evaluation.evaluator]: Inference done 88/144. Dataloading: 0.0030 s/iter. Inference: 0.2203 s/iter. Eval: 0.1089 s/iter. Total: 0.3324 s/iter. ETA=0:00:18
[08/26 14:36:11 d2.evaluation.evaluator]: Inference done 106/144. Dataloading: 0.0031 s/iter. Inference: 0.2202 s/iter. Eval: 0.0998 s/iter. Total: 0.3233 s/iter. ETA=0:00:12
[08/26 14:36:17 d2.evaluation.evaluator]: Inference done 125/144. Dataloading: 0.0033 s/iter. Inference: 0.2195 s/iter. Eval: 0.0925 s/iter. Total: 0.3156 s/iter. ETA=0:00:05
[08/26 14:36:22 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0031 s/iter. Inference: 0.2193 s/iter. Eval: 0.0890 s/iter. Total: 0.3117 s/iter. ETA=0:00:00
[08/26 14:36:22 d2.evaluation.evaluator]: Total inference time: 0:00:43.393065 (0.312180 s / iter per device, on 1 devices)
[08/26 14:36:22 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.219312 s / iter per device, on 1 devices)
[08/26 14:36:22 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 14:36:22 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 14:36:22 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/26 14:36:22 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 14:36:22 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/26 14:36:22 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:36:22 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.525
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.746
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.613
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.197
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.474
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.686
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.371
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.628
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.670
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.308
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.628
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.809
[08/26 14:36:22 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.550 | 74.560 | 61.319 | 19.669 | 47.360 | 68.641 |
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
[08/26 14:36:23 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 14:36:23 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[08/26 14:36:23 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:36:23 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.530
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.746
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.615
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.124
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.476
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.691
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.370
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.636
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.676
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.643
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.789
[08/26 14:36:23 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 53.003 | 74.625 | 61.471 | 12.377 | 47.601 | 69.089 |
[08/26 14:36:23 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 14:36:23 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 14:36:23 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:36:23 d2.evaluation.testing]: copypaste: 52.5496,74.5597,61.3195,19.6689,47.3605,68.6414
[08/26 14:36:23 d2.evaluation.testing]: copypaste: Task: segm
[08/26 14:36:23 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:36:23 d2.evaluation.testing]: copypaste: 53.0029,74.6250,61.4709,12.3773,47.6007,69.0886
[08/26 14:36:23 d2.utils.events]:  eta: 0:09:24  iter: 699  total_loss: 0.4138  loss_cls: 0.07469  loss_box_reg: 0.1555  loss_mask: 0.1621  loss_rpn_cls: 0.009297  loss_rpn_loc: 0.005373  time: 1.8902  data_time: 0.0257  lr: 0.00017483  max_mem: 10070M
[08/26 14:37:00 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 14:37:00 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 14:37:00 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 14:37:00 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 14:37:00 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 14:37:05 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0028 s/iter. Inference: 0.2265 s/iter. Eval: 0.1007 s/iter. Total: 0.3300 s/iter. ETA=0:00:43
[08/26 14:37:10 d2.evaluation.evaluator]: Inference done 30/144. Dataloading: 0.0027 s/iter. Inference: 0.2170 s/iter. Eval: 0.0594 s/iter. Total: 0.2792 s/iter. ETA=0:00:31
[08/26 14:37:15 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0026 s/iter. Inference: 0.2177 s/iter. Eval: 0.0806 s/iter. Total: 0.3010 s/iter. ETA=0:00:29
[08/26 14:37:20 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0025 s/iter. Inference: 0.2201 s/iter. Eval: 0.1120 s/iter. Total: 0.3348 s/iter. ETA=0:00:29
[08/26 14:37:26 d2.evaluation.evaluator]: Inference done 69/144. Dataloading: 0.0025 s/iter. Inference: 0.2215 s/iter. Eval: 0.1286 s/iter. Total: 0.3528 s/iter. ETA=0:00:26
[08/26 14:37:31 d2.evaluation.evaluator]: Inference done 87/144. Dataloading: 0.0032 s/iter. Inference: 0.2219 s/iter. Eval: 0.1121 s/iter. Total: 0.3373 s/iter. ETA=0:00:19
[08/26 14:37:36 d2.evaluation.evaluator]: Inference done 107/144. Dataloading: 0.0031 s/iter. Inference: 0.2203 s/iter. Eval: 0.0989 s/iter. Total: 0.3225 s/iter. ETA=0:00:11
[08/26 14:37:41 d2.evaluation.evaluator]: Inference done 127/144. Dataloading: 0.0031 s/iter. Inference: 0.2197 s/iter. Eval: 0.0895 s/iter. Total: 0.3125 s/iter. ETA=0:00:05
[08/26 14:37:46 d2.evaluation.evaluator]: Total inference time: 0:00:43.041120 (0.309648 s / iter per device, on 1 devices)
[08/26 14:37:46 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.219226 s / iter per device, on 1 devices)
[08/26 14:37:46 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 14:37:46 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 14:37:46 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/26 14:37:46 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 14:37:46 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/26 14:37:46 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:37:46 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.513
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.751
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.608
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.219
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.465
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.664
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.360
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.617
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.661
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.325
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.789
[08/26 14:37:46 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.300 | 75.069 | 60.775 | 21.863 | 46.472 | 66.387 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[08/26 14:37:46 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 14:37:46 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/26 14:37:46 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:37:46 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.526
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.751
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.601
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.114
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.473
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.687
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.364
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.634
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.676
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.325
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.647
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.789
[08/26 14:37:46 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.552 | 75.101 | 60.071 | 11.414 | 47.323 | 68.652 |
[08/26 14:37:46 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 14:37:46 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 14:37:46 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:37:46 d2.evaluation.testing]: copypaste: 51.3000,75.0686,60.7754,21.8630,46.4721,66.3873
[08/26 14:37:46 d2.evaluation.testing]: copypaste: Task: segm
[08/26 14:37:46 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:37:46 d2.evaluation.testing]: copypaste: 52.5525,75.1015,60.0707,11.4144,47.3229,68.6520
[08/26 14:37:46 d2.utils.events]:  eta: 0:08:46  iter: 719  total_loss: 0.4611  loss_cls: 0.07329  loss_box_reg: 0.1794  loss_mask: 0.17  loss_rpn_cls: 0.006459  loss_rpn_loc: 0.005252  time: 1.8900  data_time: 0.0252  lr: 0.00017982  max_mem: 10070M
[08/26 14:38:24 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 14:38:24 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 14:38:24 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 14:38:24 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 14:38:24 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 14:38:28 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0018 s/iter. Inference: 0.2146 s/iter. Eval: 0.0576 s/iter. Total: 0.2741 s/iter. ETA=0:00:36
[08/26 14:38:33 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0031 s/iter. Inference: 0.2158 s/iter. Eval: 0.0447 s/iter. Total: 0.2639 s/iter. ETA=0:00:29
[08/26 14:38:38 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0044 s/iter. Inference: 0.2207 s/iter. Eval: 0.0650 s/iter. Total: 0.2903 s/iter. ETA=0:00:28
[08/26 14:38:43 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0042 s/iter. Inference: 0.2225 s/iter. Eval: 0.0965 s/iter. Total: 0.3235 s/iter. ETA=0:00:27
[08/26 14:38:49 d2.evaluation.evaluator]: Inference done 72/144. Dataloading: 0.0038 s/iter. Inference: 0.2226 s/iter. Eval: 0.1066 s/iter. Total: 0.3332 s/iter. ETA=0:00:23
[08/26 14:38:54 d2.evaluation.evaluator]: Inference done 93/144. Dataloading: 0.0035 s/iter. Inference: 0.2202 s/iter. Eval: 0.0874 s/iter. Total: 0.3113 s/iter. ETA=0:00:15
[08/26 14:38:59 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0034 s/iter. Inference: 0.2195 s/iter. Eval: 0.0788 s/iter. Total: 0.3019 s/iter. ETA=0:00:09
[08/26 14:39:04 d2.evaluation.evaluator]: Inference done 134/144. Dataloading: 0.0033 s/iter. Inference: 0.2184 s/iter. Eval: 0.0709 s/iter. Total: 0.2928 s/iter. ETA=0:00:02
[08/26 14:39:07 d2.evaluation.evaluator]: Total inference time: 0:00:41.035844 (0.295222 s / iter per device, on 1 devices)
[08/26 14:39:07 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.218621 s / iter per device, on 1 devices)
[08/26 14:39:07 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 14:39:07 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 14:39:07 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/26 14:39:07 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 14:39:07 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/26 14:39:07 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:39:07 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.509
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.739
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.595
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.181
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.470
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.654
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.359
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.618
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.660
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.267
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.627
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.788
[08/26 14:39:07 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.923 | 73.921 | 59.545 | 18.112 | 47.018 | 65.389 |
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
[08/26 14:39:08 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 14:39:08 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.09 seconds.
[08/26 14:39:08 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:39:08 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.528
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.751
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.601
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.116
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.473
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.688
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.362
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.632
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.670
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.637
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.788
[08/26 14:39:08 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.770 | 75.064 | 60.101 | 11.624 | 47.298 | 68.799 |
[08/26 14:39:08 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 14:39:08 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 14:39:08 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:39:08 d2.evaluation.testing]: copypaste: 50.9226,73.9214,59.5454,18.1119,47.0177,65.3886
[08/26 14:39:08 d2.evaluation.testing]: copypaste: Task: segm
[08/26 14:39:08 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:39:08 d2.evaluation.testing]: copypaste: 52.7699,75.0638,60.1011,11.6236,47.2977,68.7993
[08/26 14:39:08 d2.utils.events]:  eta: 0:08:09  iter: 739  total_loss: 0.4038  loss_cls: 0.05562  loss_box_reg: 0.1395  loss_mask: 0.1626  loss_rpn_cls: 0.006232  loss_rpn_loc: 0.004102  time: 1.8896  data_time: 0.0218  lr: 0.00018482  max_mem: 10070M
[08/26 14:39:46 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 14:39:46 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 14:39:46 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 14:39:46 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 14:39:46 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 14:39:50 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0027 s/iter. Inference: 0.2224 s/iter. Eval: 0.0809 s/iter. Total: 0.3060 s/iter. ETA=0:00:40
[08/26 14:39:55 d2.evaluation.evaluator]: Inference done 30/144. Dataloading: 0.0027 s/iter. Inference: 0.2159 s/iter. Eval: 0.0551 s/iter. Total: 0.2739 s/iter. ETA=0:00:31
[08/26 14:40:00 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0026 s/iter. Inference: 0.2167 s/iter. Eval: 0.0747 s/iter. Total: 0.2941 s/iter. ETA=0:00:28
[08/26 14:40:06 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0026 s/iter. Inference: 0.2191 s/iter. Eval: 0.1055 s/iter. Total: 0.3274 s/iter. ETA=0:00:28
[08/26 14:40:11 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0027 s/iter. Inference: 0.2201 s/iter. Eval: 0.1192 s/iter. Total: 0.3422 s/iter. ETA=0:00:24
[08/26 14:40:16 d2.evaluation.evaluator]: Inference done 90/144. Dataloading: 0.0032 s/iter. Inference: 0.2202 s/iter. Eval: 0.1016 s/iter. Total: 0.3252 s/iter. ETA=0:00:17
[08/26 14:40:21 d2.evaluation.evaluator]: Inference done 110/144. Dataloading: 0.0030 s/iter. Inference: 0.2188 s/iter. Eval: 0.0905 s/iter. Total: 0.3125 s/iter. ETA=0:00:10
[08/26 14:40:26 d2.evaluation.evaluator]: Inference done 130/144. Dataloading: 0.0030 s/iter. Inference: 0.2182 s/iter. Eval: 0.0823 s/iter. Total: 0.3037 s/iter. ETA=0:00:04
[08/26 14:40:30 d2.evaluation.evaluator]: Total inference time: 0:00:42.014418 (0.302262 s / iter per device, on 1 devices)
[08/26 14:40:30 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.217836 s / iter per device, on 1 devices)
[08/26 14:40:30 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 14:40:30 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 14:40:30 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/26 14:40:30 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 14:40:30 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/26 14:40:30 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:40:30 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.519
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.745
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.607
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.212
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.469
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.673
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.366
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.618
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.663
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.308
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.627
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.789
[08/26 14:40:30 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.898 | 74.519 | 60.722 | 21.229 | 46.905 | 67.312 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[08/26 14:40:31 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 14:40:31 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/26 14:40:31 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:40:31 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.529
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.753
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.605
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.125
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.478
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.684
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.367
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.632
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.678
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.342
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.650
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.788
[08/26 14:40:31 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.935 | 75.275 | 60.472 | 12.490 | 47.847 | 68.439 |
[08/26 14:40:31 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 14:40:31 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 14:40:31 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:40:31 d2.evaluation.testing]: copypaste: 51.8975,74.5186,60.7216,21.2286,46.9048,67.3119
[08/26 14:40:31 d2.evaluation.testing]: copypaste: Task: segm
[08/26 14:40:31 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:40:31 d2.evaluation.testing]: copypaste: 52.9349,75.2753,60.4724,12.4904,47.8469,68.4388
[08/26 14:40:31 d2.utils.events]:  eta: 0:07:31  iter: 759  total_loss: 0.449  loss_cls: 0.07313  loss_box_reg: 0.181  loss_mask: 0.1693  loss_rpn_cls: 0.007839  loss_rpn_loc: 0.006407  time: 1.8898  data_time: 0.0274  lr: 0.00018981  max_mem: 10070M
[08/26 14:41:08 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 14:41:08 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 14:41:08 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 14:41:08 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 14:41:08 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 14:41:12 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0023 s/iter. Inference: 0.2143 s/iter. Eval: 0.0600 s/iter. Total: 0.2766 s/iter. ETA=0:00:36
[08/26 14:41:18 d2.evaluation.evaluator]: Inference done 30/144. Dataloading: 0.0029 s/iter. Inference: 0.2167 s/iter. Eval: 0.0566 s/iter. Total: 0.2763 s/iter. ETA=0:00:31
[08/26 14:41:23 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0037 s/iter. Inference: 0.2196 s/iter. Eval: 0.0723 s/iter. Total: 0.2957 s/iter. ETA=0:00:28
[08/26 14:41:28 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0034 s/iter. Inference: 0.2224 s/iter. Eval: 0.1055 s/iter. Total: 0.3315 s/iter. ETA=0:00:28
[08/26 14:41:33 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0032 s/iter. Inference: 0.2226 s/iter. Eval: 0.1161 s/iter. Total: 0.3420 s/iter. ETA=0:00:24
[08/26 14:41:38 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0030 s/iter. Inference: 0.2199 s/iter. Eval: 0.0952 s/iter. Total: 0.3183 s/iter. ETA=0:00:16
[08/26 14:41:43 d2.evaluation.evaluator]: Inference done 111/144. Dataloading: 0.0032 s/iter. Inference: 0.2191 s/iter. Eval: 0.0862 s/iter. Total: 0.3086 s/iter. ETA=0:00:10
[08/26 14:41:48 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0031 s/iter. Inference: 0.2180 s/iter. Eval: 0.0783 s/iter. Total: 0.2996 s/iter. ETA=0:00:03
[08/26 14:41:53 d2.evaluation.evaluator]: Total inference time: 0:00:42.133517 (0.303119 s / iter per device, on 1 devices)
[08/26 14:41:53 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.219938 s / iter per device, on 1 devices)
[08/26 14:41:53 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 14:41:53 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 14:41:53 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/26 14:41:53 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 14:41:53 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/26 14:41:53 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:41:53 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.506
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.741
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.614
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.215
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.453
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.662
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.366
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.615
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.648
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.607
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.782
[08/26 14:41:53 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.633 | 74.107 | 61.403 | 21.480 | 45.314 | 66.209 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[08/26 14:41:53 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 14:41:53 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/26 14:41:53 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:41:53 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.527
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.751
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.608
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.128
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.480
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.683
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.373
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.636
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.671
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.640
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.783
[08/26 14:41:53 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.721 | 75.088 | 60.828 | 12.810 | 48.018 | 68.342 |
[08/26 14:41:53 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 14:41:53 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 14:41:53 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:41:53 d2.evaluation.testing]: copypaste: 50.6334,74.1066,61.4027,21.4804,45.3140,66.2094
[08/26 14:41:53 d2.evaluation.testing]: copypaste: Task: segm
[08/26 14:41:53 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:41:53 d2.evaluation.testing]: copypaste: 52.7211,75.0882,60.8284,12.8100,48.0182,68.3419
[08/26 14:41:53 d2.utils.events]:  eta: 0:06:53  iter: 779  total_loss: 0.444  loss_cls: 0.08301  loss_box_reg: 0.1644  loss_mask: 0.1664  loss_rpn_cls: 0.005024  loss_rpn_loc: 0.007283  time: 1.8895  data_time: 0.0253  lr: 0.00019481  max_mem: 10070M
[08/26 14:42:31 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 14:42:31 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 14:42:31 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 14:42:31 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 14:42:31 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 14:42:35 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0033 s/iter. Inference: 0.2220 s/iter. Eval: 0.0636 s/iter. Total: 0.2890 s/iter. ETA=0:00:38
[08/26 14:42:41 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0030 s/iter. Inference: 0.2152 s/iter. Eval: 0.0490 s/iter. Total: 0.2675 s/iter. ETA=0:00:30
[08/26 14:42:46 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0029 s/iter. Inference: 0.2168 s/iter. Eval: 0.0775 s/iter. Total: 0.2974 s/iter. ETA=0:00:28
[08/26 14:42:52 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0029 s/iter. Inference: 0.2197 s/iter. Eval: 0.1151 s/iter. Total: 0.3379 s/iter. ETA=0:00:28
[08/26 14:42:57 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0028 s/iter. Inference: 0.2217 s/iter. Eval: 0.1291 s/iter. Total: 0.3538 s/iter. ETA=0:00:25
[08/26 14:43:02 d2.evaluation.evaluator]: Inference done 91/144. Dataloading: 0.0028 s/iter. Inference: 0.2200 s/iter. Eval: 0.1072 s/iter. Total: 0.3303 s/iter. ETA=0:00:17
[08/26 14:43:07 d2.evaluation.evaluator]: Inference done 110/144. Dataloading: 0.0030 s/iter. Inference: 0.2191 s/iter. Eval: 0.0973 s/iter. Total: 0.3196 s/iter. ETA=0:00:10
[08/26 14:43:12 d2.evaluation.evaluator]: Inference done 130/144. Dataloading: 0.0031 s/iter. Inference: 0.2182 s/iter. Eval: 0.0878 s/iter. Total: 0.3092 s/iter. ETA=0:00:04
[08/26 14:43:16 d2.evaluation.evaluator]: Total inference time: 0:00:42.729891 (0.307409 s / iter per device, on 1 devices)
[08/26 14:43:16 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.217869 s / iter per device, on 1 devices)
[08/26 14:43:16 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 14:43:16 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 14:43:16 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/26 14:43:17 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 14:43:17 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/26 14:43:17 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:43:17 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.515
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.742
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.611
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.216
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.466
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.665
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.370
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.622
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.666
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.638
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.780
[08/26 14:43:17 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.490 | 74.211 | 61.121 | 21.602 | 46.639 | 66.540 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[08/26 14:43:17 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 14:43:17 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/26 14:43:17 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:43:17 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.528
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.752
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.609
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.124
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.480
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.685
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.374
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.634
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.677
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.649
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.788
[08/26 14:43:17 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.828 | 75.202 | 60.901 | 12.379 | 47.974 | 68.540 |
[08/26 14:43:17 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 14:43:17 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 14:43:17 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:43:17 d2.evaluation.testing]: copypaste: 51.4898,74.2111,61.1212,21.6019,46.6390,66.5399
[08/26 14:43:17 d2.evaluation.testing]: copypaste: Task: segm
[08/26 14:43:17 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:43:17 d2.evaluation.testing]: copypaste: 52.8284,75.2024,60.9009,12.3785,47.9739,68.5395
[08/26 14:43:17 d2.utils.events]:  eta: 0:06:16  iter: 799  total_loss: 0.3961  loss_cls: 0.08076  loss_box_reg: 0.1629  loss_mask: 0.1431  loss_rpn_cls: 0.004627  loss_rpn_loc: 0.004537  time: 1.8898  data_time: 0.0248  lr: 0.0001998  max_mem: 10070M
[08/26 14:43:55 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 14:43:55 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 14:43:55 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 14:43:55 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 14:43:55 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 14:43:59 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0021 s/iter. Inference: 0.2148 s/iter. Eval: 0.0632 s/iter. Total: 0.2801 s/iter. ETA=0:00:37
[08/26 14:44:04 d2.evaluation.evaluator]: Inference done 28/144. Dataloading: 0.0054 s/iter. Inference: 0.2235 s/iter. Eval: 0.0658 s/iter. Total: 0.2950 s/iter. ETA=0:00:34
[08/26 14:44:10 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0044 s/iter. Inference: 0.2209 s/iter. Eval: 0.0753 s/iter. Total: 0.3007 s/iter. ETA=0:00:29
[08/26 14:44:15 d2.evaluation.evaluator]: Inference done 56/144. Dataloading: 0.0042 s/iter. Inference: 0.2237 s/iter. Eval: 0.1129 s/iter. Total: 0.3410 s/iter. ETA=0:00:30
[08/26 14:44:20 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0039 s/iter. Inference: 0.2243 s/iter. Eval: 0.1278 s/iter. Total: 0.3562 s/iter. ETA=0:00:27
[08/26 14:44:25 d2.evaluation.evaluator]: Inference done 87/144. Dataloading: 0.0037 s/iter. Inference: 0.2228 s/iter. Eval: 0.1103 s/iter. Total: 0.3370 s/iter. ETA=0:00:19
[08/26 14:44:30 d2.evaluation.evaluator]: Inference done 107/144. Dataloading: 0.0035 s/iter. Inference: 0.2211 s/iter. Eval: 0.0970 s/iter. Total: 0.3219 s/iter. ETA=0:00:11
[08/26 14:44:35 d2.evaluation.evaluator]: Inference done 126/144. Dataloading: 0.0034 s/iter. Inference: 0.2207 s/iter. Eval: 0.0890 s/iter. Total: 0.3134 s/iter. ETA=0:00:05
[08/26 14:44:41 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0036 s/iter. Inference: 0.2219 s/iter. Eval: 0.0868 s/iter. Total: 0.3125 s/iter. ETA=0:00:00
[08/26 14:44:41 d2.evaluation.evaluator]: Total inference time: 0:00:43.508455 (0.313010 s / iter per device, on 1 devices)
[08/26 14:44:41 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.221897 s / iter per device, on 1 devices)
[08/26 14:44:41 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 14:44:41 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 14:44:41 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/26 14:44:41 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 14:44:41 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/26 14:44:41 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:44:41 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.513
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.742
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.604
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.206
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.460
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.676
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.370
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.663
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.292
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.800
[08/26 14:44:41 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.340 | 74.246 | 60.376 | 20.614 | 45.978 | 67.572 |
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
[08/26 14:44:41 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 14:44:41 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/26 14:44:41 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:44:41 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.526
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.747
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.601
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.123
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.476
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.687
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.368
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.633
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.676
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.647
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.789
[08/26 14:44:41 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.561 | 74.693 | 60.138 | 12.296 | 47.581 | 68.676 |
[08/26 14:44:41 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 14:44:41 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 14:44:41 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:44:41 d2.evaluation.testing]: copypaste: 51.3403,74.2464,60.3757,20.6136,45.9781,67.5723
[08/26 14:44:41 d2.evaluation.testing]: copypaste: Task: segm
[08/26 14:44:41 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:44:41 d2.evaluation.testing]: copypaste: 52.5606,74.6929,60.1376,12.2964,47.5806,68.6758
[08/26 14:44:41 d2.utils.events]:  eta: 0:05:38  iter: 819  total_loss: 0.4586  loss_cls: 0.0711  loss_box_reg: 0.1599  loss_mask: 0.1824  loss_rpn_cls: 0.003626  loss_rpn_loc: 0.006542  time: 1.8898  data_time: 0.0257  lr: 0.0002048  max_mem: 10070M
[08/26 14:45:19 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 14:45:19 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 14:45:19 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 14:45:19 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 14:45:19 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 14:45:23 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0021 s/iter. Inference: 0.2150 s/iter. Eval: 0.0620 s/iter. Total: 0.2791 s/iter. ETA=0:00:37
[08/26 14:45:28 d2.evaluation.evaluator]: Inference done 30/144. Dataloading: 0.0022 s/iter. Inference: 0.2140 s/iter. Eval: 0.0507 s/iter. Total: 0.2671 s/iter. ETA=0:00:30
[08/26 14:45:34 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0029 s/iter. Inference: 0.2168 s/iter. Eval: 0.0701 s/iter. Total: 0.2901 s/iter. ETA=0:00:28
[08/26 14:45:39 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0030 s/iter. Inference: 0.2198 s/iter. Eval: 0.1050 s/iter. Total: 0.3280 s/iter. ETA=0:00:28
[08/26 14:45:44 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0033 s/iter. Inference: 0.2241 s/iter. Eval: 0.1308 s/iter. Total: 0.3584 s/iter. ETA=0:00:27
[08/26 14:45:49 d2.evaluation.evaluator]: Inference done 88/144. Dataloading: 0.0032 s/iter. Inference: 0.2216 s/iter. Eval: 0.1087 s/iter. Total: 0.3337 s/iter. ETA=0:00:18
[08/26 14:45:54 d2.evaluation.evaluator]: Inference done 107/144. Dataloading: 0.0034 s/iter. Inference: 0.2209 s/iter. Eval: 0.0970 s/iter. Total: 0.3215 s/iter. ETA=0:00:11
[08/26 14:46:00 d2.evaluation.evaluator]: Inference done 127/144. Dataloading: 0.0033 s/iter. Inference: 0.2197 s/iter. Eval: 0.0871 s/iter. Total: 0.3103 s/iter. ETA=0:00:05
[08/26 14:46:04 d2.evaluation.evaluator]: Total inference time: 0:00:42.834790 (0.308164 s / iter per device, on 1 devices)
[08/26 14:46:05 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.219582 s / iter per device, on 1 devices)
[08/26 14:46:05 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 14:46:05 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 14:46:05 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/26 14:46:05 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 14:46:05 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/26 14:46:05 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:46:05 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.526
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.754
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.623
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.229
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.470
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.688
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.365
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.630
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.672
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.633
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.803
[08/26 14:46:05 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.634 | 75.377 | 62.312 | 22.893 | 46.960 | 68.829 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[08/26 14:46:05 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 14:46:05 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/26 14:46:05 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:46:05 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.530
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.761
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.600
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.140
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.477
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.690
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.363
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.637
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.682
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.651
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.794
[08/26 14:46:05 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 53.046 | 76.076 | 60.028 | 13.986 | 47.662 | 68.972 |
[08/26 14:46:05 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 14:46:05 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 14:46:05 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:46:05 d2.evaluation.testing]: copypaste: 52.6336,75.3766,62.3117,22.8926,46.9598,68.8293
[08/26 14:46:05 d2.evaluation.testing]: copypaste: Task: segm
[08/26 14:46:05 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:46:05 d2.evaluation.testing]: copypaste: 53.0462,76.0756,60.0283,13.9860,47.6617,68.9721
[08/26 14:46:05 d2.utils.events]:  eta: 0:05:00  iter: 839  total_loss: 0.4082  loss_cls: 0.08258  loss_box_reg: 0.1672  loss_mask: 0.1621  loss_rpn_cls: 0.004651  loss_rpn_loc: 0.006397  time: 1.8900  data_time: 0.0245  lr: 0.00020979  max_mem: 10070M
[08/26 14:46:43 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 14:46:43 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 14:46:43 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 14:46:43 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 14:46:43 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 14:46:47 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0032 s/iter. Inference: 0.2337 s/iter. Eval: 0.1191 s/iter. Total: 0.3560 s/iter. ETA=0:00:47
[08/26 14:46:52 d2.evaluation.evaluator]: Inference done 30/144. Dataloading: 0.0034 s/iter. Inference: 0.2213 s/iter. Eval: 0.0620 s/iter. Total: 0.2872 s/iter. ETA=0:00:32
[08/26 14:46:58 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0031 s/iter. Inference: 0.2206 s/iter. Eval: 0.0791 s/iter. Total: 0.3031 s/iter. ETA=0:00:29
[08/26 14:47:03 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0035 s/iter. Inference: 0.2221 s/iter. Eval: 0.1068 s/iter. Total: 0.3327 s/iter. ETA=0:00:28
[08/26 14:47:08 d2.evaluation.evaluator]: Inference done 76/144. Dataloading: 0.0032 s/iter. Inference: 0.2209 s/iter. Eval: 0.1011 s/iter. Total: 0.3255 s/iter. ETA=0:00:22
[08/26 14:47:14 d2.evaluation.evaluator]: Inference done 97/144. Dataloading: 0.0033 s/iter. Inference: 0.2193 s/iter. Eval: 0.0846 s/iter. Total: 0.3075 s/iter. ETA=0:00:14
[08/26 14:47:19 d2.evaluation.evaluator]: Inference done 117/144. Dataloading: 0.0033 s/iter. Inference: 0.2183 s/iter. Eval: 0.0763 s/iter. Total: 0.2981 s/iter. ETA=0:00:08
[08/26 14:47:24 d2.evaluation.evaluator]: Inference done 136/144. Dataloading: 0.0035 s/iter. Inference: 0.2200 s/iter. Eval: 0.0707 s/iter. Total: 0.2944 s/iter. ETA=0:00:02
[08/26 14:47:26 d2.evaluation.evaluator]: Total inference time: 0:00:40.958122 (0.294663 s / iter per device, on 1 devices)
[08/26 14:47:26 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.219790 s / iter per device, on 1 devices)
[08/26 14:47:26 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 14:47:26 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 14:47:26 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/26 14:47:26 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 14:47:26 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/26 14:47:26 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:47:26 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.522
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.756
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.612
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.220
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.472
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.674
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.373
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.620
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.655
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.794
[08/26 14:47:26 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.222 | 75.591 | 61.203 | 22.006 | 47.247 | 67.403 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[08/26 14:47:26 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 14:47:27 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[08/26 14:47:27 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:47:27 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.535
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.760
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.604
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.138
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.490
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.687
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.374
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.632
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.668
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.342
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.635
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.786
[08/26 14:47:27 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 53.482 | 76.032 | 60.408 | 13.834 | 48.974 | 68.665 |
[08/26 14:47:27 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 14:47:27 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 14:47:27 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:47:27 d2.evaluation.testing]: copypaste: 52.2223,75.5906,61.2029,22.0060,47.2474,67.4026
[08/26 14:47:27 d2.evaluation.testing]: copypaste: Task: segm
[08/26 14:47:27 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:47:27 d2.evaluation.testing]: copypaste: 53.4819,76.0317,60.4079,13.8344,48.9744,68.6651
[08/26 14:47:27 d2.utils.events]:  eta: 0:04:23  iter: 859  total_loss: 0.3705  loss_cls: 0.07172  loss_box_reg: 0.1217  loss_mask: 0.1643  loss_rpn_cls: 0.004076  loss_rpn_loc: 0.003471  time: 1.8900  data_time: 0.0259  lr: 0.00021479  max_mem: 10070M
[08/26 14:48:05 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 14:48:05 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 14:48:05 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 14:48:05 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 14:48:05 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 14:48:09 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0020 s/iter. Inference: 0.2150 s/iter. Eval: 0.0547 s/iter. Total: 0.2717 s/iter. ETA=0:00:36
[08/26 14:48:14 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0022 s/iter. Inference: 0.2138 s/iter. Eval: 0.0440 s/iter. Total: 0.2602 s/iter. ETA=0:00:29
[08/26 14:48:19 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0029 s/iter. Inference: 0.2177 s/iter. Eval: 0.0679 s/iter. Total: 0.2887 s/iter. ETA=0:00:28
[08/26 14:48:25 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0028 s/iter. Inference: 0.2206 s/iter. Eval: 0.1053 s/iter. Total: 0.3289 s/iter. ETA=0:00:27
[08/26 14:48:30 d2.evaluation.evaluator]: Inference done 72/144. Dataloading: 0.0031 s/iter. Inference: 0.2232 s/iter. Eval: 0.1141 s/iter. Total: 0.3405 s/iter. ETA=0:00:24
[08/26 14:48:35 d2.evaluation.evaluator]: Inference done 93/144. Dataloading: 0.0030 s/iter. Inference: 0.2206 s/iter. Eval: 0.0938 s/iter. Total: 0.3176 s/iter. ETA=0:00:16
[08/26 14:48:40 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0031 s/iter. Inference: 0.2196 s/iter. Eval: 0.0844 s/iter. Total: 0.3072 s/iter. ETA=0:00:09
[08/26 14:48:45 d2.evaluation.evaluator]: Inference done 134/144. Dataloading: 0.0031 s/iter. Inference: 0.2184 s/iter. Eval: 0.0750 s/iter. Total: 0.2967 s/iter. ETA=0:00:02
[08/26 14:48:48 d2.evaluation.evaluator]: Total inference time: 0:00:41.294737 (0.297084 s / iter per device, on 1 devices)
[08/26 14:48:48 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.218319 s / iter per device, on 1 devices)
[08/26 14:48:48 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 14:48:48 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 14:48:48 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/26 14:48:48 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 14:48:48 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[08/26 14:48:48 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:48:48 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.518
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.757
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.619
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.231
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.471
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.666
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.368
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.621
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.667
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.325
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.634
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.786
[08/26 14:48:48 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.751 | 75.703 | 61.882 | 23.096 | 47.065 | 66.582 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[08/26 14:48:49 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 14:48:49 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/26 14:48:49 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:48:49 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.525
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.756
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.602
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.133
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.482
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.678
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.370
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.631
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.679
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.653
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.783
[08/26 14:48:49 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.529 | 75.558 | 60.199 | 13.273 | 48.165 | 67.808 |
[08/26 14:48:49 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 14:48:49 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 14:48:49 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:48:49 d2.evaluation.testing]: copypaste: 51.7511,75.7028,61.8815,23.0965,47.0649,66.5821
[08/26 14:48:49 d2.evaluation.testing]: copypaste: Task: segm
[08/26 14:48:49 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:48:49 d2.evaluation.testing]: copypaste: 52.5292,75.5575,60.1994,13.2731,48.1651,67.8082
[08/26 14:48:49 d2.utils.events]:  eta: 0:03:45  iter: 879  total_loss: 0.4036  loss_cls: 0.0727  loss_box_reg: 0.1495  loss_mask: 0.1523  loss_rpn_cls: 0.007782  loss_rpn_loc: 0.005899  time: 1.8904  data_time: 0.0288  lr: 0.00021978  max_mem: 10070M
[08/26 14:49:26 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 14:49:26 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 14:49:26 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 14:49:26 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 14:49:26 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 14:49:30 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0019 s/iter. Inference: 0.2133 s/iter. Eval: 0.0502 s/iter. Total: 0.2654 s/iter. ETA=0:00:35
[08/26 14:49:35 d2.evaluation.evaluator]: Inference done 28/144. Dataloading: 0.0035 s/iter. Inference: 0.2212 s/iter. Eval: 0.0620 s/iter. Total: 0.2870 s/iter. ETA=0:00:33
[08/26 14:49:41 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0030 s/iter. Inference: 0.2191 s/iter. Eval: 0.0693 s/iter. Total: 0.2915 s/iter. ETA=0:00:28
[08/26 14:49:46 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0031 s/iter. Inference: 0.2213 s/iter. Eval: 0.1029 s/iter. Total: 0.3275 s/iter. ETA=0:00:28
[08/26 14:49:51 d2.evaluation.evaluator]: Inference done 70/144. Dataloading: 0.0030 s/iter. Inference: 0.2219 s/iter. Eval: 0.1161 s/iter. Total: 0.3413 s/iter. ETA=0:00:25
[08/26 14:49:56 d2.evaluation.evaluator]: Inference done 91/144. Dataloading: 0.0031 s/iter. Inference: 0.2202 s/iter. Eval: 0.0956 s/iter. Total: 0.3191 s/iter. ETA=0:00:16
[08/26 14:50:01 d2.evaluation.evaluator]: Inference done 111/144. Dataloading: 0.0031 s/iter. Inference: 0.2187 s/iter. Eval: 0.0843 s/iter. Total: 0.3063 s/iter. ETA=0:00:10
[08/26 14:50:06 d2.evaluation.evaluator]: Inference done 130/144. Dataloading: 0.0032 s/iter. Inference: 0.2207 s/iter. Eval: 0.0776 s/iter. Total: 0.3017 s/iter. ETA=0:00:04
[08/26 14:50:10 d2.evaluation.evaluator]: Total inference time: 0:00:41.586512 (0.299184 s / iter per device, on 1 devices)
[08/26 14:50:10 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.220019 s / iter per device, on 1 devices)
[08/26 14:50:10 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 14:50:10 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 14:50:10 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/26 14:50:10 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 14:50:10 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/26 14:50:10 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:50:10 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.521
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.753
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.611
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.214
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.469
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.678
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.367
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.621
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.665
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.629
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.794
[08/26 14:50:10 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.087 | 75.341 | 61.103 | 21.370 | 46.943 | 67.805 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[08/26 14:50:10 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 14:50:10 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/26 14:50:10 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:50:11 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.530
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.763
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.595
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.141
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.484
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.681
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.368
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.635
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.680
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.367
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.652
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.785
[08/26 14:50:11 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.969 | 76.309 | 59.504 | 14.058 | 48.367 | 68.114 |
[08/26 14:50:11 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 14:50:11 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 14:50:11 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:50:11 d2.evaluation.testing]: copypaste: 52.0866,75.3415,61.1033,21.3697,46.9433,67.8047
[08/26 14:50:11 d2.evaluation.testing]: copypaste: Task: segm
[08/26 14:50:11 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:50:11 d2.evaluation.testing]: copypaste: 52.9694,76.3087,59.5042,14.0579,48.3673,68.1145
[08/26 14:50:11 d2.utils.events]:  eta: 0:03:08  iter: 899  total_loss: 0.4602  loss_cls: 0.07898  loss_box_reg: 0.1725  loss_mask: 0.1992  loss_rpn_cls: 0.003595  loss_rpn_loc: 0.006316  time: 1.8901  data_time: 0.0240  lr: 0.00022478  max_mem: 10070M
[08/26 14:50:48 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 14:50:48 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 14:50:48 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 14:50:48 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 14:50:48 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 14:50:53 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0025 s/iter. Inference: 0.2144 s/iter. Eval: 0.0522 s/iter. Total: 0.2690 s/iter. ETA=0:00:35
[08/26 14:50:58 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0025 s/iter. Inference: 0.2132 s/iter. Eval: 0.0464 s/iter. Total: 0.2623 s/iter. ETA=0:00:29
[08/26 14:51:03 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0027 s/iter. Inference: 0.2158 s/iter. Eval: 0.0737 s/iter. Total: 0.2924 s/iter. ETA=0:00:28
[08/26 14:51:09 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0026 s/iter. Inference: 0.2192 s/iter. Eval: 0.1110 s/iter. Total: 0.3330 s/iter. ETA=0:00:28
[08/26 14:51:14 d2.evaluation.evaluator]: Inference done 74/144. Dataloading: 0.0028 s/iter. Inference: 0.2199 s/iter. Eval: 0.1118 s/iter. Total: 0.3347 s/iter. ETA=0:00:23
[08/26 14:51:19 d2.evaluation.evaluator]: Inference done 93/144. Dataloading: 0.0030 s/iter. Inference: 0.2195 s/iter. Eval: 0.0987 s/iter. Total: 0.3214 s/iter. ETA=0:00:16
[08/26 14:51:24 d2.evaluation.evaluator]: Inference done 112/144. Dataloading: 0.0032 s/iter. Inference: 0.2186 s/iter. Eval: 0.0894 s/iter. Total: 0.3114 s/iter. ETA=0:00:09
[08/26 14:51:29 d2.evaluation.evaluator]: Inference done 133/144. Dataloading: 0.0032 s/iter. Inference: 0.2174 s/iter. Eval: 0.0797 s/iter. Total: 0.3004 s/iter. ETA=0:00:03
[08/26 14:51:33 d2.evaluation.evaluator]: Total inference time: 0:00:41.856874 (0.301129 s / iter per device, on 1 devices)
[08/26 14:51:33 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.217148 s / iter per device, on 1 devices)
[08/26 14:51:33 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 14:51:33 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 14:51:33 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/26 14:51:33 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 14:51:33 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/26 14:51:33 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:51:33 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.523
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.755
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.611
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.202
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.471
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.684
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.375
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.632
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.672
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.634
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.806
[08/26 14:51:33 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.338 | 75.457 | 61.086 | 20.157 | 47.137 | 68.354 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[08/26 14:51:33 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 14:51:33 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[08/26 14:51:33 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:51:33 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.534
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.763
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.605
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.152
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.491
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.683
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.374
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.640
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.682
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.383
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.652
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.788
[08/26 14:51:33 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 53.400 | 76.288 | 60.534 | 15.231 | 49.132 | 68.342 |
[08/26 14:51:33 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 14:51:33 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 14:51:33 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:51:33 d2.evaluation.testing]: copypaste: 52.3376,75.4566,61.0865,20.1570,47.1371,68.3541
[08/26 14:51:33 d2.evaluation.testing]: copypaste: Task: segm
[08/26 14:51:33 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:51:33 d2.evaluation.testing]: copypaste: 53.4001,76.2881,60.5343,15.2314,49.1322,68.3425
[08/26 14:51:33 d2.utils.events]:  eta: 0:02:30  iter: 919  total_loss: 0.4017  loss_cls: 0.07907  loss_box_reg: 0.161  loss_mask: 0.1424  loss_rpn_cls: 0.006359  loss_rpn_loc: 0.006255  time: 1.8899  data_time: 0.0250  lr: 0.00022977  max_mem: 10070M
[08/26 14:52:11 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 14:52:11 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 14:52:11 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 14:52:11 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 14:52:11 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 14:52:15 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0034 s/iter. Inference: 0.2161 s/iter. Eval: 0.0587 s/iter. Total: 0.2782 s/iter. ETA=0:00:37
[08/26 14:52:20 d2.evaluation.evaluator]: Inference done 30/144. Dataloading: 0.0035 s/iter. Inference: 0.2160 s/iter. Eval: 0.0527 s/iter. Total: 0.2722 s/iter. ETA=0:00:31
[08/26 14:52:25 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0037 s/iter. Inference: 0.2203 s/iter. Eval: 0.0696 s/iter. Total: 0.2937 s/iter. ETA=0:00:28
[08/26 14:52:31 d2.evaluation.evaluator]: Inference done 56/144. Dataloading: 0.0035 s/iter. Inference: 0.2227 s/iter. Eval: 0.1089 s/iter. Total: 0.3353 s/iter. ETA=0:00:29
[08/26 14:52:36 d2.evaluation.evaluator]: Inference done 69/144. Dataloading: 0.0032 s/iter. Inference: 0.2233 s/iter. Eval: 0.1221 s/iter. Total: 0.3487 s/iter. ETA=0:00:26
[08/26 14:52:41 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0032 s/iter. Inference: 0.2218 s/iter. Eval: 0.1021 s/iter. Total: 0.3272 s/iter. ETA=0:00:17
[08/26 14:52:46 d2.evaluation.evaluator]: Inference done 109/144. Dataloading: 0.0031 s/iter. Inference: 0.2202 s/iter. Eval: 0.0901 s/iter. Total: 0.3135 s/iter. ETA=0:00:10
[08/26 14:52:51 d2.evaluation.evaluator]: Inference done 130/144. Dataloading: 0.0033 s/iter. Inference: 0.2191 s/iter. Eval: 0.0803 s/iter. Total: 0.3029 s/iter. ETA=0:00:04
[08/26 14:52:56 d2.evaluation.evaluator]: Total inference time: 0:00:42.139583 (0.303162 s / iter per device, on 1 devices)
[08/26 14:52:56 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.219216 s / iter per device, on 1 devices)
[08/26 14:52:56 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 14:52:56 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 14:52:56 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/26 14:52:56 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 14:52:56 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/26 14:52:56 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:52:56 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.518
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.748
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.609
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.230
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.469
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.674
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.369
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.667
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.637
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.786
[08/26 14:52:56 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.773 | 74.802 | 60.948 | 22.992 | 46.944 | 67.436 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[08/26 14:52:56 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 14:52:56 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/26 14:52:56 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:52:56 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.530
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.760
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.591
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.137
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.483
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.688
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.374
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.641
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.682
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.367
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.655
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.786
[08/26 14:52:56 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 53.025 | 76.023 | 59.143 | 13.666 | 48.324 | 68.776 |
[08/26 14:52:56 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 14:52:56 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 14:52:56 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:52:56 d2.evaluation.testing]: copypaste: 51.7727,74.8021,60.9480,22.9918,46.9440,67.4359
[08/26 14:52:56 d2.evaluation.testing]: copypaste: Task: segm
[08/26 14:52:56 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:52:56 d2.evaluation.testing]: copypaste: 53.0247,76.0232,59.1431,13.6664,48.3241,68.7763
[08/26 14:52:56 d2.utils.events]:  eta: 0:01:52  iter: 939  total_loss: 0.3718  loss_cls: 0.0627  loss_box_reg: 0.1346  loss_mask: 0.1639  loss_rpn_cls: 0.004412  loss_rpn_loc: 0.005057  time: 1.8898  data_time: 0.0239  lr: 0.00023477  max_mem: 10070M
[08/26 14:53:34 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 14:53:34 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 14:53:34 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 14:53:34 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 14:53:34 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 14:53:38 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0019 s/iter. Inference: 0.2120 s/iter. Eval: 0.0408 s/iter. Total: 0.2547 s/iter. ETA=0:00:33
[08/26 14:53:43 d2.evaluation.evaluator]: Inference done 32/144. Dataloading: 0.0022 s/iter. Inference: 0.2111 s/iter. Eval: 0.0291 s/iter. Total: 0.2425 s/iter. ETA=0:00:27
[08/26 14:53:48 d2.evaluation.evaluator]: Inference done 48/144. Dataloading: 0.0024 s/iter. Inference: 0.2151 s/iter. Eval: 0.0537 s/iter. Total: 0.2714 s/iter. ETA=0:00:26
[08/26 14:53:53 d2.evaluation.evaluator]: Inference done 62/144. Dataloading: 0.0025 s/iter. Inference: 0.2168 s/iter. Eval: 0.0765 s/iter. Total: 0.2960 s/iter. ETA=0:00:24
[08/26 14:53:58 d2.evaluation.evaluator]: Inference done 79/144. Dataloading: 0.0027 s/iter. Inference: 0.2173 s/iter. Eval: 0.0763 s/iter. Total: 0.2964 s/iter. ETA=0:00:19
[08/26 14:54:03 d2.evaluation.evaluator]: Inference done 99/144. Dataloading: 0.0031 s/iter. Inference: 0.2173 s/iter. Eval: 0.0664 s/iter. Total: 0.2870 s/iter. ETA=0:00:12
[08/26 14:54:08 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0030 s/iter. Inference: 0.2166 s/iter. Eval: 0.0616 s/iter. Total: 0.2814 s/iter. ETA=0:00:07
[08/26 14:54:13 d2.evaluation.evaluator]: Inference done 141/144. Dataloading: 0.0030 s/iter. Inference: 0.2156 s/iter. Eval: 0.0548 s/iter. Total: 0.2736 s/iter. ETA=0:00:00
[08/26 14:54:14 d2.evaluation.evaluator]: Total inference time: 0:00:38.335721 (0.275797 s / iter per device, on 1 devices)
[08/26 14:54:14 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:29 (0.215724 s / iter per device, on 1 devices)
[08/26 14:54:14 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 14:54:14 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 14:54:14 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/26 14:54:15 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 14:54:15 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/26 14:54:15 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:54:15 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.521
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.750
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.629
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.218
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.463
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.689
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.375
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.622
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.648
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.308
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.591
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.809
[08/26 14:54:15 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.094 | 75.002 | 62.937 | 21.762 | 46.276 | 68.939 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[08/26 14:54:15 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 14:54:15 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/26 14:54:15 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:54:15 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.531
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.760
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.597
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.143
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.485
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.687
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.377
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.634
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.662
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.375
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.618
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.791
[08/26 14:54:15 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 53.102 | 75.988 | 59.737 | 14.343 | 48.546 | 68.716 |
[08/26 14:54:15 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 14:54:15 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 14:54:15 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:54:15 d2.evaluation.testing]: copypaste: 52.0942,75.0025,62.9366,21.7621,46.2762,68.9392
[08/26 14:54:15 d2.evaluation.testing]: copypaste: Task: segm
[08/26 14:54:15 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:54:15 d2.evaluation.testing]: copypaste: 53.1018,75.9881,59.7369,14.3433,48.5461,68.7164
[08/26 14:54:15 d2.utils.events]:  eta: 0:01:15  iter: 959  total_loss: 0.4235  loss_cls: 0.06341  loss_box_reg: 0.1333  loss_mask: 0.1522  loss_rpn_cls: 0.003103  loss_rpn_loc: 0.004772  time: 1.8900  data_time: 0.0240  lr: 0.00023976  max_mem: 10070M
[08/26 14:54:53 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 14:54:53 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 14:54:53 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 14:54:53 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 14:54:53 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 14:54:57 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0024 s/iter. Inference: 0.2138 s/iter. Eval: 0.0511 s/iter. Total: 0.2673 s/iter. ETA=0:00:35
[08/26 14:55:02 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0026 s/iter. Inference: 0.2135 s/iter. Eval: 0.0422 s/iter. Total: 0.2585 s/iter. ETA=0:00:29
[08/26 14:55:07 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0029 s/iter. Inference: 0.2174 s/iter. Eval: 0.0675 s/iter. Total: 0.2882 s/iter. ETA=0:00:28
[08/26 14:55:13 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0029 s/iter. Inference: 0.2199 s/iter. Eval: 0.1064 s/iter. Total: 0.3295 s/iter. ETA=0:00:28
[08/26 14:55:18 d2.evaluation.evaluator]: Inference done 75/144. Dataloading: 0.0030 s/iter. Inference: 0.2194 s/iter. Eval: 0.1030 s/iter. Total: 0.3257 s/iter. ETA=0:00:22
[08/26 14:55:23 d2.evaluation.evaluator]: Inference done 96/144. Dataloading: 0.0028 s/iter. Inference: 0.2175 s/iter. Eval: 0.0853 s/iter. Total: 0.3059 s/iter. ETA=0:00:14
[08/26 14:55:28 d2.evaluation.evaluator]: Inference done 115/144. Dataloading: 0.0030 s/iter. Inference: 0.2169 s/iter. Eval: 0.0786 s/iter. Total: 0.2988 s/iter. ETA=0:00:08
[08/26 14:55:33 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0029 s/iter. Inference: 0.2160 s/iter. Eval: 0.0695 s/iter. Total: 0.2886 s/iter. ETA=0:00:02
[08/26 14:55:36 d2.evaluation.evaluator]: Total inference time: 0:00:40.369239 (0.290426 s / iter per device, on 1 devices)
[08/26 14:55:36 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.216029 s / iter per device, on 1 devices)
[08/26 14:55:36 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 14:55:36 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 14:55:36 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/26 14:55:36 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 14:55:36 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[08/26 14:55:36 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:55:36 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.511
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.744
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.601
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.223
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.454
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.673
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.370
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.630
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.662
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.617
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.806
[08/26 14:55:36 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.114 | 74.385 | 60.061 | 22.344 | 45.412 | 67.348 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[08/26 14:55:36 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 14:55:36 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/26 14:55:36 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:55:36 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.527
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.757
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.601
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.138
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.485
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.685
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.373
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.637
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.674
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.375
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.638
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.789
[08/26 14:55:36 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.703 | 75.694 | 60.120 | 13.785 | 48.515 | 68.483 |
[08/26 14:55:36 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 14:55:36 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 14:55:36 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:55:36 d2.evaluation.testing]: copypaste: 51.1141,74.3848,60.0609,22.3435,45.4115,67.3475
[08/26 14:55:36 d2.evaluation.testing]: copypaste: Task: segm
[08/26 14:55:36 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:55:36 d2.evaluation.testing]: copypaste: 52.7025,75.6942,60.1204,13.7852,48.5147,68.4835
[08/26 14:55:36 d2.utils.events]:  eta: 0:00:37  iter: 979  total_loss: 0.4833  loss_cls: 0.07828  loss_box_reg: 0.1857  loss_mask: 0.1747  loss_rpn_cls: 0.003534  loss_rpn_loc: 0.01131  time: 1.8901  data_time: 0.0234  lr: 0.00024476  max_mem: 10070M
[08/26 14:56:14 d2.utils.events]:  eta: 0:00:00  iter: 999  total_loss: 0.3862  loss_cls: 0.07417  loss_box_reg: 0.1523  loss_mask: 0.1638  loss_rpn_cls: 0.003431  loss_rpn_loc: 0.006378  time: 1.8900  data_time: 0.0269  lr: 0.00024975  max_mem: 10070M
[08/26 14:56:14 d2.engine.hooks]: Overall training speed: 998 iterations in 0:31:26 (1.8900 s / it)
[08/26 14:56:14 d2.engine.hooks]: Total training time: 1:34:24 (1:02:57 on hooks)
[08/26 14:56:14 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/26 14:56:14 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/26 14:56:14 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/26 14:56:14 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/26 14:56:14 d2.evaluation.evaluator]: Start inference on 144 batches
[08/26 14:56:18 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0022 s/iter. Inference: 0.2132 s/iter. Eval: 0.0536 s/iter. Total: 0.2690 s/iter. ETA=0:00:35
[08/26 14:56:24 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0029 s/iter. Inference: 0.2152 s/iter. Eval: 0.0449 s/iter. Total: 0.2631 s/iter. ETA=0:00:29
[08/26 14:56:29 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0028 s/iter. Inference: 0.2160 s/iter. Eval: 0.0661 s/iter. Total: 0.2850 s/iter. ETA=0:00:27
[08/26 14:56:34 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0028 s/iter. Inference: 0.2182 s/iter. Eval: 0.1000 s/iter. Total: 0.3211 s/iter. ETA=0:00:27
[08/26 14:56:39 d2.evaluation.evaluator]: Inference done 76/144. Dataloading: 0.0027 s/iter. Inference: 0.2175 s/iter. Eval: 0.0951 s/iter. Total: 0.3155 s/iter. ETA=0:00:21
[08/26 14:56:44 d2.evaluation.evaluator]: Inference done 97/144. Dataloading: 0.0027 s/iter. Inference: 0.2168 s/iter. Eval: 0.0799 s/iter. Total: 0.2996 s/iter. ETA=0:00:14
[08/26 14:56:49 d2.evaluation.evaluator]: Inference done 115/144. Dataloading: 0.0029 s/iter. Inference: 0.2182 s/iter. Eval: 0.0752 s/iter. Total: 0.2965 s/iter. ETA=0:00:08
[08/26 14:56:54 d2.evaluation.evaluator]: Inference done 136/144. Dataloading: 0.0031 s/iter. Inference: 0.2174 s/iter. Eval: 0.0675 s/iter. Total: 0.2882 s/iter. ETA=0:00:02
[08/26 14:56:57 d2.evaluation.evaluator]: Total inference time: 0:00:40.161506 (0.288932 s / iter per device, on 1 devices)
[08/26 14:56:57 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.217220 s / iter per device, on 1 devices)
[08/26 14:56:57 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/26 14:56:57 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/26 14:56:57 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/26 14:56:57 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/26 14:56:57 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/26 14:56:57 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:56:57 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.517
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.748
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.604
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.205
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.462
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.679
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.373
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.624
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.653
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.292
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.604
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.805
[08/26 14:56:57 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.705 | 74.818 | 60.445 | 20.500 | 46.189 | 67.938 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[08/26 14:56:57 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/26 14:56:57 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[08/26 14:56:57 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/26 14:56:57 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.527
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.758
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.590
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.133
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.480
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.685
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.370
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.634
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.666
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.628
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.791
[08/26 14:56:57 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.738 | 75.762 | 58.963 | 13.307 | 47.973 | 68.532 |
[08/26 14:56:57 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/26 14:56:57 d2.evaluation.testing]: copypaste: Task: bbox
[08/26 14:56:57 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:56:57 d2.evaluation.testing]: copypaste: 51.7048,74.8181,60.4445,20.4998,46.1892,67.9383
[08/26 14:56:57 d2.evaluation.testing]: copypaste: Task: segm
[08/26 14:56:57 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/26 14:56:57 d2.evaluation.testing]: copypaste: 52.7378,75.7621,58.9633,13.3073,47.9727,68.5316