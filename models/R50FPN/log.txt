[09/02 14:19:31 d2.engine.defaults]: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[09/02 14:19:31 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [RandomBrightness(intensity_min=0.9, intensity_max=1.1), RandomContrast(intensity_min=0.9, intensity_max=1.1), RandomFlip(prob=0.5), Resize(shape=(720, 1280))]
[09/02 14:19:31 d2.data.datasets.coco]: Loaded 574 images in COCO format from ../input/petbottles/plastic data/annotations/instances_train.json
[09/02 14:19:31 d2.data.build]: Distribution of instances among all 1 categories:
|  category   | #instances   |
|:-----------:|:-------------|
| PET Bottles | 1145         |
|             |              |
[09/02 14:19:31 d2.data.build]: Using training sampler TrainingSampler
[09/02 14:19:31 d2.data.common]: Serializing 574 elements to byte tensors and concatenating them all ...
[09/02 14:19:31 d2.data.common]: Serialized dataset takes 0.45 MiB
model_final_f10217.pkl: 178MB [00:09, 18.5MB/s]                              
[09/02 14:19:45 d2.engine.train_loop]: Starting training from iteration 0
[09/02 14:20:00 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 14:20:00 d2.data.build]: Distribution of instances among all 1 categories:
|  category   | #instances   |
|:-----------:|:-------------|
| PET Bottles | 193          |
|             |              |
[09/02 14:20:00 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 14:20:00 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 14:20:00 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 14:20:00 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 14:20:10 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.1311 s/iter. Eval: 0.7268 s/iter. Total: 0.8596 s/iter. ETA=0:01:54
[09/02 14:20:15 d2.evaluation.evaluator]: Inference done 18/144. Dataloading: 0.0018 s/iter. Inference: 0.1309 s/iter. Eval: 0.7034 s/iter. Total: 0.8363 s/iter. ETA=0:01:45
[09/02 14:20:21 d2.evaluation.evaluator]: Inference done 25/144. Dataloading: 0.0019 s/iter. Inference: 0.1316 s/iter. Eval: 0.6997 s/iter. Total: 0.8334 s/iter. ETA=0:01:39
[09/02 14:20:27 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0019 s/iter. Inference: 0.1314 s/iter. Eval: 0.7123 s/iter. Total: 0.8459 s/iter. ETA=0:01:35
[09/02 14:20:32 d2.evaluation.evaluator]: Inference done 37/144. Dataloading: 0.0019 s/iter. Inference: 0.1314 s/iter. Eval: 0.7114 s/iter. Total: 0.8449 s/iter. ETA=0:01:30
[09/02 14:20:37 d2.evaluation.evaluator]: Inference done 44/144. Dataloading: 0.0020 s/iter. Inference: 0.1312 s/iter. Eval: 0.7059 s/iter. Total: 0.8393 s/iter. ETA=0:01:23
[09/02 14:20:42 d2.evaluation.evaluator]: Inference done 50/144. Dataloading: 0.0019 s/iter. Inference: 0.1310 s/iter. Eval: 0.7053 s/iter. Total: 0.8385 s/iter. ETA=0:01:18
[09/02 14:20:48 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0019 s/iter. Inference: 0.1309 s/iter. Eval: 0.7011 s/iter. Total: 0.8342 s/iter. ETA=0:01:12
[09/02 14:20:53 d2.evaluation.evaluator]: Inference done 63/144. Dataloading: 0.0020 s/iter. Inference: 0.1309 s/iter. Eval: 0.7011 s/iter. Total: 0.8341 s/iter. ETA=0:01:07
[09/02 14:20:58 d2.evaluation.evaluator]: Inference done 69/144. Dataloading: 0.0020 s/iter. Inference: 0.1309 s/iter. Eval: 0.7061 s/iter. Total: 0.8393 s/iter. ETA=0:01:02
[09/02 14:21:03 d2.evaluation.evaluator]: Inference done 75/144. Dataloading: 0.0020 s/iter. Inference: 0.1308 s/iter. Eval: 0.7062 s/iter. Total: 0.8392 s/iter. ETA=0:00:57
[09/02 14:21:09 d2.evaluation.evaluator]: Inference done 82/144. Dataloading: 0.0019 s/iter. Inference: 0.1308 s/iter. Eval: 0.7039 s/iter. Total: 0.8368 s/iter. ETA=0:00:51
[09/02 14:21:14 d2.evaluation.evaluator]: Inference done 88/144. Dataloading: 0.0019 s/iter. Inference: 0.1308 s/iter. Eval: 0.7038 s/iter. Total: 0.8367 s/iter. ETA=0:00:46
[09/02 14:21:20 d2.evaluation.evaluator]: Inference done 95/144. Dataloading: 0.0019 s/iter. Inference: 0.1307 s/iter. Eval: 0.7018 s/iter. Total: 0.8347 s/iter. ETA=0:00:40
[09/02 14:21:25 d2.evaluation.evaluator]: Inference done 101/144. Dataloading: 0.0019 s/iter. Inference: 0.1307 s/iter. Eval: 0.7023 s/iter. Total: 0.8352 s/iter. ETA=0:00:35
[09/02 14:21:30 d2.evaluation.evaluator]: Inference done 107/144. Dataloading: 0.0019 s/iter. Inference: 0.1308 s/iter. Eval: 0.7056 s/iter. Total: 0.8385 s/iter. ETA=0:00:31
[09/02 14:21:35 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0020 s/iter. Inference: 0.1307 s/iter. Eval: 0.7055 s/iter. Total: 0.8384 s/iter. ETA=0:00:25
[09/02 14:21:41 d2.evaluation.evaluator]: Inference done 120/144. Dataloading: 0.0019 s/iter. Inference: 0.1306 s/iter. Eval: 0.7047 s/iter. Total: 0.8375 s/iter. ETA=0:00:20
[09/02 14:21:46 d2.evaluation.evaluator]: Inference done 126/144. Dataloading: 0.0019 s/iter. Inference: 0.1306 s/iter. Eval: 0.7047 s/iter. Total: 0.8375 s/iter. ETA=0:00:15
[09/02 14:21:52 d2.evaluation.evaluator]: Inference done 133/144. Dataloading: 0.0019 s/iter. Inference: 0.1306 s/iter. Eval: 0.7036 s/iter. Total: 0.8363 s/iter. ETA=0:00:09
[09/02 14:21:57 d2.evaluation.evaluator]: Inference done 139/144. Dataloading: 0.0019 s/iter. Inference: 0.1306 s/iter. Eval: 0.7042 s/iter. Total: 0.8369 s/iter. ETA=0:00:04
[09/02 14:22:01 d2.evaluation.evaluator]: Total inference time: 0:01:56.267103 (0.836454 s / iter per device, on 1 devices)
[09/02 14:22:01 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:18 (0.130483 s / iter per device, on 1 devices)
[09/02 14:22:01 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 14:22:01 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 14:22:01 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/02 14:22:01 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 14:22:01 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[09/02 14:22:01 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:22:01 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.011
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.050
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.030
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.020
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.102
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.277
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.050
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.271
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.327
[09/02 14:22:01 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 1.149 | 5.021  | 0.083  | 0.034 | 0.912 | 2.957 |
Loading and preparing results...
DONE (t=0.31s)
creating index...
index created!
[09/02 14:22:02 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 14:22:03 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.21 seconds.
[09/02 14:22:03 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:22:03 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.030
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.071
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.021
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.021
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.164
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.244
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.478
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.225
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.453
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.567
[09/02 14:22:03 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 2.958 | 7.130  | 2.068  | 0.051 | 2.063 | 16.437 |
[09/02 14:22:03 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 14:22:03 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 14:22:03 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:22:03 d2.evaluation.testing]: copypaste: 1.1492,5.0207,0.0829,0.0336,0.9121,2.9570
[09/02 14:22:03 d2.evaluation.testing]: copypaste: Task: segm
[09/02 14:22:03 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:22:03 d2.evaluation.testing]: copypaste: 2.9582,7.1296,2.0683,0.0508,2.0633,16.4371
[09/02 14:22:03 d2.utils.events]:  eta: 0:11:10  iter: 19  total_loss: 1.913  loss_cls: 0.7673  loss_box_reg: 0.3045  loss_mask: 0.6922  loss_rpn_cls: 0.02649  loss_rpn_loc: 0.006385  time: 0.7194  data_time: 0.1099  lr: 4.9953e-06  max_mem: 4442M
[09/02 14:22:18 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 14:22:18 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 14:22:18 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 14:22:18 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 14:22:18 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 14:22:27 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0022 s/iter. Inference: 0.1307 s/iter. Eval: 0.6807 s/iter. Total: 0.8136 s/iter. ETA=0:01:48
[09/02 14:22:32 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0027 s/iter. Inference: 0.1305 s/iter. Eval: 0.6906 s/iter. Total: 0.8241 s/iter. ETA=0:01:44
[09/02 14:22:38 d2.evaluation.evaluator]: Inference done 24/144. Dataloading: 0.0025 s/iter. Inference: 0.1307 s/iter. Eval: 0.6908 s/iter. Total: 0.8243 s/iter. ETA=0:01:38
[09/02 14:22:43 d2.evaluation.evaluator]: Inference done 30/144. Dataloading: 0.0024 s/iter. Inference: 0.1316 s/iter. Eval: 0.7061 s/iter. Total: 0.8405 s/iter. ETA=0:01:35
[09/02 14:22:49 d2.evaluation.evaluator]: Inference done 37/144. Dataloading: 0.0023 s/iter. Inference: 0.1313 s/iter. Eval: 0.6989 s/iter. Total: 0.8329 s/iter. ETA=0:01:29
[09/02 14:22:54 d2.evaluation.evaluator]: Inference done 43/144. Dataloading: 0.0025 s/iter. Inference: 0.1317 s/iter. Eval: 0.6989 s/iter. Total: 0.8335 s/iter. ETA=0:01:24
[09/02 14:23:00 d2.evaluation.evaluator]: Inference done 50/144. Dataloading: 0.0026 s/iter. Inference: 0.1315 s/iter. Eval: 0.6960 s/iter. Total: 0.8304 s/iter. ETA=0:01:18
[09/02 14:23:05 d2.evaluation.evaluator]: Inference done 56/144. Dataloading: 0.0025 s/iter. Inference: 0.1315 s/iter. Eval: 0.6966 s/iter. Total: 0.8309 s/iter. ETA=0:01:13
[09/02 14:23:10 d2.evaluation.evaluator]: Inference done 63/144. Dataloading: 0.0026 s/iter. Inference: 0.1314 s/iter. Eval: 0.6946 s/iter. Total: 0.8288 s/iter. ETA=0:01:07
[09/02 14:23:16 d2.evaluation.evaluator]: Inference done 69/144. Dataloading: 0.0025 s/iter. Inference: 0.1320 s/iter. Eval: 0.7013 s/iter. Total: 0.8361 s/iter. ETA=0:01:02
[09/02 14:23:21 d2.evaluation.evaluator]: Inference done 76/144. Dataloading: 0.0025 s/iter. Inference: 0.1319 s/iter. Eval: 0.6990 s/iter. Total: 0.8336 s/iter. ETA=0:00:56
[09/02 14:23:26 d2.evaluation.evaluator]: Inference done 82/144. Dataloading: 0.0025 s/iter. Inference: 0.1318 s/iter. Eval: 0.6991 s/iter. Total: 0.8336 s/iter. ETA=0:00:51
[09/02 14:23:32 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0025 s/iter. Inference: 0.1317 s/iter. Eval: 0.6971 s/iter. Total: 0.8315 s/iter. ETA=0:00:45
[09/02 14:23:37 d2.evaluation.evaluator]: Inference done 95/144. Dataloading: 0.0025 s/iter. Inference: 0.1317 s/iter. Eval: 0.6974 s/iter. Total: 0.8318 s/iter. ETA=0:00:40
[09/02 14:23:43 d2.evaluation.evaluator]: Inference done 102/144. Dataloading: 0.0025 s/iter. Inference: 0.1316 s/iter. Eval: 0.6959 s/iter. Total: 0.8303 s/iter. ETA=0:00:34
[09/02 14:23:48 d2.evaluation.evaluator]: Inference done 108/144. Dataloading: 0.0025 s/iter. Inference: 0.1317 s/iter. Eval: 0.7005 s/iter. Total: 0.8349 s/iter. ETA=0:00:30
[09/02 14:23:54 d2.evaluation.evaluator]: Inference done 115/144. Dataloading: 0.0025 s/iter. Inference: 0.1316 s/iter. Eval: 0.6986 s/iter. Total: 0.8330 s/iter. ETA=0:00:24
[09/02 14:24:00 d2.evaluation.evaluator]: Inference done 122/144. Dataloading: 0.0025 s/iter. Inference: 0.1316 s/iter. Eval: 0.6984 s/iter. Total: 0.8327 s/iter. ETA=0:00:18
[09/02 14:24:05 d2.evaluation.evaluator]: Inference done 129/144. Dataloading: 0.0025 s/iter. Inference: 0.1315 s/iter. Eval: 0.6969 s/iter. Total: 0.8311 s/iter. ETA=0:00:12
[09/02 14:24:10 d2.evaluation.evaluator]: Inference done 135/144. Dataloading: 0.0025 s/iter. Inference: 0.1315 s/iter. Eval: 0.6972 s/iter. Total: 0.8314 s/iter. ETA=0:00:07
[09/02 14:24:16 d2.evaluation.evaluator]: Inference done 142/144. Dataloading: 0.0024 s/iter. Inference: 0.1314 s/iter. Eval: 0.6959 s/iter. Total: 0.8300 s/iter. ETA=0:00:01
[09/02 14:24:18 d2.evaluation.evaluator]: Total inference time: 0:01:55.718461 (0.832507 s / iter per device, on 1 devices)
[09/02 14:24:18 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:18 (0.131353 s / iter per device, on 1 devices)
[09/02 14:24:18 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 14:24:18 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 14:24:18 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[09/02 14:24:18 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 14:24:19 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.18 seconds.
[09/02 14:24:19 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:24:19 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.04 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.020
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.079
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.016
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.041
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.030
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.135
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.306
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.033
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.307
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.355
[09/02 14:24:19 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 2.045 | 7.891  | 0.194  | 0.030 | 1.649 | 4.077 |
Loading and preparing results...
DONE (t=0.29s)
creating index...
index created!
[09/02 14:24:19 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 14:24:20 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.20 seconds.
[09/02 14:24:20 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:24:20 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.056
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.115
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.049
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.034
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.173
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.079
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.315
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.560
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.517
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.695
[09/02 14:24:20 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 5.626 | 11.483 | 4.878  | 0.179 | 3.405 | 17.341 |
[09/02 14:24:20 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 14:24:20 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 14:24:20 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:24:20 d2.evaluation.testing]: copypaste: 2.0454,7.8907,0.1938,0.0296,1.6489,4.0773
[09/02 14:24:20 d2.evaluation.testing]: copypaste: Task: segm
[09/02 14:24:20 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:24:20 d2.evaluation.testing]: copypaste: 5.6260,11.4828,4.8778,0.1787,3.4055,17.3409
[09/02 14:24:20 d2.utils.events]:  eta: 0:11:04  iter: 39  total_loss: 1.695  loss_cls: 0.6753  loss_box_reg: 0.2664  loss_mask: 0.6814  loss_rpn_cls: 0.02147  loss_rpn_loc: 0.005065  time: 0.7306  data_time: 0.1300  lr: 9.9902e-06  max_mem: 4442M
[09/02 14:24:34 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 14:24:34 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 14:24:34 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 14:24:34 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 14:24:34 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 14:24:44 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.1312 s/iter. Eval: 0.7518 s/iter. Total: 0.8846 s/iter. ETA=0:01:57
[09/02 14:24:49 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0020 s/iter. Inference: 0.1313 s/iter. Eval: 0.7524 s/iter. Total: 0.8858 s/iter. ETA=0:01:52
[09/02 14:24:54 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0022 s/iter. Inference: 0.1311 s/iter. Eval: 0.7359 s/iter. Total: 0.8693 s/iter. ETA=0:01:45
[09/02 14:25:00 d2.evaluation.evaluator]: Inference done 30/144. Dataloading: 0.0021 s/iter. Inference: 0.1309 s/iter. Eval: 0.7179 s/iter. Total: 0.8512 s/iter. ETA=0:01:37
[09/02 14:25:06 d2.evaluation.evaluator]: Inference done 37/144. Dataloading: 0.0021 s/iter. Inference: 0.1308 s/iter. Eval: 0.7122 s/iter. Total: 0.8453 s/iter. ETA=0:01:30
[09/02 14:25:11 d2.evaluation.evaluator]: Inference done 44/144. Dataloading: 0.0021 s/iter. Inference: 0.1309 s/iter. Eval: 0.7053 s/iter. Total: 0.8385 s/iter. ETA=0:01:23
[09/02 14:25:17 d2.evaluation.evaluator]: Inference done 51/144. Dataloading: 0.0021 s/iter. Inference: 0.1307 s/iter. Eval: 0.7037 s/iter. Total: 0.8367 s/iter. ETA=0:01:17
[09/02 14:25:22 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0021 s/iter. Inference: 0.1312 s/iter. Eval: 0.7079 s/iter. Total: 0.8414 s/iter. ETA=0:01:13
[09/02 14:25:27 d2.evaluation.evaluator]: Inference done 63/144. Dataloading: 0.0021 s/iter. Inference: 0.1311 s/iter. Eval: 0.7078 s/iter. Total: 0.8411 s/iter. ETA=0:01:08
[09/02 14:25:33 d2.evaluation.evaluator]: Inference done 70/144. Dataloading: 0.0021 s/iter. Inference: 0.1311 s/iter. Eval: 0.7038 s/iter. Total: 0.8371 s/iter. ETA=0:01:01
[09/02 14:25:38 d2.evaluation.evaluator]: Inference done 76/144. Dataloading: 0.0021 s/iter. Inference: 0.1312 s/iter. Eval: 0.7042 s/iter. Total: 0.8377 s/iter. ETA=0:00:56
[09/02 14:25:44 d2.evaluation.evaluator]: Inference done 83/144. Dataloading: 0.0021 s/iter. Inference: 0.1311 s/iter. Eval: 0.7017 s/iter. Total: 0.8351 s/iter. ETA=0:00:50
[09/02 14:25:49 d2.evaluation.evaluator]: Inference done 90/144. Dataloading: 0.0021 s/iter. Inference: 0.1311 s/iter. Eval: 0.7010 s/iter. Total: 0.8343 s/iter. ETA=0:00:45
[09/02 14:25:55 d2.evaluation.evaluator]: Inference done 96/144. Dataloading: 0.0021 s/iter. Inference: 0.1311 s/iter. Eval: 0.7041 s/iter. Total: 0.8375 s/iter. ETA=0:00:40
[09/02 14:26:00 d2.evaluation.evaluator]: Inference done 102/144. Dataloading: 0.0020 s/iter. Inference: 0.1311 s/iter. Eval: 0.7043 s/iter. Total: 0.8377 s/iter. ETA=0:00:35
[09/02 14:26:05 d2.evaluation.evaluator]: Inference done 109/144. Dataloading: 0.0020 s/iter. Inference: 0.1311 s/iter. Eval: 0.7023 s/iter. Total: 0.8356 s/iter. ETA=0:00:29
[09/02 14:26:10 d2.evaluation.evaluator]: Inference done 115/144. Dataloading: 0.0021 s/iter. Inference: 0.1311 s/iter. Eval: 0.7023 s/iter. Total: 0.8356 s/iter. ETA=0:00:24
[09/02 14:26:16 d2.evaluation.evaluator]: Inference done 122/144. Dataloading: 0.0021 s/iter. Inference: 0.1310 s/iter. Eval: 0.7005 s/iter. Total: 0.8338 s/iter. ETA=0:00:18
[09/02 14:26:22 d2.evaluation.evaluator]: Inference done 129/144. Dataloading: 0.0021 s/iter. Inference: 0.1311 s/iter. Eval: 0.7001 s/iter. Total: 0.8336 s/iter. ETA=0:00:12
[09/02 14:26:27 d2.evaluation.evaluator]: Inference done 135/144. Dataloading: 0.0020 s/iter. Inference: 0.1313 s/iter. Eval: 0.7021 s/iter. Total: 0.8357 s/iter. ETA=0:00:07
[09/02 14:26:32 d2.evaluation.evaluator]: Inference done 141/144. Dataloading: 0.0021 s/iter. Inference: 0.1314 s/iter. Eval: 0.7019 s/iter. Total: 0.8356 s/iter. ETA=0:00:02
[09/02 14:26:35 d2.evaluation.evaluator]: Total inference time: 0:01:56.097193 (0.835232 s / iter per device, on 1 devices)
[09/02 14:26:35 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:18 (0.131301 s / iter per device, on 1 devices)
[09/02 14:26:35 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 14:26:35 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 14:26:35 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/02 14:26:35 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 14:26:35 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.
[09/02 14:26:35 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:26:35 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.042
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.148
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.005
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.034
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.069
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.065
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.207
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.351
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.075
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.346
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.411
[09/02 14:26:35 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 4.208 | 14.833 | 0.456  | 0.161 | 3.421 | 6.855 |
Loading and preparing results...
DONE (t=0.30s)
creating index...
index created!
[09/02 14:26:36 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 14:26:36 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.21 seconds.
[09/02 14:26:36 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:26:36 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.093
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.179
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.090
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.055
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.205
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.136
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.369
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.579
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.541
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.711
[09/02 14:26:36 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 9.291 | 17.870 | 9.011  | 0.357 | 5.473 | 20.530 |
[09/02 14:26:36 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 14:26:36 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 14:26:36 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:26:36 d2.evaluation.testing]: copypaste: 4.2084,14.8334,0.4560,0.1606,3.4206,6.8553
[09/02 14:26:36 d2.evaluation.testing]: copypaste: Task: segm
[09/02 14:26:36 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:26:36 d2.evaluation.testing]: copypaste: 9.2912,17.8702,9.0113,0.3570,5.4729,20.5300
[09/02 14:26:36 d2.utils.events]:  eta: 0:10:57  iter: 59  total_loss: 1.656  loss_cls: 0.5339  loss_box_reg: 0.3773  loss_mask: 0.6554  loss_rpn_cls: 0.03323  loss_rpn_loc: 0.01229  time: 0.7243  data_time: 0.0914  lr: 1.4985e-05  max_mem: 4442M
[09/02 14:26:50 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 14:26:50 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 14:26:50 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 14:26:50 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 14:26:50 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 14:27:00 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0017 s/iter. Inference: 0.1360 s/iter. Eval: 0.7864 s/iter. Total: 0.9241 s/iter. ETA=0:02:02
[09/02 14:27:05 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0023 s/iter. Inference: 0.1331 s/iter. Eval: 0.7441 s/iter. Total: 0.8797 s/iter. ETA=0:01:51
[09/02 14:27:11 d2.evaluation.evaluator]: Inference done 24/144. Dataloading: 0.0021 s/iter. Inference: 0.1322 s/iter. Eval: 0.7177 s/iter. Total: 0.8522 s/iter. ETA=0:01:42
[09/02 14:27:16 d2.evaluation.evaluator]: Inference done 30/144. Dataloading: 0.0022 s/iter. Inference: 0.1325 s/iter. Eval: 0.7133 s/iter. Total: 0.8482 s/iter. ETA=0:01:36
[09/02 14:27:22 d2.evaluation.evaluator]: Inference done 37/144. Dataloading: 0.0021 s/iter. Inference: 0.1321 s/iter. Eval: 0.7057 s/iter. Total: 0.8401 s/iter. ETA=0:01:29
[09/02 14:27:27 d2.evaluation.evaluator]: Inference done 43/144. Dataloading: 0.0021 s/iter. Inference: 0.1318 s/iter. Eval: 0.7053 s/iter. Total: 0.8395 s/iter. ETA=0:01:24
[09/02 14:27:32 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0021 s/iter. Inference: 0.1321 s/iter. Eval: 0.7092 s/iter. Total: 0.8436 s/iter. ETA=0:01:20
[09/02 14:27:37 d2.evaluation.evaluator]: Inference done 55/144. Dataloading: 0.0021 s/iter. Inference: 0.1320 s/iter. Eval: 0.7100 s/iter. Total: 0.8443 s/iter. ETA=0:01:15
[09/02 14:27:43 d2.evaluation.evaluator]: Inference done 62/144. Dataloading: 0.0021 s/iter. Inference: 0.1318 s/iter. Eval: 0.7057 s/iter. Total: 0.8398 s/iter. ETA=0:01:08
[09/02 14:27:48 d2.evaluation.evaluator]: Inference done 69/144. Dataloading: 0.0021 s/iter. Inference: 0.1322 s/iter. Eval: 0.7039 s/iter. Total: 0.8384 s/iter. ETA=0:01:02
[09/02 14:27:54 d2.evaluation.evaluator]: Inference done 76/144. Dataloading: 0.0021 s/iter. Inference: 0.1321 s/iter. Eval: 0.7007 s/iter. Total: 0.8351 s/iter. ETA=0:00:56
[09/02 14:28:00 d2.evaluation.evaluator]: Inference done 83/144. Dataloading: 0.0021 s/iter. Inference: 0.1321 s/iter. Eval: 0.7001 s/iter. Total: 0.8345 s/iter. ETA=0:00:50
[09/02 14:28:05 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0021 s/iter. Inference: 0.1323 s/iter. Eval: 0.7027 s/iter. Total: 0.8372 s/iter. ETA=0:00:46
[09/02 14:28:10 d2.evaluation.evaluator]: Inference done 95/144. Dataloading: 0.0021 s/iter. Inference: 0.1322 s/iter. Eval: 0.7027 s/iter. Total: 0.8373 s/iter. ETA=0:00:41
[09/02 14:28:16 d2.evaluation.evaluator]: Inference done 102/144. Dataloading: 0.0021 s/iter. Inference: 0.1321 s/iter. Eval: 0.7009 s/iter. Total: 0.8354 s/iter. ETA=0:00:35
[09/02 14:28:21 d2.evaluation.evaluator]: Inference done 108/144. Dataloading: 0.0021 s/iter. Inference: 0.1321 s/iter. Eval: 0.7014 s/iter. Total: 0.8358 s/iter. ETA=0:00:30
[09/02 14:28:27 d2.evaluation.evaluator]: Inference done 115/144. Dataloading: 0.0021 s/iter. Inference: 0.1320 s/iter. Eval: 0.7000 s/iter. Total: 0.8343 s/iter. ETA=0:00:24
[09/02 14:28:32 d2.evaluation.evaluator]: Inference done 122/144. Dataloading: 0.0021 s/iter. Inference: 0.1320 s/iter. Eval: 0.6997 s/iter. Total: 0.8341 s/iter. ETA=0:00:18
[09/02 14:28:38 d2.evaluation.evaluator]: Inference done 128/144. Dataloading: 0.0021 s/iter. Inference: 0.1321 s/iter. Eval: 0.7019 s/iter. Total: 0.8363 s/iter. ETA=0:00:13
[09/02 14:28:43 d2.evaluation.evaluator]: Inference done 134/144. Dataloading: 0.0021 s/iter. Inference: 0.1321 s/iter. Eval: 0.7025 s/iter. Total: 0.8369 s/iter. ETA=0:00:08
[09/02 14:28:48 d2.evaluation.evaluator]: Inference done 141/144. Dataloading: 0.0021 s/iter. Inference: 0.1320 s/iter. Eval: 0.7011 s/iter. Total: 0.8354 s/iter. ETA=0:00:02
[09/02 14:28:51 d2.evaluation.evaluator]: Total inference time: 0:01:56.051861 (0.834905 s / iter per device, on 1 devices)
[09/02 14:28:51 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:18 (0.131869 s / iter per device, on 1 devices)
[09/02 14:28:51 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 14:28:51 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 14:28:51 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/02 14:28:51 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 14:28:51 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[09/02 14:28:51 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:28:51 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.065
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.204
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.014
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.064
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.097
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.101
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.253
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.387
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.371
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.467
[09/02 14:28:51 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 6.532 | 20.369 | 1.373  | 0.240 | 6.408 | 9.690 |
Loading and preparing results...
DONE (t=0.30s)
creating index...
index created!
[09/02 14:28:52 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 14:28:52 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.22 seconds.
[09/02 14:28:52 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:28:52 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.126
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.224
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.134
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.082
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.233
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.175
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.407
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.585
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.158
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.553
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.718
[09/02 14:28:52 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:------:|:------:|:------:|:-----:|:-----:|:------:|
| 12.646 | 22.431 | 13.383 | 0.375 | 8.214 | 23.286 |
[09/02 14:28:52 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 14:28:52 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 14:28:52 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:28:52 d2.evaluation.testing]: copypaste: 6.5324,20.3689,1.3734,0.2401,6.4075,9.6897
[09/02 14:28:52 d2.evaluation.testing]: copypaste: Task: segm
[09/02 14:28:52 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:28:52 d2.evaluation.testing]: copypaste: 12.6456,22.4312,13.3833,0.3749,8.2136,23.2857
[09/02 14:28:52 d2.utils.events]:  eta: 0:10:38  iter: 79  total_loss: 1.476  loss_cls: 0.3982  loss_box_reg: 0.3444  loss_mask: 0.6275  loss_rpn_cls: 0.0294  loss_rpn_loc: 0.006203  time: 0.7191  data_time: 0.0934  lr: 1.998e-05  max_mem: 4442M
[09/02 14:29:07 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 14:29:07 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 14:29:07 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 14:29:07 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 14:29:07 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 14:29:17 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0017 s/iter. Inference: 0.1310 s/iter. Eval: 0.7552 s/iter. Total: 0.8879 s/iter. ETA=0:01:58
[09/02 14:29:22 d2.evaluation.evaluator]: Inference done 18/144. Dataloading: 0.0020 s/iter. Inference: 0.1312 s/iter. Eval: 0.7161 s/iter. Total: 0.8494 s/iter. ETA=0:01:47
[09/02 14:29:27 d2.evaluation.evaluator]: Inference done 24/144. Dataloading: 0.0021 s/iter. Inference: 0.1319 s/iter. Eval: 0.7107 s/iter. Total: 0.8450 s/iter. ETA=0:01:41
[09/02 14:29:33 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0021 s/iter. Inference: 0.1315 s/iter. Eval: 0.7000 s/iter. Total: 0.8338 s/iter. ETA=0:01:34
[09/02 14:29:38 d2.evaluation.evaluator]: Inference done 37/144. Dataloading: 0.0021 s/iter. Inference: 0.1312 s/iter. Eval: 0.7018 s/iter. Total: 0.8353 s/iter. ETA=0:01:29
[09/02 14:29:43 d2.evaluation.evaluator]: Inference done 43/144. Dataloading: 0.0021 s/iter. Inference: 0.1318 s/iter. Eval: 0.7059 s/iter. Total: 0.8402 s/iter. ETA=0:01:24
[09/02 14:29:49 d2.evaluation.evaluator]: Inference done 50/144. Dataloading: 0.0021 s/iter. Inference: 0.1316 s/iter. Eval: 0.7049 s/iter. Total: 0.8389 s/iter. ETA=0:01:18
[09/02 14:29:55 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0021 s/iter. Inference: 0.1315 s/iter. Eval: 0.7011 s/iter. Total: 0.8350 s/iter. ETA=0:01:12
[09/02 14:30:00 d2.evaluation.evaluator]: Inference done 63/144. Dataloading: 0.0021 s/iter. Inference: 0.1314 s/iter. Eval: 0.7017 s/iter. Total: 0.8355 s/iter. ETA=0:01:07
[09/02 14:30:06 d2.evaluation.evaluator]: Inference done 70/144. Dataloading: 0.0021 s/iter. Inference: 0.1313 s/iter. Eval: 0.6989 s/iter. Total: 0.8326 s/iter. ETA=0:01:01
[09/02 14:30:12 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0021 s/iter. Inference: 0.1320 s/iter. Eval: 0.7054 s/iter. Total: 0.8398 s/iter. ETA=0:00:56
[09/02 14:30:18 d2.evaluation.evaluator]: Inference done 84/144. Dataloading: 0.0021 s/iter. Inference: 0.1318 s/iter. Eval: 0.7026 s/iter. Total: 0.8369 s/iter. ETA=0:00:50
[09/02 14:30:23 d2.evaluation.evaluator]: Inference done 91/144. Dataloading: 0.0021 s/iter. Inference: 0.1318 s/iter. Eval: 0.7022 s/iter. Total: 0.8363 s/iter. ETA=0:00:44
[09/02 14:30:29 d2.evaluation.evaluator]: Inference done 98/144. Dataloading: 0.0021 s/iter. Inference: 0.1317 s/iter. Eval: 0.7002 s/iter. Total: 0.8342 s/iter. ETA=0:00:38
[09/02 14:30:35 d2.evaluation.evaluator]: Inference done 105/144. Dataloading: 0.0021 s/iter. Inference: 0.1316 s/iter. Eval: 0.6997 s/iter. Total: 0.8336 s/iter. ETA=0:00:32
[09/02 14:30:40 d2.evaluation.evaluator]: Inference done 112/144. Dataloading: 0.0021 s/iter. Inference: 0.1316 s/iter. Eval: 0.6980 s/iter. Total: 0.8319 s/iter. ETA=0:00:26
[09/02 14:30:46 d2.evaluation.evaluator]: Inference done 118/144. Dataloading: 0.0021 s/iter. Inference: 0.1318 s/iter. Eval: 0.7018 s/iter. Total: 0.8359 s/iter. ETA=0:00:21
[09/02 14:30:52 d2.evaluation.evaluator]: Inference done 125/144. Dataloading: 0.0021 s/iter. Inference: 0.1317 s/iter. Eval: 0.7005 s/iter. Total: 0.8345 s/iter. ETA=0:00:15
[09/02 14:30:57 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0021 s/iter. Inference: 0.1317 s/iter. Eval: 0.7005 s/iter. Total: 0.8346 s/iter. ETA=0:00:10
[09/02 14:31:02 d2.evaluation.evaluator]: Inference done 138/144. Dataloading: 0.0021 s/iter. Inference: 0.1316 s/iter. Eval: 0.6991 s/iter. Total: 0.8331 s/iter. ETA=0:00:04
[09/02 14:31:07 d2.evaluation.evaluator]: Total inference time: 0:01:55.820369 (0.833240 s / iter per device, on 1 devices)
[09/02 14:31:07 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:18 (0.131491 s / iter per device, on 1 devices)
[09/02 14:31:07 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 14:31:07 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 14:31:08 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/02 14:31:08 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 14:31:08 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.
[09/02 14:31:08 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:31:08 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.090
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.248
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.027
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.013
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.098
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.128
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.134
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.291
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.426
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.108
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.417
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.500
[09/02 14:31:08 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 8.981 | 24.756 | 2.707  | 1.284 | 9.793 | 12.824 |
Loading and preparing results...
DONE (t=0.30s)
creating index...
index created!
[09/02 14:31:09 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 14:31:09 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.21 seconds.
[09/02 14:31:09 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:31:09 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.153
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.256
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.172
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.005
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.110
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.258
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.196
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.418
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.598
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.125
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.576
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.724
[09/02 14:31:09 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 15.309 | 25.573 | 17.161 | 0.540 | 10.986 | 25.792 |
[09/02 14:31:09 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 14:31:09 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 14:31:09 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:31:09 d2.evaluation.testing]: copypaste: 8.9807,24.7556,2.7069,1.2841,9.7935,12.8236
[09/02 14:31:09 d2.evaluation.testing]: copypaste: Task: segm
[09/02 14:31:09 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:31:09 d2.evaluation.testing]: copypaste: 15.3087,25.5725,17.1606,0.5401,10.9855,25.7924
[09/02 14:31:09 d2.utils.events]:  eta: 0:10:22  iter: 99  total_loss: 1.355  loss_cls: 0.3324  loss_box_reg: 0.3808  loss_mask: 0.5751  loss_rpn_cls: 0.02711  loss_rpn_loc: 0.007281  time: 0.7171  data_time: 0.0959  lr: 2.4975e-05  max_mem: 4442M
[09/02 14:31:24 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 14:31:24 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 14:31:24 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 14:31:24 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 14:31:24 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 14:31:33 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0027 s/iter. Inference: 0.1304 s/iter. Eval: 0.7153 s/iter. Total: 0.8483 s/iter. ETA=0:01:52
[09/02 14:31:39 d2.evaluation.evaluator]: Inference done 18/144. Dataloading: 0.0024 s/iter. Inference: 0.1305 s/iter. Eval: 0.7040 s/iter. Total: 0.8371 s/iter. ETA=0:01:45
[09/02 14:31:45 d2.evaluation.evaluator]: Inference done 25/144. Dataloading: 0.0026 s/iter. Inference: 0.1303 s/iter. Eval: 0.6928 s/iter. Total: 0.8258 s/iter. ETA=0:01:38
[09/02 14:31:50 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0026 s/iter. Inference: 0.1317 s/iter. Eval: 0.7089 s/iter. Total: 0.8434 s/iter. ETA=0:01:35
[09/02 14:31:56 d2.evaluation.evaluator]: Inference done 38/144. Dataloading: 0.0025 s/iter. Inference: 0.1315 s/iter. Eval: 0.7008 s/iter. Total: 0.8351 s/iter. ETA=0:01:28
[09/02 14:32:01 d2.evaluation.evaluator]: Inference done 44/144. Dataloading: 0.0025 s/iter. Inference: 0.1314 s/iter. Eval: 0.7014 s/iter. Total: 0.8355 s/iter. ETA=0:01:23
[09/02 14:32:06 d2.evaluation.evaluator]: Inference done 51/144. Dataloading: 0.0024 s/iter. Inference: 0.1312 s/iter. Eval: 0.6978 s/iter. Total: 0.8316 s/iter. ETA=0:01:17
[09/02 14:32:12 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0024 s/iter. Inference: 0.1315 s/iter. Eval: 0.6965 s/iter. Total: 0.8306 s/iter. ETA=0:01:11
[09/02 14:32:18 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0025 s/iter. Inference: 0.1313 s/iter. Eval: 0.6936 s/iter. Total: 0.8277 s/iter. ETA=0:01:05
[09/02 14:32:23 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0025 s/iter. Inference: 0.1315 s/iter. Eval: 0.7001 s/iter. Total: 0.8343 s/iter. ETA=0:01:00
[09/02 14:32:29 d2.evaluation.evaluator]: Inference done 78/144. Dataloading: 0.0025 s/iter. Inference: 0.1315 s/iter. Eval: 0.6992 s/iter. Total: 0.8334 s/iter. ETA=0:00:55
[09/02 14:32:34 d2.evaluation.evaluator]: Inference done 84/144. Dataloading: 0.0025 s/iter. Inference: 0.1314 s/iter. Eval: 0.6994 s/iter. Total: 0.8335 s/iter. ETA=0:00:50
[09/02 14:32:40 d2.evaluation.evaluator]: Inference done 91/144. Dataloading: 0.0024 s/iter. Inference: 0.1314 s/iter. Eval: 0.6978 s/iter. Total: 0.8319 s/iter. ETA=0:00:44
[09/02 14:32:45 d2.evaluation.evaluator]: Inference done 97/144. Dataloading: 0.0024 s/iter. Inference: 0.1314 s/iter. Eval: 0.6984 s/iter. Total: 0.8324 s/iter. ETA=0:00:39
[09/02 14:32:50 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0024 s/iter. Inference: 0.1314 s/iter. Eval: 0.6967 s/iter. Total: 0.8306 s/iter. ETA=0:00:33
[09/02 14:32:56 d2.evaluation.evaluator]: Inference done 110/144. Dataloading: 0.0025 s/iter. Inference: 0.1315 s/iter. Eval: 0.7001 s/iter. Total: 0.8343 s/iter. ETA=0:00:28
[09/02 14:33:01 d2.evaluation.evaluator]: Inference done 117/144. Dataloading: 0.0025 s/iter. Inference: 0.1315 s/iter. Eval: 0.6985 s/iter. Total: 0.8327 s/iter. ETA=0:00:22
[09/02 14:33:07 d2.evaluation.evaluator]: Inference done 124/144. Dataloading: 0.0025 s/iter. Inference: 0.1316 s/iter. Eval: 0.6986 s/iter. Total: 0.8329 s/iter. ETA=0:00:16
[09/02 14:33:13 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0025 s/iter. Inference: 0.1315 s/iter. Eval: 0.6972 s/iter. Total: 0.8314 s/iter. ETA=0:00:10
[09/02 14:33:19 d2.evaluation.evaluator]: Inference done 138/144. Dataloading: 0.0025 s/iter. Inference: 0.1315 s/iter. Eval: 0.6972 s/iter. Total: 0.8313 s/iter. ETA=0:00:04
[09/02 14:33:24 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0024 s/iter. Inference: 0.1314 s/iter. Eval: 0.6987 s/iter. Total: 0.8327 s/iter. ETA=0:00:00
[09/02 14:33:24 d2.evaluation.evaluator]: Total inference time: 0:01:55.816014 (0.833209 s / iter per device, on 1 devices)
[09/02 14:33:24 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:18 (0.131365 s / iter per device, on 1 devices)
[09/02 14:33:24 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 14:33:24 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 14:33:24 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/02 14:33:24 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 14:33:24 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.
[09/02 14:33:24 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:33:25 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.108
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.279
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.040
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.031
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.133
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.146
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.154
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.319
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.446
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.150
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.439
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.512
[09/02 14:33:25 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 10.795 | 27.868 | 3.981  | 3.121 | 13.334 | 14.584 |
Loading and preparing results...
DONE (t=0.29s)
creating index...
index created!
[09/02 14:33:25 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 14:33:25 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.21 seconds.
[09/02 14:33:25 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:33:25 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.176
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.283
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.202
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.009
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.143
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.279
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.212
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.443
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.133
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.593
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.735
[09/02 14:33:26 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 17.640 | 28.257 | 20.231 | 0.947 | 14.294 | 27.937 |
[09/02 14:33:26 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 14:33:26 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 14:33:26 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:33:26 d2.evaluation.testing]: copypaste: 10.7952,27.8682,3.9810,3.1208,13.3344,14.5837
[09/02 14:33:26 d2.evaluation.testing]: copypaste: Task: segm
[09/02 14:33:26 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:33:26 d2.evaluation.testing]: copypaste: 17.6399,28.2570,20.2308,0.9466,14.2936,27.9368
[09/02 14:33:26 d2.utils.events]:  eta: 0:10:10  iter: 119  total_loss: 1.272  loss_cls: 0.2729  loss_box_reg: 0.3733  loss_mask: 0.534  loss_rpn_cls: 0.03102  loss_rpn_loc: 0.006728  time: 0.7197  data_time: 0.1097  lr: 2.997e-05  max_mem: 4442M
[09/02 14:33:40 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 14:33:40 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 14:33:40 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 14:33:40 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 14:33:40 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 14:33:49 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.1310 s/iter. Eval: 0.6803 s/iter. Total: 0.8129 s/iter. ETA=0:01:48
[09/02 14:33:55 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0027 s/iter. Inference: 0.1321 s/iter. Eval: 0.7079 s/iter. Total: 0.8430 s/iter. ETA=0:01:47
[09/02 14:34:00 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0026 s/iter. Inference: 0.1314 s/iter. Eval: 0.7187 s/iter. Total: 0.8532 s/iter. ETA=0:01:43
[09/02 14:34:05 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0025 s/iter. Inference: 0.1312 s/iter. Eval: 0.7156 s/iter. Total: 0.8498 s/iter. ETA=0:01:37
[09/02 14:34:11 d2.evaluation.evaluator]: Inference done 36/144. Dataloading: 0.0024 s/iter. Inference: 0.1313 s/iter. Eval: 0.7074 s/iter. Total: 0.8415 s/iter. ETA=0:01:30
[09/02 14:34:16 d2.evaluation.evaluator]: Inference done 42/144. Dataloading: 0.0023 s/iter. Inference: 0.1316 s/iter. Eval: 0.7061 s/iter. Total: 0.8404 s/iter. ETA=0:01:25
[09/02 14:34:21 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0023 s/iter. Inference: 0.1314 s/iter. Eval: 0.7004 s/iter. Total: 0.8345 s/iter. ETA=0:01:19
[09/02 14:34:26 d2.evaluation.evaluator]: Inference done 55/144. Dataloading: 0.0022 s/iter. Inference: 0.1314 s/iter. Eval: 0.7006 s/iter. Total: 0.8345 s/iter. ETA=0:01:14
[09/02 14:34:31 d2.evaluation.evaluator]: Inference done 61/144. Dataloading: 0.0026 s/iter. Inference: 0.1313 s/iter. Eval: 0.7040 s/iter. Total: 0.8382 s/iter. ETA=0:01:09
[09/02 14:34:36 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0025 s/iter. Inference: 0.1313 s/iter. Eval: 0.7038 s/iter. Total: 0.8379 s/iter. ETA=0:01:04
[09/02 14:34:42 d2.evaluation.evaluator]: Inference done 74/144. Dataloading: 0.0025 s/iter. Inference: 0.1311 s/iter. Eval: 0.7009 s/iter. Total: 0.8348 s/iter. ETA=0:00:58
[09/02 14:34:48 d2.evaluation.evaluator]: Inference done 81/144. Dataloading: 0.0024 s/iter. Inference: 0.1311 s/iter. Eval: 0.7007 s/iter. Total: 0.8345 s/iter. ETA=0:00:52
[09/02 14:34:54 d2.evaluation.evaluator]: Inference done 88/144. Dataloading: 0.0024 s/iter. Inference: 0.1310 s/iter. Eval: 0.6984 s/iter. Total: 0.8321 s/iter. ETA=0:00:46
[09/02 14:35:00 d2.evaluation.evaluator]: Inference done 95/144. Dataloading: 0.0024 s/iter. Inference: 0.1310 s/iter. Eval: 0.7014 s/iter. Total: 0.8351 s/iter. ETA=0:00:40
[09/02 14:35:05 d2.evaluation.evaluator]: Inference done 102/144. Dataloading: 0.0025 s/iter. Inference: 0.1311 s/iter. Eval: 0.6999 s/iter. Total: 0.8339 s/iter. ETA=0:00:35
[09/02 14:35:10 d2.evaluation.evaluator]: Inference done 108/144. Dataloading: 0.0026 s/iter. Inference: 0.1312 s/iter. Eval: 0.7003 s/iter. Total: 0.8344 s/iter. ETA=0:00:30
[09/02 14:35:16 d2.evaluation.evaluator]: Inference done 115/144. Dataloading: 0.0025 s/iter. Inference: 0.1311 s/iter. Eval: 0.6988 s/iter. Total: 0.8328 s/iter. ETA=0:00:24
[09/02 14:35:21 d2.evaluation.evaluator]: Inference done 121/144. Dataloading: 0.0025 s/iter. Inference: 0.1311 s/iter. Eval: 0.6990 s/iter. Total: 0.8330 s/iter. ETA=0:00:19
[09/02 14:35:27 d2.evaluation.evaluator]: Inference done 128/144. Dataloading: 0.0025 s/iter. Inference: 0.1311 s/iter. Eval: 0.6980 s/iter. Total: 0.8319 s/iter. ETA=0:00:13
[09/02 14:35:32 d2.evaluation.evaluator]: Inference done 134/144. Dataloading: 0.0025 s/iter. Inference: 0.1312 s/iter. Eval: 0.6999 s/iter. Total: 0.8339 s/iter. ETA=0:00:08
[09/02 14:35:38 d2.evaluation.evaluator]: Inference done 141/144. Dataloading: 0.0025 s/iter. Inference: 0.1314 s/iter. Eval: 0.6991 s/iter. Total: 0.8334 s/iter. ETA=0:00:02
[09/02 14:35:40 d2.evaluation.evaluator]: Total inference time: 0:01:55.831035 (0.833317 s / iter per device, on 1 devices)
[09/02 14:35:40 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:18 (0.131317 s / iter per device, on 1 devices)
[09/02 14:35:41 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 14:35:41 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 14:35:41 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/02 14:35:41 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 14:35:41 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.
[09/02 14:35:41 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:35:41 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.125
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.302
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.059
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.039
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.155
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.165
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.176
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.327
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.460
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.150
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.443
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.545
[09/02 14:35:41 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 12.490 | 30.154 | 5.928  | 3.858 | 15.463 | 16.519 |
Loading and preparing results...
DONE (t=0.29s)
creating index...
index created!
[09/02 14:35:42 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 14:35:42 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.20 seconds.
[09/02 14:35:42 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:35:42 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.196
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.308
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.228
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.016
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.155
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.311
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.225
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.445
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.630
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.192
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.744
[09/02 14:35:42 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 19.625 | 30.846 | 22.784 | 1.641 | 15.477 | 31.140 |
[09/02 14:35:42 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 14:35:42 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 14:35:42 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:35:42 d2.evaluation.testing]: copypaste: 12.4898,30.1543,5.9283,3.8577,15.4631,16.5189
[09/02 14:35:42 d2.evaluation.testing]: copypaste: Task: segm
[09/02 14:35:42 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:35:42 d2.evaluation.testing]: copypaste: 19.6254,30.8464,22.7839,1.6412,15.4769,31.1395
[09/02 14:35:42 d2.utils.events]:  eta: 0:09:57  iter: 139  total_loss: 1.175  loss_cls: 0.249  loss_box_reg: 0.3391  loss_mask: 0.5021  loss_rpn_cls: 0.02714  loss_rpn_loc: 0.01193  time: 0.7189  data_time: 0.0925  lr: 3.4965e-05  max_mem: 4442M
[09/02 14:35:56 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 14:35:56 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 14:35:56 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 14:35:56 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 14:35:56 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 14:36:06 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.1329 s/iter. Eval: 0.7707 s/iter. Total: 0.9053 s/iter. ETA=0:02:00
[09/02 14:36:11 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0026 s/iter. Inference: 0.1314 s/iter. Eval: 0.7422 s/iter. Total: 0.8764 s/iter. ETA=0:01:51
[09/02 14:36:17 d2.evaluation.evaluator]: Inference done 24/144. Dataloading: 0.0023 s/iter. Inference: 0.1314 s/iter. Eval: 0.7240 s/iter. Total: 0.8580 s/iter. ETA=0:01:42
[09/02 14:36:22 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0023 s/iter. Inference: 0.1311 s/iter. Eval: 0.7111 s/iter. Total: 0.8448 s/iter. ETA=0:01:35
[09/02 14:36:27 d2.evaluation.evaluator]: Inference done 37/144. Dataloading: 0.0024 s/iter. Inference: 0.1309 s/iter. Eval: 0.7108 s/iter. Total: 0.8443 s/iter. ETA=0:01:30
[09/02 14:36:33 d2.evaluation.evaluator]: Inference done 44/144. Dataloading: 0.0023 s/iter. Inference: 0.1309 s/iter. Eval: 0.7051 s/iter. Total: 0.8385 s/iter. ETA=0:01:23
[09/02 14:36:38 d2.evaluation.evaluator]: Inference done 50/144. Dataloading: 0.0024 s/iter. Inference: 0.1311 s/iter. Eval: 0.7083 s/iter. Total: 0.8420 s/iter. ETA=0:01:19
[09/02 14:36:43 d2.evaluation.evaluator]: Inference done 56/144. Dataloading: 0.0024 s/iter. Inference: 0.1311 s/iter. Eval: 0.7093 s/iter. Total: 0.8431 s/iter. ETA=0:01:14
[09/02 14:36:48 d2.evaluation.evaluator]: Inference done 62/144. Dataloading: 0.0024 s/iter. Inference: 0.1312 s/iter. Eval: 0.7104 s/iter. Total: 0.8442 s/iter. ETA=0:01:09
[09/02 14:36:54 d2.evaluation.evaluator]: Inference done 69/144. Dataloading: 0.0024 s/iter. Inference: 0.1312 s/iter. Eval: 0.7070 s/iter. Total: 0.8408 s/iter. ETA=0:01:03
[09/02 14:37:00 d2.evaluation.evaluator]: Inference done 76/144. Dataloading: 0.0024 s/iter. Inference: 0.1314 s/iter. Eval: 0.7058 s/iter. Total: 0.8398 s/iter. ETA=0:00:57
[09/02 14:37:05 d2.evaluation.evaluator]: Inference done 83/144. Dataloading: 0.0024 s/iter. Inference: 0.1314 s/iter. Eval: 0.7027 s/iter. Total: 0.8367 s/iter. ETA=0:00:51
[09/02 14:37:10 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0024 s/iter. Inference: 0.1312 s/iter. Eval: 0.7026 s/iter. Total: 0.8365 s/iter. ETA=0:00:46
[09/02 14:37:16 d2.evaluation.evaluator]: Inference done 95/144. Dataloading: 0.0023 s/iter. Inference: 0.1313 s/iter. Eval: 0.7054 s/iter. Total: 0.8393 s/iter. ETA=0:00:41
[09/02 14:37:22 d2.evaluation.evaluator]: Inference done 102/144. Dataloading: 0.0023 s/iter. Inference: 0.1312 s/iter. Eval: 0.7047 s/iter. Total: 0.8385 s/iter. ETA=0:00:35
[09/02 14:37:27 d2.evaluation.evaluator]: Inference done 109/144. Dataloading: 0.0024 s/iter. Inference: 0.1312 s/iter. Eval: 0.7031 s/iter. Total: 0.8369 s/iter. ETA=0:00:29
[09/02 14:37:32 d2.evaluation.evaluator]: Inference done 115/144. Dataloading: 0.0024 s/iter. Inference: 0.1314 s/iter. Eval: 0.7028 s/iter. Total: 0.8368 s/iter. ETA=0:00:24
[09/02 14:37:38 d2.evaluation.evaluator]: Inference done 122/144. Dataloading: 0.0023 s/iter. Inference: 0.1313 s/iter. Eval: 0.7012 s/iter. Total: 0.8351 s/iter. ETA=0:00:18
[09/02 14:37:44 d2.evaluation.evaluator]: Inference done 129/144. Dataloading: 0.0023 s/iter. Inference: 0.1313 s/iter. Eval: 0.7017 s/iter. Total: 0.8356 s/iter. ETA=0:00:12
[09/02 14:37:49 d2.evaluation.evaluator]: Inference done 135/144. Dataloading: 0.0023 s/iter. Inference: 0.1315 s/iter. Eval: 0.7023 s/iter. Total: 0.8364 s/iter. ETA=0:00:07
[09/02 14:37:54 d2.evaluation.evaluator]: Inference done 141/144. Dataloading: 0.0023 s/iter. Inference: 0.1315 s/iter. Eval: 0.7023 s/iter. Total: 0.8363 s/iter. ETA=0:00:02
[09/02 14:37:56 d2.evaluation.evaluator]: Total inference time: 0:01:56.189769 (0.835898 s / iter per device, on 1 devices)
[09/02 14:37:56 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:18 (0.131392 s / iter per device, on 1 devices)
[09/02 14:37:57 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 14:37:57 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 14:37:57 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/02 14:37:57 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 14:37:57 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.
[09/02 14:37:57 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:37:57 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.145
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.321
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.080
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.039
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.163
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.200
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.182
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.345
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.466
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.150
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.444
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.561
[09/02 14:37:57 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 14.476 | 32.109 | 8.005  | 3.866 | 16.343 | 20.007 |
Loading and preparing results...
DONE (t=0.28s)
creating index...
index created!
[09/02 14:37:58 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 14:37:58 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.20 seconds.
[09/02 14:37:58 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:37:58 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.213
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.326
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.251
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.156
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.346
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.234
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.463
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.625
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.601
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.745
[09/02 14:37:58 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 21.292 | 32.647 | 25.075 | 2.126 | 15.650 | 34.636 |
[09/02 14:37:58 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 14:37:58 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 14:37:58 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:37:58 d2.evaluation.testing]: copypaste: 14.4764,32.1086,8.0052,3.8664,16.3427,20.0070
[09/02 14:37:58 d2.evaluation.testing]: copypaste: Task: segm
[09/02 14:37:58 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:37:58 d2.evaluation.testing]: copypaste: 21.2917,32.6474,25.0752,2.1258,15.6496,34.6357
[09/02 14:37:58 d2.utils.events]:  eta: 0:09:41  iter: 159  total_loss: 1.104  loss_cls: 0.2371  loss_box_reg: 0.3714  loss_mask: 0.4419  loss_rpn_cls: 0.02067  loss_rpn_loc: 0.006929  time: 0.7144  data_time: 0.0521  lr: 3.996e-05  max_mem: 4442M
[09/02 14:38:12 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 14:38:12 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 14:38:12 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 14:38:12 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 14:38:12 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 14:38:21 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0022 s/iter. Inference: 0.1342 s/iter. Eval: 0.7339 s/iter. Total: 0.8703 s/iter. ETA=0:01:55
[09/02 14:38:27 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0029 s/iter. Inference: 0.1322 s/iter. Eval: 0.7351 s/iter. Total: 0.8705 s/iter. ETA=0:01:50
[09/02 14:38:32 d2.evaluation.evaluator]: Inference done 24/144. Dataloading: 0.0027 s/iter. Inference: 0.1309 s/iter. Eval: 0.7070 s/iter. Total: 0.8408 s/iter. ETA=0:01:40
[09/02 14:38:38 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0026 s/iter. Inference: 0.1300 s/iter. Eval: 0.6954 s/iter. Total: 0.8282 s/iter. ETA=0:01:33
[09/02 14:38:43 d2.evaluation.evaluator]: Inference done 38/144. Dataloading: 0.0024 s/iter. Inference: 0.1296 s/iter. Eval: 0.6868 s/iter. Total: 0.8191 s/iter. ETA=0:01:26
[09/02 14:38:49 d2.evaluation.evaluator]: Inference done 45/144. Dataloading: 0.0024 s/iter. Inference: 0.1295 s/iter. Eval: 0.6846 s/iter. Total: 0.8167 s/iter. ETA=0:01:20
[09/02 14:38:54 d2.evaluation.evaluator]: Inference done 51/144. Dataloading: 0.0024 s/iter. Inference: 0.1296 s/iter. Eval: 0.6927 s/iter. Total: 0.8248 s/iter. ETA=0:01:16
[09/02 14:39:00 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0024 s/iter. Inference: 0.1297 s/iter. Eval: 0.6929 s/iter. Total: 0.8251 s/iter. ETA=0:01:10
[09/02 14:39:05 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0023 s/iter. Inference: 0.1298 s/iter. Eval: 0.6903 s/iter. Total: 0.8226 s/iter. ETA=0:01:04
[09/02 14:39:10 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0023 s/iter. Inference: 0.1300 s/iter. Eval: 0.6921 s/iter. Total: 0.8246 s/iter. ETA=0:01:00
[09/02 14:39:16 d2.evaluation.evaluator]: Inference done 78/144. Dataloading: 0.0023 s/iter. Inference: 0.1299 s/iter. Eval: 0.6884 s/iter. Total: 0.8208 s/iter. ETA=0:00:54
[09/02 14:39:21 d2.evaluation.evaluator]: Inference done 84/144. Dataloading: 0.0023 s/iter. Inference: 0.1300 s/iter. Eval: 0.6894 s/iter. Total: 0.8219 s/iter. ETA=0:00:49
[09/02 14:39:26 d2.evaluation.evaluator]: Inference done 90/144. Dataloading: 0.0023 s/iter. Inference: 0.1303 s/iter. Eval: 0.6938 s/iter. Total: 0.8266 s/iter. ETA=0:00:44
[09/02 14:39:32 d2.evaluation.evaluator]: Inference done 97/144. Dataloading: 0.0024 s/iter. Inference: 0.1303 s/iter. Eval: 0.6942 s/iter. Total: 0.8271 s/iter. ETA=0:00:38
[09/02 14:39:38 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0023 s/iter. Inference: 0.1305 s/iter. Eval: 0.6927 s/iter. Total: 0.8258 s/iter. ETA=0:00:33
[09/02 14:39:43 d2.evaluation.evaluator]: Inference done 111/144. Dataloading: 0.0023 s/iter. Inference: 0.1304 s/iter. Eval: 0.6917 s/iter. Total: 0.8246 s/iter. ETA=0:00:27
[09/02 14:39:49 d2.evaluation.evaluator]: Inference done 118/144. Dataloading: 0.0023 s/iter. Inference: 0.1304 s/iter. Eval: 0.6907 s/iter. Total: 0.8237 s/iter. ETA=0:00:21
[09/02 14:39:54 d2.evaluation.evaluator]: Inference done 124/144. Dataloading: 0.0023 s/iter. Inference: 0.1304 s/iter. Eval: 0.6915 s/iter. Total: 0.8244 s/iter. ETA=0:00:16
[09/02 14:39:59 d2.evaluation.evaluator]: Inference done 130/144. Dataloading: 0.0023 s/iter. Inference: 0.1304 s/iter. Eval: 0.6940 s/iter. Total: 0.8269 s/iter. ETA=0:00:11
[09/02 14:40:05 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0023 s/iter. Inference: 0.1302 s/iter. Eval: 0.6913 s/iter. Total: 0.8240 s/iter. ETA=0:00:05
[09/02 14:40:10 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0023 s/iter. Inference: 0.1298 s/iter. Eval: 0.6871 s/iter. Total: 0.8195 s/iter. ETA=0:00:00
[09/02 14:40:10 d2.evaluation.evaluator]: Total inference time: 0:01:53.966807 (0.819905 s / iter per device, on 1 devices)
[09/02 14:40:10 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:18 (0.129836 s / iter per device, on 1 devices)
[09/02 14:40:10 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 14:40:10 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 14:40:10 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/02 14:40:10 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 14:40:10 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.
[09/02 14:40:10 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:40:11 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.148
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.331
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.077
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.049
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.159
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.208
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.194
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.364
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.480
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.150
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.460
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.574
[09/02 14:40:11 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 14.802 | 33.115 | 7.691  | 4.924 | 15.904 | 20.800 |
Loading and preparing results...
DONE (t=0.27s)
creating index...
index created!
[09/02 14:40:11 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 14:40:11 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.20 seconds.
[09/02 14:40:11 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:40:11 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.220
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.331
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.267
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.022
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.153
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.371
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.249
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.480
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.635
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.756
[09/02 14:40:11 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 22.035 | 33.092 | 26.700 | 2.198 | 15.296 | 37.102 |
[09/02 14:40:11 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 14:40:11 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 14:40:11 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:40:11 d2.evaluation.testing]: copypaste: 14.8019,33.1150,7.6908,4.9244,15.9037,20.8002
[09/02 14:40:11 d2.evaluation.testing]: copypaste: Task: segm
[09/02 14:40:11 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:40:11 d2.evaluation.testing]: copypaste: 22.0352,33.0924,26.7002,2.1983,15.2956,37.1021
[09/02 14:40:11 d2.utils.events]:  eta: 0:09:26  iter: 179  total_loss: 0.9914  loss_cls: 0.206  loss_box_reg: 0.3485  loss_mask: 0.4163  loss_rpn_cls: 0.03224  loss_rpn_loc: 0.009063  time: 0.7106  data_time: 0.0747  lr: 4.4955e-05  max_mem: 4442M
[09/02 14:40:25 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 14:40:25 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 14:40:25 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 14:40:25 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 14:40:25 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 14:40:35 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0018 s/iter. Inference: 0.1308 s/iter. Eval: 0.6751 s/iter. Total: 0.8077 s/iter. ETA=0:01:47
[09/02 14:40:40 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0023 s/iter. Inference: 0.1305 s/iter. Eval: 0.6877 s/iter. Total: 0.8208 s/iter. ETA=0:01:44
[09/02 14:40:46 d2.evaluation.evaluator]: Inference done 25/144. Dataloading: 0.0022 s/iter. Inference: 0.1278 s/iter. Eval: 0.6521 s/iter. Total: 0.7823 s/iter. ETA=0:01:33
[09/02 14:40:51 d2.evaluation.evaluator]: Inference done 32/144. Dataloading: 0.0025 s/iter. Inference: 0.1264 s/iter. Eval: 0.6434 s/iter. Total: 0.7725 s/iter. ETA=0:01:26
[09/02 14:40:56 d2.evaluation.evaluator]: Inference done 39/144. Dataloading: 0.0026 s/iter. Inference: 0.1258 s/iter. Eval: 0.6338 s/iter. Total: 0.7623 s/iter. ETA=0:01:20
[09/02 14:41:02 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0026 s/iter. Inference: 0.1257 s/iter. Eval: 0.6382 s/iter. Total: 0.7667 s/iter. ETA=0:01:15
[09/02 14:41:07 d2.evaluation.evaluator]: Inference done 52/144. Dataloading: 0.0025 s/iter. Inference: 0.1269 s/iter. Eval: 0.6491 s/iter. Total: 0.7788 s/iter. ETA=0:01:11
[09/02 14:41:13 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0025 s/iter. Inference: 0.1272 s/iter. Eval: 0.6534 s/iter. Total: 0.7833 s/iter. ETA=0:01:06
[09/02 14:41:18 d2.evaluation.evaluator]: Inference done 66/144. Dataloading: 0.0025 s/iter. Inference: 0.1276 s/iter. Eval: 0.6563 s/iter. Total: 0.7867 s/iter. ETA=0:01:01
[09/02 14:41:24 d2.evaluation.evaluator]: Inference done 73/144. Dataloading: 0.0025 s/iter. Inference: 0.1276 s/iter. Eval: 0.6582 s/iter. Total: 0.7886 s/iter. ETA=0:00:55
[09/02 14:41:29 d2.evaluation.evaluator]: Inference done 80/144. Dataloading: 0.0026 s/iter. Inference: 0.1274 s/iter. Eval: 0.6547 s/iter. Total: 0.7849 s/iter. ETA=0:00:50
[09/02 14:41:34 d2.evaluation.evaluator]: Inference done 86/144. Dataloading: 0.0026 s/iter. Inference: 0.1278 s/iter. Eval: 0.6582 s/iter. Total: 0.7888 s/iter. ETA=0:00:45
[09/02 14:41:40 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0026 s/iter. Inference: 0.1280 s/iter. Eval: 0.6643 s/iter. Total: 0.7952 s/iter. ETA=0:00:41
[09/02 14:41:45 d2.evaluation.evaluator]: Inference done 98/144. Dataloading: 0.0026 s/iter. Inference: 0.1282 s/iter. Eval: 0.6670 s/iter. Total: 0.7980 s/iter. ETA=0:00:36
[09/02 14:41:50 d2.evaluation.evaluator]: Inference done 105/144. Dataloading: 0.0026 s/iter. Inference: 0.1283 s/iter. Eval: 0.6660 s/iter. Total: 0.7972 s/iter. ETA=0:00:31
[09/02 14:41:55 d2.evaluation.evaluator]: Inference done 112/144. Dataloading: 0.0026 s/iter. Inference: 0.1282 s/iter. Eval: 0.6646 s/iter. Total: 0.7957 s/iter. ETA=0:00:25
[09/02 14:42:01 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0026 s/iter. Inference: 0.1282 s/iter. Eval: 0.6638 s/iter. Total: 0.7948 s/iter. ETA=0:00:19
[09/02 14:42:06 d2.evaluation.evaluator]: Inference done 125/144. Dataloading: 0.0026 s/iter. Inference: 0.1283 s/iter. Eval: 0.6659 s/iter. Total: 0.7970 s/iter. ETA=0:00:15
[09/02 14:42:11 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0025 s/iter. Inference: 0.1284 s/iter. Eval: 0.6701 s/iter. Total: 0.8013 s/iter. ETA=0:00:10
[09/02 14:42:17 d2.evaluation.evaluator]: Inference done 139/144. Dataloading: 0.0025 s/iter. Inference: 0.1279 s/iter. Eval: 0.6639 s/iter. Total: 0.7945 s/iter. ETA=0:00:03
[09/02 14:42:20 d2.evaluation.evaluator]: Total inference time: 0:01:50.130753 (0.792308 s / iter per device, on 1 devices)
[09/02 14:42:20 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:17 (0.127674 s / iter per device, on 1 devices)
[09/02 14:42:21 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 14:42:21 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 14:42:21 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/02 14:42:21 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 14:42:21 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.
[09/02 14:42:21 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:42:21 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.150
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.327
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.088
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.035
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.161
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.209
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.194
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.370
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.483
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.192
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.463
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.573
[09/02 14:42:21 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 14.976 | 32.658 | 8.846  | 3.530 | 16.138 | 20.929 |
Loading and preparing results...
DONE (t=0.26s)
creating index...
index created!
[09/02 14:42:22 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 14:42:22 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.19 seconds.
[09/02 14:42:22 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:42:22 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.221
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.329
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.271
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.023
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.162
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.359
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.246
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.492
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.637
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.242
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.758
[09/02 14:42:22 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 22.074 | 32.900 | 27.139 | 2.312 | 16.182 | 35.905 |
[09/02 14:42:22 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 14:42:22 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 14:42:22 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:42:22 d2.evaluation.testing]: copypaste: 14.9761,32.6579,8.8459,3.5300,16.1385,20.9295
[09/02 14:42:22 d2.evaluation.testing]: copypaste: Task: segm
[09/02 14:42:22 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:42:22 d2.evaluation.testing]: copypaste: 22.0739,32.8997,27.1391,2.3123,16.1816,35.9054
[09/02 14:42:22 d2.utils.events]:  eta: 0:09:12  iter: 199  total_loss: 1.041  loss_cls: 0.2041  loss_box_reg: 0.4121  loss_mask: 0.3857  loss_rpn_cls: 0.01241  loss_rpn_loc: 0.007738  time: 0.7079  data_time: 0.0693  lr: 4.995e-05  max_mem: 4442M
[09/02 14:42:36 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 14:42:36 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 14:42:36 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 14:42:36 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 14:42:36 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 14:42:46 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0023 s/iter. Inference: 0.1320 s/iter. Eval: 0.7242 s/iter. Total: 0.8585 s/iter. ETA=0:01:54
[09/02 14:42:52 d2.evaluation.evaluator]: Inference done 18/144. Dataloading: 0.0024 s/iter. Inference: 0.1311 s/iter. Eval: 0.7045 s/iter. Total: 0.8382 s/iter. ETA=0:01:45
[09/02 14:42:57 d2.evaluation.evaluator]: Inference done 26/144. Dataloading: 0.0025 s/iter. Inference: 0.1256 s/iter. Eval: 0.6319 s/iter. Total: 0.7602 s/iter. ETA=0:01:29
[09/02 14:43:02 d2.evaluation.evaluator]: Inference done 34/144. Dataloading: 0.0024 s/iter. Inference: 0.1240 s/iter. Eval: 0.6159 s/iter. Total: 0.7425 s/iter. ETA=0:01:21
[09/02 14:43:07 d2.evaluation.evaluator]: Inference done 42/144. Dataloading: 0.0024 s/iter. Inference: 0.1229 s/iter. Eval: 0.5941 s/iter. Total: 0.7196 s/iter. ETA=0:01:13
[09/02 14:43:13 d2.evaluation.evaluator]: Inference done 48/144. Dataloading: 0.0023 s/iter. Inference: 0.1292 s/iter. Eval: 0.6093 s/iter. Total: 0.7410 s/iter. ETA=0:01:11
[09/02 14:43:18 d2.evaluation.evaluator]: Inference done 54/144. Dataloading: 0.0023 s/iter. Inference: 0.1300 s/iter. Eval: 0.6254 s/iter. Total: 0.7580 s/iter. ETA=0:01:08
[09/02 14:43:23 d2.evaluation.evaluator]: Inference done 61/144. Dataloading: 0.0024 s/iter. Inference: 0.1300 s/iter. Eval: 0.6285 s/iter. Total: 0.7611 s/iter. ETA=0:01:03
[09/02 14:43:29 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0025 s/iter. Inference: 0.1300 s/iter. Eval: 0.6341 s/iter. Total: 0.7668 s/iter. ETA=0:00:58
[09/02 14:43:34 d2.evaluation.evaluator]: Inference done 75/144. Dataloading: 0.0027 s/iter. Inference: 0.1296 s/iter. Eval: 0.6322 s/iter. Total: 0.7648 s/iter. ETA=0:00:52
[09/02 14:43:40 d2.evaluation.evaluator]: Inference done 82/144. Dataloading: 0.0027 s/iter. Inference: 0.1292 s/iter. Eval: 0.6304 s/iter. Total: 0.7625 s/iter. ETA=0:00:47
[09/02 14:43:45 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0026 s/iter. Inference: 0.1293 s/iter. Eval: 0.6360 s/iter. Total: 0.7681 s/iter. ETA=0:00:42
[09/02 14:43:51 d2.evaluation.evaluator]: Inference done 95/144. Dataloading: 0.0027 s/iter. Inference: 0.1295 s/iter. Eval: 0.6430 s/iter. Total: 0.7755 s/iter. ETA=0:00:37
[09/02 14:43:56 d2.evaluation.evaluator]: Inference done 102/144. Dataloading: 0.0026 s/iter. Inference: 0.1295 s/iter. Eval: 0.6447 s/iter. Total: 0.7770 s/iter. ETA=0:00:32
[09/02 14:44:01 d2.evaluation.evaluator]: Inference done 109/144. Dataloading: 0.0026 s/iter. Inference: 0.1292 s/iter. Eval: 0.6431 s/iter. Total: 0.7752 s/iter. ETA=0:00:27
[09/02 14:44:07 d2.evaluation.evaluator]: Inference done 116/144. Dataloading: 0.0026 s/iter. Inference: 0.1292 s/iter. Eval: 0.6450 s/iter. Total: 0.7771 s/iter. ETA=0:00:21
[09/02 14:44:12 d2.evaluation.evaluator]: Inference done 123/144. Dataloading: 0.0026 s/iter. Inference: 0.1289 s/iter. Eval: 0.6421 s/iter. Total: 0.7739 s/iter. ETA=0:00:16
[09/02 14:44:18 d2.evaluation.evaluator]: Inference done 130/144. Dataloading: 0.0026 s/iter. Inference: 0.1289 s/iter. Eval: 0.6447 s/iter. Total: 0.7764 s/iter. ETA=0:00:10
[09/02 14:44:23 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0027 s/iter. Inference: 0.1287 s/iter. Eval: 0.6437 s/iter. Total: 0.7754 s/iter. ETA=0:00:05
[09/02 14:44:28 d2.evaluation.evaluator]: Total inference time: 0:01:47.047884 (0.770129 s / iter per device, on 1 devices)
[09/02 14:44:28 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:17 (0.128148 s / iter per device, on 1 devices)
[09/02 14:44:28 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 14:44:28 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 14:44:28 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/02 14:44:28 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 14:44:28 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.17 seconds.
[09/02 14:44:28 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:44:28 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.04 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.160
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.341
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.096
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.058
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.171
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.221
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.193
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.381
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.491
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.476
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.567
[09/02 14:44:28 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 15.999 | 34.085 | 9.615  | 5.793 | 17.101 | 22.078 |
Loading and preparing results...
DONE (t=0.24s)
creating index...
index created!
[09/02 14:44:29 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 14:44:29 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.18 seconds.
[09/02 14:44:29 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:44:29 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.230
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.349
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.268
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.028
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.173
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.364
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.255
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.499
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.641
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.614
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.752
[09/02 14:44:29 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 22.967 | 34.937 | 26.807 | 2.809 | 17.285 | 36.397 |
[09/02 14:44:29 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 14:44:29 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 14:44:29 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:44:29 d2.evaluation.testing]: copypaste: 15.9992,34.0852,9.6145,5.7927,17.1011,22.0784
[09/02 14:44:29 d2.evaluation.testing]: copypaste: Task: segm
[09/02 14:44:29 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:44:29 d2.evaluation.testing]: copypaste: 22.9668,34.9367,26.8073,2.8089,17.2846,36.3967
[09/02 14:44:29 d2.utils.events]:  eta: 0:08:57  iter: 219  total_loss: 1.136  loss_cls: 0.2122  loss_box_reg: 0.4762  loss_mask: 0.3101  loss_rpn_cls: 0.01945  loss_rpn_loc: 0.008948  time: 0.7069  data_time: 0.0652  lr: 5.4945e-05  max_mem: 4442M
[09/02 14:44:43 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 14:44:43 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 14:44:43 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 14:44:43 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 14:44:43 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 14:44:53 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0030 s/iter. Inference: 0.1320 s/iter. Eval: 0.7966 s/iter. Total: 0.9317 s/iter. ETA=0:02:03
[09/02 14:44:59 d2.evaluation.evaluator]: Inference done 18/144. Dataloading: 0.0026 s/iter. Inference: 0.1296 s/iter. Eval: 0.7119 s/iter. Total: 0.8444 s/iter. ETA=0:01:46
[09/02 14:45:04 d2.evaluation.evaluator]: Inference done 26/144. Dataloading: 0.0024 s/iter. Inference: 0.1243 s/iter. Eval: 0.6401 s/iter. Total: 0.7670 s/iter. ETA=0:01:30
[09/02 14:45:09 d2.evaluation.evaluator]: Inference done 34/144. Dataloading: 0.0023 s/iter. Inference: 0.1228 s/iter. Eval: 0.6123 s/iter. Total: 0.7376 s/iter. ETA=0:01:21
[09/02 14:45:14 d2.evaluation.evaluator]: Inference done 42/144. Dataloading: 0.0023 s/iter. Inference: 0.1216 s/iter. Eval: 0.5962 s/iter. Total: 0.7203 s/iter. ETA=0:01:13
[09/02 14:45:20 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0023 s/iter. Inference: 0.1227 s/iter. Eval: 0.6064 s/iter. Total: 0.7316 s/iter. ETA=0:01:09
[09/02 14:45:25 d2.evaluation.evaluator]: Inference done 55/144. Dataloading: 0.0022 s/iter. Inference: 0.1231 s/iter. Eval: 0.6211 s/iter. Total: 0.7467 s/iter. ETA=0:01:06
[09/02 14:45:31 d2.evaluation.evaluator]: Inference done 62/144. Dataloading: 0.0023 s/iter. Inference: 0.1240 s/iter. Eval: 0.6276 s/iter. Total: 0.7540 s/iter. ETA=0:01:01
[09/02 14:45:37 d2.evaluation.evaluator]: Inference done 69/144. Dataloading: 0.0023 s/iter. Inference: 0.1246 s/iter. Eval: 0.6349 s/iter. Total: 0.7620 s/iter. ETA=0:00:57
[09/02 14:45:42 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0022 s/iter. Inference: 0.1242 s/iter. Eval: 0.6309 s/iter. Total: 0.7575 s/iter. ETA=0:00:50
[09/02 14:45:48 d2.evaluation.evaluator]: Inference done 84/144. Dataloading: 0.0022 s/iter. Inference: 0.1245 s/iter. Eval: 0.6329 s/iter. Total: 0.7599 s/iter. ETA=0:00:45
[09/02 14:45:53 d2.evaluation.evaluator]: Inference done 91/144. Dataloading: 0.0023 s/iter. Inference: 0.1250 s/iter. Eval: 0.6363 s/iter. Total: 0.7638 s/iter. ETA=0:00:40
[09/02 14:45:59 d2.evaluation.evaluator]: Inference done 97/144. Dataloading: 0.0023 s/iter. Inference: 0.1256 s/iter. Eval: 0.6431 s/iter. Total: 0.7712 s/iter. ETA=0:00:36
[09/02 14:46:04 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0024 s/iter. Inference: 0.1255 s/iter. Eval: 0.6407 s/iter. Total: 0.7688 s/iter. ETA=0:00:30
[09/02 14:46:09 d2.evaluation.evaluator]: Inference done 111/144. Dataloading: 0.0024 s/iter. Inference: 0.1254 s/iter. Eval: 0.6382 s/iter. Total: 0.7662 s/iter. ETA=0:00:25
[09/02 14:46:14 d2.evaluation.evaluator]: Inference done 118/144. Dataloading: 0.0024 s/iter. Inference: 0.1253 s/iter. Eval: 0.6363 s/iter. Total: 0.7643 s/iter. ETA=0:00:19
[09/02 14:46:20 d2.evaluation.evaluator]: Inference done 125/144. Dataloading: 0.0024 s/iter. Inference: 0.1255 s/iter. Eval: 0.6380 s/iter. Total: 0.7661 s/iter. ETA=0:00:14
[09/02 14:46:25 d2.evaluation.evaluator]: Inference done 132/144. Dataloading: 0.0024 s/iter. Inference: 0.1253 s/iter. Eval: 0.6353 s/iter. Total: 0.7632 s/iter. ETA=0:00:09
[09/02 14:46:30 d2.evaluation.evaluator]: Inference done 139/144. Dataloading: 0.0024 s/iter. Inference: 0.1250 s/iter. Eval: 0.6339 s/iter. Total: 0.7615 s/iter. ETA=0:00:03
[09/02 14:46:34 d2.evaluation.evaluator]: Total inference time: 0:01:46.020130 (0.762735 s / iter per device, on 1 devices)
[09/02 14:46:34 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:17 (0.125270 s / iter per device, on 1 devices)
[09/02 14:46:34 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 14:46:34 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 14:46:34 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/02 14:46:34 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 14:46:34 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.
[09/02 14:46:34 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:46:34 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.164
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.352
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.090
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.034
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.186
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.213
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.196
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.390
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.502
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.496
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.564
[09/02 14:46:34 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 16.380 | 35.221 | 8.982  | 3.393 | 18.581 | 21.286 |
Loading and preparing results...
DONE (t=0.23s)
creating index...
index created!
[09/02 14:46:35 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 14:46:35 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.17 seconds.
[09/02 14:46:35 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:46:35 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.236
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.355
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.272
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.018
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.184
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.369
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.258
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.501
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.647
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.292
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.753
[09/02 14:46:35 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 23.553 | 35.456 | 27.218 | 1.752 | 18.401 | 36.865 |
[09/02 14:46:35 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 14:46:35 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 14:46:35 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:46:35 d2.evaluation.testing]: copypaste: 16.3804,35.2206,8.9823,3.3930,18.5814,21.2860
[09/02 14:46:35 d2.evaluation.testing]: copypaste: Task: segm
[09/02 14:46:35 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:46:35 d2.evaluation.testing]: copypaste: 23.5529,35.4561,27.2180,1.7516,18.4009,36.8653
[09/02 14:46:35 d2.utils.events]:  eta: 0:08:43  iter: 239  total_loss: 0.8444  loss_cls: 0.1488  loss_box_reg: 0.3332  loss_mask: 0.3045  loss_rpn_cls: 0.03671  loss_rpn_loc: 0.007041  time: 0.7052  data_time: 0.0593  lr: 5.994e-05  max_mem: 4442M
[09/02 14:46:49 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 14:46:49 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 14:46:49 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 14:46:49 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 14:46:49 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 14:46:58 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0019 s/iter. Inference: 0.1287 s/iter. Eval: 0.6684 s/iter. Total: 0.7989 s/iter. ETA=0:01:46
[09/02 14:47:03 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0024 s/iter. Inference: 0.1262 s/iter. Eval: 0.6911 s/iter. Total: 0.8199 s/iter. ETA=0:01:44
[09/02 14:47:09 d2.evaluation.evaluator]: Inference done 26/144. Dataloading: 0.0023 s/iter. Inference: 0.1202 s/iter. Eval: 0.5955 s/iter. Total: 0.7182 s/iter. ETA=0:01:24
[09/02 14:47:14 d2.evaluation.evaluator]: Inference done 34/144. Dataloading: 0.0025 s/iter. Inference: 0.1195 s/iter. Eval: 0.5784 s/iter. Total: 0.7006 s/iter. ETA=0:01:17
[09/02 14:47:20 d2.evaluation.evaluator]: Inference done 43/144. Dataloading: 0.0025 s/iter. Inference: 0.1188 s/iter. Eval: 0.5629 s/iter. Total: 0.6844 s/iter. ETA=0:01:09
[09/02 14:47:25 d2.evaluation.evaluator]: Inference done 50/144. Dataloading: 0.0026 s/iter. Inference: 0.1205 s/iter. Eval: 0.5796 s/iter. Total: 0.7029 s/iter. ETA=0:01:06
[09/02 14:47:30 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0027 s/iter. Inference: 0.1211 s/iter. Eval: 0.5850 s/iter. Total: 0.7089 s/iter. ETA=0:01:01
[09/02 14:47:36 d2.evaluation.evaluator]: Inference done 63/144. Dataloading: 0.0026 s/iter. Inference: 0.1220 s/iter. Eval: 0.5980 s/iter. Total: 0.7229 s/iter. ETA=0:00:58
[09/02 14:47:41 d2.evaluation.evaluator]: Inference done 69/144. Dataloading: 0.0026 s/iter. Inference: 0.1235 s/iter. Eval: 0.6114 s/iter. Total: 0.7377 s/iter. ETA=0:00:55
[09/02 14:47:46 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0026 s/iter. Inference: 0.1228 s/iter. Eval: 0.6016 s/iter. Total: 0.7273 s/iter. ETA=0:00:48
[09/02 14:47:51 d2.evaluation.evaluator]: Inference done 84/144. Dataloading: 0.0026 s/iter. Inference: 0.1228 s/iter. Eval: 0.6015 s/iter. Total: 0.7271 s/iter. ETA=0:00:43
[09/02 14:47:56 d2.evaluation.evaluator]: Inference done 91/144. Dataloading: 0.0025 s/iter. Inference: 0.1232 s/iter. Eval: 0.6055 s/iter. Total: 0.7315 s/iter. ETA=0:00:38
[09/02 14:48:02 d2.evaluation.evaluator]: Inference done 98/144. Dataloading: 0.0025 s/iter. Inference: 0.1234 s/iter. Eval: 0.6052 s/iter. Total: 0.7313 s/iter. ETA=0:00:33
[09/02 14:48:07 d2.evaluation.evaluator]: Inference done 106/144. Dataloading: 0.0025 s/iter. Inference: 0.1230 s/iter. Eval: 0.5999 s/iter. Total: 0.7256 s/iter. ETA=0:00:27
[09/02 14:48:12 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0025 s/iter. Inference: 0.1233 s/iter. Eval: 0.6046 s/iter. Total: 0.7307 s/iter. ETA=0:00:22
[09/02 14:48:18 d2.evaluation.evaluator]: Inference done 121/144. Dataloading: 0.0025 s/iter. Inference: 0.1231 s/iter. Eval: 0.6015 s/iter. Total: 0.7274 s/iter. ETA=0:00:16
[09/02 14:48:23 d2.evaluation.evaluator]: Inference done 128/144. Dataloading: 0.0026 s/iter. Inference: 0.1233 s/iter. Eval: 0.6040 s/iter. Total: 0.7300 s/iter. ETA=0:00:11
[09/02 14:48:29 d2.evaluation.evaluator]: Inference done 135/144. Dataloading: 0.0025 s/iter. Inference: 0.1232 s/iter. Eval: 0.6053 s/iter. Total: 0.7312 s/iter. ETA=0:00:06
[09/02 14:48:34 d2.evaluation.evaluator]: Inference done 143/144. Dataloading: 0.0026 s/iter. Inference: 0.1229 s/iter. Eval: 0.6002 s/iter. Total: 0.7258 s/iter. ETA=0:00:00
[09/02 14:48:35 d2.evaluation.evaluator]: Total inference time: 0:01:41.015708 (0.726732 s / iter per device, on 1 devices)
[09/02 14:48:35 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:17 (0.122900 s / iter per device, on 1 devices)
[09/02 14:48:35 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 14:48:35 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 14:48:35 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/02 14:48:35 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 14:48:35 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.09 seconds.
[09/02 14:48:35 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:48:35 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.181
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.369
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.108
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.057
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.226
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.225
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.216
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.406
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.509
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.225
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.495
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.586
[09/02 14:48:35 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 18.150 | 36.894 | 10.831 | 5.707 | 22.641 | 22.499 |
Loading and preparing results...
DONE (t=0.22s)
creating index...
index created!
[09/02 14:48:36 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 14:48:36 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.17 seconds.
[09/02 14:48:36 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:48:36 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.248
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.376
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.295
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.036
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.201
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.375
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.276
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.511
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.644
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.292
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.618
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.753
[09/02 14:48:36 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 24.811 | 37.636 | 29.538 | 3.575 | 20.092 | 37.501 |
[09/02 14:48:36 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 14:48:36 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 14:48:36 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:48:36 d2.evaluation.testing]: copypaste: 18.1498,36.8939,10.8309,5.7065,22.6408,22.4988
[09/02 14:48:36 d2.evaluation.testing]: copypaste: Task: segm
[09/02 14:48:36 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:48:36 d2.evaluation.testing]: copypaste: 24.8112,37.6360,29.5382,3.5755,20.0920,37.5014
[09/02 14:48:36 d2.utils.events]:  eta: 0:08:27  iter: 259  total_loss: 1.016  loss_cls: 0.199  loss_box_reg: 0.4661  loss_mask: 0.2731  loss_rpn_cls: 0.01773  loss_rpn_loc: 0.009626  time: 0.7044  data_time: 0.0659  lr: 6.4935e-05  max_mem: 4442M
[09/02 14:48:50 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 14:48:50 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 14:48:50 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 14:48:50 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 14:48:50 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 14:48:59 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0018 s/iter. Inference: 0.1276 s/iter. Eval: 0.6424 s/iter. Total: 0.7719 s/iter. ETA=0:01:42
[09/02 14:49:05 d2.evaluation.evaluator]: Inference done 20/144. Dataloading: 0.0023 s/iter. Inference: 0.1196 s/iter. Eval: 0.5553 s/iter. Total: 0.6775 s/iter. ETA=0:01:24
[09/02 14:49:10 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0022 s/iter. Inference: 0.1181 s/iter. Eval: 0.5307 s/iter. Total: 0.6511 s/iter. ETA=0:01:14
[09/02 14:49:16 d2.evaluation.evaluator]: Inference done 38/144. Dataloading: 0.0027 s/iter. Inference: 0.1152 s/iter. Eval: 0.5107 s/iter. Total: 0.6289 s/iter. ETA=0:01:06
[09/02 14:49:21 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0028 s/iter. Inference: 0.1162 s/iter. Eval: 0.5202 s/iter. Total: 0.6394 s/iter. ETA=0:01:02
[09/02 14:49:27 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0027 s/iter. Inference: 0.1181 s/iter. Eval: 0.5449 s/iter. Total: 0.6660 s/iter. ETA=0:01:00
[09/02 14:49:32 d2.evaluation.evaluator]: Inference done 61/144. Dataloading: 0.0027 s/iter. Inference: 0.1185 s/iter. Eval: 0.5481 s/iter. Total: 0.6695 s/iter. ETA=0:00:55
[09/02 14:49:38 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0026 s/iter. Inference: 0.1198 s/iter. Eval: 0.5620 s/iter. Total: 0.6846 s/iter. ETA=0:00:52
[09/02 14:49:43 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0026 s/iter. Inference: 0.1191 s/iter. Eval: 0.5533 s/iter. Total: 0.6753 s/iter. ETA=0:00:45
[09/02 14:49:49 d2.evaluation.evaluator]: Inference done 84/144. Dataloading: 0.0026 s/iter. Inference: 0.1192 s/iter. Eval: 0.5600 s/iter. Total: 0.6819 s/iter. ETA=0:00:40
[09/02 14:49:54 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0025 s/iter. Inference: 0.1194 s/iter. Eval: 0.5619 s/iter. Total: 0.6841 s/iter. ETA=0:00:35
[09/02 14:50:00 d2.evaluation.evaluator]: Inference done 101/144. Dataloading: 0.0025 s/iter. Inference: 0.1187 s/iter. Eval: 0.5540 s/iter. Total: 0.6755 s/iter. ETA=0:00:29
[09/02 14:50:05 d2.evaluation.evaluator]: Inference done 109/144. Dataloading: 0.0025 s/iter. Inference: 0.1186 s/iter. Eval: 0.5508 s/iter. Total: 0.6721 s/iter. ETA=0:00:23
[09/02 14:50:10 d2.evaluation.evaluator]: Inference done 117/144. Dataloading: 0.0025 s/iter. Inference: 0.1186 s/iter. Eval: 0.5513 s/iter. Total: 0.6726 s/iter. ETA=0:00:18
[09/02 14:50:15 d2.evaluation.evaluator]: Inference done 125/144. Dataloading: 0.0025 s/iter. Inference: 0.1185 s/iter. Eval: 0.5493 s/iter. Total: 0.6704 s/iter. ETA=0:00:12
[09/02 14:50:21 d2.evaluation.evaluator]: Inference done 134/144. Dataloading: 0.0025 s/iter. Inference: 0.1185 s/iter. Eval: 0.5474 s/iter. Total: 0.6685 s/iter. ETA=0:00:06
[09/02 14:50:27 d2.evaluation.evaluator]: Inference done 143/144. Dataloading: 0.0024 s/iter. Inference: 0.1183 s/iter. Eval: 0.5446 s/iter. Total: 0.6656 s/iter. ETA=0:00:00
[09/02 14:50:28 d2.evaluation.evaluator]: Total inference time: 0:01:32.708123 (0.666965 s / iter per device, on 1 devices)
[09/02 14:50:28 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:16 (0.118380 s / iter per device, on 1 devices)
[09/02 14:50:28 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 14:50:28 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 14:50:28 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/02 14:50:28 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 14:50:28 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.09 seconds.
[09/02 14:50:28 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:50:28 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.208
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.406
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.161
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.063
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.238
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.265
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.220
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.424
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.528
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.225
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.519
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.598
[09/02 14:50:28 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 20.765 | 40.603 | 16.108 | 6.318 | 23.780 | 26.516 |
Loading and preparing results...
DONE (t=0.20s)
creating index...
index created!
[09/02 14:50:29 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 14:50:29 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.15 seconds.
[09/02 14:50:29 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:50:29 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.279
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.410
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.336
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.032
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.233
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.413
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.279
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.523
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.661
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.308
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.638
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.764
[09/02 14:50:29 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 27.889 | 41.016 | 33.598 | 3.224 | 23.255 | 41.337 |
[09/02 14:50:29 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 14:50:29 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 14:50:29 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:50:29 d2.evaluation.testing]: copypaste: 20.7655,40.6032,16.1081,6.3179,23.7804,26.5164
[09/02 14:50:29 d2.evaluation.testing]: copypaste: Task: segm
[09/02 14:50:29 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:50:29 d2.evaluation.testing]: copypaste: 27.8886,41.0157,33.5983,3.2241,23.2555,41.3374
[09/02 14:50:29 d2.utils.events]:  eta: 0:08:12  iter: 279  total_loss: 0.8426  loss_cls: 0.1783  loss_box_reg: 0.3167  loss_mask: 0.2799  loss_rpn_cls: 0.01904  loss_rpn_loc: 0.005852  time: 0.7050  data_time: 0.0777  lr: 6.993e-05  max_mem: 4442M
[09/02 14:50:43 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 14:50:43 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 14:50:43 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 14:50:43 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 14:50:43 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 14:50:52 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.1235 s/iter. Eval: 0.6024 s/iter. Total: 0.7276 s/iter. ETA=0:01:36
[09/02 14:50:58 d2.evaluation.evaluator]: Inference done 20/144. Dataloading: 0.0027 s/iter. Inference: 0.1204 s/iter. Eval: 0.5616 s/iter. Total: 0.6850 s/iter. ETA=0:01:24
[09/02 14:51:03 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0025 s/iter. Inference: 0.1176 s/iter. Eval: 0.5274 s/iter. Total: 0.6477 s/iter. ETA=0:01:14
[09/02 14:51:08 d2.evaluation.evaluator]: Inference done 39/144. Dataloading: 0.0024 s/iter. Inference: 0.1147 s/iter. Eval: 0.4965 s/iter. Total: 0.6139 s/iter. ETA=0:01:04
[09/02 14:51:14 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0023 s/iter. Inference: 0.1159 s/iter. Eval: 0.5083 s/iter. Total: 0.6267 s/iter. ETA=0:01:00
[09/02 14:51:19 d2.evaluation.evaluator]: Inference done 54/144. Dataloading: 0.0024 s/iter. Inference: 0.1180 s/iter. Eval: 0.5341 s/iter. Total: 0.6548 s/iter. ETA=0:00:58
[09/02 14:51:25 d2.evaluation.evaluator]: Inference done 62/144. Dataloading: 0.0024 s/iter. Inference: 0.1185 s/iter. Eval: 0.5383 s/iter. Total: 0.6594 s/iter. ETA=0:00:54
[09/02 14:51:31 d2.evaluation.evaluator]: Inference done 69/144. Dataloading: 0.0024 s/iter. Inference: 0.1199 s/iter. Eval: 0.5584 s/iter. Total: 0.6808 s/iter. ETA=0:00:51
[09/02 14:51:36 d2.evaluation.evaluator]: Inference done 78/144. Dataloading: 0.0023 s/iter. Inference: 0.1193 s/iter. Eval: 0.5496 s/iter. Total: 0.6714 s/iter. ETA=0:00:44
[09/02 14:51:42 d2.evaluation.evaluator]: Inference done 87/144. Dataloading: 0.0023 s/iter. Inference: 0.1187 s/iter. Eval: 0.5424 s/iter. Total: 0.6636 s/iter. ETA=0:00:37
[09/02 14:51:47 d2.evaluation.evaluator]: Inference done 96/144. Dataloading: 0.0023 s/iter. Inference: 0.1182 s/iter. Eval: 0.5374 s/iter. Total: 0.6581 s/iter. ETA=0:00:31
[09/02 14:51:52 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0023 s/iter. Inference: 0.1182 s/iter. Eval: 0.5351 s/iter. Total: 0.6559 s/iter. ETA=0:00:26
[09/02 14:51:58 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0023 s/iter. Inference: 0.1179 s/iter. Eval: 0.5309 s/iter. Total: 0.6513 s/iter. ETA=0:00:20
[09/02 14:52:04 d2.evaluation.evaluator]: Inference done 122/144. Dataloading: 0.0023 s/iter. Inference: 0.1177 s/iter. Eval: 0.5325 s/iter. Total: 0.6526 s/iter. ETA=0:00:14
[09/02 14:52:09 d2.evaluation.evaluator]: Inference done 130/144. Dataloading: 0.0023 s/iter. Inference: 0.1177 s/iter. Eval: 0.5316 s/iter. Total: 0.6517 s/iter. ETA=0:00:09
[09/02 14:52:14 d2.evaluation.evaluator]: Inference done 139/144. Dataloading: 0.0022 s/iter. Inference: 0.1172 s/iter. Eval: 0.5259 s/iter. Total: 0.6455 s/iter. ETA=0:00:03
[09/02 14:52:17 d2.evaluation.evaluator]: Total inference time: 0:01:29.661101 (0.645044 s / iter per device, on 1 devices)
[09/02 14:52:17 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:16 (0.117120 s / iter per device, on 1 devices)
[09/02 14:52:17 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 14:52:17 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 14:52:17 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/02 14:52:17 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 14:52:17 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.08 seconds.
[09/02 14:52:17 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:52:17 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.231
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.439
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.187
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.045
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.260
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.288
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.240
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.445
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.532
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.522
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.606
[09/02 14:52:17 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 23.145 | 43.861 | 18.674 | 4.492 | 26.013 | 28.825 |
Loading and preparing results...
DONE (t=0.19s)
creating index...
index created!
[09/02 14:52:18 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 14:52:18 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.15 seconds.
[09/02 14:52:18 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:52:18 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.302
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.450
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.355
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.030
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.266
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.425
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.292
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.544
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.662
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.643
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.756
[09/02 14:52:18 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 30.181 | 45.009 | 35.548 | 3.043 | 26.644 | 42.513 |
[09/02 14:52:18 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 14:52:18 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 14:52:18 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:52:18 d2.evaluation.testing]: copypaste: 23.1455,43.8611,18.6737,4.4923,26.0127,28.8251
[09/02 14:52:18 d2.evaluation.testing]: copypaste: Task: segm
[09/02 14:52:18 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:52:18 d2.evaluation.testing]: copypaste: 30.1814,45.0089,35.5484,3.0434,26.6435,42.5133
[09/02 14:52:18 d2.utils.events]:  eta: 0:07:59  iter: 299  total_loss: 0.897  loss_cls: 0.1584  loss_box_reg: 0.3939  loss_mask: 0.2552  loss_rpn_cls: 0.01348  loss_rpn_loc: 0.007624  time: 0.7038  data_time: 0.0635  lr: 7.4925e-05  max_mem: 4442M
[09/02 14:52:32 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 14:52:32 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 14:52:32 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 14:52:32 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 14:52:32 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 14:52:41 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0017 s/iter. Inference: 0.1188 s/iter. Eval: 0.5502 s/iter. Total: 0.6708 s/iter. ETA=0:01:29
[09/02 14:52:46 d2.evaluation.evaluator]: Inference done 21/144. Dataloading: 0.0033 s/iter. Inference: 0.1139 s/iter. Eval: 0.4743 s/iter. Total: 0.5917 s/iter. ETA=0:01:12
[09/02 14:52:51 d2.evaluation.evaluator]: Inference done 32/144. Dataloading: 0.0029 s/iter. Inference: 0.1095 s/iter. Eval: 0.4281 s/iter. Total: 0.5407 s/iter. ETA=0:01:00
[09/02 14:52:57 d2.evaluation.evaluator]: Inference done 42/144. Dataloading: 0.0027 s/iter. Inference: 0.1082 s/iter. Eval: 0.4204 s/iter. Total: 0.5314 s/iter. ETA=0:00:54
[09/02 14:53:02 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0026 s/iter. Inference: 0.1110 s/iter. Eval: 0.4535 s/iter. Total: 0.5672 s/iter. ETA=0:00:53
[09/02 14:53:08 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0025 s/iter. Inference: 0.1126 s/iter. Eval: 0.4744 s/iter. Total: 0.5897 s/iter. ETA=0:00:51
[09/02 14:53:13 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0026 s/iter. Inference: 0.1136 s/iter. Eval: 0.4864 s/iter. Total: 0.6027 s/iter. ETA=0:00:47
[09/02 14:53:18 d2.evaluation.evaluator]: Inference done 73/144. Dataloading: 0.0026 s/iter. Inference: 0.1139 s/iter. Eval: 0.4908 s/iter. Total: 0.6075 s/iter. ETA=0:00:43
[09/02 14:53:23 d2.evaluation.evaluator]: Inference done 82/144. Dataloading: 0.0025 s/iter. Inference: 0.1135 s/iter. Eval: 0.4853 s/iter. Total: 0.6015 s/iter. ETA=0:00:37
[09/02 14:53:28 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0025 s/iter. Inference: 0.1128 s/iter. Eval: 0.4761 s/iter. Total: 0.5916 s/iter. ETA=0:00:30
[09/02 14:53:34 d2.evaluation.evaluator]: Inference done 103/144. Dataloading: 0.0026 s/iter. Inference: 0.1118 s/iter. Eval: 0.4639 s/iter. Total: 0.5785 s/iter. ETA=0:00:23
[09/02 14:53:39 d2.evaluation.evaluator]: Inference done 112/144. Dataloading: 0.0025 s/iter. Inference: 0.1121 s/iter. Eval: 0.4668 s/iter. Total: 0.5816 s/iter. ETA=0:00:18
[09/02 14:53:44 d2.evaluation.evaluator]: Inference done 121/144. Dataloading: 0.0047 s/iter. Inference: 0.1119 s/iter. Eval: 0.4653 s/iter. Total: 0.5820 s/iter. ETA=0:00:13
[09/02 14:53:50 d2.evaluation.evaluator]: Inference done 130/144. Dataloading: 0.0045 s/iter. Inference: 0.1119 s/iter. Eval: 0.4668 s/iter. Total: 0.5835 s/iter. ETA=0:00:08
[09/02 14:53:55 d2.evaluation.evaluator]: Inference done 141/144. Dataloading: 0.0044 s/iter. Inference: 0.1112 s/iter. Eval: 0.4580 s/iter. Total: 0.5737 s/iter. ETA=0:00:01
[09/02 14:53:57 d2.evaluation.evaluator]: Total inference time: 0:01:20.002626 (0.575558 s / iter per device, on 1 devices)
[09/02 14:53:57 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:15 (0.111302 s / iter per device, on 1 devices)
[09/02 14:53:57 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 14:53:57 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 14:53:57 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/02 14:53:57 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 14:53:57 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.08 seconds.
[09/02 14:53:57 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:53:57 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.257
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.473
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.214
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.035
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.279
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.326
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.239
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.446
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.538
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.516
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.635
[09/02 14:53:57 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 25.728 | 47.299 | 21.358 | 3.472 | 27.940 | 32.551 |
Loading and preparing results...
DONE (t=0.17s)
creating index...
index created!
[09/02 14:53:58 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 14:53:58 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.14 seconds.
[09/02 14:53:58 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:53:58 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.327
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.482
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.378
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.032
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.282
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.466
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.289
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.548
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.656
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.342
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.629
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.761
[09/02 14:53:58 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 32.669 | 48.227 | 37.758 | 3.185 | 28.177 | 46.552 |
[09/02 14:53:58 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 14:53:58 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 14:53:58 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:53:58 d2.evaluation.testing]: copypaste: 25.7285,47.2986,21.3584,3.4723,27.9403,32.5509
[09/02 14:53:58 d2.evaluation.testing]: copypaste: Task: segm
[09/02 14:53:58 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:53:58 d2.evaluation.testing]: copypaste: 32.6685,48.2269,37.7583,3.1847,28.1766,46.5524
[09/02 14:53:58 d2.utils.events]:  eta: 0:07:45  iter: 319  total_loss: 0.758  loss_cls: 0.1398  loss_box_reg: 0.3547  loss_mask: 0.2284  loss_rpn_cls: 0.008976  loss_rpn_loc: 0.006896  time: 0.7021  data_time: 0.0580  lr: 7.992e-05  max_mem: 4442M
[09/02 14:54:12 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 14:54:12 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 14:54:12 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 14:54:12 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 14:54:12 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 14:54:21 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0020 s/iter. Inference: 0.1155 s/iter. Eval: 0.5112 s/iter. Total: 0.6287 s/iter. ETA=0:01:23
[09/02 14:54:26 d2.evaluation.evaluator]: Inference done 22/144. Dataloading: 0.0023 s/iter. Inference: 0.1073 s/iter. Eval: 0.4066 s/iter. Total: 0.5164 s/iter. ETA=0:01:03
[09/02 14:54:31 d2.evaluation.evaluator]: Inference done 34/144. Dataloading: 0.0024 s/iter. Inference: 0.1048 s/iter. Eval: 0.3763 s/iter. Total: 0.4836 s/iter. ETA=0:00:53
[09/02 14:54:36 d2.evaluation.evaluator]: Inference done 44/144. Dataloading: 0.0025 s/iter. Inference: 0.1048 s/iter. Eval: 0.3819 s/iter. Total: 0.4893 s/iter. ETA=0:00:48
[09/02 14:54:41 d2.evaluation.evaluator]: Inference done 51/144. Dataloading: 0.0025 s/iter. Inference: 0.1080 s/iter. Eval: 0.4205 s/iter. Total: 0.5312 s/iter. ETA=0:00:49
[09/02 14:54:47 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0027 s/iter. Inference: 0.1098 s/iter. Eval: 0.4496 s/iter. Total: 0.5623 s/iter. ETA=0:00:47
[09/02 14:54:53 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0027 s/iter. Inference: 0.1107 s/iter. Eval: 0.4586 s/iter. Total: 0.5723 s/iter. ETA=0:00:43
[09/02 14:54:58 d2.evaluation.evaluator]: Inference done 78/144. Dataloading: 0.0028 s/iter. Inference: 0.1103 s/iter. Eval: 0.4493 s/iter. Total: 0.5626 s/iter. ETA=0:00:37
[09/02 14:55:03 d2.evaluation.evaluator]: Inference done 90/144. Dataloading: 0.0027 s/iter. Inference: 0.1089 s/iter. Eval: 0.4322 s/iter. Total: 0.5440 s/iter. ETA=0:00:29
[09/02 14:55:08 d2.evaluation.evaluator]: Inference done 102/144. Dataloading: 0.0027 s/iter. Inference: 0.1077 s/iter. Eval: 0.4185 s/iter. Total: 0.5291 s/iter. ETA=0:00:22
[09/02 14:55:13 d2.evaluation.evaluator]: Inference done 111/144. Dataloading: 0.0027 s/iter. Inference: 0.1079 s/iter. Eval: 0.4210 s/iter. Total: 0.5319 s/iter. ETA=0:00:17
[09/02 14:55:18 d2.evaluation.evaluator]: Inference done 121/144. Dataloading: 0.0027 s/iter. Inference: 0.1079 s/iter. Eval: 0.4197 s/iter. Total: 0.5305 s/iter. ETA=0:00:12
[09/02 14:55:24 d2.evaluation.evaluator]: Inference done 130/144. Dataloading: 0.0027 s/iter. Inference: 0.1081 s/iter. Eval: 0.4232 s/iter. Total: 0.5342 s/iter. ETA=0:00:07
[09/02 14:55:29 d2.evaluation.evaluator]: Inference done 142/144. Dataloading: 0.0026 s/iter. Inference: 0.1075 s/iter. Eval: 0.4167 s/iter. Total: 0.5270 s/iter. ETA=0:00:01
[09/02 14:55:30 d2.evaluation.evaluator]: Total inference time: 0:01:13.425032 (0.528238 s / iter per device, on 1 devices)
[09/02 14:55:30 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:14 (0.107559 s / iter per device, on 1 devices)
[09/02 14:55:30 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 14:55:30 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 14:55:30 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/02 14:55:30 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 14:55:30 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[09/02 14:55:30 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:55:31 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.277
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.493
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.260
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.045
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.293
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.356
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.253
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.460
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.547
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.242
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.523
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.645
[09/02 14:55:31 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 27.746 | 49.284 | 26.039 | 4.538 | 29.343 | 35.649 |
Loading and preparing results...
DONE (t=0.15s)
creating index...
index created!
[09/02 14:55:31 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 14:55:31 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.13 seconds.
[09/02 14:55:31 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:55:31 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.349
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.505
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.403
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.037
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.298
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.500
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.302
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.559
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.664
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.638
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.764
[09/02 14:55:31 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 34.888 | 50.452 | 40.286 | 3.669 | 29.812 | 50.003 |
[09/02 14:55:31 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 14:55:31 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 14:55:31 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:55:31 d2.evaluation.testing]: copypaste: 27.7456,49.2844,26.0387,4.5381,29.3430,35.6494
[09/02 14:55:31 d2.evaluation.testing]: copypaste: Task: segm
[09/02 14:55:31 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:55:31 d2.evaluation.testing]: copypaste: 34.8877,50.4519,40.2857,3.6688,29.8125,50.0029
[09/02 14:55:31 d2.utils.events]:  eta: 0:07:31  iter: 339  total_loss: 0.8786  loss_cls: 0.1661  loss_box_reg: 0.3903  loss_mask: 0.2246  loss_rpn_cls: 0.01439  loss_rpn_loc: 0.01168  time: 0.7016  data_time: 0.0530  lr: 8.4915e-05  max_mem: 4442M
[09/02 14:55:45 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 14:55:45 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 14:55:45 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 14:55:45 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 14:55:45 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 14:55:53 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0029 s/iter. Inference: 0.1183 s/iter. Eval: 0.5532 s/iter. Total: 0.6744 s/iter. ETA=0:01:29
[09/02 14:55:59 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0027 s/iter. Inference: 0.1072 s/iter. Eval: 0.4097 s/iter. Total: 0.5198 s/iter. ETA=0:01:02
[09/02 14:56:04 d2.evaluation.evaluator]: Inference done 35/144. Dataloading: 0.0025 s/iter. Inference: 0.1044 s/iter. Eval: 0.3758 s/iter. Total: 0.4829 s/iter. ETA=0:00:52
[09/02 14:56:09 d2.evaluation.evaluator]: Inference done 45/144. Dataloading: 0.0024 s/iter. Inference: 0.1047 s/iter. Eval: 0.3848 s/iter. Total: 0.4920 s/iter. ETA=0:00:48
[09/02 14:56:14 d2.evaluation.evaluator]: Inference done 52/144. Dataloading: 0.0024 s/iter. Inference: 0.1079 s/iter. Eval: 0.4221 s/iter. Total: 0.5325 s/iter. ETA=0:00:48
[09/02 14:56:19 d2.evaluation.evaluator]: Inference done 60/144. Dataloading: 0.0024 s/iter. Inference: 0.1093 s/iter. Eval: 0.4361 s/iter. Total: 0.5481 s/iter. ETA=0:00:46
[09/02 14:56:25 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0024 s/iter. Inference: 0.1106 s/iter. Eval: 0.4553 s/iter. Total: 0.5685 s/iter. ETA=0:00:43
[09/02 14:56:31 d2.evaluation.evaluator]: Inference done 79/144. Dataloading: 0.0025 s/iter. Inference: 0.1102 s/iter. Eval: 0.4479 s/iter. Total: 0.5608 s/iter. ETA=0:00:36
[09/02 14:56:36 d2.evaluation.evaluator]: Inference done 91/144. Dataloading: 0.0025 s/iter. Inference: 0.1087 s/iter. Eval: 0.4307 s/iter. Total: 0.5421 s/iter. ETA=0:00:28
[09/02 14:56:41 d2.evaluation.evaluator]: Inference done 103/144. Dataloading: 0.0025 s/iter. Inference: 0.1076 s/iter. Eval: 0.4171 s/iter. Total: 0.5274 s/iter. ETA=0:00:21
[09/02 14:56:46 d2.evaluation.evaluator]: Inference done 112/144. Dataloading: 0.0025 s/iter. Inference: 0.1081 s/iter. Eval: 0.4223 s/iter. Total: 0.5331 s/iter. ETA=0:00:17
[09/02 14:56:52 d2.evaluation.evaluator]: Inference done 123/144. Dataloading: 0.0025 s/iter. Inference: 0.1078 s/iter. Eval: 0.4190 s/iter. Total: 0.5296 s/iter. ETA=0:00:11
[09/02 14:56:57 d2.evaluation.evaluator]: Inference done 134/144. Dataloading: 0.0026 s/iter. Inference: 0.1075 s/iter. Eval: 0.4139 s/iter. Total: 0.5241 s/iter. ETA=0:00:05
[09/02 14:57:02 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0025 s/iter. Inference: 0.1073 s/iter. Eval: 0.4143 s/iter. Total: 0.5244 s/iter. ETA=0:00:00
[09/02 14:57:02 d2.evaluation.evaluator]: Total inference time: 0:01:12.944452 (0.524780 s / iter per device, on 1 devices)
[09/02 14:57:02 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:14 (0.107321 s / iter per device, on 1 devices)
[09/02 14:57:02 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 14:57:02 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 14:57:02 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/02 14:57:02 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 14:57:03 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[09/02 14:57:03 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:57:03 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.310
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.523
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.320
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.055
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.318
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.399
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.263
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.485
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.570
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.267
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.541
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.676
[09/02 14:57:03 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 30.982 | 52.314 | 31.964 | 5.478 | 31.783 | 39.857 |
Loading and preparing results...
DONE (t=0.15s)
creating index...
index created!
[09/02 14:57:03 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 14:57:03 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.12 seconds.
[09/02 14:57:03 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:57:03 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.374
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.538
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.423
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.036
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.320
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.527
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.305
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.572
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.667
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.642
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.768
[09/02 14:57:03 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 37.374 | 53.785 | 42.260 | 3.636 | 32.039 | 52.701 |
[09/02 14:57:03 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 14:57:03 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 14:57:03 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:57:03 d2.evaluation.testing]: copypaste: 30.9816,52.3138,31.9636,5.4779,31.7828,39.8566
[09/02 14:57:03 d2.evaluation.testing]: copypaste: Task: segm
[09/02 14:57:03 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:57:03 d2.evaluation.testing]: copypaste: 37.3736,53.7846,42.2596,3.6356,32.0393,52.7005
[09/02 14:57:03 d2.utils.events]:  eta: 0:07:17  iter: 359  total_loss: 0.8242  loss_cls: 0.1404  loss_box_reg: 0.3373  loss_mask: 0.2159  loss_rpn_cls: 0.01683  loss_rpn_loc: 0.009962  time: 0.7009  data_time: 0.0723  lr: 8.991e-05  max_mem: 4442M
[09/02 14:57:17 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 14:57:17 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 14:57:17 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 14:57:17 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 14:57:17 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 14:57:24 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0017 s/iter. Inference: 0.1036 s/iter. Eval: 0.3564 s/iter. Total: 0.4618 s/iter. ETA=0:01:01
[09/02 14:57:29 d2.evaluation.evaluator]: Inference done 27/144. Dataloading: 0.0025 s/iter. Inference: 0.0962 s/iter. Eval: 0.2615 s/iter. Total: 0.3603 s/iter. ETA=0:00:42
[09/02 14:57:34 d2.evaluation.evaluator]: Inference done 40/144. Dataloading: 0.0027 s/iter. Inference: 0.0968 s/iter. Eval: 0.2780 s/iter. Total: 0.3777 s/iter. ETA=0:00:39
[09/02 14:57:40 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0027 s/iter. Inference: 0.1004 s/iter. Eval: 0.3217 s/iter. Total: 0.4249 s/iter. ETA=0:00:40
[09/02 14:57:45 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0026 s/iter. Inference: 0.1024 s/iter. Eval: 0.3477 s/iter. Total: 0.4529 s/iter. ETA=0:00:38
[09/02 14:57:51 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0026 s/iter. Inference: 0.1036 s/iter. Eval: 0.3623 s/iter. Total: 0.4687 s/iter. ETA=0:00:35
[09/02 14:57:56 d2.evaluation.evaluator]: Inference done 82/144. Dataloading: 0.0026 s/iter. Inference: 0.1021 s/iter. Eval: 0.3462 s/iter. Total: 0.4510 s/iter. ETA=0:00:27
[09/02 14:58:01 d2.evaluation.evaluator]: Inference done 100/144. Dataloading: 0.0025 s/iter. Inference: 0.1002 s/iter. Eval: 0.3228 s/iter. Total: 0.4256 s/iter. ETA=0:00:18
[09/02 14:58:07 d2.evaluation.evaluator]: Inference done 110/144. Dataloading: 0.0026 s/iter. Inference: 0.1009 s/iter. Eval: 0.3317 s/iter. Total: 0.4354 s/iter. ETA=0:00:14
[09/02 14:58:12 d2.evaluation.evaluator]: Inference done 123/144. Dataloading: 0.0026 s/iter. Inference: 0.1006 s/iter. Eval: 0.3273 s/iter. Total: 0.4306 s/iter. ETA=0:00:09
[09/02 14:58:17 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0026 s/iter. Inference: 0.1002 s/iter. Eval: 0.3231 s/iter. Total: 0.4261 s/iter. ETA=0:00:02
[09/02 14:58:20 d2.evaluation.evaluator]: Total inference time: 0:00:59.083462 (0.425061 s / iter per device, on 1 devices)
[09/02 14:58:20 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:13 (0.100066 s / iter per device, on 1 devices)
[09/02 14:58:20 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 14:58:20 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 14:58:20 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/02 14:58:20 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 14:58:20 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[09/02 14:58:20 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:58:20 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.332
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.545
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.373
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.057
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.340
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.428
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.270
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.497
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.577
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.267
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.557
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.670
[09/02 14:58:20 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 33.236 | 54.517 | 37.287 | 5.747 | 34.048 | 42.824 |
Loading and preparing results...
DONE (t=0.12s)
creating index...
index created!
[09/02 14:58:21 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 14:58:21 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.
[09/02 14:58:21 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:58:21 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.387
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.559
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.436
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.041
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.543
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.304
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.572
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.662
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.375
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.637
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.759
[09/02 14:58:21 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 38.654 | 55.892 | 43.572 | 4.101 | 33.331 | 54.266 |
[09/02 14:58:21 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 14:58:21 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 14:58:21 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:58:21 d2.evaluation.testing]: copypaste: 33.2361,54.5172,37.2869,5.7473,34.0484,42.8242
[09/02 14:58:21 d2.evaluation.testing]: copypaste: Task: segm
[09/02 14:58:21 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:58:21 d2.evaluation.testing]: copypaste: 38.6536,55.8917,43.5723,4.1007,33.3314,54.2657
[09/02 14:58:21 d2.utils.events]:  eta: 0:07:03  iter: 379  total_loss: 0.7264  loss_cls: 0.1386  loss_box_reg: 0.3462  loss_mask: 0.2211  loss_rpn_cls: 0.0193  loss_rpn_loc: 0.007696  time: 0.7000  data_time: 0.0639  lr: 9.4905e-05  max_mem: 4442M
[09/02 14:58:35 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 14:58:35 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 14:58:35 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 14:58:35 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 14:58:35 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 14:58:42 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0015 s/iter. Inference: 0.1001 s/iter. Eval: 0.3270 s/iter. Total: 0.4287 s/iter. ETA=0:00:57
[09/02 14:58:47 d2.evaluation.evaluator]: Inference done 27/144. Dataloading: 0.0030 s/iter. Inference: 0.0955 s/iter. Eval: 0.2546 s/iter. Total: 0.3532 s/iter. ETA=0:00:41
[09/02 14:58:52 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0027 s/iter. Inference: 0.0948 s/iter. Eval: 0.2573 s/iter. Total: 0.3550 s/iter. ETA=0:00:36
[09/02 14:58:57 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0026 s/iter. Inference: 0.0988 s/iter. Eval: 0.3050 s/iter. Total: 0.4067 s/iter. ETA=0:00:38
[09/02 14:59:02 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0025 s/iter. Inference: 0.1013 s/iter. Eval: 0.3323 s/iter. Total: 0.4362 s/iter. ETA=0:00:37
[09/02 14:59:08 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0024 s/iter. Inference: 0.1026 s/iter. Eval: 0.3486 s/iter. Total: 0.4538 s/iter. ETA=0:00:34
[09/02 14:59:13 d2.evaluation.evaluator]: Inference done 80/144. Dataloading: 0.0024 s/iter. Inference: 0.1019 s/iter. Eval: 0.3434 s/iter. Total: 0.4479 s/iter. ETA=0:00:28
[09/02 14:59:18 d2.evaluation.evaluator]: Inference done 98/144. Dataloading: 0.0024 s/iter. Inference: 0.0996 s/iter. Eval: 0.3146 s/iter. Total: 0.4167 s/iter. ETA=0:00:19
[09/02 14:59:23 d2.evaluation.evaluator]: Inference done 109/144. Dataloading: 0.0023 s/iter. Inference: 0.0999 s/iter. Eval: 0.3184 s/iter. Total: 0.4208 s/iter. ETA=0:00:14
[09/02 14:59:28 d2.evaluation.evaluator]: Inference done 122/144. Dataloading: 0.0023 s/iter. Inference: 0.0997 s/iter. Eval: 0.3158 s/iter. Total: 0.4180 s/iter. ETA=0:00:09
[09/02 14:59:33 d2.evaluation.evaluator]: Inference done 136/144. Dataloading: 0.0024 s/iter. Inference: 0.0992 s/iter. Eval: 0.3098 s/iter. Total: 0.4115 s/iter. ETA=0:00:03
[09/02 14:59:37 d2.evaluation.evaluator]: Total inference time: 0:00:57.272503 (0.412032 s / iter per device, on 1 devices)
[09/02 14:59:37 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:13 (0.099156 s / iter per device, on 1 devices)
[09/02 14:59:37 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 14:59:37 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 14:59:37 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/02 14:59:37 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 14:59:37 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[09/02 14:59:37 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:59:37 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.355
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.570
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.378
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.085
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.362
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.458
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.279
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.508
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.584
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.267
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.558
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.688
[09/02 14:59:37 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 35.531 | 56.995 | 37.826 | 8.493 | 36.159 | 45.783 |
Loading and preparing results...
DONE (t=0.11s)
creating index...
index created!
[09/02 14:59:37 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 14:59:37 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.
[09/02 14:59:37 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 14:59:37 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.401
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.578
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.461
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.062
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.353
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.555
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.309
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.567
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.655
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.367
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.629
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.755
[09/02 14:59:37 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 40.053 | 57.806 | 46.146 | 6.246 | 35.264 | 55.485 |
[09/02 14:59:37 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 14:59:37 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 14:59:37 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:59:37 d2.evaluation.testing]: copypaste: 35.5313,56.9949,37.8262,8.4929,36.1591,45.7830
[09/02 14:59:37 d2.evaluation.testing]: copypaste: Task: segm
[09/02 14:59:37 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 14:59:37 d2.evaluation.testing]: copypaste: 40.0534,57.8058,46.1463,6.2456,35.2638,55.4853
[09/02 14:59:37 d2.utils.events]:  eta: 0:06:49  iter: 399  total_loss: 0.7903  loss_cls: 0.1554  loss_box_reg: 0.3203  loss_mask: 0.2004  loss_rpn_cls: 0.02239  loss_rpn_loc: 0.0119  time: 0.6992  data_time: 0.0626  lr: 9.99e-05  max_mem: 4442M
[09/02 14:59:52 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 14:59:52 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 14:59:52 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 14:59:52 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 14:59:52 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 14:59:59 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0019 s/iter. Inference: 0.1025 s/iter. Eval: 0.3601 s/iter. Total: 0.4645 s/iter. ETA=0:01:01
[09/02 15:00:04 d2.evaluation.evaluator]: Inference done 25/144. Dataloading: 0.0024 s/iter. Inference: 0.0978 s/iter. Eval: 0.2939 s/iter. Total: 0.3942 s/iter. ETA=0:00:46
[09/02 15:00:09 d2.evaluation.evaluator]: Inference done 40/144. Dataloading: 0.0025 s/iter. Inference: 0.0965 s/iter. Eval: 0.2771 s/iter. Total: 0.3765 s/iter. ETA=0:00:39
[09/02 15:00:15 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0026 s/iter. Inference: 0.1011 s/iter. Eval: 0.3294 s/iter. Total: 0.4334 s/iter. ETA=0:00:41
[09/02 15:00:20 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0026 s/iter. Inference: 0.1036 s/iter. Eval: 0.3594 s/iter. Total: 0.4659 s/iter. ETA=0:00:40
[09/02 15:00:26 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0026 s/iter. Inference: 0.1043 s/iter. Eval: 0.3723 s/iter. Total: 0.4795 s/iter. ETA=0:00:36
[09/02 15:00:31 d2.evaluation.evaluator]: Inference done 79/144. Dataloading: 0.0025 s/iter. Inference: 0.1041 s/iter. Eval: 0.3672 s/iter. Total: 0.4741 s/iter. ETA=0:00:30
[09/02 15:00:36 d2.evaluation.evaluator]: Inference done 95/144. Dataloading: 0.0025 s/iter. Inference: 0.1020 s/iter. Eval: 0.3432 s/iter. Total: 0.4479 s/iter. ETA=0:00:21
[09/02 15:00:41 d2.evaluation.evaluator]: Inference done 107/144. Dataloading: 0.0026 s/iter. Inference: 0.1018 s/iter. Eval: 0.3400 s/iter. Total: 0.4447 s/iter. ETA=0:00:16
[09/02 15:00:47 d2.evaluation.evaluator]: Inference done 120/144. Dataloading: 0.0026 s/iter. Inference: 0.1014 s/iter. Eval: 0.3356 s/iter. Total: 0.4399 s/iter. ETA=0:00:10
[09/02 15:00:52 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0026 s/iter. Inference: 0.1016 s/iter. Eval: 0.3377 s/iter. Total: 0.4422 s/iter. ETA=0:00:05
[09/02 15:00:57 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0026 s/iter. Inference: 0.1013 s/iter. Eval: 0.3339 s/iter. Total: 0.4380 s/iter. ETA=0:00:00
[09/02 15:00:57 d2.evaluation.evaluator]: Total inference time: 0:01:00.936174 (0.438390 s / iter per device, on 1 devices)
[09/02 15:00:57 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:14 (0.101254 s / iter per device, on 1 devices)
[09/02 15:00:57 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 15:00:57 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 15:00:57 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/02 15:00:57 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 15:00:57 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[09/02 15:00:57 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:00:57 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.368
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.591
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.408
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.076
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.384
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.452
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.278
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.509
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.587
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.233
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.579
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.664
[09/02 15:00:57 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 36.783 | 59.116 | 40.763 | 7.617 | 38.448 | 45.163 |
Loading and preparing results...
DONE (t=0.12s)
creating index...
index created!
[09/02 15:00:58 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 15:00:58 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.
[09/02 15:00:58 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:00:58 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.411
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.594
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.476
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.059
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.364
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.562
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.309
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.576
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.660
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.325
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.642
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.753
[09/02 15:00:58 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 41.107 | 59.373 | 47.557 | 5.869 | 36.428 | 56.224 |
[09/02 15:00:58 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 15:00:58 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 15:00:58 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:00:58 d2.evaluation.testing]: copypaste: 36.7832,59.1160,40.7629,7.6170,38.4483,45.1631
[09/02 15:00:58 d2.evaluation.testing]: copypaste: Task: segm
[09/02 15:00:58 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:00:58 d2.evaluation.testing]: copypaste: 41.1066,59.3727,47.5572,5.8689,36.4278,56.2241
[09/02 15:00:58 d2.utils.events]:  eta: 0:06:35  iter: 419  total_loss: 0.6788  loss_cls: 0.1223  loss_box_reg: 0.3341  loss_mask: 0.2179  loss_rpn_cls: 0.01347  loss_rpn_loc: 0.007873  time: 0.6999  data_time: 0.0931  lr: 0.0001049  max_mem: 4442M
[09/02 15:01:12 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 15:01:12 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 15:01:12 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 15:01:12 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 15:01:12 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 15:01:18 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0026 s/iter. Inference: 0.0972 s/iter. Eval: 0.2976 s/iter. Total: 0.3974 s/iter. ETA=0:00:52
[09/02 15:01:23 d2.evaluation.evaluator]: Inference done 26/144. Dataloading: 0.0030 s/iter. Inference: 0.0955 s/iter. Eval: 0.2625 s/iter. Total: 0.3613 s/iter. ETA=0:00:42
[09/02 15:01:28 d2.evaluation.evaluator]: Inference done 42/144. Dataloading: 0.0027 s/iter. Inference: 0.0939 s/iter. Eval: 0.2478 s/iter. Total: 0.3446 s/iter. ETA=0:00:35
[09/02 15:01:34 d2.evaluation.evaluator]: Inference done 51/144. Dataloading: 0.0027 s/iter. Inference: 0.0986 s/iter. Eval: 0.2996 s/iter. Total: 0.4011 s/iter. ETA=0:00:37
[09/02 15:01:39 d2.evaluation.evaluator]: Inference done 61/144. Dataloading: 0.0028 s/iter. Inference: 0.1004 s/iter. Eval: 0.3213 s/iter. Total: 0.4246 s/iter. ETA=0:00:35
[09/02 15:01:45 d2.evaluation.evaluator]: Inference done 72/144. Dataloading: 0.0029 s/iter. Inference: 0.1008 s/iter. Eval: 0.3275 s/iter. Total: 0.4313 s/iter. ETA=0:00:31
[09/02 15:01:50 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0027 s/iter. Inference: 0.0990 s/iter. Eval: 0.3049 s/iter. Total: 0.4067 s/iter. ETA=0:00:22
[09/02 15:01:55 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0028 s/iter. Inference: 0.0988 s/iter. Eval: 0.3001 s/iter. Total: 0.4018 s/iter. ETA=0:00:16
[09/02 15:02:01 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0028 s/iter. Inference: 0.0982 s/iter. Eval: 0.2931 s/iter. Total: 0.3943 s/iter. ETA=0:00:09
[09/02 15:02:06 d2.evaluation.evaluator]: Inference done 132/144. Dataloading: 0.0029 s/iter. Inference: 0.0979 s/iter. Eval: 0.2936 s/iter. Total: 0.3946 s/iter. ETA=0:00:04
[09/02 15:02:10 d2.evaluation.evaluator]: Total inference time: 0:00:54.614329 (0.392909 s / iter per device, on 1 devices)
[09/02 15:02:10 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:13 (0.097641 s / iter per device, on 1 devices)
[09/02 15:02:10 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 15:02:10 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 15:02:10 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/02 15:02:10 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 15:02:11 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[09/02 15:02:11 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:02:11 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.382
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.595
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.455
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.077
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.386
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.475
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.289
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.532
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.599
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.250
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.593
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.674
[09/02 15:02:11 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 38.177 | 59.451 | 45.527 | 7.672 | 38.575 | 47.453 |
Loading and preparing results...
DONE (t=0.10s)
creating index...
index created!
[09/02 15:02:11 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 15:02:11 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.
[09/02 15:02:11 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:02:11 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.412
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.605
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.469
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.068
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.358
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.565
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.309
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.577
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.657
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.375
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.632
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.752
[09/02 15:02:11 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 41.195 | 60.489 | 46.899 | 6.825 | 35.786 | 56.548 |
[09/02 15:02:11 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 15:02:11 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 15:02:11 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:02:11 d2.evaluation.testing]: copypaste: 38.1774,59.4506,45.5267,7.6721,38.5746,47.4534
[09/02 15:02:11 d2.evaluation.testing]: copypaste: Task: segm
[09/02 15:02:11 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:02:11 d2.evaluation.testing]: copypaste: 41.1951,60.4891,46.8995,6.8249,35.7864,56.5478
[09/02 15:02:11 d2.utils.events]:  eta: 0:06:21  iter: 439  total_loss: 0.7254  loss_cls: 0.1393  loss_box_reg: 0.3228  loss_mask: 0.2057  loss_rpn_cls: 0.01113  loss_rpn_loc: 0.0117  time: 0.6998  data_time: 0.0741  lr: 0.00010989  max_mem: 4442M
[09/02 15:02:25 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 15:02:25 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 15:02:25 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 15:02:25 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 15:02:25 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 15:02:31 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0019 s/iter. Inference: 0.0927 s/iter. Eval: 0.2254 s/iter. Total: 0.3200 s/iter. ETA=0:00:42
[09/02 15:02:36 d2.evaluation.evaluator]: Inference done 34/144. Dataloading: 0.0032 s/iter. Inference: 0.0863 s/iter. Eval: 0.1526 s/iter. Total: 0.2422 s/iter. ETA=0:00:26
[09/02 15:02:41 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0032 s/iter. Inference: 0.0895 s/iter. Eval: 0.1851 s/iter. Total: 0.2779 s/iter. ETA=0:00:26
[09/02 15:02:46 d2.evaluation.evaluator]: Inference done 63/144. Dataloading: 0.0029 s/iter. Inference: 0.0909 s/iter. Eval: 0.2032 s/iter. Total: 0.2972 s/iter. ETA=0:00:24
[09/02 15:02:51 d2.evaluation.evaluator]: Inference done 79/144. Dataloading: 0.0029 s/iter. Inference: 0.0920 s/iter. Eval: 0.2098 s/iter. Total: 0.3049 s/iter. ETA=0:00:19
[09/02 15:02:57 d2.evaluation.evaluator]: Inference done 103/144. Dataloading: 0.0031 s/iter. Inference: 0.0903 s/iter. Eval: 0.1901 s/iter. Total: 0.2837 s/iter. ETA=0:00:11
[09/02 15:03:02 d2.evaluation.evaluator]: Inference done 117/144. Dataloading: 0.0030 s/iter. Inference: 0.0907 s/iter. Eval: 0.1995 s/iter. Total: 0.2933 s/iter. ETA=0:00:07
[09/02 15:03:07 d2.evaluation.evaluator]: Inference done 138/144. Dataloading: 0.0029 s/iter. Inference: 0.0900 s/iter. Eval: 0.1925 s/iter. Total: 0.2855 s/iter. ETA=0:00:01
[09/02 15:03:09 d2.evaluation.evaluator]: Total inference time: 0:00:39.898598 (0.287040 s / iter per device, on 1 devices)
[09/02 15:03:09 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:12 (0.089986 s / iter per device, on 1 devices)
[09/02 15:03:09 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 15:03:09 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 15:03:09 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/02 15:03:09 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 15:03:09 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/02 15:03:09 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:03:09 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.393
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.597
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.459
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.076
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.391
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.500
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.294
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.547
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.601
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.250
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.583
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.697
[09/02 15:03:09 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 39.318 | 59.700 | 45.900 | 7.592 | 39.072 | 50.033 |
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
[09/02 15:03:09 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 15:03:09 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[09/02 15:03:09 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:03:09 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.427
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.610
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.503
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.054
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.375
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.584
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.315
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.588
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.644
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.614
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.750
[09/02 15:03:09 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 42.736 | 60.991 | 50.331 | 5.413 | 37.523 | 58.381 |
[09/02 15:03:09 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 15:03:09 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 15:03:09 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:03:09 d2.evaluation.testing]: copypaste: 39.3184,59.6998,45.8999,7.5919,39.0716,50.0334
[09/02 15:03:09 d2.evaluation.testing]: copypaste: Task: segm
[09/02 15:03:09 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:03:09 d2.evaluation.testing]: copypaste: 42.7362,60.9905,50.3308,5.4131,37.5227,58.3813
[09/02 15:03:09 d2.utils.events]:  eta: 0:06:08  iter: 459  total_loss: 0.5738  loss_cls: 0.1027  loss_box_reg: 0.2526  loss_mask: 0.1839  loss_rpn_cls: 0.01193  loss_rpn_loc: 0.005705  time: 0.6991  data_time: 0.0652  lr: 0.00011489  max_mem: 4442M
[09/02 15:03:23 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 15:03:23 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 15:03:23 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 15:03:23 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 15:03:23 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 15:03:29 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0022 s/iter. Inference: 0.0932 s/iter. Eval: 0.2463 s/iter. Total: 0.3416 s/iter. ETA=0:00:45
[09/02 15:03:34 d2.evaluation.evaluator]: Inference done 28/144. Dataloading: 0.0031 s/iter. Inference: 0.0934 s/iter. Eval: 0.2202 s/iter. Total: 0.3168 s/iter. ETA=0:00:36
[09/02 15:03:39 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0028 s/iter. Inference: 0.0918 s/iter. Eval: 0.2082 s/iter. Total: 0.3030 s/iter. ETA=0:00:29
[09/02 15:03:44 d2.evaluation.evaluator]: Inference done 55/144. Dataloading: 0.0029 s/iter. Inference: 0.0950 s/iter. Eval: 0.2509 s/iter. Total: 0.3490 s/iter. ETA=0:00:31
[09/02 15:03:50 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0028 s/iter. Inference: 0.0960 s/iter. Eval: 0.2654 s/iter. Total: 0.3644 s/iter. ETA=0:00:28
[09/02 15:03:55 d2.evaluation.evaluator]: Inference done 83/144. Dataloading: 0.0027 s/iter. Inference: 0.0953 s/iter. Eval: 0.2558 s/iter. Total: 0.3540 s/iter. ETA=0:00:21
[09/02 15:04:00 d2.evaluation.evaluator]: Inference done 103/144. Dataloading: 0.0029 s/iter. Inference: 0.0940 s/iter. Eval: 0.2366 s/iter. Total: 0.3336 s/iter. ETA=0:00:13
[09/02 15:04:05 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0029 s/iter. Inference: 0.0937 s/iter. Eval: 0.2347 s/iter. Total: 0.3315 s/iter. ETA=0:00:08
[09/02 15:04:10 d2.evaluation.evaluator]: Inference done 134/144. Dataloading: 0.0029 s/iter. Inference: 0.0934 s/iter. Eval: 0.2355 s/iter. Total: 0.3320 s/iter. ETA=0:00:03
[09/02 15:04:13 d2.evaluation.evaluator]: Total inference time: 0:00:46.183255 (0.332254 s / iter per device, on 1 devices)
[09/02 15:04:13 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:12 (0.093277 s / iter per device, on 1 devices)
[09/02 15:04:13 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 15:04:13 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 15:04:13 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/02 15:04:13 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 15:04:13 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/02 15:04:13 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:04:13 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.412
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.617
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.476
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.102
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.396
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.531
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.300
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.551
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.609
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.258
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.592
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.703
[09/02 15:04:13 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 41.200 | 61.676 | 47.570 | 10.177 | 39.633 | 53.127 |
Loading and preparing results...
DONE (t=0.10s)
creating index...
index created!
[09/02 15:04:14 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 15:04:14 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.08 seconds.
[09/02 15:04:14 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:04:14 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.431
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.625
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.501
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.068
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.374
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.591
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.313
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.585
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.648
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.762
[09/02 15:04:14 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 43.114 | 62.474 | 50.067 | 6.800 | 37.425 | 59.147 |
[09/02 15:04:14 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 15:04:14 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 15:04:14 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:04:14 d2.evaluation.testing]: copypaste: 41.1998,61.6762,47.5702,10.1771,39.6325,53.1267
[09/02 15:04:14 d2.evaluation.testing]: copypaste: Task: segm
[09/02 15:04:14 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:04:14 d2.evaluation.testing]: copypaste: 43.1141,62.4742,50.0674,6.8004,37.4249,59.1470
[09/02 15:04:14 d2.utils.events]:  eta: 0:05:54  iter: 479  total_loss: 0.6059  loss_cls: 0.1358  loss_box_reg: 0.2427  loss_mask: 0.2065  loss_rpn_cls: 0.01205  loss_rpn_loc: 0.008273  time: 0.6994  data_time: 0.0753  lr: 0.00011988  max_mem: 4442M
[09/02 15:04:27 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 15:04:27 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 15:04:27 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 15:04:27 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 15:04:27 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 15:04:33 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0015 s/iter. Inference: 0.0900 s/iter. Eval: 0.2128 s/iter. Total: 0.3043 s/iter. ETA=0:00:40
[09/02 15:04:38 d2.evaluation.evaluator]: Inference done 34/144. Dataloading: 0.0028 s/iter. Inference: 0.0863 s/iter. Eval: 0.1559 s/iter. Total: 0.2451 s/iter. ETA=0:00:26
[09/02 15:04:43 d2.evaluation.evaluator]: Inference done 48/144. Dataloading: 0.0038 s/iter. Inference: 0.0912 s/iter. Eval: 0.1879 s/iter. Total: 0.2831 s/iter. ETA=0:00:27
[09/02 15:04:48 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0038 s/iter. Inference: 0.0935 s/iter. Eval: 0.2208 s/iter. Total: 0.3184 s/iter. ETA=0:00:27
[09/02 15:04:53 d2.evaluation.evaluator]: Inference done 74/144. Dataloading: 0.0036 s/iter. Inference: 0.0938 s/iter. Eval: 0.2256 s/iter. Total: 0.3232 s/iter. ETA=0:00:22
[09/02 15:04:58 d2.evaluation.evaluator]: Inference done 96/144. Dataloading: 0.0034 s/iter. Inference: 0.0921 s/iter. Eval: 0.2056 s/iter. Total: 0.3012 s/iter. ETA=0:00:14
[09/02 15:05:03 d2.evaluation.evaluator]: Inference done 112/144. Dataloading: 0.0034 s/iter. Inference: 0.0920 s/iter. Eval: 0.2075 s/iter. Total: 0.3031 s/iter. ETA=0:00:09
[09/02 15:05:08 d2.evaluation.evaluator]: Inference done 133/144. Dataloading: 0.0033 s/iter. Inference: 0.0911 s/iter. Eval: 0.1987 s/iter. Total: 0.2933 s/iter. ETA=0:00:03
[09/02 15:05:12 d2.evaluation.evaluator]: Total inference time: 0:00:41.307927 (0.297179 s / iter per device, on 1 devices)
[09/02 15:05:12 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:12 (0.091141 s / iter per device, on 1 devices)
[09/02 15:05:12 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 15:05:12 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 15:05:12 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/02 15:05:12 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 15:05:12 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.23 seconds.
[09/02 15:05:12 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:05:12 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.422
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.630
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.500
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.097
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.407
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.543
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.311
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.560
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.612
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.267
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.590
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.714
[09/02 15:05:12 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 42.241 | 62.972 | 49.953 | 9.657 | 40.740 | 54.292 |
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
[09/02 15:05:13 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 15:05:13 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[09/02 15:05:13 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:05:13 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.445
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.639
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.521
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.076
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.381
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.322
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.592
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.648
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.615
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.758
[09/02 15:05:13 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 44.485 | 63.939 | 52.149 | 7.648 | 38.114 | 61.271 |
[09/02 15:05:13 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 15:05:13 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 15:05:13 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:05:13 d2.evaluation.testing]: copypaste: 42.2408,62.9722,49.9529,9.6569,40.7403,54.2923
[09/02 15:05:13 d2.evaluation.testing]: copypaste: Task: segm
[09/02 15:05:13 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:05:13 d2.evaluation.testing]: copypaste: 44.4854,63.9390,52.1485,7.6482,38.1139,61.2705
[09/02 15:05:13 d2.utils.events]:  eta: 0:05:40  iter: 499  total_loss: 0.5368  loss_cls: 0.1195  loss_box_reg: 0.2149  loss_mask: 0.173  loss_rpn_cls: 0.01132  loss_rpn_loc: 0.006362  time: 0.6986  data_time: 0.0598  lr: 0.00012488  max_mem: 4442M
[09/02 15:05:27 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 15:05:27 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 15:05:27 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 15:05:27 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 15:05:27 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 15:05:32 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0015 s/iter. Inference: 0.0899 s/iter. Eval: 0.2071 s/iter. Total: 0.2985 s/iter. ETA=0:00:39
[09/02 15:05:37 d2.evaluation.evaluator]: Inference done 32/144. Dataloading: 0.0036 s/iter. Inference: 0.0893 s/iter. Eval: 0.1624 s/iter. Total: 0.2555 s/iter. ETA=0:00:28
[09/02 15:05:42 d2.evaluation.evaluator]: Inference done 48/144. Dataloading: 0.0035 s/iter. Inference: 0.0903 s/iter. Eval: 0.1908 s/iter. Total: 0.2847 s/iter. ETA=0:00:27
[09/02 15:05:48 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0035 s/iter. Inference: 0.0938 s/iter. Eval: 0.2291 s/iter. Total: 0.3267 s/iter. ETA=0:00:27
[09/02 15:05:53 d2.evaluation.evaluator]: Inference done 75/144. Dataloading: 0.0033 s/iter. Inference: 0.0938 s/iter. Eval: 0.2315 s/iter. Total: 0.3287 s/iter. ETA=0:00:22
[09/02 15:05:58 d2.evaluation.evaluator]: Inference done 96/144. Dataloading: 0.0032 s/iter. Inference: 0.0923 s/iter. Eval: 0.2135 s/iter. Total: 0.3093 s/iter. ETA=0:00:14
[09/02 15:06:04 d2.evaluation.evaluator]: Inference done 114/144. Dataloading: 0.0031 s/iter. Inference: 0.0920 s/iter. Eval: 0.2109 s/iter. Total: 0.3062 s/iter. ETA=0:00:09
[09/02 15:06:09 d2.evaluation.evaluator]: Inference done 134/144. Dataloading: 0.0032 s/iter. Inference: 0.0914 s/iter. Eval: 0.2039 s/iter. Total: 0.2987 s/iter. ETA=0:00:02
[09/02 15:06:12 d2.evaluation.evaluator]: Total inference time: 0:00:41.744018 (0.300317 s / iter per device, on 1 devices)
[09/02 15:06:12 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:12 (0.091370 s / iter per device, on 1 devices)
[09/02 15:06:12 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 15:06:12 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 15:06:12 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/02 15:06:12 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 15:06:12 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/02 15:06:12 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:06:12 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.415
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.637
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.482
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.112
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.389
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.535
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.311
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.563
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.611
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.292
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.590
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.708
[09/02 15:06:12 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 41.491 | 63.741 | 48.187 | 11.220 | 38.887 | 53.538 |
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
[09/02 15:06:12 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 15:06:12 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[09/02 15:06:12 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:06:12 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.444
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.640
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.517
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.076
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.380
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.606
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.321
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.593
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.649
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.617
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.759
[09/02 15:06:12 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 44.351 | 64.003 | 51.676 | 7.589 | 38.032 | 60.552 |
[09/02 15:06:12 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 15:06:12 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 15:06:12 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:06:12 d2.evaluation.testing]: copypaste: 41.4911,63.7409,48.1866,11.2199,38.8874,53.5382
[09/02 15:06:12 d2.evaluation.testing]: copypaste: Task: segm
[09/02 15:06:12 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:06:12 d2.evaluation.testing]: copypaste: 44.3513,64.0031,51.6756,7.5891,38.0324,60.5524
[09/02 15:06:12 d2.utils.events]:  eta: 0:05:27  iter: 519  total_loss: 0.6011  loss_cls: 0.1308  loss_box_reg: 0.2831  loss_mask: 0.1893  loss_rpn_cls: 0.01223  loss_rpn_loc: 0.006947  time: 0.6986  data_time: 0.0801  lr: 0.00012987  max_mem: 4442M
[09/02 15:06:26 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 15:06:26 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 15:06:26 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 15:06:26 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 15:06:26 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 15:06:32 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.0891 s/iter. Eval: 0.1934 s/iter. Total: 0.2841 s/iter. ETA=0:00:37
[09/02 15:06:37 d2.evaluation.evaluator]: Inference done 34/144. Dataloading: 0.0027 s/iter. Inference: 0.0880 s/iter. Eval: 0.1467 s/iter. Total: 0.2375 s/iter. ETA=0:00:26
[09/02 15:06:42 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0027 s/iter. Inference: 0.0912 s/iter. Eval: 0.1856 s/iter. Total: 0.2797 s/iter. ETA=0:00:26
[09/02 15:06:47 d2.evaluation.evaluator]: Inference done 61/144. Dataloading: 0.0028 s/iter. Inference: 0.0932 s/iter. Eval: 0.2135 s/iter. Total: 0.3096 s/iter. ETA=0:00:25
[09/02 15:06:52 d2.evaluation.evaluator]: Inference done 76/144. Dataloading: 0.0027 s/iter. Inference: 0.0933 s/iter. Eval: 0.2187 s/iter. Total: 0.3149 s/iter. ETA=0:00:21
[09/02 15:06:58 d2.evaluation.evaluator]: Inference done 100/144. Dataloading: 0.0026 s/iter. Inference: 0.0914 s/iter. Eval: 0.1993 s/iter. Total: 0.2934 s/iter. ETA=0:00:12
[09/02 15:07:03 d2.evaluation.evaluator]: Inference done 116/144. Dataloading: 0.0026 s/iter. Inference: 0.0917 s/iter. Eval: 0.2019 s/iter. Total: 0.2963 s/iter. ETA=0:00:08
[09/02 15:07:08 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0027 s/iter. Inference: 0.0914 s/iter. Eval: 0.1931 s/iter. Total: 0.2873 s/iter. ETA=0:00:02
[09/02 15:07:10 d2.evaluation.evaluator]: Total inference time: 0:00:40.267870 (0.289697 s / iter per device, on 1 devices)
[09/02 15:07:10 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:12 (0.091380 s / iter per device, on 1 devices)
[09/02 15:07:10 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 15:07:10 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 15:07:10 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/02 15:07:10 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 15:07:10 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/02 15:07:10 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:07:10 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.418
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.638
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.489
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.114
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.386
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.553
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.298
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.559
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.604
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.267
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.577
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.711
[09/02 15:07:10 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 41.817 | 63.798 | 48.929 | 11.429 | 38.580 | 55.291 |
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
[09/02 15:07:11 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 15:07:11 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.08 seconds.
[09/02 15:07:11 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:07:11 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.453
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.646
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.529
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.072
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.390
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.319
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.596
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.649
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.621
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.752
[09/02 15:07:11 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 45.289 | 64.645 | 52.898 | 7.180 | 39.032 | 61.899 |
[09/02 15:07:11 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 15:07:11 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 15:07:11 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:07:11 d2.evaluation.testing]: copypaste: 41.8170,63.7982,48.9291,11.4286,38.5803,55.2911
[09/02 15:07:11 d2.evaluation.testing]: copypaste: Task: segm
[09/02 15:07:11 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:07:11 d2.evaluation.testing]: copypaste: 45.2895,64.6452,52.8981,7.1802,39.0318,61.8987
[09/02 15:07:11 d2.utils.events]:  eta: 0:05:13  iter: 539  total_loss: 0.6152  loss_cls: 0.1262  loss_box_reg: 0.2753  loss_mask: 0.1989  loss_rpn_cls: 0.009859  loss_rpn_loc: 0.01308  time: 0.6983  data_time: 0.0515  lr: 0.00013487  max_mem: 4442M
[09/02 15:07:25 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 15:07:25 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 15:07:25 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 15:07:25 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 15:07:25 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 15:07:29 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0015 s/iter. Inference: 0.0870 s/iter. Eval: 0.1730 s/iter. Total: 0.2616 s/iter. ETA=0:00:34
[09/02 15:07:34 d2.evaluation.evaluator]: Inference done 34/144. Dataloading: 0.0027 s/iter. Inference: 0.0859 s/iter. Eval: 0.1380 s/iter. Total: 0.2267 s/iter. ETA=0:00:24
[09/02 15:07:40 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0033 s/iter. Inference: 0.0905 s/iter. Eval: 0.1818 s/iter. Total: 0.2758 s/iter. ETA=0:00:26
[09/02 15:07:45 d2.evaluation.evaluator]: Inference done 62/144. Dataloading: 0.0033 s/iter. Inference: 0.0923 s/iter. Eval: 0.2072 s/iter. Total: 0.3029 s/iter. ETA=0:00:24
[09/02 15:07:50 d2.evaluation.evaluator]: Inference done 78/144. Dataloading: 0.0031 s/iter. Inference: 0.0925 s/iter. Eval: 0.2106 s/iter. Total: 0.3064 s/iter. ETA=0:00:20
[09/02 15:07:55 d2.evaluation.evaluator]: Inference done 102/144. Dataloading: 0.0030 s/iter. Inference: 0.0905 s/iter. Eval: 0.1898 s/iter. Total: 0.2835 s/iter. ETA=0:00:11
[09/02 15:08:01 d2.evaluation.evaluator]: Inference done 122/144. Dataloading: 0.0032 s/iter. Inference: 0.0902 s/iter. Eval: 0.1864 s/iter. Total: 0.2799 s/iter. ETA=0:00:06
[09/02 15:08:06 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0032 s/iter. Inference: 0.0896 s/iter. Eval: 0.1817 s/iter. Total: 0.2746 s/iter. ETA=0:00:00
[09/02 15:08:06 d2.evaluation.evaluator]: Total inference time: 0:00:38.220685 (0.274969 s / iter per device, on 1 devices)
[09/02 15:08:06 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:12 (0.089592 s / iter per device, on 1 devices)
[09/02 15:08:06 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 15:08:06 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 15:08:06 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/02 15:08:06 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 15:08:06 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[09/02 15:08:06 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:08:06 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.415
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.642
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.482
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.116
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.386
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.538
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.305
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.547
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.589
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.569
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.677
[09/02 15:08:06 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 41.517 | 64.172 | 48.157 | 11.617 | 38.584 | 53.807 |
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
[09/02 15:08:06 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 15:08:07 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.26 seconds.
[09/02 15:08:07 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:08:07 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.447
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.649
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.529
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.079
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.375
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.622
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.587
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.640
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.367
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.605
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.750
[09/02 15:08:07 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 44.655 | 64.943 | 52.945 | 7.854 | 37.548 | 62.151 |
[09/02 15:08:07 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 15:08:07 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 15:08:07 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:08:07 d2.evaluation.testing]: copypaste: 41.5175,64.1725,48.1568,11.6174,38.5841,53.8071
[09/02 15:08:07 d2.evaluation.testing]: copypaste: Task: segm
[09/02 15:08:07 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:08:07 d2.evaluation.testing]: copypaste: 44.6552,64.9430,52.9448,7.8535,37.5475,62.1506
[09/02 15:08:07 d2.utils.events]:  eta: 0:04:59  iter: 559  total_loss: 0.5623  loss_cls: 0.126  loss_box_reg: 0.1951  loss_mask: 0.1866  loss_rpn_cls: 0.01439  loss_rpn_loc: 0.008616  time: 0.6984  data_time: 0.0716  lr: 0.00013986  max_mem: 4442M
[09/02 15:08:21 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 15:08:21 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 15:08:21 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 15:08:21 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 15:08:21 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 15:08:26 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.0882 s/iter. Eval: 0.1849 s/iter. Total: 0.2748 s/iter. ETA=0:00:36
[09/02 15:08:31 d2.evaluation.evaluator]: Inference done 30/144. Dataloading: 0.0030 s/iter. Inference: 0.0902 s/iter. Eval: 0.1730 s/iter. Total: 0.2664 s/iter. ETA=0:00:30
[09/02 15:08:37 d2.evaluation.evaluator]: Inference done 48/144. Dataloading: 0.0030 s/iter. Inference: 0.0910 s/iter. Eval: 0.1910 s/iter. Total: 0.2851 s/iter. ETA=0:00:27
[09/02 15:08:42 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0030 s/iter. Inference: 0.0937 s/iter. Eval: 0.2292 s/iter. Total: 0.3260 s/iter. ETA=0:00:28
[09/02 15:08:47 d2.evaluation.evaluator]: Inference done 69/144. Dataloading: 0.0030 s/iter. Inference: 0.0953 s/iter. Eval: 0.2516 s/iter. Total: 0.3500 s/iter. ETA=0:00:26
[09/02 15:08:52 d2.evaluation.evaluator]: Inference done 88/144. Dataloading: 0.0029 s/iter. Inference: 0.0939 s/iter. Eval: 0.2361 s/iter. Total: 0.3330 s/iter. ETA=0:00:18
[09/02 15:08:57 d2.evaluation.evaluator]: Inference done 108/144. Dataloading: 0.0030 s/iter. Inference: 0.0928 s/iter. Eval: 0.2238 s/iter. Total: 0.3198 s/iter. ETA=0:00:11
[09/02 15:09:02 d2.evaluation.evaluator]: Inference done 128/144. Dataloading: 0.0029 s/iter. Inference: 0.0920 s/iter. Eval: 0.2156 s/iter. Total: 0.3107 s/iter. ETA=0:00:04
[09/02 15:09:07 d2.evaluation.evaluator]: Total inference time: 0:00:43.077619 (0.309911 s / iter per device, on 1 devices)
[09/02 15:09:07 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:12 (0.091836 s / iter per device, on 1 devices)
[09/02 15:09:07 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 15:09:07 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 15:09:07 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/02 15:09:07 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 15:09:07 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/02 15:09:07 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:09:08 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.442
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.647
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.530
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.130
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.412
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.571
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.574
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.622
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.275
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.596
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.730
[09/02 15:09:08 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 44.156 | 64.738 | 52.999 | 13.018 | 41.241 | 57.098 |
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
[09/02 15:09:08 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 15:09:08 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[09/02 15:09:08 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:09:08 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.464
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.658
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.547
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.085
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.404
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.628
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.325
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.595
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.651
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.759
[09/02 15:09:08 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 46.393 | 65.770 | 54.703 | 8.458 | 40.399 | 62.756 |
[09/02 15:09:08 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 15:09:08 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 15:09:08 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:09:08 d2.evaluation.testing]: copypaste: 44.1561,64.7382,52.9991,13.0182,41.2408,57.0985
[09/02 15:09:08 d2.evaluation.testing]: copypaste: Task: segm
[09/02 15:09:08 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:09:08 d2.evaluation.testing]: copypaste: 46.3934,65.7704,54.7026,8.4583,40.3988,62.7561
[09/02 15:09:08 d2.utils.events]:  eta: 0:04:46  iter: 579  total_loss: 0.6217  loss_cls: 0.1226  loss_box_reg: 0.2445  loss_mask: 0.2022  loss_rpn_cls: 0.01748  loss_rpn_loc: 0.01147  time: 0.6989  data_time: 0.0691  lr: 0.00014486  max_mem: 4442M
[09/02 15:09:22 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 15:09:22 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 15:09:22 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 15:09:22 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 15:09:22 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 15:09:27 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0019 s/iter. Inference: 0.0867 s/iter. Eval: 0.1718 s/iter. Total: 0.2605 s/iter. ETA=0:00:34
[09/02 15:09:32 d2.evaluation.evaluator]: Inference done 37/144. Dataloading: 0.0032 s/iter. Inference: 0.0837 s/iter. Eval: 0.1209 s/iter. Total: 0.2079 s/iter. ETA=0:00:22
[09/02 15:09:37 d2.evaluation.evaluator]: Inference done 51/144. Dataloading: 0.0034 s/iter. Inference: 0.0871 s/iter. Eval: 0.1638 s/iter. Total: 0.2545 s/iter. ETA=0:00:23
[09/02 15:09:43 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0033 s/iter. Inference: 0.0890 s/iter. Eval: 0.1864 s/iter. Total: 0.2788 s/iter. ETA=0:00:21
[09/02 15:09:48 d2.evaluation.evaluator]: Inference done 88/144. Dataloading: 0.0030 s/iter. Inference: 0.0890 s/iter. Eval: 0.1779 s/iter. Total: 0.2700 s/iter. ETA=0:00:15
[09/02 15:09:53 d2.evaluation.evaluator]: Inference done 108/144. Dataloading: 0.0032 s/iter. Inference: 0.0892 s/iter. Eval: 0.1750 s/iter. Total: 0.2675 s/iter. ETA=0:00:09
[09/02 15:09:58 d2.evaluation.evaluator]: Inference done 130/144. Dataloading: 0.0033 s/iter. Inference: 0.0888 s/iter. Eval: 0.1695 s/iter. Total: 0.2617 s/iter. ETA=0:00:03
[09/02 15:10:02 d2.evaluation.evaluator]: Total inference time: 0:00:36.333746 (0.261394 s / iter per device, on 1 devices)
[09/02 15:10:02 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:12 (0.088606 s / iter per device, on 1 devices)
[09/02 15:10:02 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 15:10:02 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 15:10:02 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/02 15:10:02 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 15:10:02 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/02 15:10:02 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:10:02 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.445
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.653
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.519
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.124
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.406
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.584
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.319
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.573
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.620
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.250
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.583
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.750
[09/02 15:10:02 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 44.463 | 65.330 | 51.926 | 12.424 | 40.640 | 58.429 |
Loading and preparing results...
DONE (t=0.06s)
creating index...
index created!
[09/02 15:10:02 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 15:10:02 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[09/02 15:10:02 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:10:02 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.464
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.664
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.539
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.095
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.402
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.633
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.327
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.595
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.645
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.325
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.612
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.761
[09/02 15:10:02 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 46.382 | 66.428 | 53.946 | 9.510 | 40.176 | 63.310 |
[09/02 15:10:02 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 15:10:02 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 15:10:02 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:10:02 d2.evaluation.testing]: copypaste: 44.4634,65.3303,51.9265,12.4243,40.6396,58.4289
[09/02 15:10:02 d2.evaluation.testing]: copypaste: Task: segm
[09/02 15:10:02 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:10:02 d2.evaluation.testing]: copypaste: 46.3822,66.4281,53.9456,9.5098,40.1756,63.3099
[09/02 15:10:02 d2.utils.events]:  eta: 0:04:32  iter: 599  total_loss: 0.5629  loss_cls: 0.1283  loss_box_reg: 0.2109  loss_mask: 0.1889  loss_rpn_cls: 0.01134  loss_rpn_loc: 0.005875  time: 0.6997  data_time: 0.0871  lr: 0.00014985  max_mem: 4442M
[09/02 15:10:16 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 15:10:16 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 15:10:16 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 15:10:16 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 15:10:16 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 15:10:20 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0037 s/iter. Inference: 0.0893 s/iter. Eval: 0.1848 s/iter. Total: 0.2779 s/iter. ETA=0:00:36
[09/02 15:10:25 d2.evaluation.evaluator]: Inference done 38/144. Dataloading: 0.0040 s/iter. Inference: 0.0849 s/iter. Eval: 0.1158 s/iter. Total: 0.2048 s/iter. ETA=0:00:21
[09/02 15:10:30 d2.evaluation.evaluator]: Inference done 51/144. Dataloading: 0.0040 s/iter. Inference: 0.0888 s/iter. Eval: 0.1630 s/iter. Total: 0.2560 s/iter. ETA=0:00:23
[09/02 15:10:36 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0039 s/iter. Inference: 0.0904 s/iter. Eval: 0.1822 s/iter. Total: 0.2768 s/iter. ETA=0:00:21
[09/02 15:10:41 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0036 s/iter. Inference: 0.0887 s/iter. Eval: 0.1630 s/iter. Total: 0.2555 s/iter. ETA=0:00:13
[09/02 15:10:46 d2.evaluation.evaluator]: Inference done 115/144. Dataloading: 0.0036 s/iter. Inference: 0.0889 s/iter. Eval: 0.1566 s/iter. Total: 0.2493 s/iter. ETA=0:00:07
[09/02 15:10:51 d2.evaluation.evaluator]: Inference done 141/144. Dataloading: 0.0034 s/iter. Inference: 0.0879 s/iter. Eval: 0.1471 s/iter. Total: 0.2386 s/iter. ETA=0:00:00
[09/02 15:10:53 d2.evaluation.evaluator]: Total inference time: 0:00:34.085109 (0.245217 s / iter per device, on 1 devices)
[09/02 15:10:53 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:12 (0.088212 s / iter per device, on 1 devices)
[09/02 15:10:53 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 15:10:53 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 15:10:53 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/02 15:10:53 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 15:10:53 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/02 15:10:53 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:10:53 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.429
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.651
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.507
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.181
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.409
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.544
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.313
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.564
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.308
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.596
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.700
[09/02 15:10:53 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 42.923 | 65.121 | 50.659 | 18.146 | 40.862 | 54.448 |
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
[09/02 15:10:53 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 15:10:53 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[09/02 15:10:53 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:10:53 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.457
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.664
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.534
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.139
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.398
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.614
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.324
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.590
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.644
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.618
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.741
[09/02 15:10:53 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.653 | 66.390 | 53.400 | 13.870 | 39.781 | 61.368 |
[09/02 15:10:53 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 15:10:53 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 15:10:53 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:10:53 d2.evaluation.testing]: copypaste: 42.9226,65.1207,50.6589,18.1464,40.8625,54.4476
[09/02 15:10:53 d2.evaluation.testing]: copypaste: Task: segm
[09/02 15:10:53 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:10:53 d2.evaluation.testing]: copypaste: 45.6526,66.3899,53.3995,13.8696,39.7814,61.3682
[09/02 15:10:53 d2.utils.events]:  eta: 0:04:18  iter: 619  total_loss: 0.5313  loss_cls: 0.09507  loss_box_reg: 0.1926  loss_mask: 0.1834  loss_rpn_cls: 0.01186  loss_rpn_loc: 0.006195  time: 0.6991  data_time: 0.0575  lr: 0.00015485  max_mem: 4442M
[09/02 15:11:08 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 15:11:08 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 15:11:08 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 15:11:08 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 15:11:08 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 15:11:12 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0015 s/iter. Inference: 0.0836 s/iter. Eval: 0.1266 s/iter. Total: 0.2118 s/iter. ETA=0:00:28
[09/02 15:11:17 d2.evaluation.evaluator]: Inference done 36/144. Dataloading: 0.0032 s/iter. Inference: 0.0841 s/iter. Eval: 0.1150 s/iter. Total: 0.2025 s/iter. ETA=0:00:21
[09/02 15:11:22 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0031 s/iter. Inference: 0.0865 s/iter. Eval: 0.1486 s/iter. Total: 0.2383 s/iter. ETA=0:00:21
[09/02 15:11:27 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0032 s/iter. Inference: 0.0885 s/iter. Eval: 0.1735 s/iter. Total: 0.2654 s/iter. ETA=0:00:20
[09/02 15:11:32 d2.evaluation.evaluator]: Inference done 94/144. Dataloading: 0.0034 s/iter. Inference: 0.0879 s/iter. Eval: 0.1554 s/iter. Total: 0.2468 s/iter. ETA=0:00:12
[09/02 15:11:37 d2.evaluation.evaluator]: Inference done 116/144. Dataloading: 0.0035 s/iter. Inference: 0.0879 s/iter. Eval: 0.1516 s/iter. Total: 0.2433 s/iter. ETA=0:00:06
[09/02 15:11:43 d2.evaluation.evaluator]: Inference done 143/144. Dataloading: 0.0036 s/iter. Inference: 0.0869 s/iter. Eval: 0.1428 s/iter. Total: 0.2334 s/iter. ETA=0:00:00
[09/02 15:11:43 d2.evaluation.evaluator]: Total inference time: 0:00:33.042816 (0.237718 s / iter per device, on 1 devices)
[09/02 15:11:43 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:12 (0.087145 s / iter per device, on 1 devices)
[09/02 15:11:43 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 15:11:43 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 15:11:43 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/02 15:11:43 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 15:11:44 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/02 15:11:44 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:11:44 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.450
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.656
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.525
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.166
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.429
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.578
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.324
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.583
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.621
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.292
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.591
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.733
[09/02 15:11:44 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.033 | 65.624 | 52.497 | 16.594 | 42.858 | 57.758 |
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
[09/02 15:11:44 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 15:11:44 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[09/02 15:11:44 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:11:44 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.465
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.657
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.550
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.127
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.411
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.330
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.599
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.643
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.342
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.614
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.748
[09/02 15:11:44 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.515 | 65.746 | 55.028 | 12.665 | 41.112 | 62.287 |
[09/02 15:11:44 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 15:11:44 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 15:11:44 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:11:44 d2.evaluation.testing]: copypaste: 45.0332,65.6244,52.4966,16.5945,42.8579,57.7577
[09/02 15:11:44 d2.evaluation.testing]: copypaste: Task: segm
[09/02 15:11:44 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:11:44 d2.evaluation.testing]: copypaste: 46.5146,65.7465,55.0282,12.6652,41.1116,62.2874
[09/02 15:11:44 d2.utils.events]:  eta: 0:04:05  iter: 639  total_loss: 0.6621  loss_cls: 0.1323  loss_box_reg: 0.2583  loss_mask: 0.1801  loss_rpn_cls: 0.01315  loss_rpn_loc: 0.008285  time: 0.6996  data_time: 0.0773  lr: 0.00015984  max_mem: 4442M
[09/02 15:11:58 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 15:11:58 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 15:11:58 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 15:11:58 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 15:11:58 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 15:12:02 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.0858 s/iter. Eval: 0.1479 s/iter. Total: 0.2353 s/iter. ETA=0:00:31
[09/02 15:12:07 d2.evaluation.evaluator]: Inference done 33/144. Dataloading: 0.0031 s/iter. Inference: 0.0895 s/iter. Eval: 0.1392 s/iter. Total: 0.2319 s/iter. ETA=0:00:25
[09/02 15:12:12 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0038 s/iter. Inference: 0.0906 s/iter. Eval: 0.1671 s/iter. Total: 0.2617 s/iter. ETA=0:00:24
[09/02 15:12:17 d2.evaluation.evaluator]: Inference done 64/144. Dataloading: 0.0035 s/iter. Inference: 0.0917 s/iter. Eval: 0.1861 s/iter. Total: 0.2815 s/iter. ETA=0:00:22
[09/02 15:12:23 d2.evaluation.evaluator]: Inference done 82/144. Dataloading: 0.0036 s/iter. Inference: 0.0914 s/iter. Eval: 0.1863 s/iter. Total: 0.2814 s/iter. ETA=0:00:17
[09/02 15:12:28 d2.evaluation.evaluator]: Inference done 108/144. Dataloading: 0.0037 s/iter. Inference: 0.0896 s/iter. Eval: 0.1682 s/iter. Total: 0.2615 s/iter. ETA=0:00:09
[09/02 15:12:33 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0036 s/iter. Inference: 0.0890 s/iter. Eval: 0.1612 s/iter. Total: 0.2539 s/iter. ETA=0:00:03
[09/02 15:12:36 d2.evaluation.evaluator]: Total inference time: 0:00:35.328834 (0.254164 s / iter per device, on 1 devices)
[09/02 15:12:36 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:12 (0.088818 s / iter per device, on 1 devices)
[09/02 15:12:36 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 15:12:36 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 15:12:36 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/02 15:12:36 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 15:12:36 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/02 15:12:36 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:12:36 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.436
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.673
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.502
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.144
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.418
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.554
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.320
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.571
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.609
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.267
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.583
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.717
[09/02 15:12:36 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 43.571 | 67.271 | 50.244 | 14.363 | 41.764 | 55.443 |
Loading and preparing results...
DONE (t=0.06s)
creating index...
index created!
[09/02 15:12:37 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 15:12:37 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[09/02 15:12:37 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:12:37 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.472
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.671
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.555
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.097
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.422
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.627
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.335
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.599
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.648
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.748
[09/02 15:12:37 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 47.231 | 67.118 | 55.547 | 9.711 | 42.181 | 62.676 |
[09/02 15:12:37 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 15:12:37 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 15:12:37 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:12:37 d2.evaluation.testing]: copypaste: 43.5710,67.2713,50.2441,14.3632,41.7637,55.4433
[09/02 15:12:37 d2.evaluation.testing]: copypaste: Task: segm
[09/02 15:12:37 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:12:37 d2.evaluation.testing]: copypaste: 47.2313,67.1178,55.5469,9.7105,42.1808,62.6759
[09/02 15:12:37 d2.utils.events]:  eta: 0:03:51  iter: 659  total_loss: 0.4984  loss_cls: 0.1054  loss_box_reg: 0.177  loss_mask: 0.1747  loss_rpn_cls: 0.0104  loss_rpn_loc: 0.005342  time: 0.6994  data_time: 0.0687  lr: 0.00016484  max_mem: 4442M
[09/02 15:12:51 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 15:12:51 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 15:12:51 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 15:12:51 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 15:12:51 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 15:12:55 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0017 s/iter. Inference: 0.0840 s/iter. Eval: 0.1343 s/iter. Total: 0.2199 s/iter. ETA=0:00:29
[09/02 15:13:00 d2.evaluation.evaluator]: Inference done 38/144. Dataloading: 0.0034 s/iter. Inference: 0.0831 s/iter. Eval: 0.1062 s/iter. Total: 0.1928 s/iter. ETA=0:00:20
[09/02 15:13:06 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0031 s/iter. Inference: 0.0870 s/iter. Eval: 0.1556 s/iter. Total: 0.2459 s/iter. ETA=0:00:22
[09/02 15:13:11 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0030 s/iter. Inference: 0.0892 s/iter. Eval: 0.1794 s/iter. Total: 0.2718 s/iter. ETA=0:00:20
[09/02 15:13:16 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0030 s/iter. Inference: 0.0882 s/iter. Eval: 0.1650 s/iter. Total: 0.2564 s/iter. ETA=0:00:13
[09/02 15:13:21 d2.evaluation.evaluator]: Inference done 117/144. Dataloading: 0.0030 s/iter. Inference: 0.0874 s/iter. Eval: 0.1542 s/iter. Total: 0.2448 s/iter. ETA=0:00:06
[09/02 15:13:27 d2.evaluation.evaluator]: Inference done 142/144. Dataloading: 0.0031 s/iter. Inference: 0.0872 s/iter. Eval: 0.1498 s/iter. Total: 0.2402 s/iter. ETA=0:00:00
[09/02 15:13:28 d2.evaluation.evaluator]: Total inference time: 0:00:34.036895 (0.244870 s / iter per device, on 1 devices)
[09/02 15:13:28 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:12 (0.087465 s / iter per device, on 1 devices)
[09/02 15:13:28 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 15:13:28 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 15:13:28 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/02 15:13:28 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 15:13:28 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/02 15:13:28 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:13:28 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.459
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.668
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.533
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.143
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.426
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.601
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.584
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.275
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.590
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.742
[09/02 15:13:28 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.903 | 66.774 | 53.275 | 14.328 | 42.633 | 60.139 |
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
[09/02 15:13:28 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 15:13:28 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[09/02 15:13:28 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:13:28 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.474
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.667
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.569
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.090
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.422
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.635
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.342
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.599
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.642
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.325
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.612
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.753
[09/02 15:13:28 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 47.398 | 66.672 | 56.869 | 8.994 | 42.239 | 63.489 |
[09/02 15:13:28 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 15:13:28 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 15:13:28 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:13:28 d2.evaluation.testing]: copypaste: 45.9028,66.7737,53.2750,14.3281,42.6326,60.1392
[09/02 15:13:28 d2.evaluation.testing]: copypaste: Task: segm
[09/02 15:13:28 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:13:28 d2.evaluation.testing]: copypaste: 47.3984,66.6720,56.8687,8.9945,42.2395,63.4887
[09/02 15:13:28 d2.utils.events]:  eta: 0:03:37  iter: 679  total_loss: 0.5766  loss_cls: 0.1143  loss_box_reg: 0.2025  loss_mask: 0.2088  loss_rpn_cls: 0.01077  loss_rpn_loc: 0.01157  time: 0.6996  data_time: 0.0836  lr: 0.00016983  max_mem: 4442M
[09/02 15:13:42 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 15:13:42 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 15:13:42 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 15:13:42 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 15:13:42 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 15:13:46 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0015 s/iter. Inference: 0.0844 s/iter. Eval: 0.1301 s/iter. Total: 0.2160 s/iter. ETA=0:00:28
[09/02 15:13:51 d2.evaluation.evaluator]: Inference done 36/144. Dataloading: 0.0037 s/iter. Inference: 0.0857 s/iter. Eval: 0.1148 s/iter. Total: 0.2043 s/iter. ETA=0:00:22
[09/02 15:13:56 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0034 s/iter. Inference: 0.0880 s/iter. Eval: 0.1567 s/iter. Total: 0.2482 s/iter. ETA=0:00:22
[09/02 15:14:01 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0035 s/iter. Inference: 0.0896 s/iter. Eval: 0.1798 s/iter. Total: 0.2731 s/iter. ETA=0:00:21
[09/02 15:14:06 d2.evaluation.evaluator]: Inference done 90/144. Dataloading: 0.0031 s/iter. Inference: 0.0884 s/iter. Eval: 0.1671 s/iter. Total: 0.2588 s/iter. ETA=0:00:13
[09/02 15:14:11 d2.evaluation.evaluator]: Inference done 114/144. Dataloading: 0.0030 s/iter. Inference: 0.0876 s/iter. Eval: 0.1579 s/iter. Total: 0.2487 s/iter. ETA=0:00:07
[09/02 15:14:17 d2.evaluation.evaluator]: Inference done 141/144. Dataloading: 0.0030 s/iter. Inference: 0.0866 s/iter. Eval: 0.1467 s/iter. Total: 0.2365 s/iter. ETA=0:00:00
[09/02 15:14:18 d2.evaluation.evaluator]: Total inference time: 0:00:33.704772 (0.242480 s / iter per device, on 1 devices)
[09/02 15:14:18 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:12 (0.087015 s / iter per device, on 1 devices)
[09/02 15:14:18 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 15:14:18 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 15:14:18 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/02 15:14:18 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 15:14:18 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/02 15:14:18 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:14:18 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.463
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.670
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.510
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.151
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.435
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.598
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.335
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.590
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.628
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.594
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.744
[09/02 15:14:18 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.281 | 67.001 | 50.958 | 15.062 | 43.506 | 59.836 |
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
[09/02 15:14:18 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 15:14:18 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[09/02 15:14:18 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:14:18 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.479
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.661
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.570
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.111
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.424
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.641
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.344
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.601
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.645
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.367
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.758
[09/02 15:14:18 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.919 | 66.094 | 56.991 | 11.130 | 42.442 | 64.101 |
[09/02 15:14:18 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 15:14:18 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 15:14:18 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:14:18 d2.evaluation.testing]: copypaste: 46.2815,67.0015,50.9577,15.0620,43.5059,59.8360
[09/02 15:14:18 d2.evaluation.testing]: copypaste: Task: segm
[09/02 15:14:18 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:14:18 d2.evaluation.testing]: copypaste: 47.9194,66.0938,56.9912,11.1305,42.4425,64.1013
[09/02 15:14:18 d2.utils.events]:  eta: 0:03:24  iter: 699  total_loss: 0.5499  loss_cls: 0.1087  loss_box_reg: 0.1536  loss_mask: 0.1859  loss_rpn_cls: 0.01331  loss_rpn_loc: 0.01032  time: 0.6990  data_time: 0.0572  lr: 0.00017483  max_mem: 4442M
[09/02 15:14:32 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 15:14:32 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 15:14:32 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 15:14:32 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 15:14:32 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 15:14:37 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0028 s/iter. Inference: 0.0846 s/iter. Eval: 0.1470 s/iter. Total: 0.2344 s/iter. ETA=0:00:31
[09/02 15:14:42 d2.evaluation.evaluator]: Inference done 36/144. Dataloading: 0.0043 s/iter. Inference: 0.0853 s/iter. Eval: 0.1199 s/iter. Total: 0.2097 s/iter. ETA=0:00:22
[09/02 15:14:47 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0038 s/iter. Inference: 0.0886 s/iter. Eval: 0.1548 s/iter. Total: 0.2475 s/iter. ETA=0:00:22
[09/02 15:14:52 d2.evaluation.evaluator]: Inference done 69/144. Dataloading: 0.0035 s/iter. Inference: 0.0898 s/iter. Eval: 0.1727 s/iter. Total: 0.2662 s/iter. ETA=0:00:19
[09/02 15:14:57 d2.evaluation.evaluator]: Inference done 95/144. Dataloading: 0.0033 s/iter. Inference: 0.0881 s/iter. Eval: 0.1538 s/iter. Total: 0.2454 s/iter. ETA=0:00:12
[09/02 15:15:02 d2.evaluation.evaluator]: Inference done 120/144. Dataloading: 0.0032 s/iter. Inference: 0.0873 s/iter. Eval: 0.1459 s/iter. Total: 0.2366 s/iter. ETA=0:00:05
[09/02 15:15:08 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0032 s/iter. Inference: 0.0874 s/iter. Eval: 0.1434 s/iter. Total: 0.2341 s/iter. ETA=0:00:00
[09/02 15:15:08 d2.evaluation.evaluator]: Total inference time: 0:00:32.593476 (0.234485 s / iter per device, on 1 devices)
[09/02 15:15:08 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:12 (0.087372 s / iter per device, on 1 devices)
[09/02 15:15:08 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 15:15:08 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 15:15:08 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/02 15:15:08 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 15:15:08 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/02 15:15:08 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:15:08 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.457
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.673
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.508
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.133
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.431
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.587
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.334
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.587
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.624
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.589
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.742
[09/02 15:15:08 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.671 | 67.265 | 50.797 | 13.345 | 43.102 | 58.655 |
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
[09/02 15:15:08 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 15:15:08 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/02 15:15:08 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:15:08 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.475
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.669
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.568
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.121
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.417
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.638
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.342
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.600
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.648
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.400
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.605
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.768
[09/02 15:15:08 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.474 | 66.921 | 56.835 | 12.065 | 41.668 | 63.849 |
[09/02 15:15:08 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 15:15:08 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 15:15:08 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:15:08 d2.evaluation.testing]: copypaste: 45.6709,67.2648,50.7966,13.3448,43.1016,58.6552
[09/02 15:15:08 d2.evaluation.testing]: copypaste: Task: segm
[09/02 15:15:08 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:15:08 d2.evaluation.testing]: copypaste: 47.4738,66.9214,56.8351,12.0649,41.6680,63.8489
[09/02 15:15:08 d2.utils.events]:  eta: 0:03:10  iter: 719  total_loss: 0.5347  loss_cls: 0.1055  loss_box_reg: 0.2023  loss_mask: 0.1985  loss_rpn_cls: 0.01116  loss_rpn_loc: 0.01146  time: 0.6988  data_time: 0.0693  lr: 0.00017982  max_mem: 4442M
[09/02 15:15:22 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 15:15:22 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 15:15:22 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 15:15:22 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 15:15:22 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 15:15:26 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.0829 s/iter. Eval: 0.1087 s/iter. Total: 0.1933 s/iter. ETA=0:00:25
[09/02 15:15:31 d2.evaluation.evaluator]: Inference done 39/144. Dataloading: 0.0034 s/iter. Inference: 0.0830 s/iter. Eval: 0.0960 s/iter. Total: 0.1826 s/iter. ETA=0:00:19
[09/02 15:15:36 d2.evaluation.evaluator]: Inference done 56/144. Dataloading: 0.0032 s/iter. Inference: 0.0860 s/iter. Eval: 0.1365 s/iter. Total: 0.2258 s/iter. ETA=0:00:19
[09/02 15:15:41 d2.evaluation.evaluator]: Inference done 75/144. Dataloading: 0.0033 s/iter. Inference: 0.0873 s/iter. Eval: 0.1462 s/iter. Total: 0.2369 s/iter. ETA=0:00:16
[09/02 15:15:46 d2.evaluation.evaluator]: Inference done 101/144. Dataloading: 0.0037 s/iter. Inference: 0.0872 s/iter. Eval: 0.1341 s/iter. Total: 0.2251 s/iter. ETA=0:00:09
[09/02 15:15:51 d2.evaluation.evaluator]: Inference done 128/144. Dataloading: 0.0034 s/iter. Inference: 0.0871 s/iter. Eval: 0.1265 s/iter. Total: 0.2172 s/iter. ETA=0:00:03
[09/02 15:15:55 d2.evaluation.evaluator]: Total inference time: 0:00:30.130841 (0.216769 s / iter per device, on 1 devices)
[09/02 15:15:55 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:12 (0.086833 s / iter per device, on 1 devices)
[09/02 15:15:55 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 15:15:55 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 15:15:55 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/02 15:15:55 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 15:15:55 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/02 15:15:55 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:15:55 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.461
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.676
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.532
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.173
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.434
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.588
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.335
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.583
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.630
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.598
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.735
[09/02 15:15:55 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.090 | 67.608 | 53.160 | 17.309 | 43.446 | 58.822 |
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
[09/02 15:15:55 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 15:15:55 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[09/02 15:15:55 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:15:55 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.480
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.676
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.587
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.137
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.423
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.641
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.347
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.598
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.651
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.442
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.609
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.762
[09/02 15:15:55 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.043 | 67.584 | 58.738 | 13.657 | 42.342 | 64.082 |
[09/02 15:15:55 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 15:15:55 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 15:15:55 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:15:55 d2.evaluation.testing]: copypaste: 46.0902,67.6082,53.1597,17.3090,43.4456,58.8223
[09/02 15:15:55 d2.evaluation.testing]: copypaste: Task: segm
[09/02 15:15:55 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:15:55 d2.evaluation.testing]: copypaste: 48.0428,67.5843,58.7385,13.6573,42.3424,64.0816
[09/02 15:15:55 d2.utils.events]:  eta: 0:02:57  iter: 739  total_loss: 0.6131  loss_cls: 0.1025  loss_box_reg: 0.2005  loss_mask: 0.1915  loss_rpn_cls: 0.01183  loss_rpn_loc: 0.008048  time: 0.6988  data_time: 0.0659  lr: 0.00018482  max_mem: 4442M
[09/02 15:16:09 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 15:16:09 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 15:16:09 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 15:16:09 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 15:16:09 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 15:16:13 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0019 s/iter. Inference: 0.0947 s/iter. Eval: 0.1255 s/iter. Total: 0.2222 s/iter. ETA=0:00:29
[09/02 15:16:18 d2.evaluation.evaluator]: Inference done 40/144. Dataloading: 0.0021 s/iter. Inference: 0.0869 s/iter. Eval: 0.0936 s/iter. Total: 0.1827 s/iter. ETA=0:00:19
[09/02 15:16:23 d2.evaluation.evaluator]: Inference done 54/144. Dataloading: 0.0021 s/iter. Inference: 0.0900 s/iter. Eval: 0.1489 s/iter. Total: 0.2411 s/iter. ETA=0:00:21
[09/02 15:16:28 d2.evaluation.evaluator]: Inference done 74/144. Dataloading: 0.0021 s/iter. Inference: 0.0897 s/iter. Eval: 0.1532 s/iter. Total: 0.2451 s/iter. ETA=0:00:17
[09/02 15:16:34 d2.evaluation.evaluator]: Inference done 103/144. Dataloading: 0.0021 s/iter. Inference: 0.0880 s/iter. Eval: 0.1369 s/iter. Total: 0.2271 s/iter. ETA=0:00:09
[09/02 15:16:39 d2.evaluation.evaluator]: Inference done 129/144. Dataloading: 0.0021 s/iter. Inference: 0.0888 s/iter. Eval: 0.1297 s/iter. Total: 0.2207 s/iter. ETA=0:00:03
[09/02 15:16:42 d2.evaluation.evaluator]: Total inference time: 0:00:30.779087 (0.221432 s / iter per device, on 1 devices)
[09/02 15:16:42 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:12 (0.088497 s / iter per device, on 1 devices)
[09/02 15:16:42 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 15:16:42 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 15:16:42 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/02 15:16:42 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 15:16:42 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/02 15:16:42 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:16:42 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.469
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.676
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.545
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.161
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.439
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.598
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.334
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.593
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.636
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.609
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.733
[09/02 15:16:42 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.917 | 67.568 | 54.546 | 16.080 | 43.911 | 59.785 |
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
[09/02 15:16:42 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 15:16:42 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[09/02 15:16:42 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:16:42 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.483
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.680
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.582
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.149
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.430
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.636
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.344
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.605
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.654
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.442
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.620
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.753
[09/02 15:16:42 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.306 | 68.039 | 58.156 | 14.921 | 42.975 | 63.633 |
[09/02 15:16:42 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 15:16:42 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 15:16:42 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:16:42 d2.evaluation.testing]: copypaste: 46.9167,67.5680,54.5461,16.0796,43.9112,59.7849
[09/02 15:16:42 d2.evaluation.testing]: copypaste: Task: segm
[09/02 15:16:42 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:16:42 d2.evaluation.testing]: copypaste: 48.3065,68.0387,58.1563,14.9212,42.9749,63.6329
[09/02 15:16:42 d2.utils.events]:  eta: 0:02:43  iter: 759  total_loss: 0.6082  loss_cls: 0.1137  loss_box_reg: 0.2413  loss_mask: 0.2118  loss_rpn_cls: 0.009706  loss_rpn_loc: 0.007311  time: 0.6985  data_time: 0.0699  lr: 0.00018981  max_mem: 4442M
[09/02 15:16:57 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 15:16:57 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 15:16:57 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 15:16:57 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 15:16:57 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 15:17:00 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0017 s/iter. Inference: 0.0837 s/iter. Eval: 0.1193 s/iter. Total: 0.2047 s/iter. ETA=0:00:27
[09/02 15:17:06 d2.evaluation.evaluator]: Inference done 40/144. Dataloading: 0.0021 s/iter. Inference: 0.0828 s/iter. Eval: 0.0951 s/iter. Total: 0.1802 s/iter. ETA=0:00:18
[09/02 15:17:11 d2.evaluation.evaluator]: Inference done 54/144. Dataloading: 0.0022 s/iter. Inference: 0.0878 s/iter. Eval: 0.1449 s/iter. Total: 0.2351 s/iter. ETA=0:00:21
[09/02 15:17:16 d2.evaluation.evaluator]: Inference done 73/144. Dataloading: 0.0022 s/iter. Inference: 0.0879 s/iter. Eval: 0.1539 s/iter. Total: 0.2441 s/iter. ETA=0:00:17
[09/02 15:17:21 d2.evaluation.evaluator]: Inference done 100/144. Dataloading: 0.0029 s/iter. Inference: 0.0868 s/iter. Eval: 0.1396 s/iter. Total: 0.2295 s/iter. ETA=0:00:10
[09/02 15:17:26 d2.evaluation.evaluator]: Inference done 122/144. Dataloading: 0.0029 s/iter. Inference: 0.0869 s/iter. Eval: 0.1394 s/iter. Total: 0.2294 s/iter. ETA=0:00:05
[09/02 15:17:31 d2.evaluation.evaluator]: Total inference time: 0:00:31.672001 (0.227856 s / iter per device, on 1 devices)
[09/02 15:17:31 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:12 (0.086836 s / iter per device, on 1 devices)
[09/02 15:17:31 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 15:17:31 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 15:17:31 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/02 15:17:31 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 15:17:31 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/02 15:17:31 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:17:31 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.454
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.677
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.507
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.172
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.426
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.579
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.325
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.575
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.620
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.590
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.718
[09/02 15:17:31 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.421 | 67.688 | 50.685 | 17.220 | 42.604 | 57.948 |
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
[09/02 15:17:31 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 15:17:31 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[09/02 15:17:31 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:17:31 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.480
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.683
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.584
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.140
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.427
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.635
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.337
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.599
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.648
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.417
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.747
[09/02 15:17:31 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.979 | 68.308 | 58.370 | 14.049 | 42.725 | 63.511 |
[09/02 15:17:31 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 15:17:31 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 15:17:31 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:17:31 d2.evaluation.testing]: copypaste: 45.4207,67.6884,50.6854,17.2201,42.6035,57.9482
[09/02 15:17:31 d2.evaluation.testing]: copypaste: Task: segm
[09/02 15:17:31 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:17:31 d2.evaluation.testing]: copypaste: 47.9788,68.3079,58.3701,14.0489,42.7246,63.5109
[09/02 15:17:31 d2.utils.events]:  eta: 0:02:29  iter: 779  total_loss: 0.5042  loss_cls: 0.1147  loss_box_reg: 0.1936  loss_mask: 0.1623  loss_rpn_cls: 0.009284  loss_rpn_loc: 0.006889  time: 0.6987  data_time: 0.0799  lr: 0.00019481  max_mem: 4442M
[09/02 15:17:45 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 15:17:45 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 15:17:45 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 15:17:45 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 15:17:45 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 15:17:48 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0035 s/iter. Inference: 0.0831 s/iter. Eval: 0.0988 s/iter. Total: 0.1854 s/iter. ETA=0:00:24
[09/02 15:17:53 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0046 s/iter. Inference: 0.0854 s/iter. Eval: 0.0812 s/iter. Total: 0.1713 s/iter. ETA=0:00:17
[09/02 15:17:58 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0042 s/iter. Inference: 0.0880 s/iter. Eval: 0.1245 s/iter. Total: 0.2168 s/iter. ETA=0:00:18
[09/02 15:18:03 d2.evaluation.evaluator]: Inference done 78/144. Dataloading: 0.0040 s/iter. Inference: 0.0875 s/iter. Eval: 0.1323 s/iter. Total: 0.2238 s/iter. ETA=0:00:14
[09/02 15:18:09 d2.evaluation.evaluator]: Inference done 108/144. Dataloading: 0.0039 s/iter. Inference: 0.0857 s/iter. Eval: 0.1187 s/iter. Total: 0.2084 s/iter. ETA=0:00:07
[09/02 15:18:14 d2.evaluation.evaluator]: Inference done 138/144. Dataloading: 0.0039 s/iter. Inference: 0.0852 s/iter. Eval: 0.1107 s/iter. Total: 0.1999 s/iter. ETA=0:00:01
[09/02 15:18:15 d2.evaluation.evaluator]: Total inference time: 0:00:28.270216 (0.203383 s / iter per device, on 1 devices)
[09/02 15:18:15 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:11 (0.085372 s / iter per device, on 1 devices)
[09/02 15:18:15 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 15:18:15 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 15:18:15 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/02 15:18:15 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 15:18:16 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/02 15:18:16 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:18:16 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.676
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.510
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.171
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.410
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.583
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.313
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.568
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.612
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.580
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.715
[09/02 15:18:16 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 44.755 | 67.559 | 50.995 | 17.055 | 41.045 | 58.348 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[09/02 15:18:16 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 15:18:16 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/02 15:18:16 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:18:16 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.477
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.678
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.576
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.155
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.416
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.637
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.329
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.591
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.640
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.417
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.602
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.747
[09/02 15:18:16 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.678 | 67.777 | 57.648 | 15.517 | 41.556 | 63.748 |
[09/02 15:18:16 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 15:18:16 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 15:18:16 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:18:16 d2.evaluation.testing]: copypaste: 44.7547,67.5594,50.9947,17.0555,41.0446,58.3483
[09/02 15:18:16 d2.evaluation.testing]: copypaste: Task: segm
[09/02 15:18:16 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:18:16 d2.evaluation.testing]: copypaste: 47.6779,67.7773,57.6482,15.5167,41.5565,63.7478
[09/02 15:18:16 d2.utils.events]:  eta: 0:02:16  iter: 799  total_loss: 0.5254  loss_cls: 0.1013  loss_box_reg: 0.1987  loss_mask: 0.1984  loss_rpn_cls: 0.01006  loss_rpn_loc: 0.005173  time: 0.6981  data_time: 0.0521  lr: 0.0001998  max_mem: 4442M
[09/02 15:18:29 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 15:18:29 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 15:18:29 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 15:18:29 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 15:18:29 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 15:18:33 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0027 s/iter. Inference: 0.0818 s/iter. Eval: 0.1022 s/iter. Total: 0.1868 s/iter. ETA=0:00:24
[09/02 15:18:38 d2.evaluation.evaluator]: Inference done 36/144. Dataloading: 0.0050 s/iter. Inference: 0.0859 s/iter. Eval: 0.1069 s/iter. Total: 0.1979 s/iter. ETA=0:00:21
[09/02 15:18:43 d2.evaluation.evaluator]: Inference done 54/144. Dataloading: 0.0042 s/iter. Inference: 0.0876 s/iter. Eval: 0.1415 s/iter. Total: 0.2334 s/iter. ETA=0:00:21
[09/02 15:18:48 d2.evaluation.evaluator]: Inference done 74/144. Dataloading: 0.0038 s/iter. Inference: 0.0885 s/iter. Eval: 0.1484 s/iter. Total: 0.2409 s/iter. ETA=0:00:16
[09/02 15:18:53 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0035 s/iter. Inference: 0.0866 s/iter. Eval: 0.1309 s/iter. Total: 0.2211 s/iter. ETA=0:00:08
[09/02 15:18:58 d2.evaluation.evaluator]: Inference done 133/144. Dataloading: 0.0037 s/iter. Inference: 0.0855 s/iter. Eval: 0.1211 s/iter. Total: 0.2104 s/iter. ETA=0:00:02
[09/02 15:19:01 d2.evaluation.evaluator]: Total inference time: 0:00:29.515726 (0.212343 s / iter per device, on 1 devices)
[09/02 15:19:01 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:11 (0.085455 s / iter per device, on 1 devices)
[09/02 15:19:01 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 15:19:01 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 15:19:01 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/02 15:19:01 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 15:19:01 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/02 15:19:01 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:19:01 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.452
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.672
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.511
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.189
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.426
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.576
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.313
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.569
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.611
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.583
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.706
[09/02 15:19:01 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.189 | 67.247 | 51.067 | 18.937 | 42.552 | 57.640 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[09/02 15:19:01 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 15:19:01 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/02 15:19:01 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:19:01 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.483
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.680
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.580
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.155
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.425
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.640
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.595
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.645
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.425
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.603
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.756
[09/02 15:19:01 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.309 | 68.043 | 58.034 | 15.538 | 42.526 | 63.980 |
[09/02 15:19:01 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 15:19:01 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 15:19:01 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:19:01 d2.evaluation.testing]: copypaste: 45.1893,67.2471,51.0673,18.9371,42.5523,57.6405
[09/02 15:19:01 d2.evaluation.testing]: copypaste: Task: segm
[09/02 15:19:01 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:19:01 d2.evaluation.testing]: copypaste: 48.3091,68.0430,58.0337,15.5378,42.5257,63.9798
[09/02 15:19:01 d2.utils.events]:  eta: 0:02:02  iter: 819  total_loss: 0.37  loss_cls: 0.07333  loss_box_reg: 0.1364  loss_mask: 0.1586  loss_rpn_cls: 0.006927  loss_rpn_loc: 0.003279  time: 0.6974  data_time: 0.0521  lr: 0.0002048  max_mem: 4442M
[09/02 15:19:15 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 15:19:15 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 15:19:15 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 15:19:16 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 15:19:16 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 15:19:19 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0025 s/iter. Inference: 0.0883 s/iter. Eval: 0.1256 s/iter. Total: 0.2164 s/iter. ETA=0:00:28
[09/02 15:19:24 d2.evaluation.evaluator]: Inference done 43/144. Dataloading: 0.0050 s/iter. Inference: 0.0829 s/iter. Eval: 0.0814 s/iter. Total: 0.1694 s/iter. ETA=0:00:17
[09/02 15:19:30 d2.evaluation.evaluator]: Inference done 61/144. Dataloading: 0.0044 s/iter. Inference: 0.0852 s/iter. Eval: 0.1207 s/iter. Total: 0.2104 s/iter. ETA=0:00:17
[09/02 15:19:35 d2.evaluation.evaluator]: Inference done 87/144. Dataloading: 0.0045 s/iter. Inference: 0.0848 s/iter. Eval: 0.1152 s/iter. Total: 0.2047 s/iter. ETA=0:00:11
[09/02 15:19:40 d2.evaluation.evaluator]: Inference done 117/144. Dataloading: 0.0040 s/iter. Inference: 0.0841 s/iter. Eval: 0.1065 s/iter. Total: 0.1947 s/iter. ETA=0:00:05
[09/02 15:19:45 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0044 s/iter. Inference: 0.0850 s/iter. Eval: 0.1074 s/iter. Total: 0.1970 s/iter. ETA=0:00:00
[09/02 15:19:45 d2.evaluation.evaluator]: Total inference time: 0:00:27.432709 (0.197358 s / iter per device, on 1 devices)
[09/02 15:19:45 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:11 (0.084999 s / iter per device, on 1 devices)
[09/02 15:19:45 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 15:19:45 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 15:19:45 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/02 15:19:45 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 15:19:45 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/02 15:19:45 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:19:45 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.466
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.683
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.531
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.179
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.431
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.602
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.326
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.583
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.627
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.367
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.590
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.739
[09/02 15:19:45 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.600 | 68.280 | 53.077 | 17.914 | 43.093 | 60.234 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[09/02 15:19:45 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 15:19:46 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/02 15:19:46 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:19:46 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.486
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.685
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.597
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.163
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.425
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.644
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.339
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.599
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.649
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.425
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.609
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.761
[09/02 15:19:46 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.623 | 68.486 | 59.702 | 16.344 | 42.527 | 64.358 |
[09/02 15:19:46 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 15:19:46 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 15:19:46 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:19:46 d2.evaluation.testing]: copypaste: 46.6001,68.2799,53.0766,17.9140,43.0930,60.2337
[09/02 15:19:46 d2.evaluation.testing]: copypaste: Task: segm
[09/02 15:19:46 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:19:46 d2.evaluation.testing]: copypaste: 48.6227,68.4865,59.7019,16.3439,42.5272,64.3578
[09/02 15:19:46 d2.utils.events]:  eta: 0:01:48  iter: 839  total_loss: 0.4131  loss_cls: 0.08555  loss_box_reg: 0.1502  loss_mask: 0.1566  loss_rpn_cls: 0.01029  loss_rpn_loc: 0.00727  time: 0.6975  data_time: 0.0823  lr: 0.00020979  max_mem: 4442M
[09/02 15:19:59 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 15:19:59 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 15:19:59 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 15:19:59 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 15:19:59 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 15:20:03 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0035 s/iter. Inference: 0.0877 s/iter. Eval: 0.1451 s/iter. Total: 0.2364 s/iter. ETA=0:00:31
[09/02 15:20:08 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0045 s/iter. Inference: 0.0834 s/iter. Eval: 0.0905 s/iter. Total: 0.1785 s/iter. ETA=0:00:18
[09/02 15:20:13 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0041 s/iter. Inference: 0.0860 s/iter. Eval: 0.1300 s/iter. Total: 0.2202 s/iter. ETA=0:00:19
[09/02 15:20:18 d2.evaluation.evaluator]: Inference done 74/144. Dataloading: 0.0042 s/iter. Inference: 0.0875 s/iter. Eval: 0.1481 s/iter. Total: 0.2399 s/iter. ETA=0:00:16
[09/02 15:20:23 d2.evaluation.evaluator]: Inference done 103/144. Dataloading: 0.0038 s/iter. Inference: 0.0857 s/iter. Eval: 0.1322 s/iter. Total: 0.2219 s/iter. ETA=0:00:09
[09/02 15:20:29 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0041 s/iter. Inference: 0.0854 s/iter. Eval: 0.1239 s/iter. Total: 0.2136 s/iter. ETA=0:00:02
[09/02 15:20:32 d2.evaluation.evaluator]: Total inference time: 0:00:29.849682 (0.214746 s / iter per device, on 1 devices)
[09/02 15:20:32 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:11 (0.085397 s / iter per device, on 1 devices)
[09/02 15:20:32 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 15:20:32 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 15:20:32 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/02 15:20:32 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 15:20:32 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/02 15:20:32 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:20:32 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.457
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.688
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.514
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.162
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.435
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.575
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.327
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.577
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.620
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.367
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.591
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.715
[09/02 15:20:32 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.674 | 68.820 | 51.391 | 16.187 | 43.506 | 57.489 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[09/02 15:20:32 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 15:20:32 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/02 15:20:32 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:20:32 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.484
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.693
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.583
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.160
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.424
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.642
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.341
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.595
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.647
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.433
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.609
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.753
[09/02 15:20:32 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.425 | 69.296 | 58.256 | 16.018 | 42.432 | 64.209 |
[09/02 15:20:32 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 15:20:32 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 15:20:32 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:20:32 d2.evaluation.testing]: copypaste: 45.6742,68.8201,51.3910,16.1870,43.5062,57.4894
[09/02 15:20:32 d2.evaluation.testing]: copypaste: Task: segm
[09/02 15:20:32 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:20:32 d2.evaluation.testing]: copypaste: 48.4253,69.2963,58.2562,16.0179,42.4315,64.2094
[09/02 15:20:32 d2.utils.events]:  eta: 0:01:35  iter: 859  total_loss: 0.4827  loss_cls: 0.1025  loss_box_reg: 0.1898  loss_mask: 0.1866  loss_rpn_cls: 0.007394  loss_rpn_loc: 0.005523  time: 0.6973  data_time: 0.0556  lr: 0.00021479  max_mem: 4442M
[09/02 15:20:45 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 15:20:45 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 15:20:45 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 15:20:45 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 15:20:45 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 15:20:50 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0049 s/iter. Inference: 0.0819 s/iter. Eval: 0.1047 s/iter. Total: 0.1915 s/iter. ETA=0:00:25
[09/02 15:20:55 d2.evaluation.evaluator]: Inference done 43/144. Dataloading: 0.0054 s/iter. Inference: 0.0817 s/iter. Eval: 0.0820 s/iter. Total: 0.1692 s/iter. ETA=0:00:17
[09/02 15:21:00 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0049 s/iter. Inference: 0.0853 s/iter. Eval: 0.1278 s/iter. Total: 0.2181 s/iter. ETA=0:00:18
[09/02 15:21:05 d2.evaluation.evaluator]: Inference done 82/144. Dataloading: 0.0042 s/iter. Inference: 0.0851 s/iter. Eval: 0.1299 s/iter. Total: 0.2194 s/iter. ETA=0:00:13
[09/02 15:21:10 d2.evaluation.evaluator]: Inference done 111/144. Dataloading: 0.0043 s/iter. Inference: 0.0845 s/iter. Eval: 0.1188 s/iter. Total: 0.2078 s/iter. ETA=0:00:06
[09/02 15:21:16 d2.evaluation.evaluator]: Inference done 142/144. Dataloading: 0.0042 s/iter. Inference: 0.0838 s/iter. Eval: 0.1101 s/iter. Total: 0.1982 s/iter. ETA=0:00:00
[09/02 15:21:17 d2.evaluation.evaluator]: Total inference time: 0:00:28.112463 (0.202248 s / iter per device, on 1 devices)
[09/02 15:21:17 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:11 (0.084007 s / iter per device, on 1 devices)
[09/02 15:21:17 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 15:21:17 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 15:21:17 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/02 15:21:17 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 15:21:17 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/02 15:21:17 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:21:17 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.464
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.683
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.538
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.173
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.434
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.590
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.326
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.578
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.624
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.367
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.599
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.714
[09/02 15:21:17 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.399 | 68.281 | 53.828 | 17.270 | 43.386 | 59.031 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[09/02 15:21:17 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 15:21:17 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/02 15:21:17 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:21:17 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.490
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.698
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.593
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.162
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.431
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.647
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.342
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.602
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.648
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.425
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.614
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.748
[09/02 15:21:17 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.951 | 69.805 | 59.254 | 16.223 | 43.112 | 64.708 |
[09/02 15:21:17 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 15:21:17 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 15:21:17 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:21:17 d2.evaluation.testing]: copypaste: 46.3993,68.2815,53.8279,17.2697,43.3856,59.0309
[09/02 15:21:17 d2.evaluation.testing]: copypaste: Task: segm
[09/02 15:21:17 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:21:17 d2.evaluation.testing]: copypaste: 48.9510,69.8046,59.2544,16.2230,43.1115,64.7080
[09/02 15:21:17 d2.utils.events]:  eta: 0:01:21  iter: 879  total_loss: 0.4883  loss_cls: 0.08226  loss_box_reg: 0.1612  loss_mask: 0.1776  loss_rpn_cls: 0.00763  loss_rpn_loc: 0.006896  time: 0.6969  data_time: 0.0567  lr: 0.00021978  max_mem: 4442M
[09/02 15:21:32 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 15:21:32 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 15:21:32 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 15:21:32 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 15:21:32 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 15:21:35 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0049 s/iter. Inference: 0.0808 s/iter. Eval: 0.0883 s/iter. Total: 0.1739 s/iter. ETA=0:00:23
[09/02 15:21:40 d2.evaluation.evaluator]: Inference done 43/144. Dataloading: 0.0053 s/iter. Inference: 0.0820 s/iter. Eval: 0.0725 s/iter. Total: 0.1598 s/iter. ETA=0:00:16
[09/02 15:21:45 d2.evaluation.evaluator]: Inference done 61/144. Dataloading: 0.0046 s/iter. Inference: 0.0842 s/iter. Eval: 0.1120 s/iter. Total: 0.2009 s/iter. ETA=0:00:16
[09/02 15:21:50 d2.evaluation.evaluator]: Inference done 90/144. Dataloading: 0.0040 s/iter. Inference: 0.0837 s/iter. Eval: 0.1048 s/iter. Total: 0.1926 s/iter. ETA=0:00:10
[09/02 15:21:55 d2.evaluation.evaluator]: Inference done 116/144. Dataloading: 0.0044 s/iter. Inference: 0.0856 s/iter. Eval: 0.1033 s/iter. Total: 0.1934 s/iter. ETA=0:00:05
[09/02 15:22:00 d2.evaluation.evaluator]: Total inference time: 0:00:26.318925 (0.189345 s / iter per device, on 1 devices)
[09/02 15:22:00 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:11 (0.085143 s / iter per device, on 1 devices)
[09/02 15:22:00 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 15:22:00 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 15:22:00 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/02 15:22:00 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 15:22:00 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/02 15:22:00 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:22:00 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.469
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.681
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.525
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.192
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.442
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.598
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.336
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.582
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.625
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.367
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.593
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.729
[09/02 15:22:00 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.927 | 68.102 | 52.515 | 19.245 | 44.171 | 59.850 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[09/02 15:22:00 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 15:22:00 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/02 15:22:00 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:22:00 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.489
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.700
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.582
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.162
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.428
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.650
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.351
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.598
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.651
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.408
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.765
[09/02 15:22:00 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.900 | 69.998 | 58.165 | 16.182 | 42.783 | 64.969 |
[09/02 15:22:00 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 15:22:00 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 15:22:00 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:22:00 d2.evaluation.testing]: copypaste: 46.9270,68.1017,52.5150,19.2448,44.1707,59.8497
[09/02 15:22:00 d2.evaluation.testing]: copypaste: Task: segm
[09/02 15:22:00 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:22:00 d2.evaluation.testing]: copypaste: 48.9001,69.9980,58.1649,16.1820,42.7828,64.9692
[09/02 15:22:00 d2.utils.events]:  eta: 0:01:07  iter: 899  total_loss: 0.5501  loss_cls: 0.09219  loss_box_reg: 0.1594  loss_mask: 0.1966  loss_rpn_cls: 0.007821  loss_rpn_loc: 0.005661  time: 0.6975  data_time: 0.0884  lr: 0.00022478  max_mem: 4442M
[09/02 15:22:14 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 15:22:14 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 15:22:14 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 15:22:14 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 15:22:14 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 15:22:17 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0018 s/iter. Inference: 0.0802 s/iter. Eval: 0.0815 s/iter. Total: 0.1634 s/iter. ETA=0:00:21
[09/02 15:22:22 d2.evaluation.evaluator]: Inference done 45/144. Dataloading: 0.0045 s/iter. Inference: 0.0819 s/iter. Eval: 0.0698 s/iter. Total: 0.1563 s/iter. ETA=0:00:15
[09/02 15:22:27 d2.evaluation.evaluator]: Inference done 62/144. Dataloading: 0.0043 s/iter. Inference: 0.0852 s/iter. Eval: 0.1085 s/iter. Total: 0.1981 s/iter. ETA=0:00:16
[09/02 15:22:32 d2.evaluation.evaluator]: Inference done 93/144. Dataloading: 0.0041 s/iter. Inference: 0.0845 s/iter. Eval: 0.0967 s/iter. Total: 0.1854 s/iter. ETA=0:00:09
[09/02 15:22:37 d2.evaluation.evaluator]: Inference done 123/144. Dataloading: 0.0045 s/iter. Inference: 0.0847 s/iter. Eval: 0.0920 s/iter. Total: 0.1813 s/iter. ETA=0:00:03
[09/02 15:22:41 d2.evaluation.evaluator]: Total inference time: 0:00:24.877356 (0.178974 s / iter per device, on 1 devices)
[09/02 15:22:41 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:11 (0.084433 s / iter per device, on 1 devices)
[09/02 15:22:41 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 15:22:41 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 15:22:41 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/02 15:22:41 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 15:22:41 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/02 15:22:41 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:22:41 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.461
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.674
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.530
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.205
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.428
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.591
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.332
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.573
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.618
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.383
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.584
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.720
[09/02 15:22:41 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.083 | 67.447 | 53.001 | 20.471 | 42.814 | 59.100 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[09/02 15:22:41 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 15:22:41 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/02 15:22:41 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:22:41 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.486
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.690
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.576
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.174
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.422
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.651
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.347
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.593
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.647
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.425
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.604
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.761
[09/02 15:22:41 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.610 | 68.953 | 57.621 | 17.407 | 42.236 | 65.139 |
[09/02 15:22:41 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 15:22:41 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 15:22:41 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:22:41 d2.evaluation.testing]: copypaste: 46.0829,67.4474,53.0013,20.4714,42.8143,59.1001
[09/02 15:22:41 d2.evaluation.testing]: copypaste: Task: segm
[09/02 15:22:41 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:22:41 d2.evaluation.testing]: copypaste: 48.6102,68.9532,57.6209,17.4070,42.2359,65.1387
[09/02 15:22:41 d2.utils.events]:  eta: 0:00:54  iter: 919  total_loss: 0.4746  loss_cls: 0.08191  loss_box_reg: 0.182  loss_mask: 0.1795  loss_rpn_cls: 0.008316  loss_rpn_loc: 0.01239  time: 0.6972  data_time: 0.0595  lr: 0.00022977  max_mem: 4442M
[09/02 15:22:55 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 15:22:55 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 15:22:55 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 15:22:55 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 15:22:55 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 15:22:58 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0072 s/iter. Inference: 0.0995 s/iter. Eval: 0.1544 s/iter. Total: 0.2611 s/iter. ETA=0:00:34
[09/02 15:23:03 d2.evaluation.evaluator]: Inference done 44/144. Dataloading: 0.0048 s/iter. Inference: 0.0848 s/iter. Eval: 0.0823 s/iter. Total: 0.1720 s/iter. ETA=0:00:17
[09/02 15:23:09 d2.evaluation.evaluator]: Inference done 64/144. Dataloading: 0.0040 s/iter. Inference: 0.0856 s/iter. Eval: 0.1109 s/iter. Total: 0.2007 s/iter. ETA=0:00:16
[09/02 15:23:14 d2.evaluation.evaluator]: Inference done 93/144. Dataloading: 0.0041 s/iter. Inference: 0.0853 s/iter. Eval: 0.1024 s/iter. Total: 0.1919 s/iter. ETA=0:00:09
[09/02 15:23:19 d2.evaluation.evaluator]: Inference done 124/144. Dataloading: 0.0043 s/iter. Inference: 0.0844 s/iter. Eval: 0.0961 s/iter. Total: 0.1848 s/iter. ETA=0:00:03
[09/02 15:23:22 d2.evaluation.evaluator]: Total inference time: 0:00:25.659488 (0.184601 s / iter per device, on 1 devices)
[09/02 15:23:22 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:11 (0.084403 s / iter per device, on 1 devices)
[09/02 15:23:22 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 15:23:22 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 15:23:22 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/02 15:23:22 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 15:23:22 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/02 15:23:22 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:23:22 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.457
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.666
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.528
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.208
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.424
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.587
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.318
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.572
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.408
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.585
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.715
[09/02 15:23:22 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.699 | 66.612 | 52.832 | 20.770 | 42.383 | 58.734 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[09/02 15:23:23 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 15:23:23 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/02 15:23:23 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:23:23 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.482
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.683
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.571
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.176
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.427
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.643
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.336
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.596
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.649
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.433
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.756
[09/02 15:23:23 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.205 | 68.316 | 57.092 | 17.561 | 42.717 | 64.293 |
[09/02 15:23:23 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 15:23:23 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 15:23:23 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:23:23 d2.evaluation.testing]: copypaste: 45.6990,66.6117,52.8316,20.7698,42.3833,58.7336
[09/02 15:23:23 d2.evaluation.testing]: copypaste: Task: segm
[09/02 15:23:23 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:23:23 d2.evaluation.testing]: copypaste: 48.2045,68.3162,57.0919,17.5609,42.7173,64.2935
[09/02 15:23:23 d2.utils.events]:  eta: 0:00:40  iter: 939  total_loss: 0.4691  loss_cls: 0.09394  loss_box_reg: 0.1465  loss_mask: 0.1885  loss_rpn_cls: 0.009043  loss_rpn_loc: 0.009458  time: 0.6967  data_time: 0.0590  lr: 0.00023477  max_mem: 4442M
[09/02 15:23:37 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 15:23:37 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 15:23:37 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 15:23:37 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 15:23:37 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 15:23:40 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.0822 s/iter. Eval: 0.0949 s/iter. Total: 0.1787 s/iter. ETA=0:00:23
[09/02 15:23:45 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0044 s/iter. Inference: 0.0825 s/iter. Eval: 0.0838 s/iter. Total: 0.1708 s/iter. ETA=0:00:17
[09/02 15:23:50 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0038 s/iter. Inference: 0.0852 s/iter. Eval: 0.1216 s/iter. Total: 0.2107 s/iter. ETA=0:00:18
[09/02 15:23:55 d2.evaluation.evaluator]: Inference done 79/144. Dataloading: 0.0040 s/iter. Inference: 0.0864 s/iter. Eval: 0.1307 s/iter. Total: 0.2213 s/iter. ETA=0:00:14
[09/02 15:24:00 d2.evaluation.evaluator]: Inference done 110/144. Dataloading: 0.0039 s/iter. Inference: 0.0852 s/iter. Eval: 0.1150 s/iter. Total: 0.2043 s/iter. ETA=0:00:06
[09/02 15:24:06 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0042 s/iter. Inference: 0.0858 s/iter. Eval: 0.1118 s/iter. Total: 0.2019 s/iter. ETA=0:00:01
[09/02 15:24:07 d2.evaluation.evaluator]: Total inference time: 0:00:28.515771 (0.205149 s / iter per device, on 1 devices)
[09/02 15:24:07 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:11 (0.085899 s / iter per device, on 1 devices)
[09/02 15:24:08 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 15:24:08 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 15:24:08 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/02 15:24:08 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 15:24:08 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/02 15:24:08 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:24:08 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.459
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.686
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.523
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.173
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.428
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.588
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.320
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.570
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.626
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.400
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.599
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.715
[09/02 15:24:08 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.875 | 68.600 | 52.252 | 17.313 | 42.758 | 58.804 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[09/02 15:24:08 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 15:24:08 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/02 15:24:08 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:24:08 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.485
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.690
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.572
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.149
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.426
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.652
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.342
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.595
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.652
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.425
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.762
[09/02 15:24:08 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.538 | 68.970 | 57.185 | 14.932 | 42.608 | 65.165 |
[09/02 15:24:08 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 15:24:08 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 15:24:08 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:24:08 d2.evaluation.testing]: copypaste: 45.8749,68.6000,52.2521,17.3134,42.7583,58.8045
[09/02 15:24:08 d2.evaluation.testing]: copypaste: Task: segm
[09/02 15:24:08 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:24:08 d2.evaluation.testing]: copypaste: 48.5380,68.9698,57.1848,14.9316,42.6079,65.1650
[09/02 15:24:08 d2.utils.events]:  eta: 0:00:27  iter: 959  total_loss: 0.5646  loss_cls: 0.1141  loss_box_reg: 0.2197  loss_mask: 0.2038  loss_rpn_cls: 0.008887  loss_rpn_loc: 0.009188  time: 0.6970  data_time: 0.0753  lr: 0.00023976  max_mem: 4442M
[09/02 15:24:21 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 15:24:21 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 15:24:21 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 15:24:21 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 15:24:21 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 15:24:24 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0066 s/iter. Inference: 0.0791 s/iter. Eval: 0.0703 s/iter. Total: 0.1559 s/iter. ETA=0:00:20
[09/02 15:24:29 d2.evaluation.evaluator]: Inference done 44/144. Dataloading: 0.0047 s/iter. Inference: 0.0835 s/iter. Eval: 0.0679 s/iter. Total: 0.1562 s/iter. ETA=0:00:15
[09/02 15:24:34 d2.evaluation.evaluator]: Inference done 64/144. Dataloading: 0.0039 s/iter. Inference: 0.0847 s/iter. Eval: 0.1014 s/iter. Total: 0.1901 s/iter. ETA=0:00:15
[09/02 15:24:40 d2.evaluation.evaluator]: Inference done 91/144. Dataloading: 0.0045 s/iter. Inference: 0.0858 s/iter. Eval: 0.0994 s/iter. Total: 0.1898 s/iter. ETA=0:00:10
[09/02 15:24:45 d2.evaluation.evaluator]: Inference done 124/144. Dataloading: 0.0047 s/iter. Inference: 0.0843 s/iter. Eval: 0.0903 s/iter. Total: 0.1794 s/iter. ETA=0:00:03
[09/02 15:24:48 d2.evaluation.evaluator]: Total inference time: 0:00:24.934893 (0.179388 s / iter per device, on 1 devices)
[09/02 15:24:48 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:11 (0.084108 s / iter per device, on 1 devices)
[09/02 15:24:48 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 15:24:48 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 15:24:48 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/02 15:24:48 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 15:24:48 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/02 15:24:48 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:24:48 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.460
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.686
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.523
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.227
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.437
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.584
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.325
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.578
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.611
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.367
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.581
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.709
[09/02 15:24:48 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.010 | 68.591 | 52.338 | 22.667 | 43.662 | 58.403 |
Loading and preparing results...
DONE (t=0.06s)
creating index...
index created!
[09/02 15:24:48 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 15:24:49 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.08 seconds.
[09/02 15:24:49 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:24:49 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.490
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.696
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.586
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.179
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.429
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.650
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.347
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.602
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.644
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.417
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.600
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.761
[09/02 15:24:49 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.982 | 69.552 | 58.576 | 17.867 | 42.904 | 64.964 |
[09/02 15:24:49 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 15:24:49 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 15:24:49 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:24:49 d2.evaluation.testing]: copypaste: 46.0100,68.5913,52.3382,22.6671,43.6625,58.4027
[09/02 15:24:49 d2.evaluation.testing]: copypaste: Task: segm
[09/02 15:24:49 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:24:49 d2.evaluation.testing]: copypaste: 48.9818,69.5516,58.5762,17.8669,42.9042,64.9644
[09/02 15:24:49 d2.utils.events]:  eta: 0:00:13  iter: 979  total_loss: 0.3742  loss_cls: 0.06853  loss_box_reg: 0.1589  loss_mask: 0.148  loss_rpn_cls: 0.004846  loss_rpn_loc: 0.003781  time: 0.6966  data_time: 0.0525  lr: 0.00024476  max_mem: 4442M
[09/02 15:25:03 d2.utils.events]:  eta: 0:00:00  iter: 999  total_loss: 0.4439  loss_cls: 0.07709  loss_box_reg: 0.1673  loss_mask: 0.156  loss_rpn_cls: 0.005938  loss_rpn_loc: 0.005973  time: 0.6964  data_time: 0.0688  lr: 0.00024975  max_mem: 4442M
[09/02 15:25:03 d2.engine.hooks]: Overall training speed: 998 iterations in 0:11:35 (0.6964 s / it)
[09/02 15:25:03 d2.engine.hooks]: Total training time: 1:05:15 (0:53:40 on hooks)
[09/02 15:25:03 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/02 15:25:03 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/02 15:25:03 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/02 15:25:03 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/02 15:25:03 d2.evaluation.evaluator]: Start inference on 144 batches
[09/02 15:25:05 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0028 s/iter. Inference: 0.0806 s/iter. Eval: 0.0629 s/iter. Total: 0.1463 s/iter. ETA=0:00:19
[09/02 15:25:11 d2.evaluation.evaluator]: Inference done 43/144. Dataloading: 0.0060 s/iter. Inference: 0.0859 s/iter. Eval: 0.0720 s/iter. Total: 0.1639 s/iter. ETA=0:00:16
[09/02 15:25:16 d2.evaluation.evaluator]: Inference done 64/144. Dataloading: 0.0049 s/iter. Inference: 0.0863 s/iter. Eval: 0.1001 s/iter. Total: 0.1914 s/iter. ETA=0:00:15
[09/02 15:25:21 d2.evaluation.evaluator]: Inference done 100/144. Dataloading: 0.0054 s/iter. Inference: 0.0849 s/iter. Eval: 0.0839 s/iter. Total: 0.1743 s/iter. ETA=0:00:07
[09/02 15:25:26 d2.evaluation.evaluator]: Inference done 134/144. Dataloading: 0.0049 s/iter. Inference: 0.0845 s/iter. Eval: 0.0782 s/iter. Total: 0.1678 s/iter. ETA=0:00:01
[09/02 15:25:28 d2.evaluation.evaluator]: Total inference time: 0:00:23.623695 (0.169955 s / iter per device, on 1 devices)
[09/02 15:25:28 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:11 (0.084583 s / iter per device, on 1 devices)
[09/02 15:25:28 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/02 15:25:28 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/02 15:25:28 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/02 15:25:28 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/02 15:25:28 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/02 15:25:28 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:25:28 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.464
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.691
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.525
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.189
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.436
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.597
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.326
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.575
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.611
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.575
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.721
[09/02 15:25:28 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.418 | 69.108 | 52.515 | 18.873 | 43.644 | 59.703 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[09/02 15:25:28 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/02 15:25:28 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/02 15:25:28 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/02 15:25:28 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.495
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.707
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.591
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.170
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.435
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.651
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.340
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.605
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.648
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.408
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.758
[09/02 15:25:28 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.504 | 70.652 | 59.134 | 16.951 | 43.499 | 65.081 |
[09/02 15:25:28 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[09/02 15:25:28 d2.evaluation.testing]: copypaste: Task: bbox
[09/02 15:25:28 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:25:28 d2.evaluation.testing]: copypaste: 46.4177,69.1080,52.5149,18.8732,43.6443,59.7027
[09/02 15:25:28 d2.evaluation.testing]: copypaste: Task: segm
[09/02 15:25:28 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/02 15:25:28 d2.evaluation.testing]: copypaste: 49.5035,70.6524,59.1340,16.9507,43.4992,65.0809