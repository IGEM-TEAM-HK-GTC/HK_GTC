[09/03 15:16:16 d2.engine.defaults]: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[09/03 15:16:16 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [RandomBrightness(intensity_min=0.9, intensity_max=1.1), RandomContrast(intensity_min=0.9, intensity_max=1.1), RandomFlip(prob=0.5)]
[09/03 15:16:16 d2.data.datasets.coco]: Loaded 574 images in COCO format from ../input/petbottles/plastic data/annotations/instances_train.json
[09/03 15:16:16 d2.data.build]: Distribution of instances among all 1 categories:
|  category   | #instances   |
|:-----------:|:-------------|
| PET Bottles | 1145         |
|             |              |
[09/03 15:16:16 d2.data.build]: Using training sampler TrainingSampler
[09/03 15:16:16 d2.data.common]: Serializing 574 elements to byte tensors and concatenating them all ...
[09/03 15:16:16 d2.data.common]: Serialized dataset takes 0.45 MiB
model_final_f10217.pkl: 178MB [00:08, 21.4MB/s]                              
[09/03 15:16:29 d2.engine.train_loop]: Starting training from iteration 0
[09/03 15:16:42 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 15:16:42 d2.data.build]: Distribution of instances among all 1 categories:
|  category   | #instances   |
|:-----------:|:-------------|
| PET Bottles | 193          |
|             |              |
[09/03 15:16:42 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 15:16:42 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 15:16:42 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 15:16:42 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 15:16:52 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.1343 s/iter. Eval: 0.6976 s/iter. Total: 0.8335 s/iter. ETA=0:01:50
[09/03 15:16:57 d2.evaluation.evaluator]: Inference done 18/144. Dataloading: 0.0018 s/iter. Inference: 0.1324 s/iter. Eval: 0.6859 s/iter. Total: 0.8204 s/iter. ETA=0:01:43
[09/03 15:17:03 d2.evaluation.evaluator]: Inference done 25/144. Dataloading: 0.0019 s/iter. Inference: 0.1318 s/iter. Eval: 0.6890 s/iter. Total: 0.8229 s/iter. ETA=0:01:37
[09/03 15:17:09 d2.evaluation.evaluator]: Inference done 32/144. Dataloading: 0.0019 s/iter. Inference: 0.1315 s/iter. Eval: 0.6865 s/iter. Total: 0.8201 s/iter. ETA=0:01:31
[09/03 15:17:14 d2.evaluation.evaluator]: Inference done 38/144. Dataloading: 0.0019 s/iter. Inference: 0.1314 s/iter. Eval: 0.7053 s/iter. Total: 0.8389 s/iter. ETA=0:01:28
[09/03 15:17:20 d2.evaluation.evaluator]: Inference done 45/144. Dataloading: 0.0019 s/iter. Inference: 0.1313 s/iter. Eval: 0.7021 s/iter. Total: 0.8355 s/iter. ETA=0:01:22
[09/03 15:17:25 d2.evaluation.evaluator]: Inference done 51/144. Dataloading: 0.0019 s/iter. Inference: 0.1312 s/iter. Eval: 0.7029 s/iter. Total: 0.8363 s/iter. ETA=0:01:17
[09/03 15:17:31 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0020 s/iter. Inference: 0.1311 s/iter. Eval: 0.6997 s/iter. Total: 0.8330 s/iter. ETA=0:01:11
[09/03 15:17:37 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0020 s/iter. Inference: 0.1310 s/iter. Eval: 0.6988 s/iter. Total: 0.8319 s/iter. ETA=0:01:05
[09/03 15:17:42 d2.evaluation.evaluator]: Inference done 72/144. Dataloading: 0.0019 s/iter. Inference: 0.1309 s/iter. Eval: 0.6965 s/iter. Total: 0.8296 s/iter. ETA=0:00:59
[09/03 15:17:48 d2.evaluation.evaluator]: Inference done 78/144. Dataloading: 0.0020 s/iter. Inference: 0.1312 s/iter. Eval: 0.7028 s/iter. Total: 0.8362 s/iter. ETA=0:00:55
[09/03 15:17:53 d2.evaluation.evaluator]: Inference done 85/144. Dataloading: 0.0020 s/iter. Inference: 0.1311 s/iter. Eval: 0.7002 s/iter. Total: 0.8336 s/iter. ETA=0:00:49
[09/03 15:17:59 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0020 s/iter. Inference: 0.1311 s/iter. Eval: 0.6998 s/iter. Total: 0.8331 s/iter. ETA=0:00:43
[09/03 15:18:05 d2.evaluation.evaluator]: Inference done 99/144. Dataloading: 0.0020 s/iter. Inference: 0.1311 s/iter. Eval: 0.6981 s/iter. Total: 0.8314 s/iter. ETA=0:00:37
[09/03 15:18:10 d2.evaluation.evaluator]: Inference done 105/144. Dataloading: 0.0020 s/iter. Inference: 0.1310 s/iter. Eval: 0.6984 s/iter. Total: 0.8316 s/iter. ETA=0:00:32
[09/03 15:18:16 d2.evaluation.evaluator]: Inference done 112/144. Dataloading: 0.0020 s/iter. Inference: 0.1309 s/iter. Eval: 0.6969 s/iter. Total: 0.8301 s/iter. ETA=0:00:26
[09/03 15:18:21 d2.evaluation.evaluator]: Inference done 118/144. Dataloading: 0.0020 s/iter. Inference: 0.1310 s/iter. Eval: 0.7026 s/iter. Total: 0.8358 s/iter. ETA=0:00:21
[09/03 15:18:27 d2.evaluation.evaluator]: Inference done 125/144. Dataloading: 0.0020 s/iter. Inference: 0.1309 s/iter. Eval: 0.7010 s/iter. Total: 0.8342 s/iter. ETA=0:00:15
[09/03 15:18:32 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0020 s/iter. Inference: 0.1309 s/iter. Eval: 0.7014 s/iter. Total: 0.8345 s/iter. ETA=0:00:10
[09/03 15:18:38 d2.evaluation.evaluator]: Inference done 138/144. Dataloading: 0.0021 s/iter. Inference: 0.1309 s/iter. Eval: 0.7003 s/iter. Total: 0.8335 s/iter. ETA=0:00:05
[09/03 15:18:43 d2.evaluation.evaluator]: Total inference time: 0:01:55.874836 (0.833632 s / iter per device, on 1 devices)
[09/03 15:18:43 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:18 (0.130876 s / iter per device, on 1 devices)
[09/03 15:18:43 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 15:18:43 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 15:18:43 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/03 15:18:43 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 15:18:43 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[09/03 15:18:43 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:18:43 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.008
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.004
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.002
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.024
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.219
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.033
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.214
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.261
[09/03 15:18:43 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.175 | 0.823  | 0.010  | 0.004 | 0.416 | 0.164 |
Loading and preparing results...
DONE (t=0.57s)
creating index...
index created!
[09/03 15:18:45 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 15:18:45 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.40 seconds.
[09/03 15:18:45 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:18:45 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.03 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.001
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000
[09/03 15:18:45 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.000 | 0.001  | 0.000  | 0.000 | 0.000 | 0.000 |
[09/03 15:18:45 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 15:18:45 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 15:18:45 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:18:45 d2.evaluation.testing]: copypaste: 0.1753,0.8229,0.0100,0.0037,0.4164,0.1636
[09/03 15:18:45 d2.evaluation.testing]: copypaste: Task: segm
[09/03 15:18:45 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:18:45 d2.evaluation.testing]: copypaste: 0.0001,0.0011,0.0000,0.0000,0.0004,0.0000
[09/03 15:18:45 d2.utils.events]:  eta: 0:10:07  iter: 19  total_loss: 1.775  loss_cls: 0.6606  loss_box_reg: 0.3338  loss_mask: 0.698  loss_rpn_cls: 0.01142  loss_rpn_loc: 0.00609  time: 0.6322  data_time: 0.0229  lr: 4.9953e-06  max_mem: 4868M
[09/03 15:18:58 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 15:18:58 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 15:18:58 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 15:18:58 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 15:18:58 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 15:19:07 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0022 s/iter. Inference: 0.1304 s/iter. Eval: 0.6661 s/iter. Total: 0.7987 s/iter. ETA=0:01:46
[09/03 15:19:12 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0028 s/iter. Inference: 0.1306 s/iter. Eval: 0.6848 s/iter. Total: 0.8184 s/iter. ETA=0:01:43
[09/03 15:19:18 d2.evaluation.evaluator]: Inference done 24/144. Dataloading: 0.0025 s/iter. Inference: 0.1310 s/iter. Eval: 0.6804 s/iter. Total: 0.8142 s/iter. ETA=0:01:37
[09/03 15:19:23 d2.evaluation.evaluator]: Inference done 30/144. Dataloading: 0.0025 s/iter. Inference: 0.1312 s/iter. Eval: 0.6990 s/iter. Total: 0.8329 s/iter. ETA=0:01:34
[09/03 15:19:29 d2.evaluation.evaluator]: Inference done 37/144. Dataloading: 0.0025 s/iter. Inference: 0.1323 s/iter. Eval: 0.6948 s/iter. Total: 0.8298 s/iter. ETA=0:01:28
[09/03 15:19:34 d2.evaluation.evaluator]: Inference done 44/144. Dataloading: 0.0024 s/iter. Inference: 0.1321 s/iter. Eval: 0.6947 s/iter. Total: 0.8295 s/iter. ETA=0:01:22
[09/03 15:19:40 d2.evaluation.evaluator]: Inference done 51/144. Dataloading: 0.0024 s/iter. Inference: 0.1318 s/iter. Eval: 0.6906 s/iter. Total: 0.8251 s/iter. ETA=0:01:16
[09/03 15:19:46 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0024 s/iter. Inference: 0.1317 s/iter. Eval: 0.6900 s/iter. Total: 0.8243 s/iter. ETA=0:01:10
[09/03 15:19:51 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0023 s/iter. Inference: 0.1316 s/iter. Eval: 0.6877 s/iter. Total: 0.8218 s/iter. ETA=0:01:04
[09/03 15:19:57 d2.evaluation.evaluator]: Inference done 72/144. Dataloading: 0.0024 s/iter. Inference: 0.1319 s/iter. Eval: 0.6879 s/iter. Total: 0.8224 s/iter. ETA=0:00:59
[09/03 15:20:02 d2.evaluation.evaluator]: Inference done 78/144. Dataloading: 0.0025 s/iter. Inference: 0.1318 s/iter. Eval: 0.6928 s/iter. Total: 0.8273 s/iter. ETA=0:00:54
[09/03 15:20:07 d2.evaluation.evaluator]: Inference done 84/144. Dataloading: 0.0025 s/iter. Inference: 0.1318 s/iter. Eval: 0.6936 s/iter. Total: 0.8282 s/iter. ETA=0:00:49
[09/03 15:20:13 d2.evaluation.evaluator]: Inference done 91/144. Dataloading: 0.0024 s/iter. Inference: 0.1317 s/iter. Eval: 0.6917 s/iter. Total: 0.8261 s/iter. ETA=0:00:43
[09/03 15:20:19 d2.evaluation.evaluator]: Inference done 98/144. Dataloading: 0.0025 s/iter. Inference: 0.1317 s/iter. Eval: 0.6916 s/iter. Total: 0.8261 s/iter. ETA=0:00:37
[09/03 15:20:25 d2.evaluation.evaluator]: Inference done 105/144. Dataloading: 0.0025 s/iter. Inference: 0.1317 s/iter. Eval: 0.6903 s/iter. Total: 0.8247 s/iter. ETA=0:00:32
[09/03 15:20:30 d2.evaluation.evaluator]: Inference done 111/144. Dataloading: 0.0025 s/iter. Inference: 0.1316 s/iter. Eval: 0.6909 s/iter. Total: 0.8253 s/iter. ETA=0:00:27
[09/03 15:20:35 d2.evaluation.evaluator]: Inference done 117/144. Dataloading: 0.0026 s/iter. Inference: 0.1317 s/iter. Eval: 0.6940 s/iter. Total: 0.8286 s/iter. ETA=0:00:22
[09/03 15:20:40 d2.evaluation.evaluator]: Inference done 123/144. Dataloading: 0.0026 s/iter. Inference: 0.1317 s/iter. Eval: 0.6943 s/iter. Total: 0.8288 s/iter. ETA=0:00:17
[09/03 15:20:45 d2.evaluation.evaluator]: Inference done 130/144. Dataloading: 0.0025 s/iter. Inference: 0.1316 s/iter. Eval: 0.6930 s/iter. Total: 0.8274 s/iter. ETA=0:00:11
[09/03 15:20:51 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0025 s/iter. Inference: 0.1316 s/iter. Eval: 0.6928 s/iter. Total: 0.8271 s/iter. ETA=0:00:05
[09/03 15:20:57 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0025 s/iter. Inference: 0.1315 s/iter. Eval: 0.6914 s/iter. Total: 0.8256 s/iter. ETA=0:00:00
[09/03 15:20:57 d2.evaluation.evaluator]: Total inference time: 0:01:54.809619 (0.825968 s / iter per device, on 1 devices)
[09/03 15:20:57 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:18 (0.131459 s / iter per device, on 1 devices)
[09/03 15:20:57 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 15:20:57 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 15:20:57 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/03 15:20:57 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 15:20:57 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[09/03 15:20:57 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:20:57 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.03 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.014
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.007
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.003
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.004
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.047
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.289
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.033
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.297
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.321
[09/03 15:20:57 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.336 | 1.375  | 0.033  | 0.006 | 0.739 | 0.307 |
Loading and preparing results...
DONE (t=0.36s)
creating index...
index created!
[09/03 15:20:58 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 15:20:59 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.25 seconds.
[09/03 15:20:59 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:20:59 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.03 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.015
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.042
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.010
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.019
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.019
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.017
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.175
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.476
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.444
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.598
[09/03 15:20:59 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 1.501 | 4.223  | 1.012  | 0.023 | 1.875 | 1.941 |
[09/03 15:20:59 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 15:20:59 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 15:20:59 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:20:59 d2.evaluation.testing]: copypaste: 0.3362,1.3746,0.0333,0.0061,0.7385,0.3069
[09/03 15:20:59 d2.evaluation.testing]: copypaste: Task: segm
[09/03 15:20:59 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:20:59 d2.evaluation.testing]: copypaste: 1.5012,4.2227,1.0124,0.0234,1.8747,1.9410
[09/03 15:20:59 d2.utils.events]:  eta: 0:09:53  iter: 39  total_loss: 1.583  loss_cls: 0.5993  loss_box_reg: 0.231  loss_mask: 0.687  loss_rpn_cls: 0.01678  loss_rpn_loc: 0.002958  time: 0.6263  data_time: 0.0074  lr: 9.9902e-06  max_mem: 4868M
[09/03 15:21:11 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 15:21:11 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 15:21:11 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 15:21:11 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 15:21:11 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 15:21:21 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0028 s/iter. Inference: 0.1310 s/iter. Eval: 0.6753 s/iter. Total: 0.8091 s/iter. ETA=0:01:47
[09/03 15:21:26 d2.evaluation.evaluator]: Inference done 18/144. Dataloading: 0.0029 s/iter. Inference: 0.1308 s/iter. Eval: 0.6856 s/iter. Total: 0.8196 s/iter. ETA=0:01:43
[09/03 15:21:32 d2.evaluation.evaluator]: Inference done 25/144. Dataloading: 0.0025 s/iter. Inference: 0.1312 s/iter. Eval: 0.6811 s/iter. Total: 0.8150 s/iter. ETA=0:01:36
[09/03 15:21:38 d2.evaluation.evaluator]: Inference done 32/144. Dataloading: 0.0025 s/iter. Inference: 0.1310 s/iter. Eval: 0.6956 s/iter. Total: 0.8294 s/iter. ETA=0:01:32
[09/03 15:21:44 d2.evaluation.evaluator]: Inference done 39/144. Dataloading: 0.0028 s/iter. Inference: 0.1314 s/iter. Eval: 0.6916 s/iter. Total: 0.8261 s/iter. ETA=0:01:26
[09/03 15:21:49 d2.evaluation.evaluator]: Inference done 45/144. Dataloading: 0.0028 s/iter. Inference: 0.1315 s/iter. Eval: 0.6937 s/iter. Total: 0.8284 s/iter. ETA=0:01:22
[09/03 15:21:55 d2.evaluation.evaluator]: Inference done 52/144. Dataloading: 0.0029 s/iter. Inference: 0.1314 s/iter. Eval: 0.6902 s/iter. Total: 0.8249 s/iter. ETA=0:01:15
[09/03 15:22:00 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0028 s/iter. Inference: 0.1316 s/iter. Eval: 0.6899 s/iter. Total: 0.8247 s/iter. ETA=0:01:10
[09/03 15:22:06 d2.evaluation.evaluator]: Inference done 66/144. Dataloading: 0.0029 s/iter. Inference: 0.1314 s/iter. Eval: 0.6870 s/iter. Total: 0.8217 s/iter. ETA=0:01:04
[09/03 15:22:11 d2.evaluation.evaluator]: Inference done 72/144. Dataloading: 0.0030 s/iter. Inference: 0.1314 s/iter. Eval: 0.6925 s/iter. Total: 0.8272 s/iter. ETA=0:00:59
[09/03 15:22:17 d2.evaluation.evaluator]: Inference done 79/144. Dataloading: 0.0031 s/iter. Inference: 0.1317 s/iter. Eval: 0.6912 s/iter. Total: 0.8264 s/iter. ETA=0:00:53
[09/03 15:22:22 d2.evaluation.evaluator]: Inference done 85/144. Dataloading: 0.0031 s/iter. Inference: 0.1317 s/iter. Eval: 0.6920 s/iter. Total: 0.8272 s/iter. ETA=0:00:48
[09/03 15:22:28 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0030 s/iter. Inference: 0.1316 s/iter. Eval: 0.6905 s/iter. Total: 0.8255 s/iter. ETA=0:00:42
[09/03 15:22:33 d2.evaluation.evaluator]: Inference done 98/144. Dataloading: 0.0032 s/iter. Inference: 0.1317 s/iter. Eval: 0.6913 s/iter. Total: 0.8266 s/iter. ETA=0:00:38
[09/03 15:22:38 d2.evaluation.evaluator]: Inference done 105/144. Dataloading: 0.0031 s/iter. Inference: 0.1317 s/iter. Eval: 0.6897 s/iter. Total: 0.8249 s/iter. ETA=0:00:32
[09/03 15:22:44 d2.evaluation.evaluator]: Inference done 112/144. Dataloading: 0.0031 s/iter. Inference: 0.1317 s/iter. Eval: 0.6932 s/iter. Total: 0.8284 s/iter. ETA=0:00:26
[09/03 15:22:50 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0031 s/iter. Inference: 0.1319 s/iter. Eval: 0.6920 s/iter. Total: 0.8274 s/iter. ETA=0:00:20
[09/03 15:22:56 d2.evaluation.evaluator]: Inference done 126/144. Dataloading: 0.0030 s/iter. Inference: 0.1319 s/iter. Eval: 0.6919 s/iter. Total: 0.8273 s/iter. ETA=0:00:14
[09/03 15:23:02 d2.evaluation.evaluator]: Inference done 133/144. Dataloading: 0.0030 s/iter. Inference: 0.1319 s/iter. Eval: 0.6905 s/iter. Total: 0.8258 s/iter. ETA=0:00:09
[09/03 15:23:07 d2.evaluation.evaluator]: Inference done 140/144. Dataloading: 0.0030 s/iter. Inference: 0.1319 s/iter. Eval: 0.6904 s/iter. Total: 0.8257 s/iter. ETA=0:00:03
[09/03 15:23:11 d2.evaluation.evaluator]: Total inference time: 0:01:54.684698 (0.825070 s / iter per device, on 1 devices)
[09/03 15:23:11 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:18 (0.131786 s / iter per device, on 1 devices)
[09/03 15:23:11 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 15:23:11 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 15:23:11 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/03 15:23:11 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 15:23:11 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[09/03 15:23:11 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:23:11 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.026
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.013
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.006
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.010
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.090
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.339
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.042
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.343
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.386
[09/03 15:23:11 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.684 | 2.639  | 0.094  | 0.014 | 1.344 | 0.632 |
Loading and preparing results...
DONE (t=0.33s)
creating index...
index created!
[09/03 15:23:12 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 15:23:12 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.23 seconds.
[09/03 15:23:12 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:23:12 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.03 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.022
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.055
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.018
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.026
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.029
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.036
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.230
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.544
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.125
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.511
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.677
[09/03 15:23:12 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 2.225 | 5.531  | 1.797  | 0.043 | 2.643 | 2.941 |
[09/03 15:23:12 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 15:23:12 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 15:23:12 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:23:12 d2.evaluation.testing]: copypaste: 0.6836,2.6386,0.0935,0.0138,1.3438,0.6319
[09/03 15:23:12 d2.evaluation.testing]: copypaste: Task: segm
[09/03 15:23:12 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:23:12 d2.evaluation.testing]: copypaste: 2.2255,5.5307,1.7969,0.0428,2.6430,2.9409
[09/03 15:23:12 d2.utils.events]:  eta: 0:09:36  iter: 59  total_loss: 1.476  loss_cls: 0.4952  loss_box_reg: 0.2787  loss_mask: 0.6654  loss_rpn_cls: 0.0115  loss_rpn_loc: 0.0039  time: 0.6238  data_time: 0.0068  lr: 1.4985e-05  max_mem: 4868M
[09/03 15:23:25 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 15:23:25 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 15:23:25 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 15:23:25 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 15:23:25 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 15:23:34 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0015 s/iter. Inference: 0.1315 s/iter. Eval: 0.6693 s/iter. Total: 0.8022 s/iter. ETA=0:01:46
[09/03 15:23:40 d2.evaluation.evaluator]: Inference done 18/144. Dataloading: 0.0021 s/iter. Inference: 0.1316 s/iter. Eval: 0.6815 s/iter. Total: 0.8154 s/iter. ETA=0:01:42
[09/03 15:23:45 d2.evaluation.evaluator]: Inference done 25/144. Dataloading: 0.0022 s/iter. Inference: 0.1312 s/iter. Eval: 0.6763 s/iter. Total: 0.8099 s/iter. ETA=0:01:36
[09/03 15:23:51 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0022 s/iter. Inference: 0.1317 s/iter. Eval: 0.6965 s/iter. Total: 0.8307 s/iter. ETA=0:01:33
[09/03 15:23:56 d2.evaluation.evaluator]: Inference done 38/144. Dataloading: 0.0022 s/iter. Inference: 0.1317 s/iter. Eval: 0.6918 s/iter. Total: 0.8259 s/iter. ETA=0:01:27
[09/03 15:24:02 d2.evaluation.evaluator]: Inference done 45/144. Dataloading: 0.0022 s/iter. Inference: 0.1317 s/iter. Eval: 0.6992 s/iter. Total: 0.8333 s/iter. ETA=0:01:22
[09/03 15:24:08 d2.evaluation.evaluator]: Inference done 52/144. Dataloading: 0.0022 s/iter. Inference: 0.1317 s/iter. Eval: 0.6959 s/iter. Total: 0.8300 s/iter. ETA=0:01:16
[09/03 15:24:14 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0021 s/iter. Inference: 0.1316 s/iter. Eval: 0.6956 s/iter. Total: 0.8296 s/iter. ETA=0:01:10
[09/03 15:24:20 d2.evaluation.evaluator]: Inference done 66/144. Dataloading: 0.0021 s/iter. Inference: 0.1315 s/iter. Eval: 0.6950 s/iter. Total: 0.8289 s/iter. ETA=0:01:04
[09/03 15:24:25 d2.evaluation.evaluator]: Inference done 72/144. Dataloading: 0.0021 s/iter. Inference: 0.1317 s/iter. Eval: 0.6987 s/iter. Total: 0.8327 s/iter. ETA=0:00:59
[09/03 15:24:31 d2.evaluation.evaluator]: Inference done 79/144. Dataloading: 0.0022 s/iter. Inference: 0.1316 s/iter. Eval: 0.6979 s/iter. Total: 0.8319 s/iter. ETA=0:00:54
[09/03 15:24:36 d2.evaluation.evaluator]: Inference done 86/144. Dataloading: 0.0022 s/iter. Inference: 0.1315 s/iter. Eval: 0.6953 s/iter. Total: 0.8294 s/iter. ETA=0:00:48
[09/03 15:24:42 d2.evaluation.evaluator]: Inference done 93/144. Dataloading: 0.0022 s/iter. Inference: 0.1315 s/iter. Eval: 0.6950 s/iter. Total: 0.8290 s/iter. ETA=0:00:42
[09/03 15:24:48 d2.evaluation.evaluator]: Inference done 100/144. Dataloading: 0.0022 s/iter. Inference: 0.1314 s/iter. Eval: 0.6934 s/iter. Total: 0.8273 s/iter. ETA=0:00:36
[09/03 15:24:54 d2.evaluation.evaluator]: Inference done 107/144. Dataloading: 0.0022 s/iter. Inference: 0.1315 s/iter. Eval: 0.6932 s/iter. Total: 0.8272 s/iter. ETA=0:00:30
[09/03 15:24:59 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0022 s/iter. Inference: 0.1317 s/iter. Eval: 0.6954 s/iter. Total: 0.8296 s/iter. ETA=0:00:25
[09/03 15:25:05 d2.evaluation.evaluator]: Inference done 120/144. Dataloading: 0.0022 s/iter. Inference: 0.1316 s/iter. Eval: 0.6956 s/iter. Total: 0.8297 s/iter. ETA=0:00:19
[09/03 15:25:10 d2.evaluation.evaluator]: Inference done 127/144. Dataloading: 0.0022 s/iter. Inference: 0.1316 s/iter. Eval: 0.6947 s/iter. Total: 0.8287 s/iter. ETA=0:00:14
[09/03 15:25:15 d2.evaluation.evaluator]: Inference done 133/144. Dataloading: 0.0023 s/iter. Inference: 0.1316 s/iter. Eval: 0.6949 s/iter. Total: 0.8290 s/iter. ETA=0:00:09
[09/03 15:25:21 d2.evaluation.evaluator]: Inference done 140/144. Dataloading: 0.0023 s/iter. Inference: 0.1316 s/iter. Eval: 0.6937 s/iter. Total: 0.8278 s/iter. ETA=0:00:03
[09/03 15:25:24 d2.evaluation.evaluator]: Total inference time: 0:01:54.980158 (0.827195 s / iter per device, on 1 devices)
[09/03 15:25:24 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:18 (0.131451 s / iter per device, on 1 devices)
[09/03 15:25:24 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 15:25:24 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 15:25:25 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/03 15:25:25 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 15:25:25 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[09/03 15:25:25 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:25:25 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.03 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.013
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.048
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.021
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.013
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.034
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.144
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.363
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.355
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.424
[09/03 15:25:25 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 1.255 | 4.753  | 0.238  | 0.064 | 2.103 | 1.290 |
Loading and preparing results...
DONE (t=0.48s)
creating index...
index created!
[09/03 15:25:26 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 15:25:26 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.30 seconds.
[09/03 15:25:26 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:25:26 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.03 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.034
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.072
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.028
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.036
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.047
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.063
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.296
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.567
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.133
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.537
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.697
[09/03 15:25:26 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 3.371 | 7.165  | 2.763  | 0.065 | 3.610 | 4.669 |
[09/03 15:25:26 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 15:25:26 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 15:25:26 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:25:26 d2.evaluation.testing]: copypaste: 1.2547,4.7534,0.2380,0.0641,2.1029,1.2902
[09/03 15:25:26 d2.evaluation.testing]: copypaste: Task: segm
[09/03 15:25:26 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:25:26 d2.evaluation.testing]: copypaste: 3.3709,7.1646,2.7633,0.0650,3.6100,4.6690
[09/03 15:25:26 d2.utils.events]:  eta: 0:09:22  iter: 79  total_loss: 1.418  loss_cls: 0.3989  loss_box_reg: 0.3332  loss_mask: 0.6388  loss_rpn_cls: 0.0226  loss_rpn_loc: 0.01112  time: 0.6222  data_time: 0.0064  lr: 1.998e-05  max_mem: 4868M
[09/03 15:25:38 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 15:25:38 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 15:25:38 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 15:25:38 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 15:25:38 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 15:25:48 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0021 s/iter. Inference: 0.1302 s/iter. Eval: 0.6988 s/iter. Total: 0.8311 s/iter. ETA=0:01:50
[09/03 15:25:53 d2.evaluation.evaluator]: Inference done 18/144. Dataloading: 0.0032 s/iter. Inference: 0.1310 s/iter. Eval: 0.6845 s/iter. Total: 0.8188 s/iter. ETA=0:01:43
[09/03 15:25:59 d2.evaluation.evaluator]: Inference done 25/144. Dataloading: 0.0028 s/iter. Inference: 0.1311 s/iter. Eval: 0.6861 s/iter. Total: 0.8201 s/iter. ETA=0:01:37
[09/03 15:26:04 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0028 s/iter. Inference: 0.1319 s/iter. Eval: 0.6961 s/iter. Total: 0.8311 s/iter. ETA=0:01:33
[09/03 15:26:10 d2.evaluation.evaluator]: Inference done 38/144. Dataloading: 0.0029 s/iter. Inference: 0.1319 s/iter. Eval: 0.6968 s/iter. Total: 0.8319 s/iter. ETA=0:01:28
[09/03 15:26:16 d2.evaluation.evaluator]: Inference done 45/144. Dataloading: 0.0028 s/iter. Inference: 0.1317 s/iter. Eval: 0.6929 s/iter. Total: 0.8277 s/iter. ETA=0:01:21
[09/03 15:26:22 d2.evaluation.evaluator]: Inference done 52/144. Dataloading: 0.0027 s/iter. Inference: 0.1316 s/iter. Eval: 0.6927 s/iter. Total: 0.8272 s/iter. ETA=0:01:16
[09/03 15:26:27 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0027 s/iter. Inference: 0.1315 s/iter. Eval: 0.6946 s/iter. Total: 0.8290 s/iter. ETA=0:01:11
[09/03 15:26:33 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0028 s/iter. Inference: 0.1314 s/iter. Eval: 0.6944 s/iter. Total: 0.8288 s/iter. ETA=0:01:05
[09/03 15:26:38 d2.evaluation.evaluator]: Inference done 72/144. Dataloading: 0.0027 s/iter. Inference: 0.1314 s/iter. Eval: 0.6922 s/iter. Total: 0.8265 s/iter. ETA=0:00:59
[09/03 15:26:44 d2.evaluation.evaluator]: Inference done 78/144. Dataloading: 0.0026 s/iter. Inference: 0.1315 s/iter. Eval: 0.6989 s/iter. Total: 0.8333 s/iter. ETA=0:00:54
[09/03 15:26:49 d2.evaluation.evaluator]: Inference done 85/144. Dataloading: 0.0026 s/iter. Inference: 0.1315 s/iter. Eval: 0.6968 s/iter. Total: 0.8311 s/iter. ETA=0:00:49
[09/03 15:26:55 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0025 s/iter. Inference: 0.1316 s/iter. Eval: 0.6963 s/iter. Total: 0.8306 s/iter. ETA=0:00:43
[09/03 15:27:01 d2.evaluation.evaluator]: Inference done 99/144. Dataloading: 0.0025 s/iter. Inference: 0.1316 s/iter. Eval: 0.6942 s/iter. Total: 0.8286 s/iter. ETA=0:00:37
[09/03 15:27:06 d2.evaluation.evaluator]: Inference done 106/144. Dataloading: 0.0025 s/iter. Inference: 0.1316 s/iter. Eval: 0.6940 s/iter. Total: 0.8283 s/iter. ETA=0:00:31
[09/03 15:27:12 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0026 s/iter. Inference: 0.1315 s/iter. Eval: 0.6928 s/iter. Total: 0.8271 s/iter. ETA=0:00:25
[09/03 15:27:18 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0026 s/iter. Inference: 0.1315 s/iter. Eval: 0.6969 s/iter. Total: 0.8312 s/iter. ETA=0:00:20
[09/03 15:27:23 d2.evaluation.evaluator]: Inference done 126/144. Dataloading: 0.0027 s/iter. Inference: 0.1314 s/iter. Eval: 0.6953 s/iter. Total: 0.8296 s/iter. ETA=0:00:14
[09/03 15:27:28 d2.evaluation.evaluator]: Inference done 132/144. Dataloading: 0.0026 s/iter. Inference: 0.1315 s/iter. Eval: 0.6956 s/iter. Total: 0.8299 s/iter. ETA=0:00:09
[09/03 15:27:34 d2.evaluation.evaluator]: Inference done 139/144. Dataloading: 0.0027 s/iter. Inference: 0.1314 s/iter. Eval: 0.6944 s/iter. Total: 0.8287 s/iter. ETA=0:00:04
[09/03 15:27:38 d2.evaluation.evaluator]: Total inference time: 0:01:55.239845 (0.829064 s / iter per device, on 1 devices)
[09/03 15:27:38 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:18 (0.131319 s / iter per device, on 1 devices)
[09/03 15:27:38 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 15:27:38 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 15:27:38 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/03 15:27:38 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 15:27:39 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[09/03 15:27:39 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:27:39 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.03 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.021
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.078
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.004
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.030
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.025
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.049
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.194
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.382
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.108
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.377
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.442
[09/03 15:27:39 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 2.133 | 7.836  | 0.439  | 0.164 | 3.002 | 2.467 |
Loading and preparing results...
DONE (t=0.31s)
creating index...
index created!
[09/03 15:27:39 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 15:27:40 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.22 seconds.
[09/03 15:27:40 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:27:40 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.051
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.107
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.045
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.048
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.083
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.089
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.338
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.577
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.142
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.546
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.711
[09/03 15:27:40 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 5.102 | 10.736 | 4.490  | 0.122 | 4.752 | 8.281 |
[09/03 15:27:40 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 15:27:40 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 15:27:40 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:27:40 d2.evaluation.testing]: copypaste: 2.1326,7.8363,0.4386,0.1635,3.0020,2.4668
[09/03 15:27:40 d2.evaluation.testing]: copypaste: Task: segm
[09/03 15:27:40 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:27:40 d2.evaluation.testing]: copypaste: 5.1017,10.7360,4.4903,0.1215,4.7515,8.2813
[09/03 15:27:40 d2.utils.events]:  eta: 0:09:09  iter: 99  total_loss: 1.132  loss_cls: 0.2972  loss_box_reg: 0.2864  loss_mask: 0.5928  loss_rpn_cls: 0.01147  loss_rpn_loc: 0.003139  time: 0.6212  data_time: 0.0062  lr: 2.4975e-05  max_mem: 4868M
[09/03 15:27:52 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 15:27:52 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 15:27:52 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 15:27:52 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 15:27:52 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 15:28:02 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0024 s/iter. Inference: 0.1311 s/iter. Eval: 0.6973 s/iter. Total: 0.8308 s/iter. ETA=0:01:50
[09/03 15:28:07 d2.evaluation.evaluator]: Inference done 18/144. Dataloading: 0.0027 s/iter. Inference: 0.1310 s/iter. Eval: 0.6816 s/iter. Total: 0.8155 s/iter. ETA=0:01:42
[09/03 15:28:13 d2.evaluation.evaluator]: Inference done 25/144. Dataloading: 0.0028 s/iter. Inference: 0.1312 s/iter. Eval: 0.6860 s/iter. Total: 0.8202 s/iter. ETA=0:01:37
[09/03 15:28:19 d2.evaluation.evaluator]: Inference done 32/144. Dataloading: 0.0026 s/iter. Inference: 0.1313 s/iter. Eval: 0.6841 s/iter. Total: 0.8183 s/iter. ETA=0:01:31
[09/03 15:28:24 d2.evaluation.evaluator]: Inference done 38/144. Dataloading: 0.0025 s/iter. Inference: 0.1317 s/iter. Eval: 0.7020 s/iter. Total: 0.8365 s/iter. ETA=0:01:28
[09/03 15:28:30 d2.evaluation.evaluator]: Inference done 45/144. Dataloading: 0.0025 s/iter. Inference: 0.1317 s/iter. Eval: 0.6964 s/iter. Total: 0.8308 s/iter. ETA=0:01:22
[09/03 15:28:36 d2.evaluation.evaluator]: Inference done 52/144. Dataloading: 0.0026 s/iter. Inference: 0.1316 s/iter. Eval: 0.6954 s/iter. Total: 0.8297 s/iter. ETA=0:01:16
[09/03 15:28:41 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0025 s/iter. Inference: 0.1315 s/iter. Eval: 0.6917 s/iter. Total: 0.8259 s/iter. ETA=0:01:10
[09/03 15:28:46 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0026 s/iter. Inference: 0.1315 s/iter. Eval: 0.6958 s/iter. Total: 0.8301 s/iter. ETA=0:01:05
[09/03 15:28:52 d2.evaluation.evaluator]: Inference done 72/144. Dataloading: 0.0025 s/iter. Inference: 0.1314 s/iter. Eval: 0.6930 s/iter. Total: 0.8271 s/iter. ETA=0:00:59
[09/03 15:28:57 d2.evaluation.evaluator]: Inference done 78/144. Dataloading: 0.0029 s/iter. Inference: 0.1322 s/iter. Eval: 0.6984 s/iter. Total: 0.8337 s/iter. ETA=0:00:55
[09/03 15:29:03 d2.evaluation.evaluator]: Inference done 85/144. Dataloading: 0.0028 s/iter. Inference: 0.1321 s/iter. Eval: 0.6959 s/iter. Total: 0.8311 s/iter. ETA=0:00:49
[09/03 15:29:09 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0028 s/iter. Inference: 0.1322 s/iter. Eval: 0.6954 s/iter. Total: 0.8306 s/iter. ETA=0:00:43
[09/03 15:29:14 d2.evaluation.evaluator]: Inference done 99/144. Dataloading: 0.0028 s/iter. Inference: 0.1321 s/iter. Eval: 0.6933 s/iter. Total: 0.8284 s/iter. ETA=0:00:37
[09/03 15:29:20 d2.evaluation.evaluator]: Inference done 106/144. Dataloading: 0.0027 s/iter. Inference: 0.1321 s/iter. Eval: 0.6935 s/iter. Total: 0.8285 s/iter. ETA=0:00:31
[09/03 15:29:26 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0027 s/iter. Inference: 0.1320 s/iter. Eval: 0.6922 s/iter. Total: 0.8271 s/iter. ETA=0:00:25
[09/03 15:29:31 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0027 s/iter. Inference: 0.1320 s/iter. Eval: 0.6968 s/iter. Total: 0.8317 s/iter. ETA=0:00:20
[09/03 15:29:37 d2.evaluation.evaluator]: Inference done 126/144. Dataloading: 0.0027 s/iter. Inference: 0.1319 s/iter. Eval: 0.6955 s/iter. Total: 0.8303 s/iter. ETA=0:00:14
[09/03 15:29:43 d2.evaluation.evaluator]: Inference done 133/144. Dataloading: 0.0027 s/iter. Inference: 0.1319 s/iter. Eval: 0.6953 s/iter. Total: 0.8301 s/iter. ETA=0:00:09
[09/03 15:29:48 d2.evaluation.evaluator]: Inference done 140/144. Dataloading: 0.0026 s/iter. Inference: 0.1318 s/iter. Eval: 0.6940 s/iter. Total: 0.8287 s/iter. ETA=0:00:03
[09/03 15:29:52 d2.evaluation.evaluator]: Total inference time: 0:01:55.248158 (0.829123 s / iter per device, on 1 devices)
[09/03 15:29:52 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:18 (0.131732 s / iter per device, on 1 devices)
[09/03 15:29:52 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 15:29:52 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 15:29:52 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/03 15:29:52 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 15:29:52 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.12 seconds.
[09/03 15:29:52 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:29:52 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.037
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.122
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.011
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.041
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.049
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.074
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.251
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.416
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.117
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.406
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.488
[09/03 15:29:52 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 3.672 | 12.151 | 1.099  | 0.320 | 4.134 | 4.918 |
Loading and preparing results...
DONE (t=0.32s)
creating index...
index created!
[09/03 15:29:53 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 15:29:53 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.23 seconds.
[09/03 15:29:53 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:29:53 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.03 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.078
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.153
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.068
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.061
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.141
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.111
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.381
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.594
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.142
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.570
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.718
[09/03 15:29:53 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 7.763 | 15.314 | 6.821  | 0.234 | 6.061 | 14.144 |
[09/03 15:29:53 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 15:29:53 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 15:29:53 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:29:53 d2.evaluation.testing]: copypaste: 3.6716,12.1509,1.0989,0.3200,4.1335,4.9183
[09/03 15:29:53 d2.evaluation.testing]: copypaste: Task: segm
[09/03 15:29:53 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:29:53 d2.evaluation.testing]: copypaste: 7.7629,15.3143,6.8208,0.2345,6.0610,14.1444
[09/03 15:29:53 d2.utils.events]:  eta: 0:08:55  iter: 119  total_loss: 1.123  loss_cls: 0.2581  loss_box_reg: 0.285  loss_mask: 0.5456  loss_rpn_cls: 0.008711  loss_rpn_loc: 0.003722  time: 0.6209  data_time: 0.0062  lr: 2.997e-05  max_mem: 4868M
[09/03 15:30:06 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 15:30:06 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 15:30:06 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 15:30:06 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 15:30:06 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 15:30:15 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.1311 s/iter. Eval: 0.6946 s/iter. Total: 0.8273 s/iter. ETA=0:01:50
[09/03 15:30:21 d2.evaluation.evaluator]: Inference done 18/144. Dataloading: 0.0026 s/iter. Inference: 0.1307 s/iter. Eval: 0.6813 s/iter. Total: 0.8149 s/iter. ETA=0:01:42
[09/03 15:30:27 d2.evaluation.evaluator]: Inference done 25/144. Dataloading: 0.0024 s/iter. Inference: 0.1311 s/iter. Eval: 0.6853 s/iter. Total: 0.8191 s/iter. ETA=0:01:37
[09/03 15:30:32 d2.evaluation.evaluator]: Inference done 32/144. Dataloading: 0.0024 s/iter. Inference: 0.1309 s/iter. Eval: 0.6819 s/iter. Total: 0.8154 s/iter. ETA=0:01:31
[09/03 15:30:38 d2.evaluation.evaluator]: Inference done 38/144. Dataloading: 0.0027 s/iter. Inference: 0.1317 s/iter. Eval: 0.6976 s/iter. Total: 0.8323 s/iter. ETA=0:01:28
[09/03 15:30:43 d2.evaluation.evaluator]: Inference done 45/144. Dataloading: 0.0026 s/iter. Inference: 0.1315 s/iter. Eval: 0.6931 s/iter. Total: 0.8274 s/iter. ETA=0:01:21
[09/03 15:30:49 d2.evaluation.evaluator]: Inference done 52/144. Dataloading: 0.0027 s/iter. Inference: 0.1321 s/iter. Eval: 0.6921 s/iter. Total: 0.8271 s/iter. ETA=0:01:16
[09/03 15:30:55 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0026 s/iter. Inference: 0.1321 s/iter. Eval: 0.6903 s/iter. Total: 0.8252 s/iter. ETA=0:01:10
[09/03 15:31:00 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0026 s/iter. Inference: 0.1319 s/iter. Eval: 0.6913 s/iter. Total: 0.8260 s/iter. ETA=0:01:05
[09/03 15:31:06 d2.evaluation.evaluator]: Inference done 72/144. Dataloading: 0.0026 s/iter. Inference: 0.1317 s/iter. Eval: 0.6900 s/iter. Total: 0.8245 s/iter. ETA=0:00:59
[09/03 15:31:11 d2.evaluation.evaluator]: Inference done 78/144. Dataloading: 0.0025 s/iter. Inference: 0.1319 s/iter. Eval: 0.6990 s/iter. Total: 0.8336 s/iter. ETA=0:00:55
[09/03 15:31:17 d2.evaluation.evaluator]: Inference done 85/144. Dataloading: 0.0025 s/iter. Inference: 0.1318 s/iter. Eval: 0.6965 s/iter. Total: 0.8310 s/iter. ETA=0:00:49
[09/03 15:31:23 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0025 s/iter. Inference: 0.1317 s/iter. Eval: 0.6963 s/iter. Total: 0.8307 s/iter. ETA=0:00:43
[09/03 15:31:28 d2.evaluation.evaluator]: Inference done 99/144. Dataloading: 0.0025 s/iter. Inference: 0.1316 s/iter. Eval: 0.6946 s/iter. Total: 0.8289 s/iter. ETA=0:00:37
[09/03 15:31:34 d2.evaluation.evaluator]: Inference done 106/144. Dataloading: 0.0025 s/iter. Inference: 0.1316 s/iter. Eval: 0.6941 s/iter. Total: 0.8284 s/iter. ETA=0:00:31
[09/03 15:31:40 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0025 s/iter. Inference: 0.1316 s/iter. Eval: 0.6983 s/iter. Total: 0.8326 s/iter. ETA=0:00:25
[09/03 15:31:46 d2.evaluation.evaluator]: Inference done 120/144. Dataloading: 0.0025 s/iter. Inference: 0.1317 s/iter. Eval: 0.6970 s/iter. Total: 0.8315 s/iter. ETA=0:00:19
[09/03 15:31:52 d2.evaluation.evaluator]: Inference done 127/144. Dataloading: 0.0025 s/iter. Inference: 0.1316 s/iter. Eval: 0.6966 s/iter. Total: 0.8310 s/iter. ETA=0:00:14
[09/03 15:31:57 d2.evaluation.evaluator]: Inference done 134/144. Dataloading: 0.0025 s/iter. Inference: 0.1316 s/iter. Eval: 0.6950 s/iter. Total: 0.8295 s/iter. ETA=0:00:08
[09/03 15:32:02 d2.evaluation.evaluator]: Inference done 140/144. Dataloading: 0.0025 s/iter. Inference: 0.1317 s/iter. Eval: 0.6953 s/iter. Total: 0.8298 s/iter. ETA=0:00:03
[09/03 15:32:06 d2.evaluation.evaluator]: Total inference time: 0:01:55.244197 (0.829095 s / iter per device, on 1 devices)
[09/03 15:32:06 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:18 (0.131570 s / iter per device, on 1 devices)
[09/03 15:32:06 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 15:32:06 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 15:32:06 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/03 15:32:06 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 15:32:06 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[09/03 15:32:06 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:32:06 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.03 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.061
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.179
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.023
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.007
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.058
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.094
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.099
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.296
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.437
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.125
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.424
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.515
[09/03 15:32:06 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 6.107 | 17.916 | 2.322  | 0.720 | 5.787 | 9.423 |
Loading and preparing results...
DONE (t=0.31s)
creating index...
index created!
[09/03 15:32:07 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 15:32:07 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.22 seconds.
[09/03 15:32:07 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:32:07 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.117
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.217
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.109
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.081
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.231
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.145
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.419
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.607
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.142
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.582
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.736
[09/03 15:32:07 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:------:|:------:|:------:|:-----:|:-----:|:------:|
| 11.673 | 21.658 | 10.920 | 0.438 | 8.110 | 23.143 |
[09/03 15:32:07 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 15:32:07 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 15:32:07 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:32:07 d2.evaluation.testing]: copypaste: 6.1075,17.9163,2.3222,0.7201,5.7865,9.4230
[09/03 15:32:07 d2.evaluation.testing]: copypaste: Task: segm
[09/03 15:32:07 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:32:07 d2.evaluation.testing]: copypaste: 11.6728,21.6579,10.9200,0.4383,8.1105,23.1428
[09/03 15:32:07 d2.utils.events]:  eta: 0:08:44  iter: 139  total_loss: 1.214  loss_cls: 0.2742  loss_box_reg: 0.3587  loss_mask: 0.5086  loss_rpn_cls: 0.009708  loss_rpn_loc: 0.006304  time: 0.6209  data_time: 0.0068  lr: 3.4965e-05  max_mem: 4868M
[09/03 15:32:20 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 15:32:20 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 15:32:20 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 15:32:20 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 15:32:20 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 15:32:29 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0018 s/iter. Inference: 0.1303 s/iter. Eval: 0.6723 s/iter. Total: 0.8044 s/iter. ETA=0:01:46
[09/03 15:32:35 d2.evaluation.evaluator]: Inference done 18/144. Dataloading: 0.0018 s/iter. Inference: 0.1304 s/iter. Eval: 0.6815 s/iter. Total: 0.8139 s/iter. ETA=0:01:42
[09/03 15:32:41 d2.evaluation.evaluator]: Inference done 25/144. Dataloading: 0.0021 s/iter. Inference: 0.1306 s/iter. Eval: 0.6787 s/iter. Total: 0.8115 s/iter. ETA=0:01:36
[09/03 15:32:46 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0022 s/iter. Inference: 0.1308 s/iter. Eval: 0.6984 s/iter. Total: 0.8316 s/iter. ETA=0:01:33
[09/03 15:32:52 d2.evaluation.evaluator]: Inference done 38/144. Dataloading: 0.0022 s/iter. Inference: 0.1321 s/iter. Eval: 0.6941 s/iter. Total: 0.8287 s/iter. ETA=0:01:27
[09/03 15:32:57 d2.evaluation.evaluator]: Inference done 45/144. Dataloading: 0.0024 s/iter. Inference: 0.1318 s/iter. Eval: 0.6932 s/iter. Total: 0.8277 s/iter. ETA=0:01:21
[09/03 15:33:03 d2.evaluation.evaluator]: Inference done 52/144. Dataloading: 0.0024 s/iter. Inference: 0.1317 s/iter. Eval: 0.6892 s/iter. Total: 0.8236 s/iter. ETA=0:01:15
[09/03 15:33:09 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0023 s/iter. Inference: 0.1316 s/iter. Eval: 0.6894 s/iter. Total: 0.8236 s/iter. ETA=0:01:10
[09/03 15:33:14 d2.evaluation.evaluator]: Inference done 66/144. Dataloading: 0.0024 s/iter. Inference: 0.1314 s/iter. Eval: 0.6869 s/iter. Total: 0.8210 s/iter. ETA=0:01:04
[09/03 15:33:20 d2.evaluation.evaluator]: Inference done 72/144. Dataloading: 0.0024 s/iter. Inference: 0.1317 s/iter. Eval: 0.6961 s/iter. Total: 0.8304 s/iter. ETA=0:00:59
[09/03 15:33:26 d2.evaluation.evaluator]: Inference done 79/144. Dataloading: 0.0024 s/iter. Inference: 0.1316 s/iter. Eval: 0.6935 s/iter. Total: 0.8277 s/iter. ETA=0:00:53
[09/03 15:33:31 d2.evaluation.evaluator]: Inference done 86/144. Dataloading: 0.0023 s/iter. Inference: 0.1316 s/iter. Eval: 0.6933 s/iter. Total: 0.8275 s/iter. ETA=0:00:47
[09/03 15:33:37 d2.evaluation.evaluator]: Inference done 93/144. Dataloading: 0.0023 s/iter. Inference: 0.1316 s/iter. Eval: 0.6918 s/iter. Total: 0.8260 s/iter. ETA=0:00:42
[09/03 15:33:43 d2.evaluation.evaluator]: Inference done 100/144. Dataloading: 0.0024 s/iter. Inference: 0.1315 s/iter. Eval: 0.6920 s/iter. Total: 0.8262 s/iter. ETA=0:00:36
[09/03 15:33:48 d2.evaluation.evaluator]: Inference done 106/144. Dataloading: 0.0025 s/iter. Inference: 0.1314 s/iter. Eval: 0.6932 s/iter. Total: 0.8273 s/iter. ETA=0:00:31
[09/03 15:33:53 d2.evaluation.evaluator]: Inference done 112/144. Dataloading: 0.0024 s/iter. Inference: 0.1316 s/iter. Eval: 0.6970 s/iter. Total: 0.8313 s/iter. ETA=0:00:26
[09/03 15:33:59 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0024 s/iter. Inference: 0.1316 s/iter. Eval: 0.6952 s/iter. Total: 0.8295 s/iter. ETA=0:00:20
[09/03 15:34:05 d2.evaluation.evaluator]: Inference done 126/144. Dataloading: 0.0024 s/iter. Inference: 0.1316 s/iter. Eval: 0.6948 s/iter. Total: 0.8291 s/iter. ETA=0:00:14
[09/03 15:34:10 d2.evaluation.evaluator]: Inference done 133/144. Dataloading: 0.0024 s/iter. Inference: 0.1315 s/iter. Eval: 0.6936 s/iter. Total: 0.8278 s/iter. ETA=0:00:09
[09/03 15:34:16 d2.evaluation.evaluator]: Inference done 140/144. Dataloading: 0.0024 s/iter. Inference: 0.1315 s/iter. Eval: 0.6935 s/iter. Total: 0.8276 s/iter. ETA=0:00:03
[09/03 15:34:19 d2.evaluation.evaluator]: Total inference time: 0:01:54.957454 (0.827032 s / iter per device, on 1 devices)
[09/03 15:34:19 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:18 (0.131347 s / iter per device, on 1 devices)
[09/03 15:34:19 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 15:34:19 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 15:34:20 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/03 15:34:20 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 15:34:20 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.
[09/03 15:34:20 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:34:20 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.092
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.239
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.042
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.016
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.080
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.148
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.123
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.320
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.454
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.125
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.439
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.539
[09/03 15:34:20 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 9.172 | 23.947 | 4.182  | 1.588 | 7.998 | 14.760 |
Loading and preparing results...
DONE (t=0.33s)
creating index...
index created!
[09/03 15:34:21 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 15:34:21 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.24 seconds.
[09/03 15:34:21 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:34:21 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.03 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.155
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.267
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.161
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.105
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.289
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.169
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.431
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.612
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.142
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.594
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.729
[09/03 15:34:21 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 15.519 | 26.744 | 16.056 | 0.806 | 10.474 | 28.888 |
[09/03 15:34:21 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 15:34:21 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 15:34:21 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:34:21 d2.evaluation.testing]: copypaste: 9.1716,23.9467,4.1822,1.5878,7.9982,14.7596
[09/03 15:34:21 d2.evaluation.testing]: copypaste: Task: segm
[09/03 15:34:21 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:34:21 d2.evaluation.testing]: copypaste: 15.5189,26.7438,16.0559,0.8062,10.4735,28.8877
[09/03 15:34:21 d2.utils.events]:  eta: 0:08:31  iter: 159  total_loss: 1.057  loss_cls: 0.2239  loss_box_reg: 0.3173  loss_mask: 0.4597  loss_rpn_cls: 0.01417  loss_rpn_loc: 0.002735  time: 0.6211  data_time: 0.0073  lr: 3.996e-05  max_mem: 4868M
[09/03 15:34:33 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 15:34:33 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 15:34:33 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 15:34:33 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 15:34:33 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 15:34:43 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0018 s/iter. Inference: 0.1313 s/iter. Eval: 0.6715 s/iter. Total: 0.8046 s/iter. ETA=0:01:47
[09/03 15:34:49 d2.evaluation.evaluator]: Inference done 18/144. Dataloading: 0.0024 s/iter. Inference: 0.1312 s/iter. Eval: 0.6806 s/iter. Total: 0.8144 s/iter. ETA=0:01:42
[09/03 15:34:54 d2.evaluation.evaluator]: Inference done 25/144. Dataloading: 0.0024 s/iter. Inference: 0.1312 s/iter. Eval: 0.6870 s/iter. Total: 0.8208 s/iter. ETA=0:01:37
[09/03 15:35:00 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0023 s/iter. Inference: 0.1316 s/iter. Eval: 0.6960 s/iter. Total: 0.8302 s/iter. ETA=0:01:33
[09/03 15:35:05 d2.evaluation.evaluator]: Inference done 38/144. Dataloading: 0.0024 s/iter. Inference: 0.1316 s/iter. Eval: 0.6903 s/iter. Total: 0.8245 s/iter. ETA=0:01:27
[09/03 15:35:11 d2.evaluation.evaluator]: Inference done 45/144. Dataloading: 0.0023 s/iter. Inference: 0.1316 s/iter. Eval: 0.6892 s/iter. Total: 0.8234 s/iter. ETA=0:01:21
[09/03 15:35:16 d2.evaluation.evaluator]: Inference done 52/144. Dataloading: 0.0023 s/iter. Inference: 0.1315 s/iter. Eval: 0.6862 s/iter. Total: 0.8202 s/iter. ETA=0:01:15
[09/03 15:35:22 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0024 s/iter. Inference: 0.1311 s/iter. Eval: 0.6852 s/iter. Total: 0.8190 s/iter. ETA=0:01:09
[09/03 15:35:27 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0025 s/iter. Inference: 0.1315 s/iter. Eval: 0.6902 s/iter. Total: 0.8245 s/iter. ETA=0:01:05
[09/03 15:35:32 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0025 s/iter. Inference: 0.1315 s/iter. Eval: 0.6912 s/iter. Total: 0.8255 s/iter. ETA=0:01:00
[09/03 15:35:38 d2.evaluation.evaluator]: Inference done 78/144. Dataloading: 0.0024 s/iter. Inference: 0.1314 s/iter. Eval: 0.6876 s/iter. Total: 0.8216 s/iter. ETA=0:00:54
[09/03 15:35:44 d2.evaluation.evaluator]: Inference done 85/144. Dataloading: 0.0024 s/iter. Inference: 0.1313 s/iter. Eval: 0.6875 s/iter. Total: 0.8214 s/iter. ETA=0:00:48
[09/03 15:35:49 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0024 s/iter. Inference: 0.1313 s/iter. Eval: 0.6859 s/iter. Total: 0.8199 s/iter. ETA=0:00:42
[09/03 15:35:54 d2.evaluation.evaluator]: Inference done 98/144. Dataloading: 0.0024 s/iter. Inference: 0.1316 s/iter. Eval: 0.6866 s/iter. Total: 0.8208 s/iter. ETA=0:00:37
[09/03 15:36:00 d2.evaluation.evaluator]: Inference done 105/144. Dataloading: 0.0023 s/iter. Inference: 0.1316 s/iter. Eval: 0.6897 s/iter. Total: 0.8239 s/iter. ETA=0:00:32
[09/03 15:36:05 d2.evaluation.evaluator]: Inference done 111/144. Dataloading: 0.0024 s/iter. Inference: 0.1316 s/iter. Eval: 0.6904 s/iter. Total: 0.8246 s/iter. ETA=0:00:27
[09/03 15:36:11 d2.evaluation.evaluator]: Inference done 118/144. Dataloading: 0.0024 s/iter. Inference: 0.1316 s/iter. Eval: 0.6891 s/iter. Total: 0.8233 s/iter. ETA=0:00:21
[09/03 15:36:17 d2.evaluation.evaluator]: Inference done 125/144. Dataloading: 0.0023 s/iter. Inference: 0.1316 s/iter. Eval: 0.6895 s/iter. Total: 0.8237 s/iter. ETA=0:00:15
[09/03 15:36:22 d2.evaluation.evaluator]: Inference done 132/144. Dataloading: 0.0023 s/iter. Inference: 0.1315 s/iter. Eval: 0.6881 s/iter. Total: 0.8221 s/iter. ETA=0:00:09
[09/03 15:36:28 d2.evaluation.evaluator]: Inference done 138/144. Dataloading: 0.0024 s/iter. Inference: 0.1314 s/iter. Eval: 0.6905 s/iter. Total: 0.8246 s/iter. ETA=0:00:04
[09/03 15:36:32 d2.evaluation.evaluator]: Total inference time: 0:01:54.526763 (0.823934 s / iter per device, on 1 devices)
[09/03 15:36:32 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:18 (0.131145 s / iter per device, on 1 devices)
[09/03 15:36:33 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 15:36:33 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 15:36:33 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/03 15:36:33 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 15:36:33 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[09/03 15:36:33 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:36:33 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.122
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.301
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.052
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.025
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.111
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.188
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.151
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.338
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.467
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.125
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.452
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.555
[09/03 15:36:33 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 12.151 | 30.075 | 5.228  | 2.477 | 11.106 | 18.771 |
Loading and preparing results...
DONE (t=0.30s)
creating index...
index created!
[09/03 15:36:34 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 15:36:34 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.21 seconds.
[09/03 15:36:34 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:36:34 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.191
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.307
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.218
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.011
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.130
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.334
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.202
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.454
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.620
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.183
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.590
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.752
[09/03 15:36:34 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 19.063 | 30.721 | 21.837 | 1.082 | 13.022 | 33.400 |
[09/03 15:36:34 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 15:36:34 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 15:36:34 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:36:34 d2.evaluation.testing]: copypaste: 12.1507,30.0752,5.2279,2.4774,11.1063,18.7706
[09/03 15:36:34 d2.evaluation.testing]: copypaste: Task: segm
[09/03 15:36:34 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:36:34 d2.evaluation.testing]: copypaste: 19.0632,30.7208,21.8372,1.0818,13.0222,33.4000
[09/03 15:36:34 d2.utils.events]:  eta: 0:08:21  iter: 179  total_loss: 1.05  loss_cls: 0.2419  loss_box_reg: 0.3904  loss_mask: 0.378  loss_rpn_cls: 0.01052  loss_rpn_loc: 0.005712  time: 0.6213  data_time: 0.0071  lr: 4.4955e-05  max_mem: 4868M
[09/03 15:36:47 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 15:36:47 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 15:36:47 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 15:36:47 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 15:36:47 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 15:36:56 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0025 s/iter. Inference: 0.1302 s/iter. Eval: 0.6655 s/iter. Total: 0.7982 s/iter. ETA=0:01:46
[09/03 15:37:02 d2.evaluation.evaluator]: Inference done 18/144. Dataloading: 0.0025 s/iter. Inference: 0.1312 s/iter. Eval: 0.6765 s/iter. Total: 0.8104 s/iter. ETA=0:01:42
[09/03 15:37:07 d2.evaluation.evaluator]: Inference done 24/144. Dataloading: 0.0028 s/iter. Inference: 0.1311 s/iter. Eval: 0.6869 s/iter. Total: 0.8210 s/iter. ETA=0:01:38
[09/03 15:37:12 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0027 s/iter. Inference: 0.1302 s/iter. Eval: 0.6710 s/iter. Total: 0.8042 s/iter. ETA=0:01:30
[09/03 15:37:18 d2.evaluation.evaluator]: Inference done 38/144. Dataloading: 0.0027 s/iter. Inference: 0.1298 s/iter. Eval: 0.6644 s/iter. Total: 0.7971 s/iter. ETA=0:01:24
[09/03 15:37:23 d2.evaluation.evaluator]: Inference done 45/144. Dataloading: 0.0026 s/iter. Inference: 0.1295 s/iter. Eval: 0.6646 s/iter. Total: 0.7969 s/iter. ETA=0:01:18
[09/03 15:37:29 d2.evaluation.evaluator]: Inference done 52/144. Dataloading: 0.0027 s/iter. Inference: 0.1296 s/iter. Eval: 0.6648 s/iter. Total: 0.7973 s/iter. ETA=0:01:13
[09/03 15:37:34 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0030 s/iter. Inference: 0.1292 s/iter. Eval: 0.6627 s/iter. Total: 0.7951 s/iter. ETA=0:01:07
[09/03 15:37:39 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0029 s/iter. Inference: 0.1295 s/iter. Eval: 0.6715 s/iter. Total: 0.8041 s/iter. ETA=0:01:03
[09/03 15:37:45 d2.evaluation.evaluator]: Inference done 72/144. Dataloading: 0.0030 s/iter. Inference: 0.1296 s/iter. Eval: 0.6736 s/iter. Total: 0.8064 s/iter. ETA=0:00:58
[09/03 15:37:51 d2.evaluation.evaluator]: Inference done 80/144. Dataloading: 0.0030 s/iter. Inference: 0.1290 s/iter. Eval: 0.6652 s/iter. Total: 0.7974 s/iter. ETA=0:00:51
[09/03 15:37:57 d2.evaluation.evaluator]: Inference done 87/144. Dataloading: 0.0029 s/iter. Inference: 0.1292 s/iter. Eval: 0.6676 s/iter. Total: 0.8000 s/iter. ETA=0:00:45
[09/03 15:38:02 d2.evaluation.evaluator]: Inference done 94/144. Dataloading: 0.0029 s/iter. Inference: 0.1293 s/iter. Eval: 0.6678 s/iter. Total: 0.8003 s/iter. ETA=0:00:40
[09/03 15:38:07 d2.evaluation.evaluator]: Inference done 100/144. Dataloading: 0.0029 s/iter. Inference: 0.1294 s/iter. Eval: 0.6702 s/iter. Total: 0.8027 s/iter. ETA=0:00:35
[09/03 15:38:13 d2.evaluation.evaluator]: Inference done 106/144. Dataloading: 0.0030 s/iter. Inference: 0.1296 s/iter. Eval: 0.6721 s/iter. Total: 0.8049 s/iter. ETA=0:00:30
[09/03 15:38:18 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0029 s/iter. Inference: 0.1296 s/iter. Eval: 0.6728 s/iter. Total: 0.8056 s/iter. ETA=0:00:24
[09/03 15:38:24 d2.evaluation.evaluator]: Inference done 120/144. Dataloading: 0.0029 s/iter. Inference: 0.1296 s/iter. Eval: 0.6706 s/iter. Total: 0.8033 s/iter. ETA=0:00:19
[09/03 15:38:29 d2.evaluation.evaluator]: Inference done 127/144. Dataloading: 0.0028 s/iter. Inference: 0.1296 s/iter. Eval: 0.6716 s/iter. Total: 0.8043 s/iter. ETA=0:00:13
[09/03 15:38:35 d2.evaluation.evaluator]: Inference done 134/144. Dataloading: 0.0028 s/iter. Inference: 0.1295 s/iter. Eval: 0.6694 s/iter. Total: 0.8019 s/iter. ETA=0:00:08
[09/03 15:38:40 d2.evaluation.evaluator]: Inference done 141/144. Dataloading: 0.0028 s/iter. Inference: 0.1291 s/iter. Eval: 0.6660 s/iter. Total: 0.7981 s/iter. ETA=0:00:02
[09/03 15:38:43 d2.evaluation.evaluator]: Total inference time: 0:01:51.292568 (0.800666 s / iter per device, on 1 devices)
[09/03 15:38:43 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:17 (0.129082 s / iter per device, on 1 devices)
[09/03 15:38:43 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 15:38:43 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 15:38:43 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/03 15:38:43 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 15:38:43 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[09/03 15:38:43 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:38:43 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.146
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.330
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.082
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.037
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.141
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.223
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.169
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.346
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.472
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.117
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.456
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.565
[09/03 15:38:43 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 14.623 | 33.050 | 8.178  | 3.723 | 14.135 | 22.324 |
Loading and preparing results...
DONE (t=0.27s)
creating index...
index created!
[09/03 15:38:44 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 15:38:44 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.20 seconds.
[09/03 15:38:44 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:38:44 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.219
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.335
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.256
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.013
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.150
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.369
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.224
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.466
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.625
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.208
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.600
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.745
[09/03 15:38:44 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 21.939 | 33.468 | 25.633 | 1.272 | 15.046 | 36.907 |
[09/03 15:38:44 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 15:38:44 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 15:38:44 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:38:44 d2.evaluation.testing]: copypaste: 14.6233,33.0496,8.1776,3.7228,14.1352,22.3239
[09/03 15:38:44 d2.evaluation.testing]: copypaste: Task: segm
[09/03 15:38:44 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:38:44 d2.evaluation.testing]: copypaste: 21.9394,33.4682,25.6332,1.2717,15.0458,36.9068
[09/03 15:38:44 d2.utils.events]:  eta: 0:08:09  iter: 199  total_loss: 1.209  loss_cls: 0.2477  loss_box_reg: 0.4954  loss_mask: 0.3586  loss_rpn_cls: 0.0121  loss_rpn_loc: 0.005112  time: 0.6211  data_time: 0.0062  lr: 4.995e-05  max_mem: 4868M
[09/03 15:38:56 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 15:38:56 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 15:38:56 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 15:38:56 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 15:38:56 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 15:39:06 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0024 s/iter. Inference: 0.1305 s/iter. Eval: 0.6699 s/iter. Total: 0.8029 s/iter. ETA=0:01:46
[09/03 15:39:12 d2.evaluation.evaluator]: Inference done 18/144. Dataloading: 0.0023 s/iter. Inference: 0.1303 s/iter. Eval: 0.6791 s/iter. Total: 0.8120 s/iter. ETA=0:01:42
[09/03 15:39:17 d2.evaluation.evaluator]: Inference done 25/144. Dataloading: 0.0026 s/iter. Inference: 0.1289 s/iter. Eval: 0.6648 s/iter. Total: 0.7965 s/iter. ETA=0:01:34
[09/03 15:39:23 d2.evaluation.evaluator]: Inference done 33/144. Dataloading: 0.0025 s/iter. Inference: 0.1268 s/iter. Eval: 0.6425 s/iter. Total: 0.7721 s/iter. ETA=0:01:25
[09/03 15:39:28 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0025 s/iter. Inference: 0.1259 s/iter. Eval: 0.6285 s/iter. Total: 0.7571 s/iter. ETA=0:01:17
[09/03 15:39:34 d2.evaluation.evaluator]: Inference done 48/144. Dataloading: 0.0025 s/iter. Inference: 0.1265 s/iter. Eval: 0.6358 s/iter. Total: 0.7650 s/iter. ETA=0:01:13
[09/03 15:39:39 d2.evaluation.evaluator]: Inference done 55/144. Dataloading: 0.0024 s/iter. Inference: 0.1266 s/iter. Eval: 0.6326 s/iter. Total: 0.7619 s/iter. ETA=0:01:07
[09/03 15:39:44 d2.evaluation.evaluator]: Inference done 61/144. Dataloading: 0.0024 s/iter. Inference: 0.1270 s/iter. Eval: 0.6440 s/iter. Total: 0.7736 s/iter. ETA=0:01:04
[09/03 15:39:50 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0025 s/iter. Inference: 0.1279 s/iter. Eval: 0.6480 s/iter. Total: 0.7787 s/iter. ETA=0:00:59
[09/03 15:39:55 d2.evaluation.evaluator]: Inference done 75/144. Dataloading: 0.0025 s/iter. Inference: 0.1280 s/iter. Eval: 0.6459 s/iter. Total: 0.7766 s/iter. ETA=0:00:53
[09/03 15:40:01 d2.evaluation.evaluator]: Inference done 82/144. Dataloading: 0.0025 s/iter. Inference: 0.1278 s/iter. Eval: 0.6431 s/iter. Total: 0.7737 s/iter. ETA=0:00:47
[09/03 15:40:06 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0025 s/iter. Inference: 0.1280 s/iter. Eval: 0.6474 s/iter. Total: 0.7783 s/iter. ETA=0:00:42
[09/03 15:40:12 d2.evaluation.evaluator]: Inference done 96/144. Dataloading: 0.0025 s/iter. Inference: 0.1282 s/iter. Eval: 0.6491 s/iter. Total: 0.7802 s/iter. ETA=0:00:37
[09/03 15:40:17 d2.evaluation.evaluator]: Inference done 102/144. Dataloading: 0.0026 s/iter. Inference: 0.1285 s/iter. Eval: 0.6560 s/iter. Total: 0.7875 s/iter. ETA=0:00:33
[09/03 15:40:23 d2.evaluation.evaluator]: Inference done 109/144. Dataloading: 0.0025 s/iter. Inference: 0.1284 s/iter. Eval: 0.6538 s/iter. Total: 0.7851 s/iter. ETA=0:00:27
[09/03 15:40:28 d2.evaluation.evaluator]: Inference done 116/144. Dataloading: 0.0025 s/iter. Inference: 0.1284 s/iter. Eval: 0.6547 s/iter. Total: 0.7860 s/iter. ETA=0:00:22
[09/03 15:40:33 d2.evaluation.evaluator]: Inference done 123/144. Dataloading: 0.0025 s/iter. Inference: 0.1282 s/iter. Eval: 0.6514 s/iter. Total: 0.7824 s/iter. ETA=0:00:16
[09/03 15:40:39 d2.evaluation.evaluator]: Inference done 130/144. Dataloading: 0.0025 s/iter. Inference: 0.1283 s/iter. Eval: 0.6537 s/iter. Total: 0.7848 s/iter. ETA=0:00:10
[09/03 15:40:44 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0025 s/iter. Inference: 0.1281 s/iter. Eval: 0.6506 s/iter. Total: 0.7815 s/iter. ETA=0:00:05
[09/03 15:40:49 d2.evaluation.evaluator]: Total inference time: 0:01:48.258400 (0.778837 s / iter per device, on 1 devices)
[09/03 15:40:49 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:17 (0.127592 s / iter per device, on 1 devices)
[09/03 15:40:50 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 15:40:50 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 15:40:50 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/03 15:40:50 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 15:40:50 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.
[09/03 15:40:50 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:40:50 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.144
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.338
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.062
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.019
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.143
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.217
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.178
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.336
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.083
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.446
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.547
[09/03 15:40:50 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 14.444 | 33.793 | 6.237  | 1.911 | 14.276 | 21.702 |
Loading and preparing results...
DONE (t=0.26s)
creating index...
index created!
[09/03 15:40:51 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 15:40:51 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.19 seconds.
[09/03 15:40:51 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:40:51 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.342
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.271
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.013
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.163
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.371
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.249
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.468
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.175
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.599
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.745
[09/03 15:40:51 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 22.537 | 34.218 | 27.118 | 1.341 | 16.301 | 37.088 |
[09/03 15:40:51 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 15:40:51 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 15:40:51 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:40:51 d2.evaluation.testing]: copypaste: 14.4437,33.7931,6.2368,1.9106,14.2763,21.7021
[09/03 15:40:51 d2.evaluation.testing]: copypaste: Task: segm
[09/03 15:40:51 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:40:51 d2.evaluation.testing]: copypaste: 22.5373,34.2177,27.1178,1.3407,16.3012,37.0881
[09/03 15:40:51 d2.utils.events]:  eta: 0:07:57  iter: 219  total_loss: 0.8751  loss_cls: 0.1866  loss_box_reg: 0.3634  loss_mask: 0.3103  loss_rpn_cls: 0.00988  loss_rpn_loc: 0.004276  time: 0.6203  data_time: 0.0065  lr: 5.4945e-05  max_mem: 4868M
[09/03 15:41:04 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 15:41:04 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 15:41:04 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 15:41:04 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 15:41:04 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 15:41:13 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0019 s/iter. Inference: 0.1318 s/iter. Eval: 0.6908 s/iter. Total: 0.8245 s/iter. ETA=0:01:49
[09/03 15:41:18 d2.evaluation.evaluator]: Inference done 18/144. Dataloading: 0.0020 s/iter. Inference: 0.1298 s/iter. Eval: 0.6641 s/iter. Total: 0.7961 s/iter. ETA=0:01:40
[09/03 15:41:23 d2.evaluation.evaluator]: Inference done 25/144. Dataloading: 0.0027 s/iter. Inference: 0.1262 s/iter. Eval: 0.6416 s/iter. Total: 0.7708 s/iter. ETA=0:01:31
[09/03 15:41:29 d2.evaluation.evaluator]: Inference done 33/144. Dataloading: 0.0030 s/iter. Inference: 0.1242 s/iter. Eval: 0.6108 s/iter. Total: 0.7381 s/iter. ETA=0:01:21
[09/03 15:41:34 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0030 s/iter. Inference: 0.1243 s/iter. Eval: 0.6010 s/iter. Total: 0.7285 s/iter. ETA=0:01:15
[09/03 15:41:40 d2.evaluation.evaluator]: Inference done 48/144. Dataloading: 0.0029 s/iter. Inference: 0.1250 s/iter. Eval: 0.6073 s/iter. Total: 0.7354 s/iter. ETA=0:01:10
[09/03 15:41:45 d2.evaluation.evaluator]: Inference done 55/144. Dataloading: 0.0029 s/iter. Inference: 0.1255 s/iter. Eval: 0.6096 s/iter. Total: 0.7381 s/iter. ETA=0:01:05
[09/03 15:41:51 d2.evaluation.evaluator]: Inference done 62/144. Dataloading: 0.0029 s/iter. Inference: 0.1262 s/iter. Eval: 0.6167 s/iter. Total: 0.7459 s/iter. ETA=0:01:01
[09/03 15:41:56 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0030 s/iter. Inference: 0.1267 s/iter. Eval: 0.6306 s/iter. Total: 0.7604 s/iter. ETA=0:00:57
[09/03 15:42:01 d2.evaluation.evaluator]: Inference done 76/144. Dataloading: 0.0030 s/iter. Inference: 0.1257 s/iter. Eval: 0.6182 s/iter. Total: 0.7471 s/iter. ETA=0:00:50
[09/03 15:42:07 d2.evaluation.evaluator]: Inference done 83/144. Dataloading: 0.0030 s/iter. Inference: 0.1261 s/iter. Eval: 0.6241 s/iter. Total: 0.7534 s/iter. ETA=0:00:45
[09/03 15:42:12 d2.evaluation.evaluator]: Inference done 90/144. Dataloading: 0.0030 s/iter. Inference: 0.1264 s/iter. Eval: 0.6278 s/iter. Total: 0.7573 s/iter. ETA=0:00:40
[09/03 15:42:18 d2.evaluation.evaluator]: Inference done 97/144. Dataloading: 0.0029 s/iter. Inference: 0.1267 s/iter. Eval: 0.6328 s/iter. Total: 0.7626 s/iter. ETA=0:00:35
[09/03 15:42:23 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0030 s/iter. Inference: 0.1267 s/iter. Eval: 0.6314 s/iter. Total: 0.7613 s/iter. ETA=0:00:30
[09/03 15:42:29 d2.evaluation.evaluator]: Inference done 111/144. Dataloading: 0.0030 s/iter. Inference: 0.1266 s/iter. Eval: 0.6312 s/iter. Total: 0.7611 s/iter. ETA=0:00:25
[09/03 15:42:34 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0031 s/iter. Inference: 0.1261 s/iter. Eval: 0.6254 s/iter. Total: 0.7548 s/iter. ETA=0:00:18
[09/03 15:42:40 d2.evaluation.evaluator]: Inference done 126/144. Dataloading: 0.0031 s/iter. Inference: 0.1263 s/iter. Eval: 0.6276 s/iter. Total: 0.7571 s/iter. ETA=0:00:13
[09/03 15:42:45 d2.evaluation.evaluator]: Inference done 134/144. Dataloading: 0.0030 s/iter. Inference: 0.1262 s/iter. Eval: 0.6256 s/iter. Total: 0.7550 s/iter. ETA=0:00:07
[09/03 15:42:51 d2.evaluation.evaluator]: Inference done 142/144. Dataloading: 0.0030 s/iter. Inference: 0.1255 s/iter. Eval: 0.6196 s/iter. Total: 0.7484 s/iter. ETA=0:00:01
[09/03 15:42:52 d2.evaluation.evaluator]: Total inference time: 0:01:44.102553 (0.748939 s / iter per device, on 1 devices)
[09/03 15:42:52 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:17 (0.125547 s / iter per device, on 1 devices)
[09/03 15:42:52 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 15:42:52 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 15:42:52 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/03 15:42:52 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 15:42:53 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[09/03 15:42:53 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:42:53 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.159
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.356
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.073
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.023
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.166
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.238
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.191
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.356
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.470
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.108
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.466
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.544
[09/03 15:42:53 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 15.924 | 35.583 | 7.326  | 2.282 | 16.645 | 23.823 |
Loading and preparing results...
DONE (t=0.24s)
creating index...
index created!
[09/03 15:42:53 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 15:42:53 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.18 seconds.
[09/03 15:42:53 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:42:53 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.03 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.242
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.363
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.299
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.017
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.183
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.389
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.255
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.490
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.636
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.208
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.617
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.747
[09/03 15:42:53 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 24.156 | 36.312 | 29.919 | 1.729 | 18.282 | 38.857 |
[09/03 15:42:53 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 15:42:53 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 15:42:53 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:42:53 d2.evaluation.testing]: copypaste: 15.9237,35.5834,7.3263,2.2819,16.6448,23.8229
[09/03 15:42:53 d2.evaluation.testing]: copypaste: Task: segm
[09/03 15:42:53 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:42:53 d2.evaluation.testing]: copypaste: 24.1558,36.3122,29.9190,1.7286,18.2824,38.8572
[09/03 15:42:53 d2.utils.events]:  eta: 0:07:45  iter: 239  total_loss: 0.9031  loss_cls: 0.1915  loss_box_reg: 0.4263  loss_mask: 0.2839  loss_rpn_cls: 0.007885  loss_rpn_loc: 0.008845  time: 0.6202  data_time: 0.0063  lr: 5.994e-05  max_mem: 4868M
[09/03 15:43:06 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 15:43:06 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 15:43:06 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 15:43:06 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 15:43:06 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 15:43:15 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0027 s/iter. Inference: 0.1291 s/iter. Eval: 0.6785 s/iter. Total: 0.8104 s/iter. ETA=0:01:47
[09/03 15:43:20 d2.evaluation.evaluator]: Inference done 18/144. Dataloading: 0.0025 s/iter. Inference: 0.1273 s/iter. Eval: 0.6401 s/iter. Total: 0.7701 s/iter. ETA=0:01:37
[09/03 15:43:26 d2.evaluation.evaluator]: Inference done 27/144. Dataloading: 0.0024 s/iter. Inference: 0.1207 s/iter. Eval: 0.5707 s/iter. Total: 0.6939 s/iter. ETA=0:01:21
[09/03 15:43:31 d2.evaluation.evaluator]: Inference done 35/144. Dataloading: 0.0022 s/iter. Inference: 0.1199 s/iter. Eval: 0.5706 s/iter. Total: 0.6929 s/iter. ETA=0:01:15
[09/03 15:43:37 d2.evaluation.evaluator]: Inference done 44/144. Dataloading: 0.0025 s/iter. Inference: 0.1189 s/iter. Eval: 0.5519 s/iter. Total: 0.6735 s/iter. ETA=0:01:07
[09/03 15:43:42 d2.evaluation.evaluator]: Inference done 50/144. Dataloading: 0.0025 s/iter. Inference: 0.1204 s/iter. Eval: 0.5731 s/iter. Total: 0.6962 s/iter. ETA=0:01:05
[09/03 15:43:47 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0025 s/iter. Inference: 0.1213 s/iter. Eval: 0.5778 s/iter. Total: 0.7018 s/iter. ETA=0:01:01
[09/03 15:43:52 d2.evaluation.evaluator]: Inference done 64/144. Dataloading: 0.0025 s/iter. Inference: 0.1223 s/iter. Eval: 0.5869 s/iter. Total: 0.7119 s/iter. ETA=0:00:56
[09/03 15:43:58 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0024 s/iter. Inference: 0.1230 s/iter. Eval: 0.5960 s/iter. Total: 0.7216 s/iter. ETA=0:00:52
[09/03 15:44:03 d2.evaluation.evaluator]: Inference done 79/144. Dataloading: 0.0024 s/iter. Inference: 0.1221 s/iter. Eval: 0.5891 s/iter. Total: 0.7139 s/iter. ETA=0:00:46
[09/03 15:44:09 d2.evaluation.evaluator]: Inference done 86/144. Dataloading: 0.0024 s/iter. Inference: 0.1227 s/iter. Eval: 0.5957 s/iter. Total: 0.7210 s/iter. ETA=0:00:41
[09/03 15:44:14 d2.evaluation.evaluator]: Inference done 93/144. Dataloading: 0.0025 s/iter. Inference: 0.1233 s/iter. Eval: 0.5994 s/iter. Total: 0.7253 s/iter. ETA=0:00:36
[09/03 15:44:19 d2.evaluation.evaluator]: Inference done 100/144. Dataloading: 0.0025 s/iter. Inference: 0.1235 s/iter. Eval: 0.6001 s/iter. Total: 0.7263 s/iter. ETA=0:00:31
[09/03 15:44:25 d2.evaluation.evaluator]: Inference done 108/144. Dataloading: 0.0025 s/iter. Inference: 0.1234 s/iter. Eval: 0.5980 s/iter. Total: 0.7242 s/iter. ETA=0:00:26
[09/03 15:44:31 d2.evaluation.evaluator]: Inference done 116/144. Dataloading: 0.0026 s/iter. Inference: 0.1233 s/iter. Eval: 0.5959 s/iter. Total: 0.7220 s/iter. ETA=0:00:20
[09/03 15:44:36 d2.evaluation.evaluator]: Inference done 124/144. Dataloading: 0.0026 s/iter. Inference: 0.1229 s/iter. Eval: 0.5922 s/iter. Total: 0.7179 s/iter. ETA=0:00:14
[09/03 15:44:41 d2.evaluation.evaluator]: Inference done 132/144. Dataloading: 0.0027 s/iter. Inference: 0.1225 s/iter. Eval: 0.5874 s/iter. Total: 0.7128 s/iter. ETA=0:00:08
[09/03 15:44:47 d2.evaluation.evaluator]: Inference done 141/144. Dataloading: 0.0026 s/iter. Inference: 0.1221 s/iter. Eval: 0.5818 s/iter. Total: 0.7068 s/iter. ETA=0:00:02
[09/03 15:44:49 d2.evaluation.evaluator]: Total inference time: 0:01:38.139587 (0.706040 s / iter per device, on 1 devices)
[09/03 15:44:49 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:16 (0.122023 s / iter per device, on 1 devices)
[09/03 15:44:49 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 15:44:49 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 15:44:49 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/03 15:44:49 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 15:44:49 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.
[09/03 15:44:49 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:44:49 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.166
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.355
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.082
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.174
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.250
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.195
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.359
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.469
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.456
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.561
[09/03 15:44:49 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 16.589 | 35.483 | 8.196  | 2.146 | 17.403 | 25.041 |
Loading and preparing results...
DONE (t=0.22s)
creating index...
index created!
[09/03 15:44:50 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 15:44:50 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.17 seconds.
[09/03 15:44:50 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:44:50 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.245
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.361
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.300
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.018
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.183
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.401
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.258
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.493
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.628
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.192
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.601
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.755
[09/03 15:44:50 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 24.531 | 36.121 | 29.983 | 1.758 | 18.299 | 40.105 |
[09/03 15:44:50 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 15:44:50 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 15:44:50 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:44:50 d2.evaluation.testing]: copypaste: 16.5890,35.4826,8.1955,2.1457,17.4033,25.0409
[09/03 15:44:50 d2.evaluation.testing]: copypaste: Task: segm
[09/03 15:44:50 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:44:50 d2.evaluation.testing]: copypaste: 24.5311,36.1209,29.9830,1.7581,18.2992,40.1054
[09/03 15:44:50 d2.utils.events]:  eta: 0:07:32  iter: 259  total_loss: 0.9426  loss_cls: 0.1534  loss_box_reg: 0.4526  loss_mask: 0.2413  loss_rpn_cls: 0.00239  loss_rpn_loc: 0.003469  time: 0.6203  data_time: 0.0064  lr: 6.4935e-05  max_mem: 4868M
[09/03 15:45:02 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 15:45:02 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 15:45:02 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 15:45:02 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 15:45:02 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 15:45:12 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0024 s/iter. Inference: 0.1292 s/iter. Eval: 0.7146 s/iter. Total: 0.8462 s/iter. ETA=0:01:52
[09/03 15:45:17 d2.evaluation.evaluator]: Inference done 19/144. Dataloading: 0.0024 s/iter. Inference: 0.1224 s/iter. Eval: 0.5966 s/iter. Total: 0.7217 s/iter. ETA=0:01:30
[09/03 15:45:22 d2.evaluation.evaluator]: Inference done 28/144. Dataloading: 0.0027 s/iter. Inference: 0.1185 s/iter. Eval: 0.5428 s/iter. Total: 0.6642 s/iter. ETA=0:01:17
[09/03 15:45:27 d2.evaluation.evaluator]: Inference done 38/144. Dataloading: 0.0025 s/iter. Inference: 0.1151 s/iter. Eval: 0.5044 s/iter. Total: 0.6222 s/iter. ETA=0:01:05
[09/03 15:45:33 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0026 s/iter. Inference: 0.1160 s/iter. Eval: 0.5139 s/iter. Total: 0.6326 s/iter. ETA=0:01:01
[09/03 15:45:38 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0025 s/iter. Inference: 0.1178 s/iter. Eval: 0.5367 s/iter. Total: 0.6573 s/iter. ETA=0:00:59
[09/03 15:45:44 d2.evaluation.evaluator]: Inference done 61/144. Dataloading: 0.0026 s/iter. Inference: 0.1187 s/iter. Eval: 0.5448 s/iter. Total: 0.6663 s/iter. ETA=0:00:55
[09/03 15:45:50 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0026 s/iter. Inference: 0.1202 s/iter. Eval: 0.5583 s/iter. Total: 0.6813 s/iter. ETA=0:00:51
[09/03 15:45:55 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0027 s/iter. Inference: 0.1191 s/iter. Eval: 0.5452 s/iter. Total: 0.6672 s/iter. ETA=0:00:44
[09/03 15:46:00 d2.evaluation.evaluator]: Inference done 85/144. Dataloading: 0.0027 s/iter. Inference: 0.1194 s/iter. Eval: 0.5484 s/iter. Total: 0.6707 s/iter. ETA=0:00:39
[09/03 15:46:06 d2.evaluation.evaluator]: Inference done 93/144. Dataloading: 0.0027 s/iter. Inference: 0.1197 s/iter. Eval: 0.5497 s/iter. Total: 0.6723 s/iter. ETA=0:00:34
[09/03 15:46:11 d2.evaluation.evaluator]: Inference done 102/144. Dataloading: 0.0027 s/iter. Inference: 0.1191 s/iter. Eval: 0.5423 s/iter. Total: 0.6642 s/iter. ETA=0:00:27
[09/03 15:46:17 d2.evaluation.evaluator]: Inference done 110/144. Dataloading: 0.0027 s/iter. Inference: 0.1194 s/iter. Eval: 0.5458 s/iter. Total: 0.6681 s/iter. ETA=0:00:22
[09/03 15:46:23 d2.evaluation.evaluator]: Inference done 120/144. Dataloading: 0.0027 s/iter. Inference: 0.1188 s/iter. Eval: 0.5377 s/iter. Total: 0.6595 s/iter. ETA=0:00:15
[09/03 15:46:28 d2.evaluation.evaluator]: Inference done 129/144. Dataloading: 0.0027 s/iter. Inference: 0.1205 s/iter. Eval: 0.5335 s/iter. Total: 0.6568 s/iter. ETA=0:00:09
[09/03 15:46:34 d2.evaluation.evaluator]: Inference done 138/144. Dataloading: 0.0027 s/iter. Inference: 0.1200 s/iter. Eval: 0.5309 s/iter. Total: 0.6538 s/iter. ETA=0:00:03
[09/03 15:46:37 d2.evaluation.evaluator]: Total inference time: 0:01:30.052105 (0.647857 s / iter per device, on 1 devices)
[09/03 15:46:37 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:16 (0.119426 s / iter per device, on 1 devices)
[09/03 15:46:37 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 15:46:37 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 15:46:37 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/03 15:46:37 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 15:46:37 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.09 seconds.
[09/03 15:46:37 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:46:37 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.184
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.372
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.111
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.037
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.183
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.285
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.209
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.370
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.468
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.133
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.449
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.564
[09/03 15:46:37 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 18.368 | 37.241 | 11.091 | 3.733 | 18.257 | 28.483 |
Loading and preparing results...
DONE (t=0.20s)
creating index...
index created!
[09/03 15:46:38 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 15:46:38 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.16 seconds.
[09/03 15:46:38 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:46:38 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.259
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.379
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.318
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.030
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.190
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.424
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.274
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.499
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.622
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.593
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.748
[09/03 15:46:38 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 25.902 | 37.896 | 31.846 | 2.987 | 19.023 | 42.398 |
[09/03 15:46:38 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 15:46:38 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 15:46:38 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:46:38 d2.evaluation.testing]: copypaste: 18.3683,37.2408,11.0914,3.7334,18.2573,28.4826
[09/03 15:46:38 d2.evaluation.testing]: copypaste: Task: segm
[09/03 15:46:38 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:46:38 d2.evaluation.testing]: copypaste: 25.9023,37.8964,31.8465,2.9867,19.0226,42.3981
[09/03 15:46:38 d2.utils.events]:  eta: 0:07:20  iter: 279  total_loss: 0.8302  loss_cls: 0.1354  loss_box_reg: 0.3983  loss_mask: 0.2228  loss_rpn_cls: 0.006126  loss_rpn_loc: 0.00489  time: 0.6197  data_time: 0.0059  lr: 6.993e-05  max_mem: 4868M
[09/03 15:46:51 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 15:46:51 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 15:46:51 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 15:46:51 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 15:46:51 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 15:47:00 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.1248 s/iter. Eval: 0.6109 s/iter. Total: 0.7373 s/iter. ETA=0:01:38
[09/03 15:47:05 d2.evaluation.evaluator]: Inference done 20/144. Dataloading: 0.0025 s/iter. Inference: 0.1161 s/iter. Eval: 0.5169 s/iter. Total: 0.6357 s/iter. ETA=0:01:18
[09/03 15:47:10 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0024 s/iter. Inference: 0.1149 s/iter. Eval: 0.5020 s/iter. Total: 0.6195 s/iter. ETA=0:01:11
[09/03 15:47:15 d2.evaluation.evaluator]: Inference done 40/144. Dataloading: 0.0027 s/iter. Inference: 0.1121 s/iter. Eval: 0.4649 s/iter. Total: 0.5798 s/iter. ETA=0:01:00
[09/03 15:47:21 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0026 s/iter. Inference: 0.1136 s/iter. Eval: 0.4879 s/iter. Total: 0.6042 s/iter. ETA=0:00:58
[09/03 15:47:26 d2.evaluation.evaluator]: Inference done 54/144. Dataloading: 0.0027 s/iter. Inference: 0.1155 s/iter. Eval: 0.5116 s/iter. Total: 0.6301 s/iter. ETA=0:00:56
[09/03 15:47:31 d2.evaluation.evaluator]: Inference done 62/144. Dataloading: 0.0028 s/iter. Inference: 0.1158 s/iter. Eval: 0.5114 s/iter. Total: 0.6302 s/iter. ETA=0:00:51
[09/03 15:47:37 d2.evaluation.evaluator]: Inference done 70/144. Dataloading: 0.0027 s/iter. Inference: 0.1166 s/iter. Eval: 0.5225 s/iter. Total: 0.6420 s/iter. ETA=0:00:47
[09/03 15:47:42 d2.evaluation.evaluator]: Inference done 81/144. Dataloading: 0.0027 s/iter. Inference: 0.1151 s/iter. Eval: 0.5027 s/iter. Total: 0.6206 s/iter. ETA=0:00:39
[09/03 15:47:47 d2.evaluation.evaluator]: Inference done 90/144. Dataloading: 0.0026 s/iter. Inference: 0.1148 s/iter. Eval: 0.4973 s/iter. Total: 0.6149 s/iter. ETA=0:00:33
[09/03 15:47:53 d2.evaluation.evaluator]: Inference done 100/144. Dataloading: 0.0027 s/iter. Inference: 0.1146 s/iter. Eval: 0.4929 s/iter. Total: 0.6104 s/iter. ETA=0:00:26
[09/03 15:47:59 d2.evaluation.evaluator]: Inference done 109/144. Dataloading: 0.0027 s/iter. Inference: 0.1147 s/iter. Eval: 0.4942 s/iter. Total: 0.6118 s/iter. ETA=0:00:21
[09/03 15:48:04 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0027 s/iter. Inference: 0.1142 s/iter. Eval: 0.4871 s/iter. Total: 0.6043 s/iter. ETA=0:00:15
[09/03 15:48:10 d2.evaluation.evaluator]: Inference done 129/144. Dataloading: 0.0026 s/iter. Inference: 0.1140 s/iter. Eval: 0.4850 s/iter. Total: 0.6018 s/iter. ETA=0:00:09
[09/03 15:48:15 d2.evaluation.evaluator]: Inference done 139/144. Dataloading: 0.0026 s/iter. Inference: 0.1136 s/iter. Eval: 0.4784 s/iter. Total: 0.5947 s/iter. ETA=0:00:02
[09/03 15:48:17 d2.evaluation.evaluator]: Total inference time: 0:01:22.246135 (0.591699 s / iter per device, on 1 devices)
[09/03 15:48:17 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:15 (0.113234 s / iter per device, on 1 devices)
[09/03 15:48:18 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 15:48:18 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 15:48:18 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/03 15:48:18 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 15:48:18 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.08 seconds.
[09/03 15:48:18 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:48:18 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.198
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.395
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.124
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.037
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.203
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.304
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.219
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.390
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.487
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.125
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.473
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.577
[09/03 15:48:18 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 19.796 | 39.537 | 12.389 | 3.732 | 20.269 | 30.353 |
Loading and preparing results...
DONE (t=0.18s)
creating index...
index created!
[09/03 15:48:18 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 15:48:19 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.15 seconds.
[09/03 15:48:19 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:48:19 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.276
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.403
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.332
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.030
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.204
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.445
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.280
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.512
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.636
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.615
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.753
[09/03 15:48:19 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 27.592 | 40.275 | 33.189 | 2.972 | 20.438 | 44.498 |
[09/03 15:48:19 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 15:48:19 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 15:48:19 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:48:19 d2.evaluation.testing]: copypaste: 19.7957,39.5370,12.3891,3.7324,20.2692,30.3531
[09/03 15:48:19 d2.evaluation.testing]: copypaste: Task: segm
[09/03 15:48:19 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:48:19 d2.evaluation.testing]: copypaste: 27.5925,40.2750,33.1891,2.9721,20.4380,44.4976
[09/03 15:48:19 d2.utils.events]:  eta: 0:07:08  iter: 299  total_loss: 0.8147  loss_cls: 0.1435  loss_box_reg: 0.3819  loss_mask: 0.1951  loss_rpn_cls: 0.004199  loss_rpn_loc: 0.003705  time: 0.6201  data_time: 0.0092  lr: 7.4925e-05  max_mem: 4868M
[09/03 15:48:31 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 15:48:31 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 15:48:31 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 15:48:31 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 15:48:31 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 15:48:40 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0022 s/iter. Inference: 0.1250 s/iter. Eval: 0.6136 s/iter. Total: 0.7408 s/iter. ETA=0:01:38
[09/03 15:48:45 d2.evaluation.evaluator]: Inference done 20/144. Dataloading: 0.0028 s/iter. Inference: 0.1158 s/iter. Eval: 0.5127 s/iter. Total: 0.6315 s/iter. ETA=0:01:18
[09/03 15:48:50 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0027 s/iter. Inference: 0.1146 s/iter. Eval: 0.4937 s/iter. Total: 0.6112 s/iter. ETA=0:01:10
[09/03 15:48:56 d2.evaluation.evaluator]: Inference done 40/144. Dataloading: 0.0026 s/iter. Inference: 0.1117 s/iter. Eval: 0.4575 s/iter. Total: 0.5719 s/iter. ETA=0:00:59
[09/03 15:49:01 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0027 s/iter. Inference: 0.1138 s/iter. Eval: 0.4819 s/iter. Total: 0.5985 s/iter. ETA=0:00:58
[09/03 15:49:06 d2.evaluation.evaluator]: Inference done 54/144. Dataloading: 0.0026 s/iter. Inference: 0.1158 s/iter. Eval: 0.5049 s/iter. Total: 0.6236 s/iter. ETA=0:00:56
[09/03 15:49:11 d2.evaluation.evaluator]: Inference done 62/144. Dataloading: 0.0027 s/iter. Inference: 0.1161 s/iter. Eval: 0.5064 s/iter. Total: 0.6254 s/iter. ETA=0:00:51
[09/03 15:49:17 d2.evaluation.evaluator]: Inference done 70/144. Dataloading: 0.0027 s/iter. Inference: 0.1167 s/iter. Eval: 0.5164 s/iter. Total: 0.6360 s/iter. ETA=0:00:47
[09/03 15:49:22 d2.evaluation.evaluator]: Inference done 81/144. Dataloading: 0.0026 s/iter. Inference: 0.1151 s/iter. Eval: 0.4955 s/iter. Total: 0.6134 s/iter. ETA=0:00:38
[09/03 15:49:27 d2.evaluation.evaluator]: Inference done 90/144. Dataloading: 0.0026 s/iter. Inference: 0.1145 s/iter. Eval: 0.4901 s/iter. Total: 0.6073 s/iter. ETA=0:00:32
[09/03 15:49:33 d2.evaluation.evaluator]: Inference done 100/144. Dataloading: 0.0027 s/iter. Inference: 0.1143 s/iter. Eval: 0.4849 s/iter. Total: 0.6021 s/iter. ETA=0:00:26
[09/03 15:49:38 d2.evaluation.evaluator]: Inference done 108/144. Dataloading: 0.0027 s/iter. Inference: 0.1145 s/iter. Eval: 0.4867 s/iter. Total: 0.6041 s/iter. ETA=0:00:21
[09/03 15:49:43 d2.evaluation.evaluator]: Inference done 117/144. Dataloading: 0.0026 s/iter. Inference: 0.1143 s/iter. Eval: 0.4839 s/iter. Total: 0.6011 s/iter. ETA=0:00:16
[09/03 15:49:49 d2.evaluation.evaluator]: Inference done 128/144. Dataloading: 0.0026 s/iter. Inference: 0.1136 s/iter. Eval: 0.4765 s/iter. Total: 0.5929 s/iter. ETA=0:00:09
[09/03 15:49:54 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0026 s/iter. Inference: 0.1136 s/iter. Eval: 0.4749 s/iter. Total: 0.5913 s/iter. ETA=0:00:04
[09/03 15:49:57 d2.evaluation.evaluator]: Total inference time: 0:01:21.355142 (0.585289 s / iter per device, on 1 devices)
[09/03 15:49:57 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:15 (0.113026 s / iter per device, on 1 devices)
[09/03 15:49:57 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 15:49:57 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 15:49:57 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/03 15:49:57 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 15:49:57 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.08 seconds.
[09/03 15:49:57 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:49:57 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.209
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.423
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.124
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.059
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.217
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.309
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.219
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.387
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.494
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.133
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.478
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.588
[09/03 15:49:57 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 20.946 | 42.294 | 12.422 | 5.911 | 21.732 | 30.858 |
Loading and preparing results...
DONE (t=0.17s)
creating index...
index created!
[09/03 15:49:58 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 15:49:58 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.15 seconds.
[09/03 15:49:58 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:49:58 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.295
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.430
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.352
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.046
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.227
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.461
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.288
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.510
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.645
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.759
[09/03 15:49:58 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 29.528 | 43.039 | 35.170 | 4.578 | 22.725 | 46.099 |
[09/03 15:49:58 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 15:49:58 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 15:49:58 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:49:58 d2.evaluation.testing]: copypaste: 20.9459,42.2939,12.4216,5.9109,21.7325,30.8584
[09/03 15:49:58 d2.evaluation.testing]: copypaste: Task: segm
[09/03 15:49:58 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:49:58 d2.evaluation.testing]: copypaste: 29.5279,43.0389,35.1703,4.5778,22.7252,46.0989
[09/03 15:49:58 d2.utils.events]:  eta: 0:06:56  iter: 319  total_loss: 0.6389  loss_cls: 0.1178  loss_box_reg: 0.3079  loss_mask: 0.195  loss_rpn_cls: 0.003054  loss_rpn_loc: 0.00201  time: 0.6200  data_time: 0.0087  lr: 7.992e-05  max_mem: 4868M
[09/03 15:50:11 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 15:50:11 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 15:50:11 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 15:50:11 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 15:50:11 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 15:50:19 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0024 s/iter. Inference: 0.1170 s/iter. Eval: 0.5197 s/iter. Total: 0.6392 s/iter. ETA=0:01:25
[09/03 15:50:24 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0024 s/iter. Inference: 0.1070 s/iter. Eval: 0.4021 s/iter. Total: 0.5117 s/iter. ETA=0:01:01
[09/03 15:50:29 d2.evaluation.evaluator]: Inference done 35/144. Dataloading: 0.0027 s/iter. Inference: 0.1056 s/iter. Eval: 0.3740 s/iter. Total: 0.4824 s/iter. ETA=0:00:52
[09/03 15:50:35 d2.evaluation.evaluator]: Inference done 45/144. Dataloading: 0.0027 s/iter. Inference: 0.1059 s/iter. Eval: 0.3884 s/iter. Total: 0.4972 s/iter. ETA=0:00:49
[09/03 15:50:40 d2.evaluation.evaluator]: Inference done 52/144. Dataloading: 0.0027 s/iter. Inference: 0.1086 s/iter. Eval: 0.4182 s/iter. Total: 0.5297 s/iter. ETA=0:00:48
[09/03 15:50:45 d2.evaluation.evaluator]: Inference done 61/144. Dataloading: 0.0030 s/iter. Inference: 0.1100 s/iter. Eval: 0.4322 s/iter. Total: 0.5454 s/iter. ETA=0:00:45
[09/03 15:50:51 d2.evaluation.evaluator]: Inference done 70/144. Dataloading: 0.0030 s/iter. Inference: 0.1104 s/iter. Eval: 0.4368 s/iter. Total: 0.5504 s/iter. ETA=0:00:40
[09/03 15:50:56 d2.evaluation.evaluator]: Inference done 83/144. Dataloading: 0.0029 s/iter. Inference: 0.1085 s/iter. Eval: 0.4112 s/iter. Total: 0.5228 s/iter. ETA=0:00:31
[09/03 15:51:01 d2.evaluation.evaluator]: Inference done 96/144. Dataloading: 0.0028 s/iter. Inference: 0.1070 s/iter. Eval: 0.3932 s/iter. Total: 0.5031 s/iter. ETA=0:00:24
[09/03 15:51:06 d2.evaluation.evaluator]: Inference done 107/144. Dataloading: 0.0029 s/iter. Inference: 0.1069 s/iter. Eval: 0.3923 s/iter. Total: 0.5022 s/iter. ETA=0:00:18
[09/03 15:51:11 d2.evaluation.evaluator]: Inference done 116/144. Dataloading: 0.0029 s/iter. Inference: 0.1073 s/iter. Eval: 0.3995 s/iter. Total: 0.5099 s/iter. ETA=0:00:14
[09/03 15:51:17 d2.evaluation.evaluator]: Inference done 129/144. Dataloading: 0.0027 s/iter. Inference: 0.1066 s/iter. Eval: 0.3919 s/iter. Total: 0.5014 s/iter. ETA=0:00:07
[09/03 15:51:22 d2.evaluation.evaluator]: Inference done 142/144. Dataloading: 0.0027 s/iter. Inference: 0.1058 s/iter. Eval: 0.3821 s/iter. Total: 0.4908 s/iter. ETA=0:00:00
[09/03 15:51:23 d2.evaluation.evaluator]: Total inference time: 0:01:08.333115 (0.491605 s / iter per device, on 1 devices)
[09/03 15:51:23 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:14 (0.105805 s / iter per device, on 1 devices)
[09/03 15:51:23 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 15:51:23 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 15:51:23 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/03 15:51:23 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 15:51:23 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[09/03 15:51:23 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:51:24 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.244
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.448
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.244
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.057
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.248
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.363
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.243
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.420
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.501
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.125
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.474
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.617
[09/03 15:51:24 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 24.368 | 44.842 | 24.421 | 5.657 | 24.774 | 36.336 |
Loading and preparing results...
DONE (t=0.14s)
creating index...
index created!
[09/03 15:51:24 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 15:51:24 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.13 seconds.
[09/03 15:51:24 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:51:24 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.319
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.453
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.384
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.053
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.257
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.495
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.296
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.524
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.633
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.606
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.755
[09/03 15:51:24 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 31.869 | 45.275 | 38.439 | 5.256 | 25.667 | 49.505 |
[09/03 15:51:24 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 15:51:24 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 15:51:24 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:51:24 d2.evaluation.testing]: copypaste: 24.3677,44.8421,24.4206,5.6566,24.7742,36.3362
[09/03 15:51:24 d2.evaluation.testing]: copypaste: Task: segm
[09/03 15:51:24 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:51:24 d2.evaluation.testing]: copypaste: 31.8692,45.2753,38.4387,5.2557,25.6668,49.5053
[09/03 15:51:24 d2.utils.events]:  eta: 0:06:43  iter: 339  total_loss: 0.6066  loss_cls: 0.09879  loss_box_reg: 0.3075  loss_mask: 0.2081  loss_rpn_cls: 0.003639  loss_rpn_loc: 0.004545  time: 0.6198  data_time: 0.0095  lr: 8.4915e-05  max_mem: 4868M
[09/03 15:51:37 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 15:51:37 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 15:51:37 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 15:51:37 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 15:51:37 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 15:51:45 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0019 s/iter. Inference: 0.1147 s/iter. Eval: 0.4771 s/iter. Total: 0.5936 s/iter. ETA=0:01:18
[09/03 15:51:50 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0024 s/iter. Inference: 0.1052 s/iter. Eval: 0.3683 s/iter. Total: 0.4761 s/iter. ETA=0:00:57
[09/03 15:51:55 d2.evaluation.evaluator]: Inference done 37/144. Dataloading: 0.0022 s/iter. Inference: 0.1015 s/iter. Eval: 0.3263 s/iter. Total: 0.4302 s/iter. ETA=0:00:46
[09/03 15:52:01 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0022 s/iter. Inference: 0.1038 s/iter. Eval: 0.3588 s/iter. Total: 0.4650 s/iter. ETA=0:00:45
[09/03 15:52:07 d2.evaluation.evaluator]: Inference done 56/144. Dataloading: 0.0022 s/iter. Inference: 0.1063 s/iter. Eval: 0.3880 s/iter. Total: 0.4966 s/iter. ETA=0:00:43
[09/03 15:52:12 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0024 s/iter. Inference: 0.1067 s/iter. Eval: 0.3981 s/iter. Total: 0.5074 s/iter. ETA=0:00:40
[09/03 15:52:17 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0024 s/iter. Inference: 0.1064 s/iter. Eval: 0.3897 s/iter. Total: 0.4988 s/iter. ETA=0:00:33
[09/03 15:52:23 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0025 s/iter. Inference: 0.1047 s/iter. Eval: 0.3689 s/iter. Total: 0.4762 s/iter. ETA=0:00:24
[09/03 15:52:28 d2.evaluation.evaluator]: Inference done 105/144. Dataloading: 0.0025 s/iter. Inference: 0.1043 s/iter. Eval: 0.3605 s/iter. Total: 0.4676 s/iter. ETA=0:00:18
[09/03 15:52:33 d2.evaluation.evaluator]: Inference done 116/144. Dataloading: 0.0025 s/iter. Inference: 0.1045 s/iter. Eval: 0.3628 s/iter. Total: 0.4699 s/iter. ETA=0:00:13
[09/03 15:52:39 d2.evaluation.evaluator]: Inference done 130/144. Dataloading: 0.0026 s/iter. Inference: 0.1038 s/iter. Eval: 0.3544 s/iter. Total: 0.4609 s/iter. ETA=0:00:06
[09/03 15:52:45 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0025 s/iter. Inference: 0.1032 s/iter. Eval: 0.3496 s/iter. Total: 0.4555 s/iter. ETA=0:00:00
[09/03 15:52:45 d2.evaluation.evaluator]: Total inference time: 0:01:03.422027 (0.456274 s / iter per device, on 1 devices)
[09/03 15:52:45 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:14 (0.103170 s / iter per device, on 1 devices)
[09/03 15:52:45 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 15:52:45 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 15:52:45 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/03 15:52:45 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 15:52:45 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[09/03 15:52:45 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:52:45 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.276
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.484
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.281
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.075
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.279
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.405
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.255
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.440
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.513
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.485
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.626
[09/03 15:52:45 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 27.643 | 48.410 | 28.121 | 7.497 | 27.909 | 40.469 |
Loading and preparing results...
DONE (t=0.13s)
creating index...
index created!
[09/03 15:52:45 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 15:52:46 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.12 seconds.
[09/03 15:52:46 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:52:46 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.349
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.491
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.416
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.060
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.288
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.530
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.302
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.541
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.639
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.258
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.611
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.758
[09/03 15:52:46 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 34.881 | 49.098 | 41.635 | 6.017 | 28.755 | 53.033 |
[09/03 15:52:46 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 15:52:46 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 15:52:46 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:52:46 d2.evaluation.testing]: copypaste: 27.6429,48.4098,28.1215,7.4966,27.9091,40.4691
[09/03 15:52:46 d2.evaluation.testing]: copypaste: Task: segm
[09/03 15:52:46 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:52:46 d2.evaluation.testing]: copypaste: 34.8812,49.0977,41.6353,6.0168,28.7552,53.0328
[09/03 15:52:46 d2.utils.events]:  eta: 0:06:31  iter: 359  total_loss: 0.639  loss_cls: 0.1354  loss_box_reg: 0.3409  loss_mask: 0.174  loss_rpn_cls: 0.005985  loss_rpn_loc: 0.003233  time: 0.6193  data_time: 0.0088  lr: 8.991e-05  max_mem: 4868M
[09/03 15:52:58 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 15:52:58 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 15:52:58 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 15:52:58 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 15:52:58 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 15:53:05 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0021 s/iter. Inference: 0.1083 s/iter. Eval: 0.4075 s/iter. Total: 0.5179 s/iter. ETA=0:01:08
[09/03 15:53:10 d2.evaluation.evaluator]: Inference done 26/144. Dataloading: 0.0028 s/iter. Inference: 0.0979 s/iter. Eval: 0.2948 s/iter. Total: 0.3957 s/iter. ETA=0:00:46
[09/03 15:53:16 d2.evaluation.evaluator]: Inference done 40/144. Dataloading: 0.0035 s/iter. Inference: 0.0975 s/iter. Eval: 0.2919 s/iter. Total: 0.3931 s/iter. ETA=0:00:40
[09/03 15:53:21 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0035 s/iter. Inference: 0.1021 s/iter. Eval: 0.3369 s/iter. Total: 0.4428 s/iter. ETA=0:00:42
[09/03 15:53:27 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0032 s/iter. Inference: 0.1036 s/iter. Eval: 0.3545 s/iter. Total: 0.4616 s/iter. ETA=0:00:39
[09/03 15:53:32 d2.evaluation.evaluator]: Inference done 69/144. Dataloading: 0.0032 s/iter. Inference: 0.1047 s/iter. Eval: 0.3616 s/iter. Total: 0.4697 s/iter. ETA=0:00:35
[09/03 15:53:37 d2.evaluation.evaluator]: Inference done 85/144. Dataloading: 0.0030 s/iter. Inference: 0.1025 s/iter. Eval: 0.3361 s/iter. Total: 0.4419 s/iter. ETA=0:00:26
[09/03 15:53:42 d2.evaluation.evaluator]: Inference done 101/144. Dataloading: 0.0029 s/iter. Inference: 0.1009 s/iter. Eval: 0.3174 s/iter. Total: 0.4214 s/iter. ETA=0:00:18
[09/03 15:53:48 d2.evaluation.evaluator]: Inference done 112/144. Dataloading: 0.0030 s/iter. Inference: 0.1017 s/iter. Eval: 0.3305 s/iter. Total: 0.4354 s/iter. ETA=0:00:13
[09/03 15:53:54 d2.evaluation.evaluator]: Inference done 126/144. Dataloading: 0.0030 s/iter. Inference: 0.1014 s/iter. Eval: 0.3226 s/iter. Total: 0.4272 s/iter. ETA=0:00:07
[09/03 15:53:59 d2.evaluation.evaluator]: Inference done 141/144. Dataloading: 0.0030 s/iter. Inference: 0.1008 s/iter. Eval: 0.3150 s/iter. Total: 0.4189 s/iter. ETA=0:00:01
[09/03 15:54:00 d2.evaluation.evaluator]: Total inference time: 0:00:58.317699 (0.419552 s / iter per device, on 1 devices)
[09/03 15:54:00 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:14 (0.100732 s / iter per device, on 1 devices)
[09/03 15:54:00 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 15:54:00 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 15:54:00 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/03 15:54:00 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 15:54:00 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[09/03 15:54:00 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:54:00 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.286
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.501
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.290
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.073
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.288
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.425
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.266
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.454
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.519
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.125
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.488
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.645
[09/03 15:54:00 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 28.606 | 50.057 | 29.020 | 7.344 | 28.828 | 42.473 |
Loading and preparing results...
DONE (t=0.12s)
creating index...
index created!
[09/03 15:54:01 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 15:54:01 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[09/03 15:54:01 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:54:01 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.362
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.513
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.436
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.060
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.306
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.543
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.315
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.554
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.642
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.225
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.615
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.767
[09/03 15:54:01 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 36.157 | 51.315 | 43.609 | 6.008 | 30.617 | 54.285 |
[09/03 15:54:01 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 15:54:01 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 15:54:01 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:54:01 d2.evaluation.testing]: copypaste: 28.6056,50.0569,29.0201,7.3441,28.8278,42.4730
[09/03 15:54:01 d2.evaluation.testing]: copypaste: Task: segm
[09/03 15:54:01 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:54:01 d2.evaluation.testing]: copypaste: 36.1566,51.3150,43.6093,6.0076,30.6167,54.2853
[09/03 15:54:01 d2.utils.events]:  eta: 0:06:19  iter: 379  total_loss: 0.6785  loss_cls: 0.1076  loss_box_reg: 0.3785  loss_mask: 0.1483  loss_rpn_cls: 0.001641  loss_rpn_loc: 0.004055  time: 0.6190  data_time: 0.0087  lr: 9.4905e-05  max_mem: 4868M
[09/03 15:54:13 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 15:54:13 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 15:54:13 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 15:54:14 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 15:54:14 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 15:54:21 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0020 s/iter. Inference: 0.1112 s/iter. Eval: 0.4959 s/iter. Total: 0.6091 s/iter. ETA=0:01:21
[09/03 15:54:26 d2.evaluation.evaluator]: Inference done 25/144. Dataloading: 0.0032 s/iter. Inference: 0.1026 s/iter. Eval: 0.3366 s/iter. Total: 0.4429 s/iter. ETA=0:00:52
[09/03 15:54:31 d2.evaluation.evaluator]: Inference done 39/144. Dataloading: 0.0029 s/iter. Inference: 0.0996 s/iter. Eval: 0.3054 s/iter. Total: 0.4083 s/iter. ETA=0:00:42
[09/03 15:54:37 d2.evaluation.evaluator]: Inference done 48/144. Dataloading: 0.0027 s/iter. Inference: 0.1023 s/iter. Eval: 0.3368 s/iter. Total: 0.4422 s/iter. ETA=0:00:42
[09/03 15:54:42 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0030 s/iter. Inference: 0.1042 s/iter. Eval: 0.3602 s/iter. Total: 0.4677 s/iter. ETA=0:00:40
[09/03 15:54:48 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0029 s/iter. Inference: 0.1048 s/iter. Eval: 0.3681 s/iter. Total: 0.4761 s/iter. ETA=0:00:36
[09/03 15:54:53 d2.evaluation.evaluator]: Inference done 84/144. Dataloading: 0.0030 s/iter. Inference: 0.1024 s/iter. Eval: 0.3382 s/iter. Total: 0.4439 s/iter. ETA=0:00:26
[09/03 15:54:58 d2.evaluation.evaluator]: Inference done 100/144. Dataloading: 0.0032 s/iter. Inference: 0.1013 s/iter. Eval: 0.3221 s/iter. Total: 0.4268 s/iter. ETA=0:00:18
[09/03 15:55:03 d2.evaluation.evaluator]: Inference done 111/144. Dataloading: 0.0031 s/iter. Inference: 0.1018 s/iter. Eval: 0.3271 s/iter. Total: 0.4323 s/iter. ETA=0:00:14
[09/03 15:55:08 d2.evaluation.evaluator]: Inference done 124/144. Dataloading: 0.0031 s/iter. Inference: 0.1014 s/iter. Eval: 0.3230 s/iter. Total: 0.4278 s/iter. ETA=0:00:08
[09/03 15:55:14 d2.evaluation.evaluator]: Inference done 139/144. Dataloading: 0.0031 s/iter. Inference: 0.1007 s/iter. Eval: 0.3142 s/iter. Total: 0.4182 s/iter. ETA=0:00:02
[09/03 15:55:16 d2.evaluation.evaluator]: Total inference time: 0:00:58.110694 (0.418063 s / iter per device, on 1 devices)
[09/03 15:55:16 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:13 (0.100634 s / iter per device, on 1 devices)
[09/03 15:55:16 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 15:55:16 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 15:55:16 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/03 15:55:16 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 15:55:16 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[09/03 15:55:16 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:55:16 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.322
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.538
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.332
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.079
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.325
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.458
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.278
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.473
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.546
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.523
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.655
[09/03 15:55:16 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 32.215 | 53.809 | 33.216 | 7.859 | 32.456 | 45.771 |
Loading and preparing results...
DONE (t=0.12s)
creating index...
index created!
[09/03 15:55:16 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 15:55:16 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[09/03 15:55:16 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:55:16 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.377
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.539
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.450
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.053
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.320
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.552
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.313
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.552
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.647
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.292
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.620
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.759
[09/03 15:55:16 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 37.709 | 53.901 | 45.006 | 5.342 | 31.971 | 55.231 |
[09/03 15:55:16 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 15:55:16 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 15:55:16 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:55:16 d2.evaluation.testing]: copypaste: 32.2147,53.8092,33.2163,7.8595,32.4557,45.7710
[09/03 15:55:16 d2.evaluation.testing]: copypaste: Task: segm
[09/03 15:55:16 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:55:16 d2.evaluation.testing]: copypaste: 37.7089,53.9010,45.0055,5.3415,31.9709,55.2310
[09/03 15:55:16 d2.utils.events]:  eta: 0:06:06  iter: 399  total_loss: 0.6019  loss_cls: 0.11  loss_box_reg: 0.3381  loss_mask: 0.1497  loss_rpn_cls: 0.002562  loss_rpn_loc: 0.003444  time: 0.6187  data_time: 0.0098  lr: 9.99e-05  max_mem: 4868M
[09/03 15:55:29 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 15:55:29 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 15:55:29 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 15:55:29 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 15:55:29 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 15:55:35 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0021 s/iter. Inference: 0.0970 s/iter. Eval: 0.2623 s/iter. Total: 0.3614 s/iter. ETA=0:00:48
[09/03 15:55:40 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0031 s/iter. Inference: 0.0953 s/iter. Eval: 0.2129 s/iter. Total: 0.3114 s/iter. ETA=0:00:35
[09/03 15:55:45 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0037 s/iter. Inference: 0.0957 s/iter. Eval: 0.2139 s/iter. Total: 0.3134 s/iter. ETA=0:00:30
[09/03 15:55:51 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0036 s/iter. Inference: 0.0972 s/iter. Eval: 0.2386 s/iter. Total: 0.3396 s/iter. ETA=0:00:29
[09/03 15:55:56 d2.evaluation.evaluator]: Inference done 72/144. Dataloading: 0.0034 s/iter. Inference: 0.0974 s/iter. Eval: 0.2471 s/iter. Total: 0.3480 s/iter. ETA=0:00:25
[09/03 15:56:01 d2.evaluation.evaluator]: Inference done 98/144. Dataloading: 0.0033 s/iter. Inference: 0.0942 s/iter. Eval: 0.2075 s/iter. Total: 0.3051 s/iter. ETA=0:00:14
[09/03 15:56:06 d2.evaluation.evaluator]: Inference done 112/144. Dataloading: 0.0033 s/iter. Inference: 0.0950 s/iter. Eval: 0.2179 s/iter. Total: 0.3163 s/iter. ETA=0:00:10
[09/03 15:56:11 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0031 s/iter. Inference: 0.0942 s/iter. Eval: 0.2111 s/iter. Total: 0.3086 s/iter. ETA=0:00:04
[09/03 15:56:15 d2.evaluation.evaluator]: Total inference time: 0:00:42.559298 (0.306182 s / iter per device, on 1 devices)
[09/03 15:56:15 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:13 (0.093786 s / iter per device, on 1 devices)
[09/03 15:56:15 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 15:56:15 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 15:56:15 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/03 15:56:15 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 15:56:15 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/03 15:56:15 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:56:15 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.348
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.569
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.376
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.064
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.360
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.473
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.284
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.485
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.551
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.150
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.535
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.653
[09/03 15:56:15 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 34.758 | 56.917 | 37.604 | 6.424 | 36.042 | 47.316 |
Loading and preparing results...
DONE (t=0.09s)
creating index...
index created!
[09/03 15:56:16 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 15:56:16 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.09 seconds.
[09/03 15:56:16 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:56:16 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.401
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.566
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.476
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.067
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.345
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.579
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.553
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.632
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.250
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.601
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.756
[09/03 15:56:16 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 40.135 | 56.631 | 47.563 | 6.682 | 34.482 | 57.917 |
[09/03 15:56:16 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 15:56:16 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 15:56:16 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:56:16 d2.evaluation.testing]: copypaste: 34.7583,56.9173,37.6044,6.4241,36.0422,47.3164
[09/03 15:56:16 d2.evaluation.testing]: copypaste: Task: segm
[09/03 15:56:16 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:56:16 d2.evaluation.testing]: copypaste: 40.1351,56.6311,47.5634,6.6823,34.4822,57.9170
[09/03 15:56:16 d2.utils.events]:  eta: 0:05:54  iter: 419  total_loss: 0.6996  loss_cls: 0.114  loss_box_reg: 0.3603  loss_mask: 0.2049  loss_rpn_cls: 0.002874  loss_rpn_loc: 0.005405  time: 0.6184  data_time: 0.0098  lr: 0.0001049  max_mem: 4868M
[09/03 15:56:28 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 15:56:28 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 15:56:28 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 15:56:28 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 15:56:28 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 15:56:34 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0021 s/iter. Inference: 0.0956 s/iter. Eval: 0.2678 s/iter. Total: 0.3655 s/iter. ETA=0:00:48
[09/03 15:56:39 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0037 s/iter. Inference: 0.0935 s/iter. Eval: 0.2070 s/iter. Total: 0.3043 s/iter. ETA=0:00:34
[09/03 15:56:44 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0032 s/iter. Inference: 0.0929 s/iter. Eval: 0.2072 s/iter. Total: 0.3034 s/iter. ETA=0:00:29
[09/03 15:56:49 d2.evaluation.evaluator]: Inference done 56/144. Dataloading: 0.0032 s/iter. Inference: 0.0959 s/iter. Eval: 0.2443 s/iter. Total: 0.3435 s/iter. ETA=0:00:30
[09/03 15:56:54 d2.evaluation.evaluator]: Inference done 70/144. Dataloading: 0.0030 s/iter. Inference: 0.0962 s/iter. Eval: 0.2511 s/iter. Total: 0.3505 s/iter. ETA=0:00:25
[09/03 15:56:59 d2.evaluation.evaluator]: Inference done 90/144. Dataloading: 0.0033 s/iter. Inference: 0.0941 s/iter. Eval: 0.2297 s/iter. Total: 0.3272 s/iter. ETA=0:00:17
[09/03 15:57:05 d2.evaluation.evaluator]: Inference done 108/144. Dataloading: 0.0033 s/iter. Inference: 0.0938 s/iter. Eval: 0.2255 s/iter. Total: 0.3228 s/iter. ETA=0:00:11
[09/03 15:57:10 d2.evaluation.evaluator]: Inference done 126/144. Dataloading: 0.0033 s/iter. Inference: 0.0934 s/iter. Eval: 0.2212 s/iter. Total: 0.3181 s/iter. ETA=0:00:05
[09/03 15:57:15 d2.evaluation.evaluator]: Total inference time: 0:00:43.378269 (0.312074 s / iter per device, on 1 devices)
[09/03 15:57:15 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:12 (0.092777 s / iter per device, on 1 devices)
[09/03 15:57:15 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 15:57:15 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 15:57:15 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/03 15:57:15 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 15:57:15 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/03 15:57:15 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:57:15 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.384
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.597
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.433
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.060
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.381
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.530
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.302
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.513
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.566
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.150
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.543
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.682
[09/03 15:57:15 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 38.414 | 59.666 | 43.283 | 6.047 | 38.097 | 52.980 |
Loading and preparing results...
DONE (t=0.08s)
creating index...
index created!
[09/03 15:57:16 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 15:57:16 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.09 seconds.
[09/03 15:57:16 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:57:16 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.413
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.593
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.469
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.046
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.357
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.587
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.325
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.570
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.639
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.292
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.611
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.752
[09/03 15:57:16 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 41.281 | 59.347 | 46.928 | 4.567 | 35.660 | 58.737 |
[09/03 15:57:16 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 15:57:16 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 15:57:16 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:57:16 d2.evaluation.testing]: copypaste: 38.4142,59.6665,43.2828,6.0473,38.0975,52.9798
[09/03 15:57:16 d2.evaluation.testing]: copypaste: Task: segm
[09/03 15:57:16 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:57:16 d2.evaluation.testing]: copypaste: 41.2806,59.3469,46.9282,4.5674,35.6595,58.7368
[09/03 15:57:16 d2.utils.events]:  eta: 0:05:42  iter: 439  total_loss: 0.5221  loss_cls: 0.1105  loss_box_reg: 0.2578  loss_mask: 0.1716  loss_rpn_cls: 0.005686  loss_rpn_loc: 0.003437  time: 0.6181  data_time: 0.0095  lr: 0.00010989  max_mem: 4868M
[09/03 15:57:28 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 15:57:28 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 15:57:28 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 15:57:28 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 15:57:28 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 15:57:35 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.1007 s/iter. Eval: 0.2950 s/iter. Total: 0.3973 s/iter. ETA=0:00:52
[09/03 15:57:40 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0030 s/iter. Inference: 0.0922 s/iter. Eval: 0.2164 s/iter. Total: 0.3118 s/iter. ETA=0:00:35
[09/03 15:57:45 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0032 s/iter. Inference: 0.0932 s/iter. Eval: 0.2184 s/iter. Total: 0.3150 s/iter. ETA=0:00:30
[09/03 15:57:50 d2.evaluation.evaluator]: Inference done 56/144. Dataloading: 0.0033 s/iter. Inference: 0.0962 s/iter. Eval: 0.2559 s/iter. Total: 0.3556 s/iter. ETA=0:00:31
[09/03 15:57:56 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0032 s/iter. Inference: 0.0973 s/iter. Eval: 0.2736 s/iter. Total: 0.3743 s/iter. ETA=0:00:28
[09/03 15:58:01 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0032 s/iter. Inference: 0.0951 s/iter. Eval: 0.2446 s/iter. Total: 0.3430 s/iter. ETA=0:00:18
[09/03 15:58:06 d2.evaluation.evaluator]: Inference done 105/144. Dataloading: 0.0032 s/iter. Inference: 0.0953 s/iter. Eval: 0.2426 s/iter. Total: 0.3413 s/iter. ETA=0:00:13
[09/03 15:58:12 d2.evaluation.evaluator]: Inference done 123/144. Dataloading: 0.0031 s/iter. Inference: 0.0946 s/iter. Eval: 0.2356 s/iter. Total: 0.3335 s/iter. ETA=0:00:07
[09/03 15:58:17 d2.evaluation.evaluator]: Inference done 142/144. Dataloading: 0.0031 s/iter. Inference: 0.0938 s/iter. Eval: 0.2273 s/iter. Total: 0.3243 s/iter. ETA=0:00:00
[09/03 15:58:18 d2.evaluation.evaluator]: Total inference time: 0:00:45.478913 (0.327186 s / iter per device, on 1 devices)
[09/03 15:58:18 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:13 (0.093960 s / iter per device, on 1 devices)
[09/03 15:58:18 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 15:58:18 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 15:58:18 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/03 15:58:18 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 15:58:18 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/03 15:58:18 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:58:18 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.403
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.612
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.452
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.063
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.403
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.544
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.313
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.536
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.589
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.242
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.561
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.700
[09/03 15:58:18 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 40.287 | 61.239 | 45.229 | 6.336 | 40.319 | 54.385 |
Loading and preparing results...
DONE (t=0.09s)
creating index...
index created!
[09/03 15:58:18 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 15:58:18 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.09 seconds.
[09/03 15:58:18 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:58:18 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.434
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.613
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.509
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.047
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.372
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.615
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.334
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.584
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.650
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.325
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.620
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.761
[09/03 15:58:18 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 43.390 | 61.347 | 50.874 | 4.670 | 37.236 | 61.462 |
[09/03 15:58:18 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 15:58:18 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 15:58:18 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:58:18 d2.evaluation.testing]: copypaste: 40.2870,61.2392,45.2290,6.3356,40.3194,54.3852
[09/03 15:58:18 d2.evaluation.testing]: copypaste: Task: segm
[09/03 15:58:18 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:58:18 d2.evaluation.testing]: copypaste: 43.3900,61.3472,50.8737,4.6697,37.2362,61.4620
[09/03 15:58:18 d2.utils.events]:  eta: 0:05:29  iter: 459  total_loss: 0.6073  loss_cls: 0.09566  loss_box_reg: 0.2925  loss_mask: 0.1801  loss_rpn_cls: 0.002493  loss_rpn_loc: 0.00409  time: 0.6180  data_time: 0.0088  lr: 0.00011489  max_mem: 4868M
[09/03 15:58:31 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 15:58:31 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 15:58:31 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 15:58:31 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 15:58:31 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 15:58:36 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0017 s/iter. Inference: 0.0917 s/iter. Eval: 0.2230 s/iter. Total: 0.3163 s/iter. ETA=0:00:42
[09/03 15:58:41 d2.evaluation.evaluator]: Inference done 32/144. Dataloading: 0.0036 s/iter. Inference: 0.0903 s/iter. Eval: 0.1720 s/iter. Total: 0.2661 s/iter. ETA=0:00:29
[09/03 15:58:46 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0038 s/iter. Inference: 0.0923 s/iter. Eval: 0.1989 s/iter. Total: 0.2951 s/iter. ETA=0:00:28
[09/03 15:58:52 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0035 s/iter. Inference: 0.0945 s/iter. Eval: 0.2279 s/iter. Total: 0.3261 s/iter. ETA=0:00:27
[09/03 15:58:57 d2.evaluation.evaluator]: Inference done 75/144. Dataloading: 0.0033 s/iter. Inference: 0.0945 s/iter. Eval: 0.2253 s/iter. Total: 0.3233 s/iter. ETA=0:00:22
[09/03 15:59:02 d2.evaluation.evaluator]: Inference done 100/144. Dataloading: 0.0034 s/iter. Inference: 0.0924 s/iter. Eval: 0.1981 s/iter. Total: 0.2941 s/iter. ETA=0:00:12
[09/03 15:59:07 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0033 s/iter. Inference: 0.0919 s/iter. Eval: 0.1947 s/iter. Total: 0.2901 s/iter. ETA=0:00:07
[09/03 15:59:12 d2.evaluation.evaluator]: Inference done 141/144. Dataloading: 0.0034 s/iter. Inference: 0.0912 s/iter. Eval: 0.1855 s/iter. Total: 0.2802 s/iter. ETA=0:00:00
[09/03 15:59:13 d2.evaluation.evaluator]: Total inference time: 0:00:39.360998 (0.283173 s / iter per device, on 1 devices)
[09/03 15:59:13 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:12 (0.091311 s / iter per device, on 1 devices)
[09/03 15:59:13 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 15:59:13 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 15:59:14 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/03 15:59:14 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 15:59:14 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/03 15:59:14 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:59:14 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.394
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.613
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.472
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.064
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.416
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.526
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.302
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.537
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.582
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.192
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.569
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.676
[09/03 15:59:14 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 39.448 | 61.313 | 47.250 | 6.417 | 41.579 | 52.563 |
Loading and preparing results...
DONE (t=0.08s)
creating index...
index created!
[09/03 15:59:14 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 15:59:14 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.08 seconds.
[09/03 15:59:14 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 15:59:14 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.430
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.611
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.508
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.047
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.376
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.326
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.588
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.646
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.292
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.767
[09/03 15:59:14 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 43.016 | 61.071 | 50.790 | 4.741 | 37.621 | 60.988 |
[09/03 15:59:14 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 15:59:14 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 15:59:14 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:59:14 d2.evaluation.testing]: copypaste: 39.4479,61.3128,47.2497,6.4172,41.5786,52.5633
[09/03 15:59:14 d2.evaluation.testing]: copypaste: Task: segm
[09/03 15:59:14 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 15:59:14 d2.evaluation.testing]: copypaste: 43.0161,61.0710,50.7901,4.7411,37.6207,60.9877
[09/03 15:59:14 d2.utils.events]:  eta: 0:05:17  iter: 479  total_loss: 0.5984  loss_cls: 0.112  loss_box_reg: 0.2878  loss_mask: 0.1987  loss_rpn_cls: 0.005272  loss_rpn_loc: 0.008427  time: 0.6178  data_time: 0.0087  lr: 0.00011988  max_mem: 4868M
[09/03 15:59:27 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 15:59:27 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 15:59:27 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 15:59:27 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 15:59:27 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 15:59:32 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0032 s/iter. Inference: 0.0951 s/iter. Eval: 0.2373 s/iter. Total: 0.3355 s/iter. ETA=0:00:44
[09/03 15:59:37 d2.evaluation.evaluator]: Inference done 34/144. Dataloading: 0.0029 s/iter. Inference: 0.0872 s/iter. Eval: 0.1541 s/iter. Total: 0.2444 s/iter. ETA=0:00:26
[09/03 15:59:42 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0030 s/iter. Inference: 0.0903 s/iter. Eval: 0.1882 s/iter. Total: 0.2816 s/iter. ETA=0:00:26
[09/03 15:59:47 d2.evaluation.evaluator]: Inference done 61/144. Dataloading: 0.0028 s/iter. Inference: 0.0930 s/iter. Eval: 0.2179 s/iter. Total: 0.3140 s/iter. ETA=0:00:26
[09/03 15:59:53 d2.evaluation.evaluator]: Inference done 79/144. Dataloading: 0.0030 s/iter. Inference: 0.0925 s/iter. Eval: 0.2127 s/iter. Total: 0.3085 s/iter. ETA=0:00:20
[09/03 15:59:58 d2.evaluation.evaluator]: Inference done 101/144. Dataloading: 0.0035 s/iter. Inference: 0.0920 s/iter. Eval: 0.1960 s/iter. Total: 0.2917 s/iter. ETA=0:00:12
[09/03 16:00:03 d2.evaluation.evaluator]: Inference done 122/144. Dataloading: 0.0036 s/iter. Inference: 0.0912 s/iter. Eval: 0.1886 s/iter. Total: 0.2837 s/iter. ETA=0:00:06
[09/03 16:00:08 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0035 s/iter. Inference: 0.0907 s/iter. Eval: 0.1831 s/iter. Total: 0.2774 s/iter. ETA=0:00:00
[09/03 16:00:09 d2.evaluation.evaluator]: Total inference time: 0:00:38.617185 (0.277821 s / iter per device, on 1 devices)
[09/03 16:00:09 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:12 (0.090660 s / iter per device, on 1 devices)
[09/03 16:00:09 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 16:00:09 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 16:00:09 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/03 16:00:09 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 16:00:09 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/03 16:00:09 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:00:09 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.389
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.622
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.461
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.064
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.403
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.520
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.295
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.531
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.582
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.175
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.575
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.668
[09/03 16:00:09 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 38.914 | 62.198 | 46.132 | 6.360 | 40.281 | 52.046 |
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
[09/03 16:00:09 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 16:00:09 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.08 seconds.
[09/03 16:00:09 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:00:09 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.426
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.617
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.502
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.037
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.371
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.607
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.581
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.641
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.242
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.753
[09/03 16:00:09 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 42.622 | 61.734 | 50.177 | 3.693 | 37.136 | 60.656 |
[09/03 16:00:09 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 16:00:09 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 16:00:09 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:00:09 d2.evaluation.testing]: copypaste: 38.9137,62.1982,46.1323,6.3597,40.2814,52.0458
[09/03 16:00:09 d2.evaluation.testing]: copypaste: Task: segm
[09/03 16:00:09 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:00:09 d2.evaluation.testing]: copypaste: 42.6220,61.7341,50.1772,3.6934,37.1360,60.6561
[09/03 16:00:09 d2.utils.events]:  eta: 0:05:05  iter: 499  total_loss: 0.6918  loss_cls: 0.1474  loss_box_reg: 0.2674  loss_mask: 0.213  loss_rpn_cls: 0.00798  loss_rpn_loc: 0.006831  time: 0.6182  data_time: 0.0097  lr: 0.00012488  max_mem: 4868M
[09/03 16:00:21 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 16:00:21 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 16:00:21 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 16:00:21 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 16:00:21 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 16:00:27 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0020 s/iter. Inference: 0.0935 s/iter. Eval: 0.2394 s/iter. Total: 0.3349 s/iter. ETA=0:00:44
[09/03 16:00:32 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0031 s/iter. Inference: 0.0908 s/iter. Eval: 0.2072 s/iter. Total: 0.3012 s/iter. ETA=0:00:34
[09/03 16:00:38 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0033 s/iter. Inference: 0.0929 s/iter. Eval: 0.2240 s/iter. Total: 0.3207 s/iter. ETA=0:00:31
[09/03 16:00:44 d2.evaluation.evaluator]: Inference done 56/144. Dataloading: 0.0034 s/iter. Inference: 0.0965 s/iter. Eval: 0.2673 s/iter. Total: 0.3675 s/iter. ETA=0:00:32
[09/03 16:00:49 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0032 s/iter. Inference: 0.0978 s/iter. Eval: 0.2838 s/iter. Total: 0.3852 s/iter. ETA=0:00:29
[09/03 16:00:54 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0031 s/iter. Inference: 0.0951 s/iter. Eval: 0.2502 s/iter. Total: 0.3487 s/iter. ETA=0:00:19
[09/03 16:00:59 d2.evaluation.evaluator]: Inference done 108/144. Dataloading: 0.0029 s/iter. Inference: 0.0940 s/iter. Eval: 0.2365 s/iter. Total: 0.3337 s/iter. ETA=0:00:12
[09/03 16:01:04 d2.evaluation.evaluator]: Inference done 129/144. Dataloading: 0.0030 s/iter. Inference: 0.0928 s/iter. Eval: 0.2226 s/iter. Total: 0.3186 s/iter. ETA=0:00:04
[09/03 16:01:09 d2.evaluation.evaluator]: Total inference time: 0:00:44.148051 (0.317612 s / iter per device, on 1 devices)
[09/03 16:01:09 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:12 (0.092771 s / iter per device, on 1 devices)
[09/03 16:01:09 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 16:01:09 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 16:01:09 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/03 16:01:09 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 16:01:09 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/03 16:01:09 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:01:09 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.399
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.622
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.479
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.085
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.408
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.533
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.302
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.546
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.594
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.242
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.572
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.697
[09/03 16:01:09 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 39.928 | 62.215 | 47.891 | 8.500 | 40.796 | 53.296 |
Loading and preparing results...
DONE (t=0.09s)
creating index...
index created!
[09/03 16:01:10 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 16:01:10 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.08 seconds.
[09/03 16:01:10 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:01:10 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.446
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.632
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.517
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.053
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.384
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.630
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.330
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.594
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.651
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.275
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.774
[09/03 16:01:10 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 44.643 | 63.210 | 51.679 | 5.327 | 38.375 | 63.010 |
[09/03 16:01:10 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 16:01:10 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 16:01:10 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:01:10 d2.evaluation.testing]: copypaste: 39.9281,62.2150,47.8912,8.5000,40.7959,53.2959
[09/03 16:01:10 d2.evaluation.testing]: copypaste: Task: segm
[09/03 16:01:10 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:01:10 d2.evaluation.testing]: copypaste: 44.6434,63.2104,51.6793,5.3267,38.3745,63.0102
[09/03 16:01:10 d2.utils.events]:  eta: 0:04:53  iter: 519  total_loss: 0.541  loss_cls: 0.1162  loss_box_reg: 0.2138  loss_mask: 0.1589  loss_rpn_cls: 0.009115  loss_rpn_loc: 0.006831  time: 0.6181  data_time: 0.0087  lr: 0.00012987  max_mem: 4868M
[09/03 16:01:22 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 16:01:22 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 16:01:22 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 16:01:22 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 16:01:22 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 16:01:27 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0019 s/iter. Inference: 0.0885 s/iter. Eval: 0.1836 s/iter. Total: 0.2739 s/iter. ETA=0:00:36
[09/03 16:01:32 d2.evaluation.evaluator]: Inference done 36/144. Dataloading: 0.0029 s/iter. Inference: 0.0848 s/iter. Eval: 0.1307 s/iter. Total: 0.2185 s/iter. ETA=0:00:23
[09/03 16:01:37 d2.evaluation.evaluator]: Inference done 50/144. Dataloading: 0.0032 s/iter. Inference: 0.0887 s/iter. Eval: 0.1804 s/iter. Total: 0.2724 s/iter. ETA=0:00:25
[09/03 16:01:43 d2.evaluation.evaluator]: Inference done 63/144. Dataloading: 0.0033 s/iter. Inference: 0.0910 s/iter. Eval: 0.2058 s/iter. Total: 0.3004 s/iter. ETA=0:00:24
[09/03 16:01:48 d2.evaluation.evaluator]: Inference done 83/144. Dataloading: 0.0032 s/iter. Inference: 0.0903 s/iter. Eval: 0.1948 s/iter. Total: 0.2885 s/iter. ETA=0:00:17
[09/03 16:01:53 d2.evaluation.evaluator]: Inference done 108/144. Dataloading: 0.0030 s/iter. Inference: 0.0891 s/iter. Eval: 0.1762 s/iter. Total: 0.2686 s/iter. ETA=0:00:09
[09/03 16:01:58 d2.evaluation.evaluator]: Inference done 132/144. Dataloading: 0.0032 s/iter. Inference: 0.0885 s/iter. Eval: 0.1656 s/iter. Total: 0.2575 s/iter. ETA=0:00:03
[09/03 16:02:01 d2.evaluation.evaluator]: Total inference time: 0:00:35.623343 (0.256283 s / iter per device, on 1 devices)
[09/03 16:02:01 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:12 (0.088281 s / iter per device, on 1 devices)
[09/03 16:02:01 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 16:02:01 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 16:02:01 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/03 16:02:01 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 16:02:01 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/03 16:02:01 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:02:01 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.433
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.648
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.496
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.092
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.423
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.574
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.328
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.569
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.258
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.608
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.717
[09/03 16:02:01 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 43.324 | 64.790 | 49.591 | 9.243 | 42.345 | 57.367 |
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
[09/03 16:02:01 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 16:02:01 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[09/03 16:02:01 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:02:01 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.456
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.654
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.523
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.068
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.388
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.640
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.339
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.591
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.650
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.308
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.622
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.762
[09/03 16:02:01 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 45.550 | 65.423 | 52.287 | 6.839 | 38.763 | 63.992 |
[09/03 16:02:01 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 16:02:01 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 16:02:01 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:02:01 d2.evaluation.testing]: copypaste: 43.3239,64.7898,49.5906,9.2433,42.3448,57.3674
[09/03 16:02:01 d2.evaluation.testing]: copypaste: Task: segm
[09/03 16:02:01 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:02:01 d2.evaluation.testing]: copypaste: 45.5502,65.4228,52.2872,6.8395,38.7634,63.9917
[09/03 16:02:01 d2.utils.events]:  eta: 0:04:41  iter: 539  total_loss: 0.5029  loss_cls: 0.1056  loss_box_reg: 0.207  loss_mask: 0.1793  loss_rpn_cls: 0.007877  loss_rpn_loc: 0.005525  time: 0.6177  data_time: 0.0096  lr: 0.00013487  max_mem: 4868M
[09/03 16:02:14 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 16:02:14 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 16:02:14 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 16:02:14 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 16:02:14 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 16:02:19 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0038 s/iter. Inference: 0.0919 s/iter. Eval: 0.1942 s/iter. Total: 0.2899 s/iter. ETA=0:00:38
[09/03 16:02:24 d2.evaluation.evaluator]: Inference done 37/144. Dataloading: 0.0028 s/iter. Inference: 0.0861 s/iter. Eval: 0.1257 s/iter. Total: 0.2148 s/iter. ETA=0:00:22
[09/03 16:02:29 d2.evaluation.evaluator]: Inference done 51/144. Dataloading: 0.0029 s/iter. Inference: 0.0895 s/iter. Eval: 0.1744 s/iter. Total: 0.2669 s/iter. ETA=0:00:24
[09/03 16:02:35 d2.evaluation.evaluator]: Inference done 66/144. Dataloading: 0.0027 s/iter. Inference: 0.0911 s/iter. Eval: 0.1933 s/iter. Total: 0.2873 s/iter. ETA=0:00:22
[09/03 16:02:40 d2.evaluation.evaluator]: Inference done 86/144. Dataloading: 0.0029 s/iter. Inference: 0.0910 s/iter. Eval: 0.1847 s/iter. Total: 0.2787 s/iter. ETA=0:00:16
[09/03 16:02:45 d2.evaluation.evaluator]: Inference done 108/144. Dataloading: 0.0028 s/iter. Inference: 0.0902 s/iter. Eval: 0.1776 s/iter. Total: 0.2707 s/iter. ETA=0:00:09
[09/03 16:02:50 d2.evaluation.evaluator]: Inference done 132/144. Dataloading: 0.0029 s/iter. Inference: 0.0892 s/iter. Eval: 0.1670 s/iter. Total: 0.2592 s/iter. ETA=0:00:03
[09/03 16:02:53 d2.evaluation.evaluator]: Total inference time: 0:00:35.923456 (0.258442 s / iter per device, on 1 devices)
[09/03 16:02:53 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:12 (0.088907 s / iter per device, on 1 devices)
[09/03 16:02:53 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 16:02:53 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 16:02:53 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/03 16:02:53 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 16:02:53 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/03 16:02:53 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:02:53 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.425
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.652
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.496
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.123
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.430
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.561
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.325
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.558
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.292
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.589
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.714
[09/03 16:02:53 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 42.511 | 65.189 | 49.559 | 12.347 | 42.975 | 56.064 |
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
[09/03 16:02:53 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 16:02:54 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[09/03 16:02:54 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:02:54 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.451
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.643
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.528
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.089
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.390
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.633
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.338
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.592
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.651
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.308
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.768
[09/03 16:02:54 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 45.131 | 64.255 | 52.840 | 8.940 | 38.977 | 63.265 |
[09/03 16:02:54 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 16:02:54 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 16:02:54 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:02:54 d2.evaluation.testing]: copypaste: 42.5105,65.1890,49.5591,12.3468,42.9752,56.0645
[09/03 16:02:54 d2.evaluation.testing]: copypaste: Task: segm
[09/03 16:02:54 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:02:54 d2.evaluation.testing]: copypaste: 45.1313,64.2555,52.8395,8.9398,38.9765,63.2647
[09/03 16:02:54 d2.utils.events]:  eta: 0:04:28  iter: 559  total_loss: 0.4766  loss_cls: 0.09154  loss_box_reg: 0.2247  loss_mask: 0.1471  loss_rpn_cls: 0.00761  loss_rpn_loc: 0.00447  time: 0.6180  data_time: 0.0105  lr: 0.00013986  max_mem: 4868M
[09/03 16:03:06 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 16:03:06 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 16:03:06 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 16:03:06 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 16:03:06 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 16:03:09 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0015 s/iter. Inference: 0.0828 s/iter. Eval: 0.1087 s/iter. Total: 0.1931 s/iter. ETA=0:00:25
[09/03 16:03:14 d2.evaluation.evaluator]: Inference done 38/144. Dataloading: 0.0050 s/iter. Inference: 0.0879 s/iter. Eval: 0.0939 s/iter. Total: 0.1869 s/iter. ETA=0:00:19
[09/03 16:03:20 d2.evaluation.evaluator]: Inference done 56/144. Dataloading: 0.0049 s/iter. Inference: 0.0890 s/iter. Eval: 0.1306 s/iter. Total: 0.2247 s/iter. ETA=0:00:19
[09/03 16:03:25 d2.evaluation.evaluator]: Inference done 81/144. Dataloading: 0.0045 s/iter. Inference: 0.0877 s/iter. Eval: 0.1259 s/iter. Total: 0.2182 s/iter. ETA=0:00:13
[09/03 16:03:30 d2.evaluation.evaluator]: Inference done 112/144. Dataloading: 0.0042 s/iter. Inference: 0.0864 s/iter. Eval: 0.1136 s/iter. Total: 0.2044 s/iter. ETA=0:00:06
[09/03 16:03:36 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0041 s/iter. Inference: 0.0859 s/iter. Eval: 0.1066 s/iter. Total: 0.1968 s/iter. ETA=0:00:00
[09/03 16:03:36 d2.evaluation.evaluator]: Total inference time: 0:00:27.408900 (0.197186 s / iter per device, on 1 devices)
[09/03 16:03:36 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:11 (0.085879 s / iter per device, on 1 devices)
[09/03 16:03:36 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 16:03:36 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 16:03:36 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/03 16:03:36 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 16:03:36 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/03 16:03:36 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:03:36 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.431
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.640
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.514
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.111
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.428
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.576
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.320
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.571
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.612
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.225
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.586
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.727
[09/03 16:03:36 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 43.117 | 64.045 | 51.410 | 11.135 | 42.799 | 57.574 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[09/03 16:03:36 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 16:03:36 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[09/03 16:03:36 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:03:36 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.463
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.658
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.556
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.082
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.401
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.648
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.335
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.600
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.650
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.283
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.776
[09/03 16:03:36 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 46.304 | 65.762 | 55.623 | 8.164 | 40.070 | 64.836 |
[09/03 16:03:36 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 16:03:36 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 16:03:36 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:03:36 d2.evaluation.testing]: copypaste: 43.1173,64.0446,51.4099,11.1347,42.7988,57.5742
[09/03 16:03:36 d2.evaluation.testing]: copypaste: Task: segm
[09/03 16:03:36 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:03:36 d2.evaluation.testing]: copypaste: 46.3036,65.7624,55.6229,8.1642,40.0702,64.8358
[09/03 16:03:36 d2.utils.events]:  eta: 0:04:16  iter: 579  total_loss: 0.4564  loss_cls: 0.1027  loss_box_reg: 0.1848  loss_mask: 0.1474  loss_rpn_cls: 0.003136  loss_rpn_loc: 0.004849  time: 0.6177  data_time: 0.0084  lr: 0.00014486  max_mem: 4868M
[09/03 16:03:49 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 16:03:49 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 16:03:49 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 16:03:49 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 16:03:49 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 16:03:53 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0018 s/iter. Inference: 0.0864 s/iter. Eval: 0.1460 s/iter. Total: 0.2342 s/iter. ETA=0:00:31
[09/03 16:03:58 d2.evaluation.evaluator]: Inference done 39/144. Dataloading: 0.0046 s/iter. Inference: 0.0861 s/iter. Eval: 0.1036 s/iter. Total: 0.1944 s/iter. ETA=0:00:20
[09/03 16:04:03 d2.evaluation.evaluator]: Inference done 54/144. Dataloading: 0.0042 s/iter. Inference: 0.0887 s/iter. Eval: 0.1490 s/iter. Total: 0.2420 s/iter. ETA=0:00:21
[09/03 16:04:08 d2.evaluation.evaluator]: Inference done 72/144. Dataloading: 0.0038 s/iter. Inference: 0.0894 s/iter. Eval: 0.1591 s/iter. Total: 0.2524 s/iter. ETA=0:00:18
[09/03 16:04:13 d2.evaluation.evaluator]: Inference done 103/144. Dataloading: 0.0042 s/iter. Inference: 0.0872 s/iter. Eval: 0.1329 s/iter. Total: 0.2244 s/iter. ETA=0:00:09
[09/03 16:04:19 d2.evaluation.evaluator]: Inference done 129/144. Dataloading: 0.0041 s/iter. Inference: 0.0869 s/iter. Eval: 0.1280 s/iter. Total: 0.2191 s/iter. ETA=0:00:03
[09/03 16:04:22 d2.evaluation.evaluator]: Total inference time: 0:00:30.870643 (0.222091 s / iter per device, on 1 devices)
[09/03 16:04:22 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:12 (0.087594 s / iter per device, on 1 devices)
[09/03 16:04:22 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 16:04:22 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 16:04:22 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/03 16:04:22 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 16:04:22 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/03 16:04:22 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:04:22 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.442
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.661
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.513
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.122
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.425
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.585
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.329
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.575
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.624
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.225
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.606
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.729
[09/03 16:04:22 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 44.228 | 66.129 | 51.261 | 12.177 | 42.492 | 58.491 |
Loading and preparing results...
DONE (t=0.06s)
creating index...
index created!
[09/03 16:04:23 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 16:04:23 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[09/03 16:04:23 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:04:23 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.462
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.669
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.542
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.091
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.394
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.642
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.338
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.597
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.655
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.292
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.629
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.768
[09/03 16:04:23 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 46.230 | 66.854 | 54.211 | 9.070 | 39.441 | 64.179 |
[09/03 16:04:23 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 16:04:23 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 16:04:23 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:04:23 d2.evaluation.testing]: copypaste: 44.2283,66.1288,51.2609,12.1770,42.4919,58.4907
[09/03 16:04:23 d2.evaluation.testing]: copypaste: Task: segm
[09/03 16:04:23 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:04:23 d2.evaluation.testing]: copypaste: 46.2298,66.8539,54.2110,9.0700,39.4411,64.1785
[09/03 16:04:23 d2.utils.events]:  eta: 0:04:04  iter: 599  total_loss: 0.5144  loss_cls: 0.1199  loss_box_reg: 0.2696  loss_mask: 0.1523  loss_rpn_cls: 0.005252  loss_rpn_loc: 0.007218  time: 0.6181  data_time: 0.0102  lr: 0.00014985  max_mem: 4868M
[09/03 16:04:35 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 16:04:35 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 16:04:35 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 16:04:35 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 16:04:35 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 16:04:39 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.0855 s/iter. Eval: 0.1337 s/iter. Total: 0.2207 s/iter. ETA=0:00:29
[09/03 16:04:44 d2.evaluation.evaluator]: Inference done 40/144. Dataloading: 0.0050 s/iter. Inference: 0.0848 s/iter. Eval: 0.0954 s/iter. Total: 0.1853 s/iter. ETA=0:00:19
[09/03 16:04:49 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0047 s/iter. Inference: 0.0869 s/iter. Eval: 0.1302 s/iter. Total: 0.2218 s/iter. ETA=0:00:19
[09/03 16:04:54 d2.evaluation.evaluator]: Inference done 82/144. Dataloading: 0.0043 s/iter. Inference: 0.0867 s/iter. Eval: 0.1248 s/iter. Total: 0.2159 s/iter. ETA=0:00:13
[09/03 16:04:59 d2.evaluation.evaluator]: Inference done 109/144. Dataloading: 0.0045 s/iter. Inference: 0.0871 s/iter. Eval: 0.1177 s/iter. Total: 0.2093 s/iter. ETA=0:00:07
[09/03 16:05:04 d2.evaluation.evaluator]: Inference done 139/144. Dataloading: 0.0045 s/iter. Inference: 0.0863 s/iter. Eval: 0.1098 s/iter. Total: 0.2006 s/iter. ETA=0:00:01
[09/03 16:05:06 d2.evaluation.evaluator]: Total inference time: 0:00:28.218100 (0.203008 s / iter per device, on 1 devices)
[09/03 16:05:06 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:12 (0.086443 s / iter per device, on 1 devices)
[09/03 16:05:06 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 16:05:06 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 16:05:06 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/03 16:05:06 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 16:05:06 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/03 16:05:06 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:05:06 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.454
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.666
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.517
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.115
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.437
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.602
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.331
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.573
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.620
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.233
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.593
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.736
[09/03 16:05:06 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.403 | 66.589 | 51.703 | 11.506 | 43.723 | 60.211 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[09/03 16:05:06 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 16:05:06 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[09/03 16:05:06 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:05:06 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.474
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.666
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.558
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.088
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.412
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.654
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.343
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.597
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.653
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.308
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.621
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.771
[09/03 16:05:06 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 47.403 | 66.606 | 55.784 | 8.783 | 41.164 | 65.393 |
[09/03 16:05:06 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 16:05:06 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 16:05:06 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:05:06 d2.evaluation.testing]: copypaste: 45.4033,66.5885,51.7035,11.5056,43.7233,60.2111
[09/03 16:05:06 d2.evaluation.testing]: copypaste: Task: segm
[09/03 16:05:06 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:05:06 d2.evaluation.testing]: copypaste: 47.4031,66.6058,55.7836,8.7829,41.1635,65.3926
[09/03 16:05:06 d2.utils.events]:  eta: 0:03:52  iter: 619  total_loss: 0.4881  loss_cls: 0.1032  loss_box_reg: 0.2007  loss_mask: 0.1496  loss_rpn_cls: 0.002727  loss_rpn_loc: 0.006093  time: 0.6177  data_time: 0.0091  lr: 0.00015485  max_mem: 4868M
[09/03 16:05:18 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 16:05:18 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 16:05:18 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 16:05:18 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 16:05:18 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 16:05:23 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.0874 s/iter. Eval: 0.1593 s/iter. Total: 0.2484 s/iter. ETA=0:00:33
[09/03 16:05:28 d2.evaluation.evaluator]: Inference done 36/144. Dataloading: 0.0027 s/iter. Inference: 0.0868 s/iter. Eval: 0.1220 s/iter. Total: 0.2116 s/iter. ETA=0:00:22
[09/03 16:05:33 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0033 s/iter. Inference: 0.0887 s/iter. Eval: 0.1576 s/iter. Total: 0.2499 s/iter. ETA=0:00:22
[09/03 16:05:39 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0032 s/iter. Inference: 0.0910 s/iter. Eval: 0.1884 s/iter. Total: 0.2829 s/iter. ETA=0:00:21
[09/03 16:05:44 d2.evaluation.evaluator]: Inference done 98/144. Dataloading: 0.0034 s/iter. Inference: 0.0911 s/iter. Eval: 0.1518 s/iter. Total: 0.2467 s/iter. ETA=0:00:11
[09/03 16:05:49 d2.evaluation.evaluator]: Inference done 122/144. Dataloading: 0.0036 s/iter. Inference: 0.0901 s/iter. Eval: 0.1454 s/iter. Total: 0.2393 s/iter. ETA=0:00:05
[09/03 16:05:54 d2.evaluation.evaluator]: Total inference time: 0:00:32.256242 (0.232059 s / iter per device, on 1 devices)
[09/03 16:05:54 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:12 (0.089122 s / iter per device, on 1 devices)
[09/03 16:05:54 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 16:05:54 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 16:05:54 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/03 16:05:54 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 16:05:54 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/03 16:05:54 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:05:54 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.455
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.687
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.514
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.103
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.455
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.588
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.335
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.575
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.625
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.183
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.730
[09/03 16:05:54 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.526 | 68.674 | 51.431 | 10.269 | 45.472 | 58.804 |
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
[09/03 16:05:54 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 16:05:54 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[09/03 16:05:54 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:05:54 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.483
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.693
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.563
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.080
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.420
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.659
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.347
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.602
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.660
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.267
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.634
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.777
[09/03 16:05:54 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 48.317 | 69.257 | 56.329 | 8.027 | 42.028 | 65.893 |
[09/03 16:05:54 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 16:05:54 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 16:05:54 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:05:54 d2.evaluation.testing]: copypaste: 45.5262,68.6745,51.4313,10.2689,45.4717,58.8037
[09/03 16:05:54 d2.evaluation.testing]: copypaste: Task: segm
[09/03 16:05:54 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:05:54 d2.evaluation.testing]: copypaste: 48.3165,69.2569,56.3290,8.0267,42.0279,65.8934
[09/03 16:05:54 d2.utils.events]:  eta: 0:03:40  iter: 639  total_loss: 0.5131  loss_cls: 0.08834  loss_box_reg: 0.2248  loss_mask: 0.1828  loss_rpn_cls: 0.00538  loss_rpn_loc: 0.006107  time: 0.6177  data_time: 0.0086  lr: 0.00015984  max_mem: 4868M
[09/03 16:06:06 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 16:06:06 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 16:06:06 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 16:06:06 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 16:06:06 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 16:06:10 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0021 s/iter. Inference: 0.0824 s/iter. Eval: 0.0937 s/iter. Total: 0.1782 s/iter. ETA=0:00:23
[09/03 16:06:15 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0051 s/iter. Inference: 0.0861 s/iter. Eval: 0.0803 s/iter. Total: 0.1717 s/iter. ETA=0:00:17
[09/03 16:06:20 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0047 s/iter. Inference: 0.0879 s/iter. Eval: 0.1216 s/iter. Total: 0.2143 s/iter. ETA=0:00:18
[09/03 16:06:26 d2.evaluation.evaluator]: Inference done 90/144. Dataloading: 0.0042 s/iter. Inference: 0.0863 s/iter. Eval: 0.1058 s/iter. Total: 0.1964 s/iter. ETA=0:00:10
[09/03 16:06:31 d2.evaluation.evaluator]: Inference done 120/144. Dataloading: 0.0041 s/iter. Inference: 0.0861 s/iter. Eval: 0.0995 s/iter. Total: 0.1899 s/iter. ETA=0:00:04
[09/03 16:06:35 d2.evaluation.evaluator]: Total inference time: 0:00:25.825779 (0.185797 s / iter per device, on 1 devices)
[09/03 16:06:35 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:11 (0.085239 s / iter per device, on 1 devices)
[09/03 16:06:35 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 16:06:35 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 16:06:35 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/03 16:06:35 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 16:06:35 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/03 16:06:35 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:06:35 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.450
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.672
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.492
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.103
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.447
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.590
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.324
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.567
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.183
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.594
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.724
[09/03 16:06:35 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 44.992 | 67.187 | 49.234 | 10.323 | 44.695 | 59.047 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[09/03 16:06:35 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 16:06:35 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[09/03 16:06:35 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:06:35 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.476
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.673
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.564
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.071
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.426
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.648
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.338
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.592
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.644
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.250
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.618
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.759
[09/03 16:06:35 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 47.574 | 67.262 | 56.405 | 7.134 | 42.551 | 64.758 |
[09/03 16:06:35 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 16:06:35 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 16:06:35 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:06:35 d2.evaluation.testing]: copypaste: 44.9917,67.1865,49.2335,10.3235,44.6950,59.0467
[09/03 16:06:35 d2.evaluation.testing]: copypaste: Task: segm
[09/03 16:06:35 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:06:35 d2.evaluation.testing]: copypaste: 47.5742,67.2623,56.4048,7.1342,42.5511,64.7579
[09/03 16:06:35 d2.utils.events]:  eta: 0:03:27  iter: 659  total_loss: 0.5995  loss_cls: 0.1039  loss_box_reg: 0.2807  loss_mask: 0.1976  loss_rpn_cls: 0.002063  loss_rpn_loc: 0.00624  time: 0.6176  data_time: 0.0091  lr: 0.00016484  max_mem: 4868M
[09/03 16:06:47 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 16:06:47 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 16:06:47 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 16:06:47 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 16:06:47 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 16:06:51 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0021 s/iter. Inference: 0.0828 s/iter. Eval: 0.1035 s/iter. Total: 0.1885 s/iter. ETA=0:00:25
[09/03 16:06:56 d2.evaluation.evaluator]: Inference done 43/144. Dataloading: 0.0036 s/iter. Inference: 0.0846 s/iter. Eval: 0.0826 s/iter. Total: 0.1709 s/iter. ETA=0:00:17
[09/03 16:07:01 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0033 s/iter. Inference: 0.0873 s/iter. Eval: 0.1251 s/iter. Total: 0.2159 s/iter. ETA=0:00:18
[09/03 16:07:06 d2.evaluation.evaluator]: Inference done 87/144. Dataloading: 0.0031 s/iter. Inference: 0.0862 s/iter. Eval: 0.1145 s/iter. Total: 0.2039 s/iter. ETA=0:00:11
[09/03 16:07:11 d2.evaluation.evaluator]: Inference done 118/144. Dataloading: 0.0033 s/iter. Inference: 0.0854 s/iter. Eval: 0.1034 s/iter. Total: 0.1922 s/iter. ETA=0:00:04
[09/03 16:07:16 d2.evaluation.evaluator]: Total inference time: 0:00:26.340666 (0.189501 s / iter per device, on 1 devices)
[09/03 16:07:16 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:11 (0.085295 s / iter per device, on 1 devices)
[09/03 16:07:16 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 16:07:16 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 16:07:16 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/03 16:07:16 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 16:07:16 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/03 16:07:16 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:07:16 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.451
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.672
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.502
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.104
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.436
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.600
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.327
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.570
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.611
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.183
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.588
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.730
[09/03 16:07:16 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.086 | 67.201 | 50.228 | 10.358 | 43.573 | 59.957 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[09/03 16:07:16 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 16:07:16 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[09/03 16:07:16 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:07:16 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.475
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.672
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.575
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.079
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.427
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.647
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.338
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.596
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.644
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.242
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.767
[09/03 16:07:16 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 47.543 | 67.229 | 57.529 | 7.878 | 42.725 | 64.750 |
[09/03 16:07:16 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 16:07:16 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 16:07:16 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:07:16 d2.evaluation.testing]: copypaste: 45.0864,67.2005,50.2277,10.3579,43.5734,59.9573
[09/03 16:07:16 d2.evaluation.testing]: copypaste: Task: segm
[09/03 16:07:16 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:07:16 d2.evaluation.testing]: copypaste: 47.5426,67.2286,57.5287,7.8780,42.7248,64.7499
[09/03 16:07:16 d2.utils.events]:  eta: 0:03:15  iter: 679  total_loss: 0.3053  loss_cls: 0.05699  loss_box_reg: 0.13  loss_mask: 0.1122  loss_rpn_cls: 0.005064  loss_rpn_loc: 0.002891  time: 0.6174  data_time: 0.0078  lr: 0.00016983  max_mem: 4868M
[09/03 16:07:28 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 16:07:28 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 16:07:28 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 16:07:28 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 16:07:28 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 16:07:33 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.0883 s/iter. Eval: 0.1870 s/iter. Total: 0.2768 s/iter. ETA=0:00:36
[09/03 16:07:38 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0046 s/iter. Inference: 0.0926 s/iter. Eval: 0.1894 s/iter. Total: 0.2867 s/iter. ETA=0:00:32
[09/03 16:07:44 d2.evaluation.evaluator]: Inference done 48/144. Dataloading: 0.0037 s/iter. Inference: 0.0912 s/iter. Eval: 0.1840 s/iter. Total: 0.2790 s/iter. ETA=0:00:26
[09/03 16:07:49 d2.evaluation.evaluator]: Inference done 60/144. Dataloading: 0.0036 s/iter. Inference: 0.0936 s/iter. Eval: 0.2123 s/iter. Total: 0.3097 s/iter. ETA=0:00:26
[09/03 16:07:54 d2.evaluation.evaluator]: Inference done 78/144. Dataloading: 0.0038 s/iter. Inference: 0.0930 s/iter. Eval: 0.2057 s/iter. Total: 0.3026 s/iter. ETA=0:00:19
[09/03 16:07:59 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0037 s/iter. Inference: 0.0908 s/iter. Eval: 0.1798 s/iter. Total: 0.2744 s/iter. ETA=0:00:10
[09/03 16:08:04 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0040 s/iter. Inference: 0.0891 s/iter. Eval: 0.1633 s/iter. Total: 0.2565 s/iter. ETA=0:00:03
[09/03 16:08:07 d2.evaluation.evaluator]: Total inference time: 0:00:35.280871 (0.253819 s / iter per device, on 1 devices)
[09/03 16:08:07 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:12 (0.088769 s / iter per device, on 1 devices)
[09/03 16:08:07 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 16:08:07 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 16:08:07 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/03 16:08:07 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 16:08:07 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/03 16:08:07 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:08:07 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.453
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.686
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.524
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.085
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.442
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.602
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.330
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.570
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.250
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.583
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.730
[09/03 16:08:07 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 45.297 | 68.570 | 52.443 | 8.540 | 44.215 | 60.223 |
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
[09/03 16:08:07 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 16:08:07 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[09/03 16:08:07 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:08:07 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.479
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.683
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.573
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.071
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.428
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.651
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.344
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.600
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.662
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.630
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.776
[09/03 16:08:07 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 47.938 | 68.291 | 57.331 | 7.075 | 42.844 | 65.126 |
[09/03 16:08:07 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 16:08:07 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 16:08:07 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:08:07 d2.evaluation.testing]: copypaste: 45.2975,68.5698,52.4428,8.5399,44.2154,60.2232
[09/03 16:08:07 d2.evaluation.testing]: copypaste: Task: segm
[09/03 16:08:07 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:08:07 d2.evaluation.testing]: copypaste: 47.9385,68.2914,57.3310,7.0749,42.8439,65.1264
[09/03 16:08:07 d2.utils.events]:  eta: 0:03:03  iter: 699  total_loss: 0.564  loss_cls: 0.1154  loss_box_reg: 0.2387  loss_mask: 0.1747  loss_rpn_cls: 0.006921  loss_rpn_loc: 0.005826  time: 0.6172  data_time: 0.0084  lr: 0.00017483  max_mem: 4868M
[09/03 16:08:20 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 16:08:20 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 16:08:20 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 16:08:20 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 16:08:20 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 16:08:24 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0015 s/iter. Inference: 0.0863 s/iter. Eval: 0.1520 s/iter. Total: 0.2398 s/iter. ETA=0:00:31
[09/03 16:08:29 d2.evaluation.evaluator]: Inference done 39/144. Dataloading: 0.0042 s/iter. Inference: 0.0842 s/iter. Eval: 0.1032 s/iter. Total: 0.1917 s/iter. ETA=0:00:20
[09/03 16:08:34 d2.evaluation.evaluator]: Inference done 55/144. Dataloading: 0.0039 s/iter. Inference: 0.0871 s/iter. Eval: 0.1398 s/iter. Total: 0.2309 s/iter. ETA=0:00:20
[09/03 16:08:39 d2.evaluation.evaluator]: Inference done 75/144. Dataloading: 0.0035 s/iter. Inference: 0.0876 s/iter. Eval: 0.1465 s/iter. Total: 0.2376 s/iter. ETA=0:00:16
[09/03 16:08:45 d2.evaluation.evaluator]: Inference done 105/144. Dataloading: 0.0037 s/iter. Inference: 0.0870 s/iter. Eval: 0.1276 s/iter. Total: 0.2185 s/iter. ETA=0:00:08
[09/03 16:08:50 d2.evaluation.evaluator]: Inference done 136/144. Dataloading: 0.0040 s/iter. Inference: 0.0858 s/iter. Eval: 0.1158 s/iter. Total: 0.2057 s/iter. ETA=0:00:01
[09/03 16:08:52 d2.evaluation.evaluator]: Total inference time: 0:00:28.843457 (0.207507 s / iter per device, on 1 devices)
[09/03 16:08:52 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:11 (0.085765 s / iter per device, on 1 devices)
[09/03 16:08:52 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 16:08:52 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 16:08:52 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/03 16:08:52 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 16:08:52 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/03 16:08:52 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:08:52 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.464
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.687
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.538
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.110
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.436
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.608
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.332
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.580
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.625
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.233
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.601
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.738
[09/03 16:08:52 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.441 | 68.745 | 53.797 | 10.964 | 43.632 | 60.785 |
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
[09/03 16:08:52 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 16:08:52 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[09/03 16:08:52 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:08:52 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.485
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.691
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.585
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.090
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.427
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.654
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.345
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.601
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.657
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.308
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.627
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.773
[09/03 16:08:52 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 48.463 | 69.115 | 58.479 | 8.959 | 42.696 | 65.391 |
[09/03 16:08:52 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 16:08:52 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 16:08:52 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:08:52 d2.evaluation.testing]: copypaste: 46.4406,68.7448,53.7971,10.9644,43.6318,60.7853
[09/03 16:08:52 d2.evaluation.testing]: copypaste: Task: segm
[09/03 16:08:52 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:08:52 d2.evaluation.testing]: copypaste: 48.4628,69.1155,58.4791,8.9588,42.6962,65.3906
[09/03 16:08:52 d2.utils.events]:  eta: 0:02:51  iter: 719  total_loss: 0.452  loss_cls: 0.08669  loss_box_reg: 0.18  loss_mask: 0.1316  loss_rpn_cls: 0.003041  loss_rpn_loc: 0.003932  time: 0.6171  data_time: 0.0086  lr: 0.00017982  max_mem: 4868M
[09/03 16:09:05 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 16:09:05 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 16:09:05 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 16:09:05 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 16:09:05 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 16:09:08 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0019 s/iter. Inference: 0.0831 s/iter. Eval: 0.1156 s/iter. Total: 0.2005 s/iter. ETA=0:00:26
[09/03 16:09:13 d2.evaluation.evaluator]: Inference done 43/144. Dataloading: 0.0036 s/iter. Inference: 0.0828 s/iter. Eval: 0.0795 s/iter. Total: 0.1661 s/iter. ETA=0:00:16
[09/03 16:09:18 d2.evaluation.evaluator]: Inference done 60/144. Dataloading: 0.0034 s/iter. Inference: 0.0856 s/iter. Eval: 0.1178 s/iter. Total: 0.2070 s/iter. ETA=0:00:17
[09/03 16:09:23 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0034 s/iter. Inference: 0.0849 s/iter. Eval: 0.1078 s/iter. Total: 0.1962 s/iter. ETA=0:00:10
[09/03 16:09:28 d2.evaluation.evaluator]: Inference done 120/144. Dataloading: 0.0037 s/iter. Inference: 0.0845 s/iter. Eval: 0.0990 s/iter. Total: 0.1874 s/iter. ETA=0:00:04
[09/03 16:09:32 d2.evaluation.evaluator]: Total inference time: 0:00:25.638415 (0.184449 s / iter per device, on 1 devices)
[09/03 16:09:32 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:11 (0.084178 s / iter per device, on 1 devices)
[09/03 16:09:32 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 16:09:32 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 16:09:32 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/03 16:09:32 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 16:09:33 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/03 16:09:33 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:09:33 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.694
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.556
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.134
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.452
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.598
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.326
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.574
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.242
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.586
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.729
[09/03 16:09:33 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.755 | 69.410 | 55.564 | 13.428 | 45.158 | 59.753 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[09/03 16:09:33 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 16:09:33 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[09/03 16:09:33 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:09:33 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.487
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.696
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.579
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.079
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.436
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.659
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.346
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.601
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.651
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.292
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.773
[09/03 16:09:33 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 48.733 | 69.645 | 57.900 | 7.896 | 43.598 | 65.857 |
[09/03 16:09:33 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 16:09:33 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 16:09:33 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:09:33 d2.evaluation.testing]: copypaste: 45.7548,69.4099,55.5638,13.4281,45.1580,59.7526
[09/03 16:09:33 d2.evaluation.testing]: copypaste: Task: segm
[09/03 16:09:33 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:09:33 d2.evaluation.testing]: copypaste: 48.7328,69.6452,57.8998,7.8956,43.5980,65.8569
[09/03 16:09:33 d2.utils.events]:  eta: 0:02:38  iter: 739  total_loss: 0.4409  loss_cls: 0.1096  loss_box_reg: 0.1721  loss_mask: 0.1313  loss_rpn_cls: 0.003509  loss_rpn_loc: 0.003829  time: 0.6174  data_time: 0.0098  lr: 0.00018482  max_mem: 4868M
[09/03 16:09:45 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 16:09:45 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 16:09:45 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 16:09:45 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 16:09:46 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 16:09:50 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.0865 s/iter. Eval: 0.1415 s/iter. Total: 0.2296 s/iter. ETA=0:00:30
[09/03 16:09:55 d2.evaluation.evaluator]: Inference done 38/144. Dataloading: 0.0025 s/iter. Inference: 0.0837 s/iter. Eval: 0.1099 s/iter. Total: 0.1962 s/iter. ETA=0:00:20
[09/03 16:10:00 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0027 s/iter. Inference: 0.0872 s/iter. Eval: 0.1558 s/iter. Total: 0.2459 s/iter. ETA=0:00:22
[09/03 16:10:06 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0029 s/iter. Inference: 0.0891 s/iter. Eval: 0.1773 s/iter. Total: 0.2695 s/iter. ETA=0:00:20
[09/03 16:10:11 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0034 s/iter. Inference: 0.0897 s/iter. Eval: 0.1603 s/iter. Total: 0.2535 s/iter. ETA=0:00:13
[09/03 16:10:16 d2.evaluation.evaluator]: Inference done 120/144. Dataloading: 0.0034 s/iter. Inference: 0.0882 s/iter. Eval: 0.1440 s/iter. Total: 0.2357 s/iter. ETA=0:00:05
[09/03 16:10:21 d2.evaluation.evaluator]: Total inference time: 0:00:32.112907 (0.231028 s / iter per device, on 1 devices)
[09/03 16:10:21 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:12 (0.087655 s / iter per device, on 1 devices)
[09/03 16:10:21 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 16:10:21 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 16:10:21 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/03 16:10:21 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 16:10:21 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/03 16:10:21 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:10:21 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.467
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.709
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.526
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.135
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.446
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.604
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.337
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.581
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.621
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.250
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.596
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.733
[09/03 16:10:21 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.682 | 70.904 | 52.636 | 13.494 | 44.588 | 60.393 |
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
[09/03 16:10:21 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 16:10:21 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[09/03 16:10:21 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:10:21 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.497
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.706
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.593
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.094
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.438
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.664
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.605
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.661
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.635
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.767
[09/03 16:10:21 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 49.698 | 70.588 | 59.287 | 9.352 | 43.765 | 66.370 |
[09/03 16:10:21 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 16:10:21 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 16:10:21 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:10:21 d2.evaluation.testing]: copypaste: 46.6818,70.9037,52.6359,13.4942,44.5877,60.3933
[09/03 16:10:21 d2.evaluation.testing]: copypaste: Task: segm
[09/03 16:10:21 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:10:21 d2.evaluation.testing]: copypaste: 49.6976,70.5877,59.2867,9.3519,43.7650,66.3702
[09/03 16:10:21 d2.utils.events]:  eta: 0:02:26  iter: 759  total_loss: 0.4567  loss_cls: 0.1131  loss_box_reg: 0.1819  loss_mask: 0.1696  loss_rpn_cls: 0.006007  loss_rpn_loc: 0.004378  time: 0.6177  data_time: 0.0097  lr: 0.00018981  max_mem: 4868M
[09/03 16:10:33 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 16:10:33 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 16:10:33 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 16:10:33 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 16:10:33 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 16:10:36 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0043 s/iter. Inference: 0.0825 s/iter. Eval: 0.0872 s/iter. Total: 0.1739 s/iter. ETA=0:00:23
[09/03 16:10:41 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0053 s/iter. Inference: 0.0867 s/iter. Eval: 0.0761 s/iter. Total: 0.1682 s/iter. ETA=0:00:17
[09/03 16:10:46 d2.evaluation.evaluator]: Inference done 62/144. Dataloading: 0.0049 s/iter. Inference: 0.0866 s/iter. Eval: 0.1027 s/iter. Total: 0.1943 s/iter. ETA=0:00:15
[09/03 16:10:51 d2.evaluation.evaluator]: Inference done 96/144. Dataloading: 0.0046 s/iter. Inference: 0.0849 s/iter. Eval: 0.0872 s/iter. Total: 0.1768 s/iter. ETA=0:00:08
[09/03 16:10:56 d2.evaluation.evaluator]: Inference done 128/144. Dataloading: 0.0048 s/iter. Inference: 0.0850 s/iter. Eval: 0.0820 s/iter. Total: 0.1721 s/iter. ETA=0:00:02
[09/03 16:10:59 d2.evaluation.evaluator]: Total inference time: 0:00:23.928161 (0.172145 s / iter per device, on 1 devices)
[09/03 16:10:59 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:11 (0.084779 s / iter per device, on 1 devices)
[09/03 16:10:59 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 16:10:59 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 16:10:59 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/03 16:10:59 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 16:10:59 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/03 16:10:59 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:10:59 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.479
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.707
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.552
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.454
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.341
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.587
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.630
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.283
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.604
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.738
[09/03 16:10:59 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.907 | 70.710 | 55.238 | 16.689 | 45.402 | 61.896 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[09/03 16:10:59 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 16:10:59 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/03 16:10:59 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:10:59 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.501
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.709
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.612
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.447
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.659
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.356
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.604
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.648
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.621
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.752
[09/03 16:10:59 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 50.063 | 70.860 | 61.167 | 9.988 | 44.731 | 65.872 |
[09/03 16:10:59 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 16:10:59 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 16:10:59 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:10:59 d2.evaluation.testing]: copypaste: 47.9073,70.7103,55.2385,16.6886,45.4023,61.8957
[09/03 16:10:59 d2.evaluation.testing]: copypaste: Task: segm
[09/03 16:10:59 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:10:59 d2.evaluation.testing]: copypaste: 50.0634,70.8598,61.1670,9.9875,44.7310,65.8717
[09/03 16:10:59 d2.utils.events]:  eta: 0:02:14  iter: 779  total_loss: 0.4059  loss_cls: 0.08015  loss_box_reg: 0.158  loss_mask: 0.1463  loss_rpn_cls: 0.007023  loss_rpn_loc: 0.003817  time: 0.6172  data_time: 0.0096  lr: 0.00019481  max_mem: 4868M
[09/03 16:11:12 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 16:11:12 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 16:11:12 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 16:11:12 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 16:11:12 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 16:11:15 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.0828 s/iter. Eval: 0.1005 s/iter. Total: 0.1849 s/iter. ETA=0:00:24
[09/03 16:11:20 d2.evaluation.evaluator]: Inference done 37/144. Dataloading: 0.0049 s/iter. Inference: 0.0882 s/iter. Eval: 0.0991 s/iter. Total: 0.1923 s/iter. ETA=0:00:20
[09/03 16:11:25 d2.evaluation.evaluator]: Inference done 56/144. Dataloading: 0.0046 s/iter. Inference: 0.0887 s/iter. Eval: 0.1260 s/iter. Total: 0.2196 s/iter. ETA=0:00:19
[09/03 16:11:30 d2.evaluation.evaluator]: Inference done 79/144. Dataloading: 0.0045 s/iter. Inference: 0.0880 s/iter. Eval: 0.1264 s/iter. Total: 0.2192 s/iter. ETA=0:00:14
[09/03 16:11:35 d2.evaluation.evaluator]: Inference done 112/144. Dataloading: 0.0044 s/iter. Inference: 0.0862 s/iter. Eval: 0.1091 s/iter. Total: 0.2000 s/iter. ETA=0:00:06
[09/03 16:11:41 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0042 s/iter. Inference: 0.0860 s/iter. Eval: 0.1027 s/iter. Total: 0.1931 s/iter. ETA=0:00:00
[09/03 16:11:41 d2.evaluation.evaluator]: Total inference time: 0:00:26.887824 (0.193438 s / iter per device, on 1 devices)
[09/03 16:11:41 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:11 (0.086011 s / iter per device, on 1 devices)
[09/03 16:11:41 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 16:11:41 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 16:11:41 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/03 16:11:41 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 16:11:41 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/03 16:11:41 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:11:41 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.480
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.705
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.549
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.158
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.462
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.624
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.341
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.587
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.627
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.275
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.599
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.741
[09/03 16:11:41 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.986 | 70.534 | 54.923 | 15.771 | 46.168 | 62.408 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[09/03 16:11:41 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 16:11:41 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[09/03 16:11:41 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:11:41 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.499
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.714
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.593
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.102
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.440
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.667
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.355
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.607
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.654
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.325
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.767
[09/03 16:11:41 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.878 | 71.411 | 59.295 | 10.236 | 44.042 | 66.710 |
[09/03 16:11:41 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 16:11:41 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 16:11:41 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:11:41 d2.evaluation.testing]: copypaste: 47.9857,70.5340,54.9231,15.7713,46.1679,62.4080
[09/03 16:11:41 d2.evaluation.testing]: copypaste: Task: segm
[09/03 16:11:41 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:11:41 d2.evaluation.testing]: copypaste: 49.8782,71.4113,59.2953,10.2363,44.0420,66.7100
[09/03 16:11:41 d2.utils.events]:  eta: 0:02:02  iter: 799  total_loss: 0.4845  loss_cls: 0.0893  loss_box_reg: 0.2092  loss_mask: 0.1402  loss_rpn_cls: 0.003181  loss_rpn_loc: 0.006238  time: 0.6171  data_time: 0.0083  lr: 0.0001998  max_mem: 4868M
[09/03 16:11:54 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 16:11:54 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 16:11:54 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 16:11:54 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 16:11:54 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 16:11:56 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.0802 s/iter. Eval: 0.0629 s/iter. Total: 0.1448 s/iter. ETA=0:00:19
[09/03 16:12:01 d2.evaluation.evaluator]: Inference done 45/144. Dataloading: 0.0052 s/iter. Inference: 0.0833 s/iter. Eval: 0.0591 s/iter. Total: 0.1477 s/iter. ETA=0:00:14
[09/03 16:12:06 d2.evaluation.evaluator]: Inference done 70/144. Dataloading: 0.0052 s/iter. Inference: 0.0838 s/iter. Eval: 0.0797 s/iter. Total: 0.1688 s/iter. ETA=0:00:12
[09/03 16:12:11 d2.evaluation.evaluator]: Inference done 106/144. Dataloading: 0.0066 s/iter. Inference: 0.0837 s/iter. Eval: 0.0677 s/iter. Total: 0.1581 s/iter. ETA=0:00:06
[09/03 16:12:17 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0063 s/iter. Inference: 0.0832 s/iter. Eval: 0.0635 s/iter. Total: 0.1533 s/iter. ETA=0:00:00
[09/03 16:12:17 d2.evaluation.evaluator]: Total inference time: 0:00:21.360413 (0.153672 s / iter per device, on 1 devices)
[09/03 16:12:17 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:11 (0.083238 s / iter per device, on 1 devices)
[09/03 16:12:17 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 16:12:17 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 16:12:17 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/03 16:12:17 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 16:12:17 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/03 16:12:17 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:12:17 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.472
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.698
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.541
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.134
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.440
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.629
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.339
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.567
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.605
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.192
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.570
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.741
[09/03 16:12:17 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.237 | 69.759 | 54.083 | 13.429 | 44.004 | 62.897 |
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/03 16:12:17 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 16:12:17 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/03 16:12:17 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:12:17 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.497
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.709
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.590
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.083
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.442
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.662
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.352
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.593
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.639
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.275
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.606
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.762
[09/03 16:12:17 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 49.653 | 70.926 | 58.990 | 8.291 | 44.183 | 66.164 |
[09/03 16:12:17 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 16:12:17 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 16:12:17 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:12:17 d2.evaluation.testing]: copypaste: 47.2374,69.7590,54.0829,13.4294,44.0040,62.8968
[09/03 16:12:17 d2.evaluation.testing]: copypaste: Task: segm
[09/03 16:12:17 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:12:17 d2.evaluation.testing]: copypaste: 49.6528,70.9262,58.9900,8.2912,44.1833,66.1636
[09/03 16:12:17 d2.utils.events]:  eta: 0:01:49  iter: 819  total_loss: 0.3914  loss_cls: 0.07867  loss_box_reg: 0.1579  loss_mask: 0.1424  loss_rpn_cls: 0.005203  loss_rpn_loc: 0.003459  time: 0.6169  data_time: 0.0090  lr: 0.0002048  max_mem: 4868M
[09/03 16:12:29 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 16:12:29 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 16:12:29 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 16:12:29 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 16:12:29 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 16:12:33 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0043 s/iter. Inference: 0.0839 s/iter. Eval: 0.1423 s/iter. Total: 0.2304 s/iter. ETA=0:00:30
[09/03 16:12:38 d2.evaluation.evaluator]: Inference done 38/144. Dataloading: 0.0056 s/iter. Inference: 0.0853 s/iter. Eval: 0.1040 s/iter. Total: 0.1951 s/iter. ETA=0:00:20
[09/03 16:12:43 d2.evaluation.evaluator]: Inference done 56/144. Dataloading: 0.0044 s/iter. Inference: 0.0870 s/iter. Eval: 0.1347 s/iter. Total: 0.2264 s/iter. ETA=0:00:19
[09/03 16:12:48 d2.evaluation.evaluator]: Inference done 81/144. Dataloading: 0.0042 s/iter. Inference: 0.0869 s/iter. Eval: 0.1283 s/iter. Total: 0.2197 s/iter. ETA=0:00:13
[09/03 16:12:54 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0044 s/iter. Inference: 0.0855 s/iter. Eval: 0.1114 s/iter. Total: 0.2015 s/iter. ETA=0:00:06
[09/03 16:12:59 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0044 s/iter. Inference: 0.0855 s/iter. Eval: 0.1053 s/iter. Total: 0.1954 s/iter. ETA=0:00:00
[09/03 16:12:59 d2.evaluation.evaluator]: Total inference time: 0:00:27.215153 (0.195792 s / iter per device, on 1 devices)
[09/03 16:12:59 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:11 (0.085519 s / iter per device, on 1 devices)
[09/03 16:12:59 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 16:12:59 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 16:12:59 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/03 16:12:59 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 16:12:59 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/03 16:12:59 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:12:59 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.449
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.715
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.504
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.166
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.429
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.569
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.320
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.550
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.599
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.283
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.582
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.688
[09/03 16:12:59 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 44.930 | 71.548 | 50.427 | 16.607 | 42.856 | 56.879 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[09/03 16:12:59 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 16:12:59 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[09/03 16:12:59 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:12:59 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.495
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.717
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.590
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.113
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.428
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.657
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.344
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.599
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.651
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.626
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.748
[09/03 16:12:59 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.544 | 71.723 | 58.975 | 11.332 | 42.782 | 65.749 |
[09/03 16:12:59 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 16:12:59 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 16:12:59 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:12:59 d2.evaluation.testing]: copypaste: 44.9300,71.5475,50.4267,16.6070,42.8562,56.8793
[09/03 16:12:59 d2.evaluation.testing]: copypaste: Task: segm
[09/03 16:12:59 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:12:59 d2.evaluation.testing]: copypaste: 49.5442,71.7231,58.9745,11.3324,42.7821,65.7486
[09/03 16:12:59 d2.utils.events]:  eta: 0:01:37  iter: 839  total_loss: 0.4049  loss_cls: 0.07859  loss_box_reg: 0.1368  loss_mask: 0.1467  loss_rpn_cls: 0.001337  loss_rpn_loc: 0.002935  time: 0.6168  data_time: 0.0095  lr: 0.00020979  max_mem: 4868M
[09/03 16:13:11 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 16:13:12 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 16:13:12 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 16:13:12 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 16:13:12 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 16:13:14 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0028 s/iter. Inference: 0.0796 s/iter. Eval: 0.0605 s/iter. Total: 0.1430 s/iter. ETA=0:00:19
[09/03 16:13:19 d2.evaluation.evaluator]: Inference done 42/144. Dataloading: 0.0050 s/iter. Inference: 0.0881 s/iter. Eval: 0.0681 s/iter. Total: 0.1615 s/iter. ETA=0:00:16
[09/03 16:13:24 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0046 s/iter. Inference: 0.0864 s/iter. Eval: 0.0880 s/iter. Total: 0.1792 s/iter. ETA=0:00:13
[09/03 16:13:30 d2.evaluation.evaluator]: Inference done 103/144. Dataloading: 0.0057 s/iter. Inference: 0.0863 s/iter. Eval: 0.0727 s/iter. Total: 0.1649 s/iter. ETA=0:00:06
[09/03 16:13:35 d2.evaluation.evaluator]: Inference done 141/144. Dataloading: 0.0056 s/iter. Inference: 0.0852 s/iter. Eval: 0.0650 s/iter. Total: 0.1560 s/iter. ETA=0:00:00
[09/03 16:13:35 d2.evaluation.evaluator]: Total inference time: 0:00:21.989410 (0.158197 s / iter per device, on 1 devices)
[09/03 16:13:35 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:11 (0.085194 s / iter per device, on 1 devices)
[09/03 16:13:35 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 16:13:35 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 16:13:35 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/03 16:13:35 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 16:13:35 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/03 16:13:35 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:13:35 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.476
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.699
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.551
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.184
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.460
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.627
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.351
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.586
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.622
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.233
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.587
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.755
[09/03 16:13:35 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.599 | 69.855 | 55.143 | 18.419 | 46.020 | 62.706 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[09/03 16:13:36 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 16:13:36 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/03 16:13:36 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:13:36 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.503
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.712
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.593
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.125
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.448
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.675
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.363
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.611
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.657
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.325
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.617
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.788
[09/03 16:13:36 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.331 | 71.224 | 59.312 | 12.477 | 44.764 | 67.469 |
[09/03 16:13:36 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 16:13:36 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 16:13:36 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:13:36 d2.evaluation.testing]: copypaste: 47.5991,69.8555,55.1434,18.4191,46.0201,62.7058
[09/03 16:13:36 d2.evaluation.testing]: copypaste: Task: segm
[09/03 16:13:36 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:13:36 d2.evaluation.testing]: copypaste: 50.3306,71.2244,59.3123,12.4774,44.7641,67.4694
[09/03 16:13:36 d2.utils.events]:  eta: 0:01:25  iter: 859  total_loss: 0.4238  loss_cls: 0.07501  loss_box_reg: 0.1344  loss_mask: 0.1426  loss_rpn_cls: 0.002029  loss_rpn_loc: 0.002872  time: 0.6166  data_time: 0.0088  lr: 0.00021479  max_mem: 4868M
[09/03 16:13:48 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 16:13:48 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 16:13:48 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 16:13:48 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 16:13:48 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 16:13:52 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0027 s/iter. Inference: 0.0819 s/iter. Eval: 0.0908 s/iter. Total: 0.1754 s/iter. ETA=0:00:23
[09/03 16:13:57 d2.evaluation.evaluator]: Inference done 43/144. Dataloading: 0.0037 s/iter. Inference: 0.0826 s/iter. Eval: 0.0764 s/iter. Total: 0.1629 s/iter. ETA=0:00:16
[09/03 16:14:02 d2.evaluation.evaluator]: Inference done 61/144. Dataloading: 0.0035 s/iter. Inference: 0.0859 s/iter. Eval: 0.1128 s/iter. Total: 0.2024 s/iter. ETA=0:00:16
[09/03 16:14:07 d2.evaluation.evaluator]: Inference done 93/144. Dataloading: 0.0036 s/iter. Inference: 0.0849 s/iter. Eval: 0.0979 s/iter. Total: 0.1865 s/iter. ETA=0:00:09
[09/03 16:14:12 d2.evaluation.evaluator]: Inference done 126/144. Dataloading: 0.0042 s/iter. Inference: 0.0847 s/iter. Eval: 0.0884 s/iter. Total: 0.1775 s/iter. ETA=0:00:03
[09/03 16:14:16 d2.evaluation.evaluator]: Total inference time: 0:00:24.665393 (0.177449 s / iter per device, on 1 devices)
[09/03 16:14:16 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:11 (0.084546 s / iter per device, on 1 devices)
[09/03 16:14:16 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 16:14:16 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 16:14:16 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/03 16:14:16 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 16:14:16 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/03 16:14:16 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:14:16 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.471
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.683
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.533
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.165
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.451
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.647
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.343
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.585
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.627
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.591
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.765
[09/03 16:14:16 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.079 | 68.349 | 53.344 | 16.549 | 45.112 | 64.707 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[09/03 16:14:16 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 16:14:16 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[09/03 16:14:16 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:14:16 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.491
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.689
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.595
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.129
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.440
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.670
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.353
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.656
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.622
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.779
[09/03 16:14:16 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.077 | 68.898 | 59.516 | 12.903 | 44.037 | 67.008 |
[09/03 16:14:16 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 16:14:16 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 16:14:16 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:14:16 d2.evaluation.testing]: copypaste: 47.0786,68.3487,53.3436,16.5492,45.1119,64.7075
[09/03 16:14:16 d2.evaluation.testing]: copypaste: Task: segm
[09/03 16:14:16 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:14:16 d2.evaluation.testing]: copypaste: 49.0773,68.8978,59.5156,12.9030,44.0372,67.0084
[09/03 16:14:16 d2.utils.events]:  eta: 0:01:13  iter: 879  total_loss: 0.5341  loss_cls: 0.1094  loss_box_reg: 0.2123  loss_mask: 0.1661  loss_rpn_cls: 0.003416  loss_rpn_loc: 0.005248  time: 0.6166  data_time: 0.0096  lr: 0.00021978  max_mem: 4868M
[09/03 16:14:29 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 16:14:29 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 16:14:29 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 16:14:29 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 16:14:29 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 16:14:32 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0041 s/iter. Inference: 0.0801 s/iter. Eval: 0.0710 s/iter. Total: 0.1552 s/iter. ETA=0:00:20
[09/03 16:14:37 d2.evaluation.evaluator]: Inference done 44/144. Dataloading: 0.0042 s/iter. Inference: 0.0838 s/iter. Eval: 0.0653 s/iter. Total: 0.1534 s/iter. ETA=0:00:15
[09/03 16:14:42 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0035 s/iter. Inference: 0.0841 s/iter. Eval: 0.0875 s/iter. Total: 0.1753 s/iter. ETA=0:00:13
[09/03 16:14:47 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0052 s/iter. Inference: 0.0842 s/iter. Eval: 0.0736 s/iter. Total: 0.1631 s/iter. ETA=0:00:06
[09/03 16:14:52 d2.evaluation.evaluator]: Inference done 140/144. Dataloading: 0.0052 s/iter. Inference: 0.0840 s/iter. Eval: 0.0674 s/iter. Total: 0.1567 s/iter. ETA=0:00:00
[09/03 16:14:53 d2.evaluation.evaluator]: Total inference time: 0:00:22.209903 (0.159783 s / iter per device, on 1 devices)
[09/03 16:14:53 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:11 (0.084073 s / iter per device, on 1 devices)
[09/03 16:14:53 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 16:14:53 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 16:14:53 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/03 16:14:53 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 16:14:53 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.22 seconds.
[09/03 16:14:53 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:14:53 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.493
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.702
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.559
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.171
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.467
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.640
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.345
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.587
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.633
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.225
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.604
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.756
[09/03 16:14:53 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.333 | 70.153 | 55.939 | 17.099 | 46.708 | 63.970 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[09/03 16:14:53 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 16:14:53 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/03 16:14:53 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:14:53 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.513
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.725
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.620
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.144
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.455
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.673
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.354
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.607
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.661
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.325
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.631
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.773
[09/03 16:14:53 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.312 | 72.459 | 61.977 | 14.388 | 45.525 | 67.320 |
[09/03 16:14:53 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 16:14:53 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 16:14:53 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:14:53 d2.evaluation.testing]: copypaste: 49.3334,70.1529,55.9391,17.0990,46.7077,63.9697
[09/03 16:14:53 d2.evaluation.testing]: copypaste: Task: segm
[09/03 16:14:53 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:14:53 d2.evaluation.testing]: copypaste: 51.3121,72.4589,61.9766,14.3882,45.5250,67.3201
[09/03 16:14:53 d2.utils.events]:  eta: 0:01:01  iter: 899  total_loss: 0.517  loss_cls: 0.09992  loss_box_reg: 0.211  loss_mask: 0.1665  loss_rpn_cls: 0.004895  loss_rpn_loc: 0.009542  time: 0.6168  data_time: 0.0102  lr: 0.00022478  max_mem: 4868M
[09/03 16:15:06 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 16:15:06 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 16:15:06 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 16:15:06 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 16:15:06 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 16:15:09 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0017 s/iter. Inference: 0.0813 s/iter. Eval: 0.0666 s/iter. Total: 0.1497 s/iter. ETA=0:00:19
[09/03 16:15:14 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0049 s/iter. Inference: 0.0819 s/iter. Eval: 0.0577 s/iter. Total: 0.1447 s/iter. ETA=0:00:14
[09/03 16:15:19 d2.evaluation.evaluator]: Inference done 76/144. Dataloading: 0.0049 s/iter. Inference: 0.0820 s/iter. Eval: 0.0693 s/iter. Total: 0.1564 s/iter. ETA=0:00:10
[09/03 16:15:24 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0057 s/iter. Inference: 0.0824 s/iter. Eval: 0.0611 s/iter. Total: 0.1495 s/iter. ETA=0:00:04
[09/03 16:15:29 d2.evaluation.evaluator]: Total inference time: 0:00:20.905069 (0.150396 s / iter per device, on 1 devices)
[09/03 16:15:29 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:11 (0.083368 s / iter per device, on 1 devices)
[09/03 16:15:29 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 16:15:29 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 16:15:29 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/03 16:15:29 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 16:15:29 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/03 16:15:29 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:15:29 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.481
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.702
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.573
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.191
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.461
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.612
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.344
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.567
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.617
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.250
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.592
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.726
[09/03 16:15:29 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.149 | 70.194 | 57.259 | 19.073 | 46.087 | 61.210 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[09/03 16:15:29 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 16:15:29 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[09/03 16:15:29 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:15:29 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.502
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.715
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.603
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.147
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.444
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.662
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.353
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.588
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.644
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.325
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.762
[09/03 16:15:29 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.163 | 71.457 | 60.329 | 14.741 | 44.360 | 66.163 |
[09/03 16:15:29 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 16:15:29 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 16:15:29 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:15:29 d2.evaluation.testing]: copypaste: 48.1491,70.1943,57.2586,19.0735,46.0875,61.2105
[09/03 16:15:29 d2.evaluation.testing]: copypaste: Task: segm
[09/03 16:15:29 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:15:29 d2.evaluation.testing]: copypaste: 50.1631,71.4570,60.3295,14.7406,44.3597,66.1631
[09/03 16:15:29 d2.utils.events]:  eta: 0:00:48  iter: 919  total_loss: 0.3773  loss_cls: 0.05994  loss_box_reg: 0.154  loss_mask: 0.1311  loss_rpn_cls: 0.00174  loss_rpn_loc: 0.002706  time: 0.6167  data_time: 0.0102  lr: 0.00022977  max_mem: 4868M
[09/03 16:15:41 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 16:15:41 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 16:15:41 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 16:15:41 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 16:15:41 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 16:15:44 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0030 s/iter. Inference: 0.0813 s/iter. Eval: 0.0691 s/iter. Total: 0.1534 s/iter. ETA=0:00:20
[09/03 16:15:49 d2.evaluation.evaluator]: Inference done 43/144. Dataloading: 0.0045 s/iter. Inference: 0.0817 s/iter. Eval: 0.0696 s/iter. Total: 0.1560 s/iter. ETA=0:00:15
[09/03 16:15:55 d2.evaluation.evaluator]: Inference done 62/144. Dataloading: 0.0043 s/iter. Inference: 0.0845 s/iter. Eval: 0.1059 s/iter. Total: 0.1948 s/iter. ETA=0:00:15
[09/03 16:16:00 d2.evaluation.evaluator]: Inference done 96/144. Dataloading: 0.0044 s/iter. Inference: 0.0839 s/iter. Eval: 0.0890 s/iter. Total: 0.1774 s/iter. ETA=0:00:08
[09/03 16:16:05 d2.evaluation.evaluator]: Inference done 126/144. Dataloading: 0.0048 s/iter. Inference: 0.0847 s/iter. Eval: 0.0855 s/iter. Total: 0.1752 s/iter. ETA=0:00:03
[09/03 16:16:08 d2.evaluation.evaluator]: Total inference time: 0:00:24.238212 (0.174376 s / iter per device, on 1 devices)
[09/03 16:16:08 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:11 (0.084510 s / iter per device, on 1 devices)
[09/03 16:16:08 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 16:16:08 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 16:16:08 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/03 16:16:08 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 16:16:08 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/03 16:16:08 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:16:08 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.465
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.695
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.518
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.150
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.436
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.630
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.338
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.568
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.605
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.175
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.573
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.738
[09/03 16:16:08 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.511 | 69.524 | 51.841 | 15.033 | 43.637 | 62.997 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[09/03 16:16:08 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 16:16:08 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/03 16:16:08 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:16:08 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.495
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.699
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.599
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.127
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.434
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.665
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.356
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.609
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.651
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.292
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.771
[09/03 16:16:08 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.502 | 69.917 | 59.859 | 12.687 | 43.393 | 66.486 |
[09/03 16:16:08 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 16:16:08 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 16:16:08 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:16:08 d2.evaluation.testing]: copypaste: 46.5106,69.5241,51.8410,15.0335,43.6370,62.9975
[09/03 16:16:08 d2.evaluation.testing]: copypaste: Task: segm
[09/03 16:16:08 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:16:08 d2.evaluation.testing]: copypaste: 49.5023,69.9175,59.8586,12.6874,43.3931,66.4859
[09/03 16:16:08 d2.utils.events]:  eta: 0:00:36  iter: 939  total_loss: 0.3736  loss_cls: 0.0621  loss_box_reg: 0.1611  loss_mask: 0.1265  loss_rpn_cls: 0.001114  loss_rpn_loc: 0.003037  time: 0.6165  data_time: 0.0094  lr: 0.00023477  max_mem: 4868M
[09/03 16:16:20 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 16:16:20 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 16:16:20 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 16:16:20 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 16:16:20 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 16:16:23 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0029 s/iter. Inference: 0.0822 s/iter. Eval: 0.0437 s/iter. Total: 0.1288 s/iter. ETA=0:00:17
[09/03 16:16:28 d2.evaluation.evaluator]: Inference done 48/144. Dataloading: 0.0065 s/iter. Inference: 0.0843 s/iter. Eval: 0.0461 s/iter. Total: 0.1372 s/iter. ETA=0:00:13
[09/03 16:16:33 d2.evaluation.evaluator]: Inference done 84/144. Dataloading: 0.0064 s/iter. Inference: 0.0832 s/iter. Eval: 0.0484 s/iter. Total: 0.1383 s/iter. ETA=0:00:08
[09/03 16:16:38 d2.evaluation.evaluator]: Inference done 118/144. Dataloading: 0.0068 s/iter. Inference: 0.0861 s/iter. Eval: 0.0478 s/iter. Total: 0.1410 s/iter. ETA=0:00:03
[09/03 16:16:41 d2.evaluation.evaluator]: Total inference time: 0:00:19.376623 (0.139400 s / iter per device, on 1 devices)
[09/03 16:16:41 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:11 (0.085663 s / iter per device, on 1 devices)
[09/03 16:16:41 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 16:16:41 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 16:16:41 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/03 16:16:41 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 16:16:41 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/03 16:16:41 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:16:41 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.485
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.704
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.571
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.179
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.476
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.626
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.349
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.581
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.625
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.233
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.602
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.738
[09/03 16:16:41 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.503 | 70.413 | 57.089 | 17.917 | 47.601 | 62.602 |
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/03 16:16:41 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 16:16:41 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/03 16:16:41 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:16:41 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.510
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.706
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.621
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.159
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.453
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.682
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.359
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.606
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.647
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.342
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.768
[09/03 16:16:41 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.996 | 70.616 | 62.145 | 15.885 | 45.293 | 68.204 |
[09/03 16:16:41 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 16:16:41 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 16:16:41 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:16:41 d2.evaluation.testing]: copypaste: 48.5030,70.4133,57.0894,17.9172,47.6008,62.6017
[09/03 16:16:41 d2.evaluation.testing]: copypaste: Task: segm
[09/03 16:16:41 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:16:41 d2.evaluation.testing]: copypaste: 50.9961,70.6158,62.1453,15.8848,45.2930,68.2041
[09/03 16:16:41 d2.utils.events]:  eta: 0:00:24  iter: 959  total_loss: 0.3809  loss_cls: 0.07154  loss_box_reg: 0.1415  loss_mask: 0.1237  loss_rpn_cls: 0.003397  loss_rpn_loc: 0.004639  time: 0.6165  data_time: 0.0086  lr: 0.00023976  max_mem: 4868M
[09/03 16:16:54 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 16:16:54 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 16:16:54 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 16:16:54 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 16:16:54 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 16:16:57 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0061 s/iter. Inference: 0.0888 s/iter. Eval: 0.1057 s/iter. Total: 0.2005 s/iter. ETA=0:00:26
[09/03 16:17:02 d2.evaluation.evaluator]: Inference done 43/144. Dataloading: 0.0047 s/iter. Inference: 0.0835 s/iter. Eval: 0.0750 s/iter. Total: 0.1633 s/iter. ETA=0:00:16
[09/03 16:17:07 d2.evaluation.evaluator]: Inference done 62/144. Dataloading: 0.0040 s/iter. Inference: 0.0854 s/iter. Eval: 0.1109 s/iter. Total: 0.2004 s/iter. ETA=0:00:16
[09/03 16:17:13 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0054 s/iter. Inference: 0.0869 s/iter. Eval: 0.0976 s/iter. Total: 0.1900 s/iter. ETA=0:00:09
[09/03 16:17:18 d2.evaluation.evaluator]: Inference done 128/144. Dataloading: 0.0055 s/iter. Inference: 0.0860 s/iter. Eval: 0.0838 s/iter. Total: 0.1755 s/iter. ETA=0:00:02
[09/03 16:17:21 d2.evaluation.evaluator]: Total inference time: 0:00:24.612091 (0.177065 s / iter per device, on 1 devices)
[09/03 16:17:21 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:11 (0.086262 s / iter per device, on 1 devices)
[09/03 16:17:21 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 16:17:21 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 16:17:21 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/03 16:17:21 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 16:17:21 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/03 16:17:21 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:17:21 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.470
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.696
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.544
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.172
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.440
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.628
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.341
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.572
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.578
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.739
[09/03 16:17:21 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.010 | 69.645 | 54.362 | 17.155 | 43.988 | 62.789 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[09/03 16:17:21 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 16:17:21 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/03 16:17:21 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:17:21 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.506
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.713
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.594
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.162
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.437
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.690
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.360
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.656
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.283
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.621
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.785
[09/03 16:17:21 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.608 | 71.250 | 59.370 | 16.249 | 43.691 | 69.030 |
[09/03 16:17:21 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 16:17:21 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 16:17:21 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:17:21 d2.evaluation.testing]: copypaste: 47.0102,69.6452,54.3617,17.1551,43.9880,62.7888
[09/03 16:17:21 d2.evaluation.testing]: copypaste: Task: segm
[09/03 16:17:21 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:17:21 d2.evaluation.testing]: copypaste: 50.6077,71.2503,59.3702,16.2490,43.6911,69.0300
[09/03 16:17:21 d2.utils.events]:  eta: 0:00:12  iter: 979  total_loss: 0.3148  loss_cls: 0.05006  loss_box_reg: 0.1509  loss_mask: 0.1208  loss_rpn_cls: 0.001546  loss_rpn_loc: 0.003407  time: 0.6165  data_time: 0.0095  lr: 0.00024476  max_mem: 4868M
[09/03 16:17:33 d2.utils.events]:  eta: 0:00:00  iter: 999  total_loss: 0.3038  loss_cls: 0.052  loss_box_reg: 0.1576  loss_mask: 0.1277  loss_rpn_cls: 0.003376  loss_rpn_loc: 0.001571  time: 0.6163  data_time: 0.0087  lr: 0.00024975  max_mem: 4868M
[09/03 16:17:33 d2.engine.hooks]: Overall training speed: 998 iterations in 0:10:15 (0.6163 s / it)
[09/03 16:17:33 d2.engine.hooks]: Total training time: 1:01:02 (0:50:47 on hooks)
[09/03 16:17:33 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/03 16:17:33 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/03 16:17:33 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/03 16:17:33 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/03 16:17:33 d2.evaluation.evaluator]: Start inference on 144 batches
[09/03 16:17:36 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0017 s/iter. Inference: 0.0822 s/iter. Eval: 0.0666 s/iter. Total: 0.1504 s/iter. ETA=0:00:20
[09/03 16:17:41 d2.evaluation.evaluator]: Inference done 44/144. Dataloading: 0.0032 s/iter. Inference: 0.0835 s/iter. Eval: 0.0668 s/iter. Total: 0.1537 s/iter. ETA=0:00:15
[09/03 16:17:46 d2.evaluation.evaluator]: Inference done 66/144. Dataloading: 0.0033 s/iter. Inference: 0.0849 s/iter. Eval: 0.0929 s/iter. Total: 0.1813 s/iter. ETA=0:00:14
[09/03 16:17:52 d2.evaluation.evaluator]: Inference done 103/144. Dataloading: 0.0042 s/iter. Inference: 0.0847 s/iter. Eval: 0.0772 s/iter. Total: 0.1664 s/iter. ETA=0:00:06
[09/03 16:17:57 d2.evaluation.evaluator]: Inference done 140/144. Dataloading: 0.0047 s/iter. Inference: 0.0844 s/iter. Eval: 0.0689 s/iter. Total: 0.1583 s/iter. ETA=0:00:00
[09/03 16:17:58 d2.evaluation.evaluator]: Total inference time: 0:00:22.246825 (0.160049 s / iter per device, on 1 devices)
[09/03 16:17:58 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:11 (0.084387 s / iter per device, on 1 devices)
[09/03 16:17:58 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/03 16:17:58 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/03 16:17:58 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/03 16:17:58 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/03 16:17:58 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/03 16:17:58 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:17:58 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.494
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.712
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.540
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.173
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.467
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.648
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.353
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.588
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.631
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.600
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.762
[09/03 16:17:58 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.389 | 71.194 | 54.043 | 17.263 | 46.668 | 64.833 |
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/03 16:17:58 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/03 16:17:58 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/03 16:17:58 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/03 16:17:58 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.511
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.722
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.606
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.448
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.683
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.365
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.657
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.622
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.780
[09/03 16:17:58 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.143 | 72.193 | 60.648 | 16.731 | 44.783 | 68.262 |
[09/03 16:17:58 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/03 16:17:58 d2.evaluation.testing]: copypaste: Task: bbox
[09/03 16:17:58 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:17:58 d2.evaluation.testing]: copypaste: 49.3885,71.1942,54.0432,17.2633,46.6675,64.8327
[09/03 16:17:58 d2.evaluation.testing]: copypaste: Task: segm
[09/03 16:17:58 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/03 16:17:58 d2.evaluation.testing]: copypaste: 51.1430,72.1930,60.6483,16.7312,44.7828,68.2624