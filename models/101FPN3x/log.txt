[08/24 07:46:06 d2.engine.defaults]: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[08/24 07:46:06 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [RandomBrightness(intensity_min=0.9, intensity_max=1.1), RandomContrast(intensity_min=0.9, intensity_max=1.1), RandomBrightness(intensity_min=0.9, intensity_max=1.1), RandomFlip(prob=0.5), Resize(shape=(720, 1280))]
[08/24 07:46:06 d2.data.datasets.coco]: Loaded 574 images in COCO format from ../input/petbottles/plastic data/annotations/instances_train.json
[08/24 07:46:06 d2.data.build]: Distribution of instances among all 1 categories:
|  category   | #instances   |
|:-----------:|:-------------|
| PET Bottles | 1145         |
|             |              |
[08/24 07:46:06 d2.data.build]: Using training sampler TrainingSampler
[08/24 07:46:06 d2.data.common]: Serializing 574 elements to byte tensors and concatenating them all ...
[08/24 07:46:06 d2.data.common]: Serialized dataset takes 0.45 MiB
model_final_a3ec72.pkl: 254MB [00:08, 31.4MB/s]                              
[08/24 07:46:19 d2.engine.train_loop]: Starting training from iteration 0
[08/24 07:46:38 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 07:46:38 d2.data.build]: Distribution of instances among all 1 categories:
|  category   | #instances   |
|:-----------:|:-------------|
| PET Bottles | 193          |
|             |              |
[08/24 07:46:38 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 07:46:38 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 07:46:38 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 07:46:38 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 07:46:48 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0018 s/iter. Inference: 0.1609 s/iter. Eval: 0.6898 s/iter. Total: 0.8525 s/iter. ETA=0:01:53
[08/24 07:46:53 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0020 s/iter. Inference: 0.1601 s/iter. Eval: 0.6842 s/iter. Total: 0.8465 s/iter. ETA=0:01:47
[08/24 07:46:58 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0022 s/iter. Inference: 0.1606 s/iter. Eval: 0.7024 s/iter. Total: 0.8654 s/iter. ETA=0:01:44
[08/24 07:47:03 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0021 s/iter. Inference: 0.1613 s/iter. Eval: 0.7017 s/iter. Total: 0.8655 s/iter. ETA=0:01:39
[08/24 07:47:09 d2.evaluation.evaluator]: Inference done 35/144. Dataloading: 0.0021 s/iter. Inference: 0.1609 s/iter. Eval: 0.7022 s/iter. Total: 0.8656 s/iter. ETA=0:01:34
[08/24 07:47:14 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0021 s/iter. Inference: 0.1608 s/iter. Eval: 0.6983 s/iter. Total: 0.8615 s/iter. ETA=0:01:28
[08/24 07:47:19 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0021 s/iter. Inference: 0.1607 s/iter. Eval: 0.7001 s/iter. Total: 0.8632 s/iter. ETA=0:01:23
[08/24 07:47:24 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0021 s/iter. Inference: 0.1606 s/iter. Eval: 0.6978 s/iter. Total: 0.8608 s/iter. ETA=0:01:18
[08/24 07:47:29 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0021 s/iter. Inference: 0.1605 s/iter. Eval: 0.6983 s/iter. Total: 0.8613 s/iter. ETA=0:01:13
[08/24 07:47:35 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0021 s/iter. Inference: 0.1605 s/iter. Eval: 0.7031 s/iter. Total: 0.8660 s/iter. ETA=0:01:08
[08/24 07:47:40 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0022 s/iter. Inference: 0.1604 s/iter. Eval: 0.7033 s/iter. Total: 0.8661 s/iter. ETA=0:01:03
[08/24 07:47:45 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0022 s/iter. Inference: 0.1603 s/iter. Eval: 0.7014 s/iter. Total: 0.8642 s/iter. ETA=0:00:57
[08/24 07:47:50 d2.evaluation.evaluator]: Inference done 83/144. Dataloading: 0.0021 s/iter. Inference: 0.1603 s/iter. Eval: 0.7015 s/iter. Total: 0.8641 s/iter. ETA=0:00:52
[08/24 07:47:55 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0021 s/iter. Inference: 0.1602 s/iter. Eval: 0.6999 s/iter. Total: 0.8625 s/iter. ETA=0:00:47
[08/24 07:48:00 d2.evaluation.evaluator]: Inference done 95/144. Dataloading: 0.0021 s/iter. Inference: 0.1602 s/iter. Eval: 0.7004 s/iter. Total: 0.8630 s/iter. ETA=0:00:42
[08/24 07:48:06 d2.evaluation.evaluator]: Inference done 101/144. Dataloading: 0.0022 s/iter. Inference: 0.1604 s/iter. Eval: 0.7038 s/iter. Total: 0.8666 s/iter. ETA=0:00:37
[08/24 07:48:11 d2.evaluation.evaluator]: Inference done 107/144. Dataloading: 0.0022 s/iter. Inference: 0.1604 s/iter. Eval: 0.7042 s/iter. Total: 0.8670 s/iter. ETA=0:00:32
[08/24 07:48:16 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0022 s/iter. Inference: 0.1603 s/iter. Eval: 0.7029 s/iter. Total: 0.8656 s/iter. ETA=0:00:26
[08/24 07:48:21 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0021 s/iter. Inference: 0.1603 s/iter. Eval: 0.7018 s/iter. Total: 0.8645 s/iter. ETA=0:00:21
[08/24 07:48:26 d2.evaluation.evaluator]: Inference done 125/144. Dataloading: 0.0021 s/iter. Inference: 0.1602 s/iter. Eval: 0.7021 s/iter. Total: 0.8647 s/iter. ETA=0:00:16
[08/24 07:48:31 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0021 s/iter. Inference: 0.1602 s/iter. Eval: 0.7010 s/iter. Total: 0.8637 s/iter. ETA=0:00:11
[08/24 07:48:37 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0022 s/iter. Inference: 0.1602 s/iter. Eval: 0.7015 s/iter. Total: 0.8641 s/iter. ETA=0:00:06
[08/24 07:48:42 d2.evaluation.evaluator]: Inference done 143/144. Dataloading: 0.0021 s/iter. Inference: 0.1602 s/iter. Eval: 0.7036 s/iter. Total: 0.8663 s/iter. ETA=0:00:00
[08/24 07:48:43 d2.evaluation.evaluator]: Total inference time: 0:02:00.434892 (0.866438 s / iter per device, on 1 devices)
[08/24 07:48:43 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:22 (0.160211 s / iter per device, on 1 devices)
[08/24 07:48:43 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 07:48:43 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 07:48:43 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[08/24 07:48:43 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 07:48:44 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.18 seconds.
[08/24 07:48:44 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 07:48:44 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.05 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.025
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.006
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.007
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.047
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.231
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.025
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.250
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.236
[08/24 07:48:44 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.377 | 2.453  | 0.009  | 0.002 | 0.596 | 0.234 |
Loading and preparing results...
DONE (t=0.37s)
creating index...
index created!
[08/24 07:48:45 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 07:48:45 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.27 seconds.
[08/24 07:48:45 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 07:48:45 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.03 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.021
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.045
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.024
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.020
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.040
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.041
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.159
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.490
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.471
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.592
[08/24 07:48:45 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 2.123 | 4.487  | 2.436  | 0.077 | 1.954 | 4.028 |
[08/24 07:48:45 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 07:48:45 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 07:48:45 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 07:48:45 d2.evaluation.testing]: copypaste: 0.3770,2.4529,0.0092,0.0022,0.5959,0.2342
[08/24 07:48:45 d2.evaluation.testing]: copypaste: Task: segm
[08/24 07:48:45 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 07:48:45 d2.evaluation.testing]: copypaste: 2.1226,4.4875,2.4360,0.0773,1.9541,4.0278
[08/24 07:48:45 d2.utils.events]:  eta: 0:14:31  iter: 19  total_loss: 1.851  loss_cls: 0.7387  loss_box_reg: 0.3036  loss_mask: 0.6924  loss_rpn_cls: 0.04455  loss_rpn_loc: 0.01059  time: 0.9191  data_time: 0.0731  lr: 4.9953e-06  max_mem: 6143M
[08/24 07:49:03 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 07:49:03 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 07:49:03 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 07:49:03 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 07:49:03 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 07:49:13 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0019 s/iter. Inference: 0.1604 s/iter. Eval: 0.7026 s/iter. Total: 0.8649 s/iter. ETA=0:01:55
[08/24 07:49:18 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0032 s/iter. Inference: 0.1625 s/iter. Eval: 0.7194 s/iter. Total: 0.8856 s/iter. ETA=0:01:52
[08/24 07:49:23 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0031 s/iter. Inference: 0.1617 s/iter. Eval: 0.7041 s/iter. Total: 0.8694 s/iter. ETA=0:01:45
[08/24 07:49:29 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0033 s/iter. Inference: 0.1620 s/iter. Eval: 0.7017 s/iter. Total: 0.8674 s/iter. ETA=0:01:39
[08/24 07:49:34 d2.evaluation.evaluator]: Inference done 35/144. Dataloading: 0.0033 s/iter. Inference: 0.1616 s/iter. Eval: 0.6960 s/iter. Total: 0.8612 s/iter. ETA=0:01:33
[08/24 07:49:39 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0032 s/iter. Inference: 0.1614 s/iter. Eval: 0.6942 s/iter. Total: 0.8591 s/iter. ETA=0:01:28
[08/24 07:49:44 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0032 s/iter. Inference: 0.1618 s/iter. Eval: 0.6957 s/iter. Total: 0.8611 s/iter. ETA=0:01:23
[08/24 07:49:49 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0031 s/iter. Inference: 0.1618 s/iter. Eval: 0.7005 s/iter. Total: 0.8657 s/iter. ETA=0:01:18
[08/24 07:49:55 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0031 s/iter. Inference: 0.1619 s/iter. Eval: 0.7011 s/iter. Total: 0.8665 s/iter. ETA=0:01:13
[08/24 07:50:00 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0030 s/iter. Inference: 0.1617 s/iter. Eval: 0.6989 s/iter. Total: 0.8640 s/iter. ETA=0:01:08
[08/24 07:50:05 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0030 s/iter. Inference: 0.1617 s/iter. Eval: 0.6996 s/iter. Total: 0.8646 s/iter. ETA=0:01:03
[08/24 07:50:10 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0030 s/iter. Inference: 0.1615 s/iter. Eval: 0.6978 s/iter. Total: 0.8626 s/iter. ETA=0:00:57
[08/24 07:50:15 d2.evaluation.evaluator]: Inference done 83/144. Dataloading: 0.0029 s/iter. Inference: 0.1617 s/iter. Eval: 0.6978 s/iter. Total: 0.8627 s/iter. ETA=0:00:52
[08/24 07:50:20 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0029 s/iter. Inference: 0.1616 s/iter. Eval: 0.6964 s/iter. Total: 0.8612 s/iter. ETA=0:00:47
[08/24 07:50:25 d2.evaluation.evaluator]: Inference done 95/144. Dataloading: 0.0030 s/iter. Inference: 0.1616 s/iter. Eval: 0.6980 s/iter. Total: 0.8628 s/iter. ETA=0:00:42
[08/24 07:50:31 d2.evaluation.evaluator]: Inference done 101/144. Dataloading: 0.0030 s/iter. Inference: 0.1617 s/iter. Eval: 0.6992 s/iter. Total: 0.8642 s/iter. ETA=0:00:37
[08/24 07:50:36 d2.evaluation.evaluator]: Inference done 107/144. Dataloading: 0.0030 s/iter. Inference: 0.1616 s/iter. Eval: 0.6992 s/iter. Total: 0.8641 s/iter. ETA=0:00:31
[08/24 07:50:41 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0030 s/iter. Inference: 0.1615 s/iter. Eval: 0.6978 s/iter. Total: 0.8625 s/iter. ETA=0:00:26
[08/24 07:50:46 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0030 s/iter. Inference: 0.1614 s/iter. Eval: 0.6979 s/iter. Total: 0.8626 s/iter. ETA=0:00:21
[08/24 07:50:51 d2.evaluation.evaluator]: Inference done 125/144. Dataloading: 0.0030 s/iter. Inference: 0.1613 s/iter. Eval: 0.6970 s/iter. Total: 0.8616 s/iter. ETA=0:00:16
[08/24 07:50:56 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0030 s/iter. Inference: 0.1613 s/iter. Eval: 0.6970 s/iter. Total: 0.8616 s/iter. ETA=0:00:11
[08/24 07:51:02 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0030 s/iter. Inference: 0.1614 s/iter. Eval: 0.6990 s/iter. Total: 0.8637 s/iter. ETA=0:00:06
[08/24 07:51:07 d2.evaluation.evaluator]: Inference done 143/144. Dataloading: 0.0030 s/iter. Inference: 0.1613 s/iter. Eval: 0.6992 s/iter. Total: 0.8637 s/iter. ETA=0:00:00
[08/24 07:51:08 d2.evaluation.evaluator]: Total inference time: 0:02:00.078150 (0.863872 s / iter per device, on 1 devices)
[08/24 07:51:08 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:22 (0.161262 s / iter per device, on 1 devices)
[08/24 07:51:08 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 07:51:08 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 07:51:08 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[08/24 07:51:08 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 07:51:08 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.
[08/24 07:51:08 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 07:51:08 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.046
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.013
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.007
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.019
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.089
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.313
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.025
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.302
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.386
[08/24 07:51:08 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.838 | 4.606  | 0.037  | 0.004 | 1.291 | 0.690 |
Loading and preparing results...
DONE (t=0.30s)
creating index...
index created!
[08/24 07:51:09 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 07:51:10 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.44 seconds.
[08/24 07:51:10 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 07:51:10 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.03 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.039
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.081
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.040
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.037
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.067
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.067
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.270
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.564
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.531
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.706
[08/24 07:51:10 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 3.888 | 8.111  | 4.045  | 0.197 | 3.693 | 6.740 |
[08/24 07:51:10 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 07:51:10 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 07:51:10 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 07:51:10 d2.evaluation.testing]: copypaste: 0.8382,4.6059,0.0368,0.0039,1.2911,0.6902
[08/24 07:51:10 d2.evaluation.testing]: copypaste: Task: segm
[08/24 07:51:10 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 07:51:10 d2.evaluation.testing]: copypaste: 3.8876,8.1112,4.0453,0.1969,3.6930,6.7396
[08/24 07:51:10 d2.utils.events]:  eta: 0:14:11  iter: 39  total_loss: 1.775  loss_cls: 0.6749  loss_box_reg: 0.4048  loss_mask: 0.6778  loss_rpn_cls: 0.01194  loss_rpn_loc: 0.005493  time: 0.9025  data_time: 0.0166  lr: 9.9902e-06  max_mem: 6143M
[08/24 07:51:27 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 07:51:27 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 07:51:27 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 07:51:27 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 07:51:27 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 07:51:38 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0024 s/iter. Inference: 0.1649 s/iter. Eval: 0.7341 s/iter. Total: 0.9014 s/iter. ETA=0:01:59
[08/24 07:51:43 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0024 s/iter. Inference: 0.1629 s/iter. Eval: 0.7165 s/iter. Total: 0.8821 s/iter. ETA=0:01:52
[08/24 07:51:48 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0026 s/iter. Inference: 0.1619 s/iter. Eval: 0.7018 s/iter. Total: 0.8666 s/iter. ETA=0:01:44
[08/24 07:51:53 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0025 s/iter. Inference: 0.1616 s/iter. Eval: 0.7003 s/iter. Total: 0.8647 s/iter. ETA=0:01:39
[08/24 07:51:58 d2.evaluation.evaluator]: Inference done 35/144. Dataloading: 0.0026 s/iter. Inference: 0.1615 s/iter. Eval: 0.6957 s/iter. Total: 0.8600 s/iter. ETA=0:01:33
[08/24 07:52:03 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0027 s/iter. Inference: 0.1621 s/iter. Eval: 0.6969 s/iter. Total: 0.8619 s/iter. ETA=0:01:28
[08/24 07:52:08 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0027 s/iter. Inference: 0.1618 s/iter. Eval: 0.6936 s/iter. Total: 0.8584 s/iter. ETA=0:01:23
[08/24 07:52:14 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0027 s/iter. Inference: 0.1623 s/iter. Eval: 0.6997 s/iter. Total: 0.8649 s/iter. ETA=0:01:18
[08/24 07:52:19 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0028 s/iter. Inference: 0.1624 s/iter. Eval: 0.6990 s/iter. Total: 0.8645 s/iter. ETA=0:01:13
[08/24 07:52:24 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0028 s/iter. Inference: 0.1622 s/iter. Eval: 0.6987 s/iter. Total: 0.8640 s/iter. ETA=0:01:08
[08/24 07:52:29 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0028 s/iter. Inference: 0.1620 s/iter. Eval: 0.6964 s/iter. Total: 0.8615 s/iter. ETA=0:01:02
[08/24 07:52:34 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0028 s/iter. Inference: 0.1618 s/iter. Eval: 0.6946 s/iter. Total: 0.8595 s/iter. ETA=0:00:57
[08/24 07:52:39 d2.evaluation.evaluator]: Inference done 83/144. Dataloading: 0.0028 s/iter. Inference: 0.1617 s/iter. Eval: 0.6951 s/iter. Total: 0.8599 s/iter. ETA=0:00:52
[08/24 07:52:44 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0028 s/iter. Inference: 0.1616 s/iter. Eval: 0.6941 s/iter. Total: 0.8589 s/iter. ETA=0:00:47
[08/24 07:52:50 d2.evaluation.evaluator]: Inference done 95/144. Dataloading: 0.0028 s/iter. Inference: 0.1617 s/iter. Eval: 0.6996 s/iter. Total: 0.8644 s/iter. ETA=0:00:42
[08/24 07:52:55 d2.evaluation.evaluator]: Inference done 101/144. Dataloading: 0.0028 s/iter. Inference: 0.1616 s/iter. Eval: 0.6980 s/iter. Total: 0.8627 s/iter. ETA=0:00:37
[08/24 07:53:00 d2.evaluation.evaluator]: Inference done 107/144. Dataloading: 0.0029 s/iter. Inference: 0.1615 s/iter. Eval: 0.6982 s/iter. Total: 0.8628 s/iter. ETA=0:00:31
[08/24 07:53:05 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0029 s/iter. Inference: 0.1614 s/iter. Eval: 0.6971 s/iter. Total: 0.8617 s/iter. ETA=0:00:26
[08/24 07:53:10 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0029 s/iter. Inference: 0.1613 s/iter. Eval: 0.6971 s/iter. Total: 0.8616 s/iter. ETA=0:00:21
[08/24 07:53:15 d2.evaluation.evaluator]: Inference done 125/144. Dataloading: 0.0029 s/iter. Inference: 0.1613 s/iter. Eval: 0.6959 s/iter. Total: 0.8603 s/iter. ETA=0:00:16
[08/24 07:53:21 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0030 s/iter. Inference: 0.1612 s/iter. Eval: 0.6966 s/iter. Total: 0.8610 s/iter. ETA=0:00:11
[08/24 07:53:26 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0030 s/iter. Inference: 0.1613 s/iter. Eval: 0.6979 s/iter. Total: 0.8625 s/iter. ETA=0:00:06
[08/24 07:53:31 d2.evaluation.evaluator]: Inference done 143/144. Dataloading: 0.0029 s/iter. Inference: 0.1612 s/iter. Eval: 0.6974 s/iter. Total: 0.8618 s/iter. ETA=0:00:00
[08/24 07:53:32 d2.evaluation.evaluator]: Total inference time: 0:01:59.824681 (0.862048 s / iter per device, on 1 devices)
[08/24 07:53:32 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:22 (0.161218 s / iter per device, on 1 devices)
[08/24 07:53:32 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 07:53:32 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 07:53:32 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[08/24 07:53:32 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 07:53:33 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[08/24 07:53:33 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 07:53:33 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.018
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.085
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.029
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.017
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.033
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.173
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.377
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.083
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.367
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.448
[08/24 07:53:33 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 1.836 | 8.508  | 0.154  | 0.020 | 2.911 | 1.735 |
Loading and preparing results...
DONE (t=0.30s)
creating index...
index created!
[08/24 07:53:33 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 07:53:34 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.22 seconds.
[08/24 07:53:34 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 07:53:34 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.03 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.063
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.125
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.075
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.006
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.063
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.097
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.095
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.352
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.593
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.158
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.562
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.726
[08/24 07:53:34 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 6.343 | 12.517 | 7.453  | 0.581 | 6.296 | 9.695 |
[08/24 07:53:34 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 07:53:34 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 07:53:34 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 07:53:34 d2.evaluation.testing]: copypaste: 1.8357,8.5081,0.1539,0.0203,2.9108,1.7348
[08/24 07:53:34 d2.evaluation.testing]: copypaste: Task: segm
[08/24 07:53:34 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 07:53:34 d2.evaluation.testing]: copypaste: 6.3426,12.5167,7.4533,0.5812,6.2962,9.6952
[08/24 07:53:34 d2.utils.events]:  eta: 0:13:51  iter: 59  total_loss: 1.611  loss_cls: 0.5067  loss_box_reg: 0.3142  loss_mask: 0.6535  loss_rpn_cls: 0.02759  loss_rpn_loc: 0.009022  time: 0.8968  data_time: 0.0264  lr: 1.4985e-05  max_mem: 6143M
[08/24 07:53:52 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 07:53:52 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 07:53:52 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 07:53:52 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 07:53:52 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 07:54:02 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0023 s/iter. Inference: 0.1604 s/iter. Eval: 0.6853 s/iter. Total: 0.8481 s/iter. ETA=0:01:52
[08/24 07:54:07 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0026 s/iter. Inference: 0.1604 s/iter. Eval: 0.6964 s/iter. Total: 0.8595 s/iter. ETA=0:01:49
[08/24 07:54:12 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0026 s/iter. Inference: 0.1602 s/iter. Eval: 0.6903 s/iter. Total: 0.8534 s/iter. ETA=0:01:43
[08/24 07:54:18 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0026 s/iter. Inference: 0.1603 s/iter. Eval: 0.6924 s/iter. Total: 0.8554 s/iter. ETA=0:01:38
[08/24 07:54:23 d2.evaluation.evaluator]: Inference done 35/144. Dataloading: 0.0026 s/iter. Inference: 0.1603 s/iter. Eval: 0.6888 s/iter. Total: 0.8520 s/iter. ETA=0:01:32
[08/24 07:54:28 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0027 s/iter. Inference: 0.1607 s/iter. Eval: 0.7026 s/iter. Total: 0.8663 s/iter. ETA=0:01:29
[08/24 07:54:33 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0028 s/iter. Inference: 0.1606 s/iter. Eval: 0.7056 s/iter. Total: 0.8692 s/iter. ETA=0:01:24
[08/24 07:54:39 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0029 s/iter. Inference: 0.1605 s/iter. Eval: 0.7059 s/iter. Total: 0.8695 s/iter. ETA=0:01:19
[08/24 07:54:44 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0029 s/iter. Inference: 0.1605 s/iter. Eval: 0.7034 s/iter. Total: 0.8670 s/iter. ETA=0:01:13
[08/24 07:54:49 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0028 s/iter. Inference: 0.1605 s/iter. Eval: 0.7031 s/iter. Total: 0.8667 s/iter. ETA=0:01:08
[08/24 07:54:54 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0028 s/iter. Inference: 0.1605 s/iter. Eval: 0.7005 s/iter. Total: 0.8639 s/iter. ETA=0:01:03
[08/24 07:55:00 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0030 s/iter. Inference: 0.1610 s/iter. Eval: 0.7067 s/iter. Total: 0.8709 s/iter. ETA=0:00:58
[08/24 07:55:05 d2.evaluation.evaluator]: Inference done 83/144. Dataloading: 0.0030 s/iter. Inference: 0.1610 s/iter. Eval: 0.7045 s/iter. Total: 0.8687 s/iter. ETA=0:00:52
[08/24 07:55:10 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0030 s/iter. Inference: 0.1610 s/iter. Eval: 0.7043 s/iter. Total: 0.8685 s/iter. ETA=0:00:47
[08/24 07:55:15 d2.evaluation.evaluator]: Inference done 95/144. Dataloading: 0.0030 s/iter. Inference: 0.1609 s/iter. Eval: 0.7027 s/iter. Total: 0.8668 s/iter. ETA=0:00:42
[08/24 07:55:20 d2.evaluation.evaluator]: Inference done 101/144. Dataloading: 0.0029 s/iter. Inference: 0.1608 s/iter. Eval: 0.7025 s/iter. Total: 0.8665 s/iter. ETA=0:00:37
[08/24 07:55:25 d2.evaluation.evaluator]: Inference done 107/144. Dataloading: 0.0029 s/iter. Inference: 0.1608 s/iter. Eval: 0.7011 s/iter. Total: 0.8650 s/iter. ETA=0:00:32
[08/24 07:55:30 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0028 s/iter. Inference: 0.1608 s/iter. Eval: 0.7003 s/iter. Total: 0.8642 s/iter. ETA=0:00:26
[08/24 07:55:36 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0029 s/iter. Inference: 0.1609 s/iter. Eval: 0.7047 s/iter. Total: 0.8687 s/iter. ETA=0:00:21
[08/24 07:55:41 d2.evaluation.evaluator]: Inference done 125/144. Dataloading: 0.0029 s/iter. Inference: 0.1609 s/iter. Eval: 0.7031 s/iter. Total: 0.8671 s/iter. ETA=0:00:16
[08/24 07:55:46 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0029 s/iter. Inference: 0.1608 s/iter. Eval: 0.7033 s/iter. Total: 0.8673 s/iter. ETA=0:00:11
[08/24 07:55:51 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0029 s/iter. Inference: 0.1608 s/iter. Eval: 0.7020 s/iter. Total: 0.8660 s/iter. ETA=0:00:06
[08/24 07:55:56 d2.evaluation.evaluator]: Inference done 143/144. Dataloading: 0.0029 s/iter. Inference: 0.1607 s/iter. Eval: 0.7020 s/iter. Total: 0.8658 s/iter. ETA=0:00:00
[08/24 07:55:57 d2.evaluation.evaluator]: Total inference time: 0:02:00.372207 (0.865987 s / iter per device, on 1 devices)
[08/24 07:55:57 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:22 (0.160663 s / iter per device, on 1 devices)
[08/24 07:55:58 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 07:55:58 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 07:55:58 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[08/24 07:55:58 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 07:55:58 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[08/24 07:55:58 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 07:55:58 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.029
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.120
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.004
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.040
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.031
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.059
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.235
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.413
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.150
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.403
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.479
[08/24 07:55:58 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 2.931 | 11.954 | 0.425  | 0.175 | 3.967 | 3.093 |
Loading and preparing results...
DONE (t=0.31s)
creating index...
index created!
[08/24 07:55:59 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 07:55:59 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.23 seconds.
[08/24 07:55:59 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 07:55:59 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.03 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.080
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.151
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.095
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.007
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.073
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.122
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.132
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.389
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.608
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.208
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.576
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.738
[08/24 07:55:59 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 8.024 | 15.099 | 9.524  | 0.663 | 7.324 | 12.231 |
[08/24 07:55:59 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 07:55:59 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 07:55:59 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 07:55:59 d2.evaluation.testing]: copypaste: 2.9305,11.9537,0.4247,0.1754,3.9669,3.0927
[08/24 07:55:59 d2.evaluation.testing]: copypaste: Task: segm
[08/24 07:55:59 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 07:55:59 d2.evaluation.testing]: copypaste: 8.0237,15.0987,9.5238,0.6631,7.3243,12.2306
[08/24 07:55:59 d2.utils.events]:  eta: 0:13:37  iter: 79  total_loss: 1.427  loss_cls: 0.4082  loss_box_reg: 0.3999  loss_mask: 0.6145  loss_rpn_cls: 0.01404  loss_rpn_loc: 0.006456  time: 0.8994  data_time: 0.0296  lr: 1.998e-05  max_mem: 6143M
[08/24 07:56:18 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 07:56:18 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 07:56:18 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 07:56:18 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 07:56:18 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 07:56:27 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0030 s/iter. Inference: 0.1603 s/iter. Eval: 0.6973 s/iter. Total: 0.8607 s/iter. ETA=0:01:54
[08/24 07:56:32 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0030 s/iter. Inference: 0.1601 s/iter. Eval: 0.6855 s/iter. Total: 0.8488 s/iter. ETA=0:01:47
[08/24 07:56:38 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0028 s/iter. Inference: 0.1614 s/iter. Eval: 0.7183 s/iter. Total: 0.8828 s/iter. ETA=0:01:46
[08/24 07:56:43 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0028 s/iter. Inference: 0.1611 s/iter. Eval: 0.7095 s/iter. Total: 0.8736 s/iter. ETA=0:01:40
[08/24 07:56:48 d2.evaluation.evaluator]: Inference done 35/144. Dataloading: 0.0028 s/iter. Inference: 0.1611 s/iter. Eval: 0.7088 s/iter. Total: 0.8729 s/iter. ETA=0:01:35
[08/24 07:56:54 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0028 s/iter. Inference: 0.1610 s/iter. Eval: 0.7042 s/iter. Total: 0.8682 s/iter. ETA=0:01:29
[08/24 07:56:59 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0028 s/iter. Inference: 0.1608 s/iter. Eval: 0.7097 s/iter. Total: 0.8735 s/iter. ETA=0:01:24
[08/24 07:57:04 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0028 s/iter. Inference: 0.1608 s/iter. Eval: 0.7060 s/iter. Total: 0.8699 s/iter. ETA=0:01:19
[08/24 07:57:09 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0029 s/iter. Inference: 0.1607 s/iter. Eval: 0.7035 s/iter. Total: 0.8674 s/iter. ETA=0:01:13
[08/24 07:57:15 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0028 s/iter. Inference: 0.1609 s/iter. Eval: 0.7120 s/iter. Total: 0.8761 s/iter. ETA=0:01:09
[08/24 07:57:20 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0028 s/iter. Inference: 0.1608 s/iter. Eval: 0.7090 s/iter. Total: 0.8730 s/iter. ETA=0:01:03
[08/24 07:57:25 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0029 s/iter. Inference: 0.1607 s/iter. Eval: 0.7082 s/iter. Total: 0.8722 s/iter. ETA=0:00:58
[08/24 07:57:30 d2.evaluation.evaluator]: Inference done 83/144. Dataloading: 0.0029 s/iter. Inference: 0.1607 s/iter. Eval: 0.7056 s/iter. Total: 0.8694 s/iter. ETA=0:00:53
[08/24 07:57:35 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0029 s/iter. Inference: 0.1609 s/iter. Eval: 0.7051 s/iter. Total: 0.8692 s/iter. ETA=0:00:47
[08/24 07:57:40 d2.evaluation.evaluator]: Inference done 95/144. Dataloading: 0.0029 s/iter. Inference: 0.1608 s/iter. Eval: 0.7031 s/iter. Total: 0.8671 s/iter. ETA=0:00:42
[08/24 07:57:45 d2.evaluation.evaluator]: Inference done 101/144. Dataloading: 0.0029 s/iter. Inference: 0.1608 s/iter. Eval: 0.7029 s/iter. Total: 0.8669 s/iter. ETA=0:00:37
[08/24 07:57:50 d2.evaluation.evaluator]: Inference done 107/144. Dataloading: 0.0029 s/iter. Inference: 0.1607 s/iter. Eval: 0.7013 s/iter. Total: 0.8651 s/iter. ETA=0:00:32
[08/24 07:57:56 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0028 s/iter. Inference: 0.1608 s/iter. Eval: 0.7013 s/iter. Total: 0.8653 s/iter. ETA=0:00:26
[08/24 07:58:01 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0029 s/iter. Inference: 0.1608 s/iter. Eval: 0.7039 s/iter. Total: 0.8679 s/iter. ETA=0:00:21
[08/24 07:58:06 d2.evaluation.evaluator]: Inference done 125/144. Dataloading: 0.0029 s/iter. Inference: 0.1607 s/iter. Eval: 0.7038 s/iter. Total: 0.8678 s/iter. ETA=0:00:16
[08/24 07:58:11 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0029 s/iter. Inference: 0.1607 s/iter. Eval: 0.7027 s/iter. Total: 0.8666 s/iter. ETA=0:00:11
[08/24 07:58:17 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0029 s/iter. Inference: 0.1608 s/iter. Eval: 0.7028 s/iter. Total: 0.8668 s/iter. ETA=0:00:06
[08/24 07:58:22 d2.evaluation.evaluator]: Inference done 143/144. Dataloading: 0.0029 s/iter. Inference: 0.1607 s/iter. Eval: 0.7015 s/iter. Total: 0.8654 s/iter. ETA=0:00:00
[08/24 07:58:23 d2.evaluation.evaluator]: Total inference time: 0:02:00.307077 (0.865519 s / iter per device, on 1 devices)
[08/24 07:58:23 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:22 (0.160659 s / iter per device, on 1 devices)
[08/24 07:58:23 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 07:58:23 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 07:58:23 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[08/24 07:58:23 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 07:58:23 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[08/24 07:58:23 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 07:58:23 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.03 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.043
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.157
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.011
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.016
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.054
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.050
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.084
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.286
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.465
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.267
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.454
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.521
[08/24 07:58:23 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 4.296 | 15.671 | 1.075  | 1.597 | 5.432 | 4.964 |
Loading and preparing results...
DONE (t=0.32s)
creating index...
index created!
[08/24 07:58:24 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 07:58:24 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.23 seconds.
[08/24 07:58:24 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 07:58:24 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.102
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.178
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.123
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.014
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.088
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.163
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.173
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.418
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.633
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.283
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.600
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.755
[08/24 07:58:24 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:------:|:------:|:------:|:-----:|:-----:|:------:|
| 10.152 | 17.833 | 12.303 | 1.368 | 8.762 | 16.327 |
[08/24 07:58:24 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 07:58:24 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 07:58:24 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 07:58:24 d2.evaluation.testing]: copypaste: 4.2965,15.6714,1.0750,1.5970,5.4317,4.9640
[08/24 07:58:24 d2.evaluation.testing]: copypaste: Task: segm
[08/24 07:58:24 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 07:58:24 d2.evaluation.testing]: copypaste: 10.1515,17.8332,12.3025,1.3685,8.7622,16.3271
[08/24 07:58:24 d2.utils.events]:  eta: 0:13:18  iter: 99  total_loss: 1.303  loss_cls: 0.3273  loss_box_reg: 0.3565  loss_mask: 0.5793  loss_rpn_cls: 0.01767  loss_rpn_loc: 0.005058  time: 0.9050  data_time: 0.0504  lr: 2.4975e-05  max_mem: 6143M
[08/24 07:58:43 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 07:58:43 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 07:58:43 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 07:58:43 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 07:58:43 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 07:58:53 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0031 s/iter. Inference: 0.1613 s/iter. Eval: 0.7101 s/iter. Total: 0.8746 s/iter. ETA=0:01:56
[08/24 07:58:58 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0027 s/iter. Inference: 0.1611 s/iter. Eval: 0.6933 s/iter. Total: 0.8573 s/iter. ETA=0:01:48
[08/24 07:59:03 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0026 s/iter. Inference: 0.1609 s/iter. Eval: 0.7047 s/iter. Total: 0.8684 s/iter. ETA=0:01:45
[08/24 07:59:08 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0026 s/iter. Inference: 0.1609 s/iter. Eval: 0.7084 s/iter. Total: 0.8721 s/iter. ETA=0:01:40
[08/24 07:59:14 d2.evaluation.evaluator]: Inference done 35/144. Dataloading: 0.0027 s/iter. Inference: 0.1608 s/iter. Eval: 0.7078 s/iter. Total: 0.8716 s/iter. ETA=0:01:35
[08/24 07:59:19 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0029 s/iter. Inference: 0.1608 s/iter. Eval: 0.7024 s/iter. Total: 0.8664 s/iter. ETA=0:01:29
[08/24 07:59:24 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0029 s/iter. Inference: 0.1606 s/iter. Eval: 0.7024 s/iter. Total: 0.8661 s/iter. ETA=0:01:24
[08/24 07:59:29 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0029 s/iter. Inference: 0.1605 s/iter. Eval: 0.7052 s/iter. Total: 0.8688 s/iter. ETA=0:01:19
[08/24 07:59:34 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0029 s/iter. Inference: 0.1606 s/iter. Eval: 0.7055 s/iter. Total: 0.8692 s/iter. ETA=0:01:13
[08/24 07:59:40 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0028 s/iter. Inference: 0.1606 s/iter. Eval: 0.7092 s/iter. Total: 0.8729 s/iter. ETA=0:01:08
[08/24 07:59:45 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0028 s/iter. Inference: 0.1607 s/iter. Eval: 0.7086 s/iter. Total: 0.8723 s/iter. ETA=0:01:03
[08/24 07:59:50 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0028 s/iter. Inference: 0.1606 s/iter. Eval: 0.7059 s/iter. Total: 0.8695 s/iter. ETA=0:00:58
[08/24 07:59:55 d2.evaluation.evaluator]: Inference done 83/144. Dataloading: 0.0027 s/iter. Inference: 0.1607 s/iter. Eval: 0.7062 s/iter. Total: 0.8698 s/iter. ETA=0:00:53
[08/24 08:00:00 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0028 s/iter. Inference: 0.1607 s/iter. Eval: 0.7041 s/iter. Total: 0.8678 s/iter. ETA=0:00:47
[08/24 08:00:05 d2.evaluation.evaluator]: Inference done 95/144. Dataloading: 0.0028 s/iter. Inference: 0.1607 s/iter. Eval: 0.7024 s/iter. Total: 0.8661 s/iter. ETA=0:00:42
[08/24 08:00:11 d2.evaluation.evaluator]: Inference done 101/144. Dataloading: 0.0028 s/iter. Inference: 0.1606 s/iter. Eval: 0.7036 s/iter. Total: 0.8673 s/iter. ETA=0:00:37
[08/24 08:00:16 d2.evaluation.evaluator]: Inference done 107/144. Dataloading: 0.0027 s/iter. Inference: 0.1607 s/iter. Eval: 0.7061 s/iter. Total: 0.8698 s/iter. ETA=0:00:32
[08/24 08:00:21 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0028 s/iter. Inference: 0.1607 s/iter. Eval: 0.7059 s/iter. Total: 0.8695 s/iter. ETA=0:00:26
[08/24 08:00:26 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0028 s/iter. Inference: 0.1606 s/iter. Eval: 0.7043 s/iter. Total: 0.8679 s/iter. ETA=0:00:21
[08/24 08:00:32 d2.evaluation.evaluator]: Inference done 125/144. Dataloading: 0.0027 s/iter. Inference: 0.1606 s/iter. Eval: 0.7045 s/iter. Total: 0.8681 s/iter. ETA=0:00:16
[08/24 08:00:37 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0027 s/iter. Inference: 0.1606 s/iter. Eval: 0.7031 s/iter. Total: 0.8666 s/iter. ETA=0:00:11
[08/24 08:00:42 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0028 s/iter. Inference: 0.1606 s/iter. Eval: 0.7032 s/iter. Total: 0.8667 s/iter. ETA=0:00:06
[08/24 08:00:47 d2.evaluation.evaluator]: Inference done 143/144. Dataloading: 0.0028 s/iter. Inference: 0.1605 s/iter. Eval: 0.7046 s/iter. Total: 0.8681 s/iter. ETA=0:00:00
[08/24 08:00:48 d2.evaluation.evaluator]: Total inference time: 0:02:00.696287 (0.868319 s / iter per device, on 1 devices)
[08/24 08:00:48 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:22 (0.160467 s / iter per device, on 1 devices)
[08/24 08:00:48 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:00:48 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:00:48 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/24 08:00:48 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:00:49 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[08/24 08:00:49 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:00:49 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.03 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.065
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.225
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.017
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.030
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.076
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.074
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.106
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.319
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.481
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.308
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.465
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.539
[08/24 08:00:49 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 6.467 | 22.539 | 1.728  | 3.012 | 7.600 | 7.423 |
Loading and preparing results...
DONE (t=0.31s)
creating index...
index created!
[08/24 08:00:49 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:00:50 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.32 seconds.
[08/24 08:00:50 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:00:50 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.04 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.143
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.240
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.174
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.038
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.113
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.242
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.190
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.440
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.642
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.758
[08/24 08:00:50 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 14.316 | 23.972 | 17.403 | 3.782 | 11.314 | 24.186 |
[08/24 08:00:50 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:00:50 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:00:50 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:00:50 d2.evaluation.testing]: copypaste: 6.4672,22.5389,1.7284,3.0124,7.5997,7.4228
[08/24 08:00:50 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:00:50 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:00:50 d2.evaluation.testing]: copypaste: 14.3156,23.9717,17.4032,3.7820,11.3137,24.1861
[08/24 08:00:50 d2.utils.events]:  eta: 0:13:01  iter: 119  total_loss: 1.462  loss_cls: 0.3064  loss_box_reg: 0.4122  loss_mask: 0.5231  loss_rpn_cls: 0.0552  loss_rpn_loc: 0.01703  time: 0.9094  data_time: 0.0450  lr: 2.997e-05  max_mem: 6143M
[08/24 08:01:08 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:01:08 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:01:08 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:01:08 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:01:08 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:01:18 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0025 s/iter. Inference: 0.1605 s/iter. Eval: 0.6759 s/iter. Total: 0.8389 s/iter. ETA=0:01:51
[08/24 08:01:23 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0024 s/iter. Inference: 0.1640 s/iter. Eval: 0.7162 s/iter. Total: 0.8828 s/iter. ETA=0:01:52
[08/24 08:01:28 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0026 s/iter. Inference: 0.1626 s/iter. Eval: 0.7017 s/iter. Total: 0.8671 s/iter. ETA=0:01:44
[08/24 08:01:33 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0026 s/iter. Inference: 0.1619 s/iter. Eval: 0.6945 s/iter. Total: 0.8593 s/iter. ETA=0:01:38
[08/24 08:01:39 d2.evaluation.evaluator]: Inference done 35/144. Dataloading: 0.0029 s/iter. Inference: 0.1616 s/iter. Eval: 0.6984 s/iter. Total: 0.8631 s/iter. ETA=0:01:34
[08/24 08:01:44 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0028 s/iter. Inference: 0.1614 s/iter. Eval: 0.6950 s/iter. Total: 0.8595 s/iter. ETA=0:01:28
[08/24 08:01:49 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0027 s/iter. Inference: 0.1613 s/iter. Eval: 0.6956 s/iter. Total: 0.8597 s/iter. ETA=0:01:23
[08/24 08:01:54 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0025 s/iter. Inference: 0.1611 s/iter. Eval: 0.6937 s/iter. Total: 0.8576 s/iter. ETA=0:01:18
[08/24 08:01:59 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0026 s/iter. Inference: 0.1609 s/iter. Eval: 0.6940 s/iter. Total: 0.8578 s/iter. ETA=0:01:12
[08/24 08:02:05 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0026 s/iter. Inference: 0.1608 s/iter. Eval: 0.7031 s/iter. Total: 0.8668 s/iter. ETA=0:01:08
[08/24 08:02:10 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0026 s/iter. Inference: 0.1609 s/iter. Eval: 0.7027 s/iter. Total: 0.8665 s/iter. ETA=0:01:03
[08/24 08:02:15 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0026 s/iter. Inference: 0.1607 s/iter. Eval: 0.7005 s/iter. Total: 0.8641 s/iter. ETA=0:00:57
[08/24 08:02:20 d2.evaluation.evaluator]: Inference done 83/144. Dataloading: 0.0026 s/iter. Inference: 0.1608 s/iter. Eval: 0.7003 s/iter. Total: 0.8640 s/iter. ETA=0:00:52
[08/24 08:02:25 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0026 s/iter. Inference: 0.1608 s/iter. Eval: 0.6989 s/iter. Total: 0.8626 s/iter. ETA=0:00:47
[08/24 08:02:30 d2.evaluation.evaluator]: Inference done 95/144. Dataloading: 0.0026 s/iter. Inference: 0.1608 s/iter. Eval: 0.6989 s/iter. Total: 0.8627 s/iter. ETA=0:00:42
[08/24 08:02:35 d2.evaluation.evaluator]: Inference done 101/144. Dataloading: 0.0026 s/iter. Inference: 0.1607 s/iter. Eval: 0.6974 s/iter. Total: 0.8611 s/iter. ETA=0:00:37
[08/24 08:02:41 d2.evaluation.evaluator]: Inference done 107/144. Dataloading: 0.0027 s/iter. Inference: 0.1608 s/iter. Eval: 0.7009 s/iter. Total: 0.8648 s/iter. ETA=0:00:31
[08/24 08:02:46 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0028 s/iter. Inference: 0.1608 s/iter. Eval: 0.6996 s/iter. Total: 0.8634 s/iter. ETA=0:00:26
[08/24 08:02:51 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0027 s/iter. Inference: 0.1607 s/iter. Eval: 0.6997 s/iter. Total: 0.8634 s/iter. ETA=0:00:21
[08/24 08:02:56 d2.evaluation.evaluator]: Inference done 125/144. Dataloading: 0.0027 s/iter. Inference: 0.1606 s/iter. Eval: 0.6987 s/iter. Total: 0.8624 s/iter. ETA=0:00:16
[08/24 08:03:01 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0027 s/iter. Inference: 0.1606 s/iter. Eval: 0.6975 s/iter. Total: 0.8611 s/iter. ETA=0:00:11
[08/24 08:03:06 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0027 s/iter. Inference: 0.1606 s/iter. Eval: 0.6979 s/iter. Total: 0.8615 s/iter. ETA=0:00:06
[08/24 08:03:11 d2.evaluation.evaluator]: Inference done 143/144. Dataloading: 0.0027 s/iter. Inference: 0.1605 s/iter. Eval: 0.6970 s/iter. Total: 0.8605 s/iter. ETA=0:00:00
[08/24 08:03:12 d2.evaluation.evaluator]: Total inference time: 0:01:59.632267 (0.860664 s / iter per device, on 1 devices)
[08/24 08:03:12 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:22 (0.160448 s / iter per device, on 1 devices)
[08/24 08:03:12 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:03:12 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:03:13 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[08/24 08:03:13 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:03:13 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.18 seconds.
[08/24 08:03:13 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:03:13 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.04 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.098
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.299
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.034
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.058
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.102
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.121
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.126
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.363
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.488
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.468
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.553
[08/24 08:03:13 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:-----:|:------:|:------:|:-----:|:------:|:------:|
| 9.804 | 29.927 | 3.448  | 5.818 | 10.225 | 12.082 |
Loading and preparing results...
DONE (t=0.30s)
creating index...
index created!
[08/24 08:03:14 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:03:14 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.22 seconds.
[08/24 08:03:14 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:03:14 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.205
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.330
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.242
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.074
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.157
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.342
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.211
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.485
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.650
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.325
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.618
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.765
[08/24 08:03:14 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 20.451 | 33.021 | 24.187 | 7.412 | 15.702 | 34.170 |
[08/24 08:03:14 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:03:14 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:03:14 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:03:14 d2.evaluation.testing]: copypaste: 9.8040,29.9275,3.4482,5.8176,10.2249,12.0819
[08/24 08:03:14 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:03:14 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:03:14 d2.evaluation.testing]: copypaste: 20.4512,33.0205,24.1873,7.4119,15.7019,34.1704
[08/24 08:03:14 d2.utils.events]:  eta: 0:12:45  iter: 139  total_loss: 1.238  loss_cls: 0.2724  loss_box_reg: 0.3899  loss_mask: 0.4756  loss_rpn_cls: 0.02643  loss_rpn_loc: 0.005093  time: 0.9088  data_time: 0.0336  lr: 3.4965e-05  max_mem: 6143M
[08/24 08:03:32 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:03:32 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:03:32 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:03:32 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:03:32 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:03:42 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0023 s/iter. Inference: 0.1607 s/iter. Eval: 0.6935 s/iter. Total: 0.8565 s/iter. ETA=0:01:53
[08/24 08:03:47 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0027 s/iter. Inference: 0.1624 s/iter. Eval: 0.6944 s/iter. Total: 0.8598 s/iter. ETA=0:01:49
[08/24 08:03:53 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0027 s/iter. Inference: 0.1618 s/iter. Eval: 0.6881 s/iter. Total: 0.8528 s/iter. ETA=0:01:43
[08/24 08:03:58 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0027 s/iter. Inference: 0.1615 s/iter. Eval: 0.6928 s/iter. Total: 0.8572 s/iter. ETA=0:01:38
[08/24 08:04:03 d2.evaluation.evaluator]: Inference done 35/144. Dataloading: 0.0027 s/iter. Inference: 0.1613 s/iter. Eval: 0.6903 s/iter. Total: 0.8546 s/iter. ETA=0:01:33
[08/24 08:04:08 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0027 s/iter. Inference: 0.1612 s/iter. Eval: 0.6986 s/iter. Total: 0.8627 s/iter. ETA=0:01:28
[08/24 08:04:13 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0026 s/iter. Inference: 0.1615 s/iter. Eval: 0.7008 s/iter. Total: 0.8653 s/iter. ETA=0:01:23
[08/24 08:04:19 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0027 s/iter. Inference: 0.1613 s/iter. Eval: 0.6984 s/iter. Total: 0.8627 s/iter. ETA=0:01:18
[08/24 08:04:24 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0029 s/iter. Inference: 0.1613 s/iter. Eval: 0.6976 s/iter. Total: 0.8621 s/iter. ETA=0:01:13
[08/24 08:04:29 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0028 s/iter. Inference: 0.1611 s/iter. Eval: 0.6954 s/iter. Total: 0.8596 s/iter. ETA=0:01:07
[08/24 08:04:34 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0028 s/iter. Inference: 0.1615 s/iter. Eval: 0.6951 s/iter. Total: 0.8597 s/iter. ETA=0:01:02
[08/24 08:04:39 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0028 s/iter. Inference: 0.1614 s/iter. Eval: 0.6939 s/iter. Total: 0.8584 s/iter. ETA=0:00:57
[08/24 08:04:45 d2.evaluation.evaluator]: Inference done 83/144. Dataloading: 0.0030 s/iter. Inference: 0.1618 s/iter. Eval: 0.7016 s/iter. Total: 0.8666 s/iter. ETA=0:00:52
[08/24 08:04:50 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0030 s/iter. Inference: 0.1616 s/iter. Eval: 0.7033 s/iter. Total: 0.8682 s/iter. ETA=0:00:47
[08/24 08:04:55 d2.evaluation.evaluator]: Inference done 95/144. Dataloading: 0.0030 s/iter. Inference: 0.1616 s/iter. Eval: 0.7037 s/iter. Total: 0.8685 s/iter. ETA=0:00:42
[08/24 08:05:00 d2.evaluation.evaluator]: Inference done 101/144. Dataloading: 0.0029 s/iter. Inference: 0.1615 s/iter. Eval: 0.7022 s/iter. Total: 0.8669 s/iter. ETA=0:00:37
[08/24 08:05:06 d2.evaluation.evaluator]: Inference done 107/144. Dataloading: 0.0029 s/iter. Inference: 0.1614 s/iter. Eval: 0.7025 s/iter. Total: 0.8671 s/iter. ETA=0:00:32
[08/24 08:05:11 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0029 s/iter. Inference: 0.1614 s/iter. Eval: 0.7012 s/iter. Total: 0.8658 s/iter. ETA=0:00:26
[08/24 08:05:16 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0028 s/iter. Inference: 0.1615 s/iter. Eval: 0.7050 s/iter. Total: 0.8697 s/iter. ETA=0:00:21
[08/24 08:05:21 d2.evaluation.evaluator]: Inference done 125/144. Dataloading: 0.0028 s/iter. Inference: 0.1614 s/iter. Eval: 0.7036 s/iter. Total: 0.8681 s/iter. ETA=0:00:16
[08/24 08:05:27 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0028 s/iter. Inference: 0.1614 s/iter. Eval: 0.7037 s/iter. Total: 0.8682 s/iter. ETA=0:00:11
[08/24 08:05:32 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0029 s/iter. Inference: 0.1613 s/iter. Eval: 0.7025 s/iter. Total: 0.8669 s/iter. ETA=0:00:06
[08/24 08:05:37 d2.evaluation.evaluator]: Inference done 143/144. Dataloading: 0.0028 s/iter. Inference: 0.1612 s/iter. Eval: 0.7013 s/iter. Total: 0.8655 s/iter. ETA=0:00:00
[08/24 08:05:37 d2.evaluation.evaluator]: Total inference time: 0:02:00.328348 (0.865672 s / iter per device, on 1 devices)
[08/24 08:05:37 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:22 (0.161126 s / iter per device, on 1 devices)
[08/24 08:05:38 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:05:38 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:05:38 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/24 08:05:38 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:05:38 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[08/24 08:05:38 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:05:38 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.122
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.348
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.044
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.060
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.121
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.156
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.148
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.373
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.497
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.342
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.480
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.555
[08/24 08:05:38 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 12.171 | 34.796 | 4.447  | 5.998 | 12.091 | 15.578 |
Loading and preparing results...
DONE (t=0.29s)
creating index...
index created!
[08/24 08:05:39 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:05:39 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.21 seconds.
[08/24 08:05:39 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:05:39 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.239
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.382
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.286
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.075
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.179
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.404
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.229
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.506
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.653
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.621
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.762
[08/24 08:05:39 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 23.944 | 38.197 | 28.556 | 7.523 | 17.895 | 40.437 |
[08/24 08:05:39 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:05:39 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:05:39 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:05:39 d2.evaluation.testing]: copypaste: 12.1707,34.7964,4.4470,5.9976,12.0912,15.5779
[08/24 08:05:39 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:05:39 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:05:39 d2.evaluation.testing]: copypaste: 23.9441,38.1974,28.5555,7.5235,17.8954,40.4368
[08/24 08:05:39 d2.utils.events]:  eta: 0:12:27  iter: 159  total_loss: 1.083  loss_cls: 0.233  loss_box_reg: 0.3914  loss_mask: 0.414  loss_rpn_cls: 0.01161  loss_rpn_loc: 0.004003  time: 0.9091  data_time: 0.0431  lr: 3.996e-05  max_mem: 6143M
[08/24 08:05:57 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:05:57 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:05:57 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:05:57 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:05:57 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:06:07 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0027 s/iter. Inference: 0.1601 s/iter. Eval: 0.6801 s/iter. Total: 0.8429 s/iter. ETA=0:01:52
[08/24 08:06:13 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0029 s/iter. Inference: 0.1604 s/iter. Eval: 0.6954 s/iter. Total: 0.8589 s/iter. ETA=0:01:49
[08/24 08:06:18 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0028 s/iter. Inference: 0.1602 s/iter. Eval: 0.6915 s/iter. Total: 0.8548 s/iter. ETA=0:01:43
[08/24 08:06:23 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0029 s/iter. Inference: 0.1603 s/iter. Eval: 0.7125 s/iter. Total: 0.8759 s/iter. ETA=0:01:40
[08/24 08:06:28 d2.evaluation.evaluator]: Inference done 35/144. Dataloading: 0.0029 s/iter. Inference: 0.1603 s/iter. Eval: 0.7053 s/iter. Total: 0.8687 s/iter. ETA=0:01:34
[08/24 08:06:33 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0028 s/iter. Inference: 0.1601 s/iter. Eval: 0.7029 s/iter. Total: 0.8661 s/iter. ETA=0:01:29
[08/24 08:06:38 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0029 s/iter. Inference: 0.1600 s/iter. Eval: 0.6987 s/iter. Total: 0.8618 s/iter. ETA=0:01:23
[08/24 08:06:44 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0030 s/iter. Inference: 0.1600 s/iter. Eval: 0.6992 s/iter. Total: 0.8625 s/iter. ETA=0:01:18
[08/24 08:06:49 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0029 s/iter. Inference: 0.1600 s/iter. Eval: 0.6967 s/iter. Total: 0.8599 s/iter. ETA=0:01:13
[08/24 08:06:54 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0029 s/iter. Inference: 0.1602 s/iter. Eval: 0.7056 s/iter. Total: 0.8690 s/iter. ETA=0:01:08
[08/24 08:06:59 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0028 s/iter. Inference: 0.1602 s/iter. Eval: 0.7030 s/iter. Total: 0.8663 s/iter. ETA=0:01:03
[08/24 08:07:05 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0029 s/iter. Inference: 0.1603 s/iter. Eval: 0.7015 s/iter. Total: 0.8650 s/iter. ETA=0:00:57
[08/24 08:07:10 d2.evaluation.evaluator]: Inference done 83/144. Dataloading: 0.0029 s/iter. Inference: 0.1603 s/iter. Eval: 0.6996 s/iter. Total: 0.8630 s/iter. ETA=0:00:52
[08/24 08:07:15 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0029 s/iter. Inference: 0.1603 s/iter. Eval: 0.6989 s/iter. Total: 0.8623 s/iter. ETA=0:00:47
[08/24 08:07:20 d2.evaluation.evaluator]: Inference done 95/144. Dataloading: 0.0029 s/iter. Inference: 0.1602 s/iter. Eval: 0.6985 s/iter. Total: 0.8619 s/iter. ETA=0:00:42
[08/24 08:07:25 d2.evaluation.evaluator]: Inference done 101/144. Dataloading: 0.0029 s/iter. Inference: 0.1602 s/iter. Eval: 0.6974 s/iter. Total: 0.8607 s/iter. ETA=0:00:37
[08/24 08:07:30 d2.evaluation.evaluator]: Inference done 106/144. Dataloading: 0.0030 s/iter. Inference: 0.1605 s/iter. Eval: 0.7041 s/iter. Total: 0.8678 s/iter. ETA=0:00:32
[08/24 08:07:35 d2.evaluation.evaluator]: Inference done 112/144. Dataloading: 0.0030 s/iter. Inference: 0.1604 s/iter. Eval: 0.7028 s/iter. Total: 0.8665 s/iter. ETA=0:00:27
[08/24 08:07:40 d2.evaluation.evaluator]: Inference done 118/144. Dataloading: 0.0030 s/iter. Inference: 0.1605 s/iter. Eval: 0.7024 s/iter. Total: 0.8662 s/iter. ETA=0:00:22
[08/24 08:07:45 d2.evaluation.evaluator]: Inference done 124/144. Dataloading: 0.0030 s/iter. Inference: 0.1605 s/iter. Eval: 0.7013 s/iter. Total: 0.8650 s/iter. ETA=0:00:17
[08/24 08:07:50 d2.evaluation.evaluator]: Inference done 130/144. Dataloading: 0.0030 s/iter. Inference: 0.1604 s/iter. Eval: 0.7014 s/iter. Total: 0.8651 s/iter. ETA=0:00:12
[08/24 08:07:56 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0030 s/iter. Inference: 0.1603 s/iter. Eval: 0.6993 s/iter. Total: 0.8628 s/iter. ETA=0:00:06
[08/24 08:08:02 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0029 s/iter. Inference: 0.1600 s/iter. Eval: 0.6969 s/iter. Total: 0.8600 s/iter. ETA=0:00:00
[08/24 08:08:02 d2.evaluation.evaluator]: Total inference time: 0:01:59.600873 (0.860438 s / iter per device, on 1 devices)
[08/24 08:08:02 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:22 (0.159981 s / iter per device, on 1 devices)
[08/24 08:08:02 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:08:02 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:08:02 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/24 08:08:02 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:08:02 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[08/24 08:08:02 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:08:02 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.144
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.378
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.053
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.064
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.151
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.173
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.179
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.397
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.520
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.392
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.500
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.579
[08/24 08:08:02 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 14.368 | 37.802 | 5.329  | 6.403 | 15.149 | 17.250 |
Loading and preparing results...
DONE (t=0.28s)
creating index...
index created!
[08/24 08:08:03 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:08:03 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.20 seconds.
[08/24 08:08:03 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:08:03 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.253
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.400
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.310
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.077
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.190
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.426
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.254
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.522
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.668
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.442
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.633
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.771
[08/24 08:08:03 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 25.280 | 40.018 | 31.029 | 7.720 | 18.964 | 42.633 |
[08/24 08:08:03 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:08:03 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:08:03 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:08:03 d2.evaluation.testing]: copypaste: 14.3681,37.8021,5.3288,6.4029,15.1493,17.2501
[08/24 08:08:03 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:08:03 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:08:03 d2.evaluation.testing]: copypaste: 25.2796,40.0175,31.0290,7.7198,18.9642,42.6332
[08/24 08:08:03 d2.utils.events]:  eta: 0:12:09  iter: 179  total_loss: 1.114  loss_cls: 0.2472  loss_box_reg: 0.3753  loss_mask: 0.3933  loss_rpn_cls: 0.0496  loss_rpn_loc: 0.01172  time: 0.9098  data_time: 0.0353  lr: 4.4955e-05  max_mem: 6143M
[08/24 08:08:22 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:08:22 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:08:22 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:08:22 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:08:22 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:08:32 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0021 s/iter. Inference: 0.1601 s/iter. Eval: 0.7125 s/iter. Total: 0.8747 s/iter. ETA=0:01:56
[08/24 08:08:37 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0027 s/iter. Inference: 0.1615 s/iter. Eval: 0.6951 s/iter. Total: 0.8596 s/iter. ETA=0:01:49
[08/24 08:08:42 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0028 s/iter. Inference: 0.1607 s/iter. Eval: 0.7024 s/iter. Total: 0.8661 s/iter. ETA=0:01:44
[08/24 08:08:47 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0028 s/iter. Inference: 0.1602 s/iter. Eval: 0.6964 s/iter. Total: 0.8596 s/iter. ETA=0:01:38
[08/24 08:08:53 d2.evaluation.evaluator]: Inference done 36/144. Dataloading: 0.0027 s/iter. Inference: 0.1593 s/iter. Eval: 0.6810 s/iter. Total: 0.8433 s/iter. ETA=0:01:31
[08/24 08:08:59 d2.evaluation.evaluator]: Inference done 43/144. Dataloading: 0.0028 s/iter. Inference: 0.1590 s/iter. Eval: 0.6750 s/iter. Total: 0.8370 s/iter. ETA=0:01:24
[08/24 08:09:04 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0028 s/iter. Inference: 0.1591 s/iter. Eval: 0.6764 s/iter. Total: 0.8385 s/iter. ETA=0:01:19
[08/24 08:09:09 d2.evaluation.evaluator]: Inference done 55/144. Dataloading: 0.0028 s/iter. Inference: 0.1595 s/iter. Eval: 0.6792 s/iter. Total: 0.8417 s/iter. ETA=0:01:14
[08/24 08:09:14 d2.evaluation.evaluator]: Inference done 61/144. Dataloading: 0.0028 s/iter. Inference: 0.1602 s/iter. Eval: 0.6861 s/iter. Total: 0.8494 s/iter. ETA=0:01:10
[08/24 08:09:20 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0028 s/iter. Inference: 0.1602 s/iter. Eval: 0.6875 s/iter. Total: 0.8507 s/iter. ETA=0:01:05
[08/24 08:09:25 d2.evaluation.evaluator]: Inference done 74/144. Dataloading: 0.0028 s/iter. Inference: 0.1596 s/iter. Eval: 0.6802 s/iter. Total: 0.8428 s/iter. ETA=0:00:58
[08/24 08:09:31 d2.evaluation.evaluator]: Inference done 81/144. Dataloading: 0.0027 s/iter. Inference: 0.1593 s/iter. Eval: 0.6781 s/iter. Total: 0.8404 s/iter. ETA=0:00:52
[08/24 08:09:36 d2.evaluation.evaluator]: Inference done 88/144. Dataloading: 0.0027 s/iter. Inference: 0.1592 s/iter. Eval: 0.6758 s/iter. Total: 0.8379 s/iter. ETA=0:00:46
[08/24 08:09:42 d2.evaluation.evaluator]: Inference done 94/144. Dataloading: 0.0027 s/iter. Inference: 0.1592 s/iter. Eval: 0.6776 s/iter. Total: 0.8397 s/iter. ETA=0:00:41
[08/24 08:09:47 d2.evaluation.evaluator]: Inference done 100/144. Dataloading: 0.0028 s/iter. Inference: 0.1592 s/iter. Eval: 0.6797 s/iter. Total: 0.8419 s/iter. ETA=0:00:37
[08/24 08:09:52 d2.evaluation.evaluator]: Inference done 106/144. Dataloading: 0.0029 s/iter. Inference: 0.1593 s/iter. Eval: 0.6805 s/iter. Total: 0.8429 s/iter. ETA=0:00:32
[08/24 08:09:57 d2.evaluation.evaluator]: Inference done 112/144. Dataloading: 0.0029 s/iter. Inference: 0.1593 s/iter. Eval: 0.6805 s/iter. Total: 0.8430 s/iter. ETA=0:00:26
[08/24 08:10:02 d2.evaluation.evaluator]: Inference done 118/144. Dataloading: 0.0029 s/iter. Inference: 0.1594 s/iter. Eval: 0.6804 s/iter. Total: 0.8430 s/iter. ETA=0:00:21
[08/24 08:10:07 d2.evaluation.evaluator]: Inference done 124/144. Dataloading: 0.0029 s/iter. Inference: 0.1594 s/iter. Eval: 0.6806 s/iter. Total: 0.8432 s/iter. ETA=0:00:16
[08/24 08:10:12 d2.evaluation.evaluator]: Inference done 130/144. Dataloading: 0.0029 s/iter. Inference: 0.1594 s/iter. Eval: 0.6813 s/iter. Total: 0.8439 s/iter. ETA=0:00:11
[08/24 08:10:17 d2.evaluation.evaluator]: Inference done 136/144. Dataloading: 0.0029 s/iter. Inference: 0.1593 s/iter. Eval: 0.6814 s/iter. Total: 0.8438 s/iter. ETA=0:00:06
[08/24 08:10:23 d2.evaluation.evaluator]: Inference done 143/144. Dataloading: 0.0029 s/iter. Inference: 0.1589 s/iter. Eval: 0.6798 s/iter. Total: 0.8419 s/iter. ETA=0:00:00
[08/24 08:10:24 d2.evaluation.evaluator]: Total inference time: 0:01:57.094068 (0.842403 s / iter per device, on 1 devices)
[08/24 08:10:24 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:22 (0.158918 s / iter per device, on 1 devices)
[08/24 08:10:24 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:10:24 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:10:24 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/24 08:10:24 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:10:24 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[08/24 08:10:24 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:10:24 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.160
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.409
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.055
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.076
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.164
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.197
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.195
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.401
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.507
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.477
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.588
[08/24 08:10:24 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 15.984 | 40.930 | 5.528  | 7.590 | 16.395 | 19.681 |
Loading and preparing results...
DONE (t=0.26s)
creating index...
index created!
[08/24 08:10:25 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:10:25 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.19 seconds.
[08/24 08:10:25 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:10:25 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.269
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.422
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.336
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.078
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.202
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.462
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.270
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.536
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.674
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.425
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.641
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.777
[08/24 08:10:25 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 26.906 | 42.241 | 33.600 | 7.842 | 20.235 | 46.227 |
[08/24 08:10:25 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:10:25 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:10:25 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:10:25 d2.evaluation.testing]: copypaste: 15.9840,40.9304,5.5282,7.5896,16.3947,19.6811
[08/24 08:10:25 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:10:25 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:10:25 d2.evaluation.testing]: copypaste: 26.9058,42.2406,33.5996,7.8423,20.2353,46.2273
[08/24 08:10:25 d2.utils.events]:  eta: 0:11:53  iter: 199  total_loss: 1.001  loss_cls: 0.2072  loss_box_reg: 0.3966  loss_mask: 0.3514  loss_rpn_cls: 0.01931  loss_rpn_loc: 0.006144  time: 0.9124  data_time: 0.0321  lr: 4.995e-05  max_mem: 6143M
[08/24 08:10:43 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:10:43 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:10:43 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:10:43 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:10:43 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:10:53 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0029 s/iter. Inference: 0.1595 s/iter. Eval: 0.6938 s/iter. Total: 0.8563 s/iter. ETA=0:01:53
[08/24 08:10:59 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0037 s/iter. Inference: 0.1597 s/iter. Eval: 0.7148 s/iter. Total: 0.8789 s/iter. ETA=0:01:51
[08/24 08:11:04 d2.evaluation.evaluator]: Inference done 24/144. Dataloading: 0.0036 s/iter. Inference: 0.1577 s/iter. Eval: 0.6764 s/iter. Total: 0.8381 s/iter. ETA=0:01:40
[08/24 08:11:10 d2.evaluation.evaluator]: Inference done 32/144. Dataloading: 0.0034 s/iter. Inference: 0.1561 s/iter. Eval: 0.6436 s/iter. Total: 0.8035 s/iter. ETA=0:01:29
[08/24 08:11:15 d2.evaluation.evaluator]: Inference done 39/144. Dataloading: 0.0033 s/iter. Inference: 0.1553 s/iter. Eval: 0.6305 s/iter. Total: 0.7894 s/iter. ETA=0:01:22
[08/24 08:11:21 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0032 s/iter. Inference: 0.1557 s/iter. Eval: 0.6352 s/iter. Total: 0.7945 s/iter. ETA=0:01:17
[08/24 08:11:26 d2.evaluation.evaluator]: Inference done 52/144. Dataloading: 0.0032 s/iter. Inference: 0.1562 s/iter. Eval: 0.6405 s/iter. Total: 0.8003 s/iter. ETA=0:01:13
[08/24 08:11:31 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0031 s/iter. Inference: 0.1567 s/iter. Eval: 0.6472 s/iter. Total: 0.8073 s/iter. ETA=0:01:09
[08/24 08:11:36 d2.evaluation.evaluator]: Inference done 64/144. Dataloading: 0.0030 s/iter. Inference: 0.1568 s/iter. Eval: 0.6546 s/iter. Total: 0.8147 s/iter. ETA=0:01:05
[08/24 08:11:41 d2.evaluation.evaluator]: Inference done 70/144. Dataloading: 0.0031 s/iter. Inference: 0.1572 s/iter. Eval: 0.6597 s/iter. Total: 0.8203 s/iter. ETA=0:01:00
[08/24 08:11:47 d2.evaluation.evaluator]: Inference done 78/144. Dataloading: 0.0031 s/iter. Inference: 0.1560 s/iter. Eval: 0.6440 s/iter. Total: 0.8033 s/iter. ETA=0:00:53
[08/24 08:11:52 d2.evaluation.evaluator]: Inference done 85/144. Dataloading: 0.0031 s/iter. Inference: 0.1555 s/iter. Eval: 0.6396 s/iter. Total: 0.7986 s/iter. ETA=0:00:47
[08/24 08:11:58 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0031 s/iter. Inference: 0.1557 s/iter. Eval: 0.6405 s/iter. Total: 0.7996 s/iter. ETA=0:00:41
[08/24 08:12:03 d2.evaluation.evaluator]: Inference done 99/144. Dataloading: 0.0031 s/iter. Inference: 0.1554 s/iter. Eval: 0.6356 s/iter. Total: 0.7944 s/iter. ETA=0:00:35
[08/24 08:12:08 d2.evaluation.evaluator]: Inference done 106/144. Dataloading: 0.0030 s/iter. Inference: 0.1552 s/iter. Eval: 0.6323 s/iter. Total: 0.7908 s/iter. ETA=0:00:30
[08/24 08:12:13 d2.evaluation.evaluator]: Inference done 112/144. Dataloading: 0.0030 s/iter. Inference: 0.1553 s/iter. Eval: 0.6351 s/iter. Total: 0.7937 s/iter. ETA=0:00:25
[08/24 08:12:18 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0030 s/iter. Inference: 0.1552 s/iter. Eval: 0.6340 s/iter. Total: 0.7925 s/iter. ETA=0:00:19
[08/24 08:12:24 d2.evaluation.evaluator]: Inference done 125/144. Dataloading: 0.0030 s/iter. Inference: 0.1555 s/iter. Eval: 0.6366 s/iter. Total: 0.7953 s/iter. ETA=0:00:15
[08/24 08:12:29 d2.evaluation.evaluator]: Inference done 132/144. Dataloading: 0.0030 s/iter. Inference: 0.1553 s/iter. Eval: 0.6346 s/iter. Total: 0.7932 s/iter. ETA=0:00:09
[08/24 08:12:34 d2.evaluation.evaluator]: Inference done 140/144. Dataloading: 0.0030 s/iter. Inference: 0.1548 s/iter. Eval: 0.6273 s/iter. Total: 0.7854 s/iter. ETA=0:00:03
[08/24 08:12:38 d2.evaluation.evaluator]: Total inference time: 0:01:49.420850 (0.787200 s / iter per device, on 1 devices)
[08/24 08:12:38 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:21 (0.154848 s / iter per device, on 1 devices)
[08/24 08:12:38 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:12:38 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:12:38 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/24 08:12:38 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:12:38 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.
[08/24 08:12:38 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:12:38 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.185
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.425
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.070
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.080
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.189
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.231
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.204
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.422
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.524
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.500
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.598
[08/24 08:12:38 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 18.503 | 42.508 | 7.038  | 8.031 | 18.898 | 23.059 |
Loading and preparing results...
DONE (t=0.25s)
creating index...
index created!
[08/24 08:12:39 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:12:39 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.18 seconds.
[08/24 08:12:39 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:12:39 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.281
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.431
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.350
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.081
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.209
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.475
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.273
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.548
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.675
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.425
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.643
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.776
[08/24 08:12:39 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 28.145 | 43.114 | 34.968 | 8.054 | 20.948 | 47.500 |
[08/24 08:12:39 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:12:39 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:12:39 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:12:39 d2.evaluation.testing]: copypaste: 18.5033,42.5085,7.0381,8.0307,18.8984,23.0586
[08/24 08:12:39 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:12:39 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:12:39 d2.evaluation.testing]: copypaste: 28.1454,43.1139,34.9682,8.0536,20.9484,47.4996
[08/24 08:12:39 d2.utils.events]:  eta: 0:11:34  iter: 219  total_loss: 0.9362  loss_cls: 0.1948  loss_box_reg: 0.3481  loss_mask: 0.3313  loss_rpn_cls: 0.01695  loss_rpn_loc: 0.01565  time: 0.9108  data_time: 0.0201  lr: 5.4945e-05  max_mem: 6143M
[08/24 08:12:57 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:12:57 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:12:57 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:12:57 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:12:57 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:13:07 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0023 s/iter. Inference: 0.1595 s/iter. Eval: 0.7036 s/iter. Total: 0.8653 s/iter. ETA=0:01:55
[08/24 08:13:13 d2.evaluation.evaluator]: Inference done 18/144. Dataloading: 0.0030 s/iter. Inference: 0.1563 s/iter. Eval: 0.6543 s/iter. Total: 0.8139 s/iter. ETA=0:01:42
[08/24 08:13:18 d2.evaluation.evaluator]: Inference done 26/144. Dataloading: 0.0029 s/iter. Inference: 0.1537 s/iter. Eval: 0.6160 s/iter. Total: 0.7729 s/iter. ETA=0:01:31
[08/24 08:13:24 d2.evaluation.evaluator]: Inference done 34/144. Dataloading: 0.0033 s/iter. Inference: 0.1519 s/iter. Eval: 0.5979 s/iter. Total: 0.7533 s/iter. ETA=0:01:22
[08/24 08:13:30 d2.evaluation.evaluator]: Inference done 42/144. Dataloading: 0.0036 s/iter. Inference: 0.1513 s/iter. Eval: 0.5903 s/iter. Total: 0.7453 s/iter. ETA=0:01:16
[08/24 08:13:35 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0034 s/iter. Inference: 0.1525 s/iter. Eval: 0.6032 s/iter. Total: 0.7593 s/iter. ETA=0:01:12
[08/24 08:13:40 d2.evaluation.evaluator]: Inference done 55/144. Dataloading: 0.0033 s/iter. Inference: 0.1536 s/iter. Eval: 0.6118 s/iter. Total: 0.7689 s/iter. ETA=0:01:08
[08/24 08:13:46 d2.evaluation.evaluator]: Inference done 62/144. Dataloading: 0.0033 s/iter. Inference: 0.1540 s/iter. Eval: 0.6143 s/iter. Total: 0.7718 s/iter. ETA=0:01:03
[08/24 08:13:51 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0032 s/iter. Inference: 0.1543 s/iter. Eval: 0.6207 s/iter. Total: 0.7785 s/iter. ETA=0:00:59
[08/24 08:13:57 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0032 s/iter. Inference: 0.1529 s/iter. Eval: 0.6040 s/iter. Total: 0.7604 s/iter. ETA=0:00:50
[08/24 08:14:02 d2.evaluation.evaluator]: Inference done 84/144. Dataloading: 0.0033 s/iter. Inference: 0.1530 s/iter. Eval: 0.6056 s/iter. Total: 0.7621 s/iter. ETA=0:00:45
[08/24 08:14:07 d2.evaluation.evaluator]: Inference done 91/144. Dataloading: 0.0033 s/iter. Inference: 0.1529 s/iter. Eval: 0.6027 s/iter. Total: 0.7591 s/iter. ETA=0:00:40
[08/24 08:14:12 d2.evaluation.evaluator]: Inference done 99/144. Dataloading: 0.0033 s/iter. Inference: 0.1520 s/iter. Eval: 0.5931 s/iter. Total: 0.7487 s/iter. ETA=0:00:33
[08/24 08:14:17 d2.evaluation.evaluator]: Inference done 106/144. Dataloading: 0.0033 s/iter. Inference: 0.1519 s/iter. Eval: 0.5911 s/iter. Total: 0.7466 s/iter. ETA=0:00:28
[08/24 08:14:23 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0033 s/iter. Inference: 0.1520 s/iter. Eval: 0.5917 s/iter. Total: 0.7472 s/iter. ETA=0:00:23
[08/24 08:14:28 d2.evaluation.evaluator]: Inference done 121/144. Dataloading: 0.0034 s/iter. Inference: 0.1515 s/iter. Eval: 0.5857 s/iter. Total: 0.7408 s/iter. ETA=0:00:17
[08/24 08:14:33 d2.evaluation.evaluator]: Inference done 128/144. Dataloading: 0.0033 s/iter. Inference: 0.1514 s/iter. Eval: 0.5863 s/iter. Total: 0.7413 s/iter. ETA=0:00:11
[08/24 08:14:39 d2.evaluation.evaluator]: Inference done 135/144. Dataloading: 0.0034 s/iter. Inference: 0.1516 s/iter. Eval: 0.5889 s/iter. Total: 0.7441 s/iter. ETA=0:00:06
[08/24 08:14:44 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0033 s/iter. Inference: 0.1510 s/iter. Eval: 0.5821 s/iter. Total: 0.7366 s/iter. ETA=0:00:00
[08/24 08:14:44 d2.evaluation.evaluator]: Total inference time: 0:01:42.440599 (0.736983 s / iter per device, on 1 devices)
[08/24 08:14:44 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:20 (0.150962 s / iter per device, on 1 devices)
[08/24 08:14:45 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:14:45 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:14:45 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/24 08:14:45 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:14:45 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.09 seconds.
[08/24 08:14:45 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:14:45 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.193
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.430
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.081
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.083
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.198
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.242
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.211
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.434
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.533
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.505
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.612
[08/24 08:14:45 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 19.330 | 43.029 | 8.139  | 8.301 | 19.759 | 24.229 |
Loading and preparing results...
DONE (t=0.38s)
creating index...
index created!
[08/24 08:14:46 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:14:46 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.22 seconds.
[08/24 08:14:46 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:14:46 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.286
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.439
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.367
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.084
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.206
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.486
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.276
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.555
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.669
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.417
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.632
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.780
[08/24 08:14:46 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 28.645 | 43.881 | 36.731 | 8.400 | 20.571 | 48.551 |
[08/24 08:14:46 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:14:46 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:14:46 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:14:46 d2.evaluation.testing]: copypaste: 19.3303,43.0291,8.1390,8.3008,19.7594,24.2287
[08/24 08:14:46 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:14:46 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:14:46 d2.evaluation.testing]: copypaste: 28.6448,43.8811,36.7308,8.4003,20.5712,48.5506
[08/24 08:14:46 d2.utils.events]:  eta: 0:11:18  iter: 239  total_loss: 0.7628  loss_cls: 0.1547  loss_box_reg: 0.3439  loss_mask: 0.2671  loss_rpn_cls: 0.008412  loss_rpn_loc: 0.004914  time: 0.9111  data_time: 0.0308  lr: 5.994e-05  max_mem: 6143M
[08/24 08:15:04 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:15:04 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:15:04 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:15:04 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:15:04 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:15:14 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0019 s/iter. Inference: 0.1581 s/iter. Eval: 0.6656 s/iter. Total: 0.8257 s/iter. ETA=0:01:49
[08/24 08:15:20 d2.evaluation.evaluator]: Inference done 18/144. Dataloading: 0.0029 s/iter. Inference: 0.1538 s/iter. Eval: 0.6189 s/iter. Total: 0.7758 s/iter. ETA=0:01:37
[08/24 08:15:25 d2.evaluation.evaluator]: Inference done 26/144. Dataloading: 0.0030 s/iter. Inference: 0.1505 s/iter. Eval: 0.5733 s/iter. Total: 0.7271 s/iter. ETA=0:01:25
[08/24 08:15:30 d2.evaluation.evaluator]: Inference done 34/144. Dataloading: 0.0029 s/iter. Inference: 0.1486 s/iter. Eval: 0.5541 s/iter. Total: 0.7058 s/iter. ETA=0:01:17
[08/24 08:15:35 d2.evaluation.evaluator]: Inference done 42/144. Dataloading: 0.0030 s/iter. Inference: 0.1483 s/iter. Eval: 0.5462 s/iter. Total: 0.6977 s/iter. ETA=0:01:11
[08/24 08:15:41 d2.evaluation.evaluator]: Inference done 48/144. Dataloading: 0.0030 s/iter. Inference: 0.1500 s/iter. Eval: 0.5728 s/iter. Total: 0.7260 s/iter. ETA=0:01:09
[08/24 08:15:46 d2.evaluation.evaluator]: Inference done 54/144. Dataloading: 0.0030 s/iter. Inference: 0.1519 s/iter. Eval: 0.5875 s/iter. Total: 0.7426 s/iter. ETA=0:01:06
[08/24 08:15:51 d2.evaluation.evaluator]: Inference done 61/144. Dataloading: 0.0029 s/iter. Inference: 0.1520 s/iter. Eval: 0.5873 s/iter. Total: 0.7424 s/iter. ETA=0:01:01
[08/24 08:15:57 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0028 s/iter. Inference: 0.1526 s/iter. Eval: 0.5960 s/iter. Total: 0.7518 s/iter. ETA=0:00:57
[08/24 08:16:02 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0028 s/iter. Inference: 0.1511 s/iter. Eval: 0.5778 s/iter. Total: 0.7319 s/iter. ETA=0:00:49
[08/24 08:16:07 d2.evaluation.evaluator]: Inference done 85/144. Dataloading: 0.0028 s/iter. Inference: 0.1502 s/iter. Eval: 0.5690 s/iter. Total: 0.7222 s/iter. ETA=0:00:42
[08/24 08:16:13 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0029 s/iter. Inference: 0.1503 s/iter. Eval: 0.5715 s/iter. Total: 0.7249 s/iter. ETA=0:00:37
[08/24 08:16:18 d2.evaluation.evaluator]: Inference done 101/144. Dataloading: 0.0029 s/iter. Inference: 0.1496 s/iter. Eval: 0.5611 s/iter. Total: 0.7137 s/iter. ETA=0:00:30
[08/24 08:16:23 d2.evaluation.evaluator]: Inference done 109/144. Dataloading: 0.0029 s/iter. Inference: 0.1494 s/iter. Eval: 0.5589 s/iter. Total: 0.7114 s/iter. ETA=0:00:24
[08/24 08:16:29 d2.evaluation.evaluator]: Inference done 117/144. Dataloading: 0.0030 s/iter. Inference: 0.1492 s/iter. Eval: 0.5564 s/iter. Total: 0.7087 s/iter. ETA=0:00:19
[08/24 08:16:34 d2.evaluation.evaluator]: Inference done 125/144. Dataloading: 0.0029 s/iter. Inference: 0.1489 s/iter. Eval: 0.5521 s/iter. Total: 0.7041 s/iter. ETA=0:00:13
[08/24 08:16:39 d2.evaluation.evaluator]: Inference done 133/144. Dataloading: 0.0029 s/iter. Inference: 0.1486 s/iter. Eval: 0.5493 s/iter. Total: 0.7011 s/iter. ETA=0:00:07
[08/24 08:16:45 d2.evaluation.evaluator]: Inference done 142/144. Dataloading: 0.0029 s/iter. Inference: 0.1481 s/iter. Eval: 0.5456 s/iter. Total: 0.6968 s/iter. ETA=0:00:01
[08/24 08:16:47 d2.evaluation.evaluator]: Total inference time: 0:01:37.080517 (0.698421 s / iter per device, on 1 devices)
[08/24 08:16:47 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:20 (0.148171 s / iter per device, on 1 devices)
[08/24 08:16:47 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:16:47 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:16:47 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[08/24 08:16:47 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:16:47 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.
[08/24 08:16:47 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:16:47 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.205
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.450
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.093
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.089
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.198
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.270
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.211
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.427
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.525
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.505
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.592
[08/24 08:16:47 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 20.469 | 44.956 | 9.314  | 8.919 | 19.825 | 27.024 |
Loading and preparing results...
DONE (t=0.20s)
creating index...
index created!
[08/24 08:16:48 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:16:48 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.16 seconds.
[08/24 08:16:48 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:16:48 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.305
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.461
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.379
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.086
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.228
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.492
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.281
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.548
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.668
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.408
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.635
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.773
[08/24 08:16:48 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 30.523 | 46.060 | 37.884 | 8.587 | 22.764 | 49.238 |
[08/24 08:16:48 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:16:48 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:16:48 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:16:48 d2.evaluation.testing]: copypaste: 20.4689,44.9561,9.3136,8.9189,19.8253,27.0245
[08/24 08:16:48 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:16:48 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:16:48 d2.evaluation.testing]: copypaste: 30.5231,46.0601,37.8843,8.5874,22.7635,49.2377
[08/24 08:16:48 d2.utils.events]:  eta: 0:11:01  iter: 259  total_loss: 0.858  loss_cls: 0.1775  loss_box_reg: 0.3851  loss_mask: 0.2734  loss_rpn_cls: 0.01305  loss_rpn_loc: 0.007612  time: 0.9101  data_time: 0.0193  lr: 6.4935e-05  max_mem: 6143M
[08/24 08:17:06 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:17:06 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:17:06 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:17:06 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:17:06 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:17:16 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0036 s/iter. Inference: 0.1587 s/iter. Eval: 0.7182 s/iter. Total: 0.8805 s/iter. ETA=0:01:57
[08/24 08:17:21 d2.evaluation.evaluator]: Inference done 19/144. Dataloading: 0.0026 s/iter. Inference: 0.1505 s/iter. Eval: 0.5970 s/iter. Total: 0.7503 s/iter. ETA=0:01:33
[08/24 08:17:26 d2.evaluation.evaluator]: Inference done 27/144. Dataloading: 0.0024 s/iter. Inference: 0.1485 s/iter. Eval: 0.5642 s/iter. Total: 0.7153 s/iter. ETA=0:01:23
[08/24 08:17:32 d2.evaluation.evaluator]: Inference done 35/144. Dataloading: 0.0026 s/iter. Inference: 0.1481 s/iter. Eval: 0.5555 s/iter. Total: 0.7064 s/iter. ETA=0:01:17
[08/24 08:17:37 d2.evaluation.evaluator]: Inference done 43/144. Dataloading: 0.0027 s/iter. Inference: 0.1474 s/iter. Eval: 0.5438 s/iter. Total: 0.6941 s/iter. ETA=0:01:10
[08/24 08:17:42 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0026 s/iter. Inference: 0.1488 s/iter. Eval: 0.5619 s/iter. Total: 0.7135 s/iter. ETA=0:01:07
[08/24 08:17:47 d2.evaluation.evaluator]: Inference done 55/144. Dataloading: 0.0028 s/iter. Inference: 0.1498 s/iter. Eval: 0.5781 s/iter. Total: 0.7310 s/iter. ETA=0:01:05
[08/24 08:17:53 d2.evaluation.evaluator]: Inference done 62/144. Dataloading: 0.0028 s/iter. Inference: 0.1504 s/iter. Eval: 0.5841 s/iter. Total: 0.7375 s/iter. ETA=0:01:00
[08/24 08:17:58 d2.evaluation.evaluator]: Inference done 69/144. Dataloading: 0.0029 s/iter. Inference: 0.1511 s/iter. Eval: 0.5911 s/iter. Total: 0.7454 s/iter. ETA=0:00:55
[08/24 08:18:04 d2.evaluation.evaluator]: Inference done 78/144. Dataloading: 0.0028 s/iter. Inference: 0.1496 s/iter. Eval: 0.5714 s/iter. Total: 0.7240 s/iter. ETA=0:00:47
[08/24 08:18:09 d2.evaluation.evaluator]: Inference done 87/144. Dataloading: 0.0028 s/iter. Inference: 0.1487 s/iter. Eval: 0.5571 s/iter. Total: 0.7089 s/iter. ETA=0:00:40
[08/24 08:18:14 d2.evaluation.evaluator]: Inference done 95/144. Dataloading: 0.0027 s/iter. Inference: 0.1484 s/iter. Eval: 0.5517 s/iter. Total: 0.7030 s/iter. ETA=0:00:34
[08/24 08:18:19 d2.evaluation.evaluator]: Inference done 103/144. Dataloading: 0.0027 s/iter. Inference: 0.1480 s/iter. Eval: 0.5492 s/iter. Total: 0.7002 s/iter. ETA=0:00:28
[08/24 08:18:25 d2.evaluation.evaluator]: Inference done 111/144. Dataloading: 0.0028 s/iter. Inference: 0.1479 s/iter. Eval: 0.5464 s/iter. Total: 0.6974 s/iter. ETA=0:00:23
[08/24 08:18:30 d2.evaluation.evaluator]: Inference done 120/144. Dataloading: 0.0027 s/iter. Inference: 0.1473 s/iter. Eval: 0.5389 s/iter. Total: 0.6891 s/iter. ETA=0:00:16
[08/24 08:18:36 d2.evaluation.evaluator]: Inference done 129/144. Dataloading: 0.0027 s/iter. Inference: 0.1471 s/iter. Eval: 0.5356 s/iter. Total: 0.6857 s/iter. ETA=0:00:10
[08/24 08:18:41 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0027 s/iter. Inference: 0.1469 s/iter. Eval: 0.5343 s/iter. Total: 0.6842 s/iter. ETA=0:00:04
[08/24 08:18:45 d2.evaluation.evaluator]: Total inference time: 0:01:34.508306 (0.679916 s / iter per device, on 1 devices)
[08/24 08:18:45 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:20 (0.146541 s / iter per device, on 1 devices)
[08/24 08:18:45 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:18:45 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:18:45 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/24 08:18:45 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:18:46 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.30 seconds.
[08/24 08:18:46 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:18:46 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.221
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.485
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.116
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.097
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.217
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.283
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.215
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.427
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.533
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.375
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.508
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.605
[08/24 08:18:46 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 22.067 | 48.502 | 11.628 | 9.684 | 21.685 | 28.288 |
Loading and preparing results...
DONE (t=0.20s)
creating index...
index created!
[08/24 08:18:46 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:18:47 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.16 seconds.
[08/24 08:18:47 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:18:47 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.324
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.486
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.399
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.091
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.249
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.501
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.283
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.550
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.669
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.442
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.633
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.774
[08/24 08:18:47 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 32.381 | 48.576 | 39.853 | 9.126 | 24.873 | 50.056 |
[08/24 08:18:47 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:18:47 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:18:47 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:18:47 d2.evaluation.testing]: copypaste: 22.0665,48.5016,11.6283,9.6838,21.6846,28.2879
[08/24 08:18:47 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:18:47 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:18:47 d2.evaluation.testing]: copypaste: 32.3812,48.5757,39.8530,9.1257,24.8731,50.0562
[08/24 08:18:47 d2.utils.events]:  eta: 0:10:43  iter: 279  total_loss: 0.8448  loss_cls: 0.1588  loss_box_reg: 0.3789  loss_mask: 0.2391  loss_rpn_cls: 0.01316  loss_rpn_loc: 0.007749  time: 0.9093  data_time: 0.0346  lr: 6.993e-05  max_mem: 6143M
[08/24 08:19:05 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:19:05 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:19:05 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:19:05 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:19:05 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:19:14 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0029 s/iter. Inference: 0.1538 s/iter. Eval: 0.6323 s/iter. Total: 0.7890 s/iter. ETA=0:01:44
[08/24 08:19:19 d2.evaluation.evaluator]: Inference done 20/144. Dataloading: 0.0027 s/iter. Inference: 0.1458 s/iter. Eval: 0.5161 s/iter. Total: 0.6648 s/iter. ETA=0:01:22
[08/24 08:19:25 d2.evaluation.evaluator]: Inference done 28/144. Dataloading: 0.0028 s/iter. Inference: 0.1466 s/iter. Eval: 0.5170 s/iter. Total: 0.6666 s/iter. ETA=0:01:17
[08/24 08:19:30 d2.evaluation.evaluator]: Inference done 38/144. Dataloading: 0.0031 s/iter. Inference: 0.1435 s/iter. Eval: 0.4824 s/iter. Total: 0.6293 s/iter. ETA=0:01:06
[08/24 08:19:35 d2.evaluation.evaluator]: Inference done 45/144. Dataloading: 0.0029 s/iter. Inference: 0.1446 s/iter. Eval: 0.5002 s/iter. Total: 0.6479 s/iter. ETA=0:01:04
[08/24 08:19:40 d2.evaluation.evaluator]: Inference done 51/144. Dataloading: 0.0028 s/iter. Inference: 0.1466 s/iter. Eval: 0.5236 s/iter. Total: 0.6733 s/iter. ETA=0:01:02
[08/24 08:19:46 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0030 s/iter. Inference: 0.1473 s/iter. Eval: 0.5351 s/iter. Total: 0.6856 s/iter. ETA=0:00:58
[08/24 08:19:51 d2.evaluation.evaluator]: Inference done 66/144. Dataloading: 0.0029 s/iter. Inference: 0.1475 s/iter. Eval: 0.5371 s/iter. Total: 0.6878 s/iter. ETA=0:00:53
[08/24 08:19:56 d2.evaluation.evaluator]: Inference done 73/144. Dataloading: 0.0028 s/iter. Inference: 0.1475 s/iter. Eval: 0.5423 s/iter. Total: 0.6929 s/iter. ETA=0:00:49
[08/24 08:20:01 d2.evaluation.evaluator]: Inference done 82/144. Dataloading: 0.0028 s/iter. Inference: 0.1464 s/iter. Eval: 0.5275 s/iter. Total: 0.6770 s/iter. ETA=0:00:41
[08/24 08:20:07 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0029 s/iter. Inference: 0.1452 s/iter. Eval: 0.5132 s/iter. Total: 0.6615 s/iter. ETA=0:00:34
[08/24 08:20:12 d2.evaluation.evaluator]: Inference done 102/144. Dataloading: 0.0028 s/iter. Inference: 0.1440 s/iter. Eval: 0.4984 s/iter. Total: 0.6454 s/iter. ETA=0:00:27
[08/24 08:20:17 d2.evaluation.evaluator]: Inference done 110/144. Dataloading: 0.0028 s/iter. Inference: 0.1441 s/iter. Eval: 0.5006 s/iter. Total: 0.6478 s/iter. ETA=0:00:22
[08/24 08:20:22 d2.evaluation.evaluator]: Inference done 120/144. Dataloading: 0.0028 s/iter. Inference: 0.1433 s/iter. Eval: 0.4896 s/iter. Total: 0.6359 s/iter. ETA=0:00:15
[08/24 08:20:28 d2.evaluation.evaluator]: Inference done 129/144. Dataloading: 0.0028 s/iter. Inference: 0.1430 s/iter. Eval: 0.4862 s/iter. Total: 0.6322 s/iter. ETA=0:00:09
[08/24 08:20:33 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0028 s/iter. Inference: 0.1430 s/iter. Eval: 0.4875 s/iter. Total: 0.6335 s/iter. ETA=0:00:04
[08/24 08:20:37 d2.evaluation.evaluator]: Total inference time: 0:01:27.523837 (0.629668 s / iter per device, on 1 devices)
[08/24 08:20:37 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:19 (0.142661 s / iter per device, on 1 devices)
[08/24 08:20:37 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:20:37 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:20:37 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/24 08:20:37 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:20:37 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.08 seconds.
[08/24 08:20:37 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:20:37 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.251
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.506
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.160
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.095
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.251
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.313
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.245
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.458
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.554
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.375
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.528
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.632
[08/24 08:20:37 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 25.107 | 50.630 | 15.981 | 9.535 | 25.131 | 31.259 |
Loading and preparing results...
DONE (t=0.29s)
creating index...
index created!
[08/24 08:20:38 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:20:38 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.40 seconds.
[08/24 08:20:38 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:20:38 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.340
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.508
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.410
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.095
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.268
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.515
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.290
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.556
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.674
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.442
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.639
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.777
[08/24 08:20:38 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 33.959 | 50.752 | 40.990 | 9.524 | 26.792 | 51.475 |
[08/24 08:20:38 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:20:38 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:20:38 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:20:38 d2.evaluation.testing]: copypaste: 25.1065,50.6300,15.9814,9.5353,25.1314,31.2591
[08/24 08:20:38 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:20:38 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:20:38 d2.evaluation.testing]: copypaste: 33.9592,50.7519,40.9901,9.5238,26.7922,51.4752
[08/24 08:20:38 d2.utils.events]:  eta: 0:10:26  iter: 299  total_loss: 0.8822  loss_cls: 0.167  loss_box_reg: 0.3647  loss_mask: 0.2577  loss_rpn_cls: 0.01763  loss_rpn_loc: 0.01084  time: 0.9094  data_time: 0.0349  lr: 7.4925e-05  max_mem: 6143M
[08/24 08:20:56 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:20:56 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:20:56 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:20:56 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:20:56 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:21:05 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.1592 s/iter. Eval: 0.6085 s/iter. Total: 0.7693 s/iter. ETA=0:01:42
[08/24 08:21:11 d2.evaluation.evaluator]: Inference done 21/144. Dataloading: 0.0024 s/iter. Inference: 0.1459 s/iter. Eval: 0.4990 s/iter. Total: 0.6476 s/iter. ETA=0:01:19
[08/24 08:21:16 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0025 s/iter. Inference: 0.1417 s/iter. Eval: 0.4550 s/iter. Total: 0.5995 s/iter. ETA=0:01:07
[08/24 08:21:22 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0024 s/iter. Inference: 0.1403 s/iter. Eval: 0.4429 s/iter. Total: 0.5858 s/iter. ETA=0:01:00
[08/24 08:21:27 d2.evaluation.evaluator]: Inference done 48/144. Dataloading: 0.0024 s/iter. Inference: 0.1425 s/iter. Eval: 0.4705 s/iter. Total: 0.6158 s/iter. ETA=0:00:59
[08/24 08:21:33 d2.evaluation.evaluator]: Inference done 55/144. Dataloading: 0.0024 s/iter. Inference: 0.1442 s/iter. Eval: 0.4890 s/iter. Total: 0.6359 s/iter. ETA=0:00:56
[08/24 08:21:38 d2.evaluation.evaluator]: Inference done 62/144. Dataloading: 0.0026 s/iter. Inference: 0.1455 s/iter. Eval: 0.5061 s/iter. Total: 0.6545 s/iter. ETA=0:00:53
[08/24 08:21:44 d2.evaluation.evaluator]: Inference done 70/144. Dataloading: 0.0026 s/iter. Inference: 0.1462 s/iter. Eval: 0.5170 s/iter. Total: 0.6660 s/iter. ETA=0:00:49
[08/24 08:21:50 d2.evaluation.evaluator]: Inference done 81/144. Dataloading: 0.0028 s/iter. Inference: 0.1442 s/iter. Eval: 0.4936 s/iter. Total: 0.6408 s/iter. ETA=0:00:40
[08/24 08:21:55 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0027 s/iter. Inference: 0.1425 s/iter. Eval: 0.4726 s/iter. Total: 0.6181 s/iter. ETA=0:00:32
[08/24 08:22:00 d2.evaluation.evaluator]: Inference done 103/144. Dataloading: 0.0028 s/iter. Inference: 0.1414 s/iter. Eval: 0.4616 s/iter. Total: 0.6061 s/iter. ETA=0:00:24
[08/24 08:22:06 d2.evaluation.evaluator]: Inference done 112/144. Dataloading: 0.0029 s/iter. Inference: 0.1414 s/iter. Eval: 0.4635 s/iter. Total: 0.6081 s/iter. ETA=0:00:19
[08/24 08:22:11 d2.evaluation.evaluator]: Inference done 122/144. Dataloading: 0.0029 s/iter. Inference: 0.1411 s/iter. Eval: 0.4575 s/iter. Total: 0.6018 s/iter. ETA=0:00:13
[08/24 08:22:17 d2.evaluation.evaluator]: Inference done 133/144. Dataloading: 0.0029 s/iter. Inference: 0.1404 s/iter. Eval: 0.4506 s/iter. Total: 0.5943 s/iter. ETA=0:00:06
[08/24 08:22:22 d2.evaluation.evaluator]: Inference done 143/144. Dataloading: 0.0029 s/iter. Inference: 0.1400 s/iter. Eval: 0.4446 s/iter. Total: 0.5877 s/iter. ETA=0:00:00
[08/24 08:22:23 d2.evaluation.evaluator]: Total inference time: 0:01:21.990448 (0.589859 s / iter per device, on 1 devices)
[08/24 08:22:23 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:19 (0.140088 s / iter per device, on 1 devices)
[08/24 08:22:23 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:22:23 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:22:23 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/24 08:22:23 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:22:23 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[08/24 08:22:23 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:22:23 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.271
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.540
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.201
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.101
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.274
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.338
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.252
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.475
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.553
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.523
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.644
[08/24 08:22:23 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 27.110 | 54.030 | 20.080 | 10.137 | 27.380 | 33.782 |
Loading and preparing results...
DONE (t=0.17s)
creating index...
index created!
[08/24 08:22:24 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:22:24 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.14 seconds.
[08/24 08:22:24 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:22:24 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.364
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.539
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.444
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.099
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.293
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.536
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.304
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.583
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.673
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.417
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.643
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.773
[08/24 08:22:24 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 36.384 | 53.927 | 44.404 | 9.937 | 29.296 | 53.587 |
[08/24 08:22:24 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:22:24 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:22:24 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:22:24 d2.evaluation.testing]: copypaste: 27.1103,54.0304,20.0798,10.1368,27.3804,33.7818
[08/24 08:22:24 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:22:24 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:22:24 d2.evaluation.testing]: copypaste: 36.3843,53.9269,44.4042,9.9371,29.2956,53.5872
[08/24 08:22:24 d2.utils.events]:  eta: 0:10:07  iter: 319  total_loss: 0.6772  loss_cls: 0.1214  loss_box_reg: 0.3235  loss_mask: 0.198  loss_rpn_cls: 0.009557  loss_rpn_loc: 0.00581  time: 0.9082  data_time: 0.0230  lr: 7.992e-05  max_mem: 6143M
[08/24 08:22:43 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:22:43 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:22:43 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:22:43 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:22:43 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:22:51 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0023 s/iter. Inference: 0.1464 s/iter. Eval: 0.5443 s/iter. Total: 0.6930 s/iter. ETA=0:01:32
[08/24 08:22:57 d2.evaluation.evaluator]: Inference done 21/144. Dataloading: 0.0025 s/iter. Inference: 0.1416 s/iter. Eval: 0.4599 s/iter. Total: 0.6042 s/iter. ETA=0:01:14
[08/24 08:23:02 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0028 s/iter. Inference: 0.1395 s/iter. Eval: 0.4376 s/iter. Total: 0.5801 s/iter. ETA=0:01:05
[08/24 08:23:08 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0027 s/iter. Inference: 0.1384 s/iter. Eval: 0.4240 s/iter. Total: 0.5653 s/iter. ETA=0:00:58
[08/24 08:23:13 d2.evaluation.evaluator]: Inference done 48/144. Dataloading: 0.0027 s/iter. Inference: 0.1409 s/iter. Eval: 0.4576 s/iter. Total: 0.6014 s/iter. ETA=0:00:57
[08/24 08:23:18 d2.evaluation.evaluator]: Inference done 55/144. Dataloading: 0.0027 s/iter. Inference: 0.1424 s/iter. Eval: 0.4762 s/iter. Total: 0.6216 s/iter. ETA=0:00:55
[08/24 08:23:23 d2.evaluation.evaluator]: Inference done 62/144. Dataloading: 0.0027 s/iter. Inference: 0.1437 s/iter. Eval: 0.4894 s/iter. Total: 0.6360 s/iter. ETA=0:00:52
[08/24 08:23:29 d2.evaluation.evaluator]: Inference done 69/144. Dataloading: 0.0027 s/iter. Inference: 0.1445 s/iter. Eval: 0.5020 s/iter. Total: 0.6494 s/iter. ETA=0:00:48
[08/24 08:23:34 d2.evaluation.evaluator]: Inference done 79/144. Dataloading: 0.0027 s/iter. Inference: 0.1432 s/iter. Eval: 0.4878 s/iter. Total: 0.6339 s/iter. ETA=0:00:41
[08/24 08:23:40 d2.evaluation.evaluator]: Inference done 91/144. Dataloading: 0.0027 s/iter. Inference: 0.1415 s/iter. Eval: 0.4653 s/iter. Total: 0.6096 s/iter. ETA=0:00:32
[08/24 08:23:45 d2.evaluation.evaluator]: Inference done 102/144. Dataloading: 0.0026 s/iter. Inference: 0.1402 s/iter. Eval: 0.4514 s/iter. Total: 0.5944 s/iter. ETA=0:00:24
[08/24 08:23:50 d2.evaluation.evaluator]: Inference done 111/144. Dataloading: 0.0027 s/iter. Inference: 0.1402 s/iter. Eval: 0.4516 s/iter. Total: 0.5947 s/iter. ETA=0:00:19
[08/24 08:23:56 d2.evaluation.evaluator]: Inference done 122/144. Dataloading: 0.0026 s/iter. Inference: 0.1397 s/iter. Eval: 0.4468 s/iter. Total: 0.5893 s/iter. ETA=0:00:12
[08/24 08:24:01 d2.evaluation.evaluator]: Inference done 132/144. Dataloading: 0.0027 s/iter. Inference: 0.1390 s/iter. Eval: 0.4416 s/iter. Total: 0.5835 s/iter. ETA=0:00:07
[08/24 08:24:06 d2.evaluation.evaluator]: Inference done 142/144. Dataloading: 0.0027 s/iter. Inference: 0.1386 s/iter. Eval: 0.4373 s/iter. Total: 0.5788 s/iter. ETA=0:00:01
[08/24 08:24:08 d2.evaluation.evaluator]: Total inference time: 0:01:20.838834 (0.581574 s / iter per device, on 1 devices)
[08/24 08:24:08 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:19 (0.138753 s / iter per device, on 1 devices)
[08/24 08:24:08 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:24:08 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:24:08 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/24 08:24:08 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:24:08 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[08/24 08:24:08 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:24:08 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.285
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.558
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.220
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.107
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.287
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.352
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.263
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.479
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.558
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.532
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.645
[08/24 08:24:08 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 28.462 | 55.845 | 21.979 | 10.743 | 28.670 | 35.221 |
Loading and preparing results...
DONE (t=0.16s)
creating index...
index created!
[08/24 08:24:09 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:24:09 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.14 seconds.
[08/24 08:24:09 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:24:09 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.380
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.558
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.467
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.099
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.304
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.562
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.311
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.582
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.679
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.392
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.652
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.777
[08/24 08:24:09 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 38.019 | 55.776 | 46.747 | 9.858 | 30.402 | 56.247 |
[08/24 08:24:09 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:24:09 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:24:09 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:24:09 d2.evaluation.testing]: copypaste: 28.4623,55.8451,21.9791,10.7426,28.6701,35.2215
[08/24 08:24:09 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:24:09 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:24:09 d2.evaluation.testing]: copypaste: 38.0188,55.7757,46.7469,9.8575,30.4021,56.2472
[08/24 08:24:09 d2.utils.events]:  eta: 0:09:52  iter: 339  total_loss: 0.925  loss_cls: 0.183  loss_box_reg: 0.4321  loss_mask: 0.2352  loss_rpn_cls: 0.02206  loss_rpn_loc: 0.01357  time: 0.9098  data_time: 0.0307  lr: 8.4915e-05  max_mem: 6143M
[08/24 08:24:27 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:24:27 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:24:27 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:24:27 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:24:27 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:24:36 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0034 s/iter. Inference: 0.1441 s/iter. Eval: 0.5419 s/iter. Total: 0.6895 s/iter. ETA=0:01:31
[08/24 08:24:41 d2.evaluation.evaluator]: Inference done 21/144. Dataloading: 0.0033 s/iter. Inference: 0.1395 s/iter. Eval: 0.4388 s/iter. Total: 0.5818 s/iter. ETA=0:01:11
[08/24 08:24:46 d2.evaluation.evaluator]: Inference done 32/144. Dataloading: 0.0028 s/iter. Inference: 0.1372 s/iter. Eval: 0.4074 s/iter. Total: 0.5475 s/iter. ETA=0:01:01
[08/24 08:24:52 d2.evaluation.evaluator]: Inference done 43/144. Dataloading: 0.0028 s/iter. Inference: 0.1367 s/iter. Eval: 0.4027 s/iter. Total: 0.5423 s/iter. ETA=0:00:54
[08/24 08:24:58 d2.evaluation.evaluator]: Inference done 50/144. Dataloading: 0.0026 s/iter. Inference: 0.1395 s/iter. Eval: 0.4372 s/iter. Total: 0.5795 s/iter. ETA=0:00:54
[08/24 08:25:03 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0026 s/iter. Inference: 0.1410 s/iter. Eval: 0.4574 s/iter. Total: 0.6012 s/iter. ETA=0:00:52
[08/24 08:25:08 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0028 s/iter. Inference: 0.1413 s/iter. Eval: 0.4632 s/iter. Total: 0.6075 s/iter. ETA=0:00:47
[08/24 08:25:13 d2.evaluation.evaluator]: Inference done 73/144. Dataloading: 0.0027 s/iter. Inference: 0.1415 s/iter. Eval: 0.4678 s/iter. Total: 0.6122 s/iter. ETA=0:00:43
[08/24 08:25:19 d2.evaluation.evaluator]: Inference done 85/144. Dataloading: 0.0027 s/iter. Inference: 0.1396 s/iter. Eval: 0.4445 s/iter. Total: 0.5871 s/iter. ETA=0:00:34
[08/24 08:25:24 d2.evaluation.evaluator]: Inference done 97/144. Dataloading: 0.0027 s/iter. Inference: 0.1384 s/iter. Eval: 0.4307 s/iter. Total: 0.5720 s/iter. ETA=0:00:26
[08/24 08:25:30 d2.evaluation.evaluator]: Inference done 108/144. Dataloading: 0.0026 s/iter. Inference: 0.1379 s/iter. Eval: 0.4247 s/iter. Total: 0.5654 s/iter. ETA=0:00:20
[08/24 08:25:35 d2.evaluation.evaluator]: Inference done 118/144. Dataloading: 0.0027 s/iter. Inference: 0.1374 s/iter. Eval: 0.4195 s/iter. Total: 0.5598 s/iter. ETA=0:00:14
[08/24 08:25:40 d2.evaluation.evaluator]: Inference done 129/144. Dataloading: 0.0027 s/iter. Inference: 0.1371 s/iter. Eval: 0.4147 s/iter. Total: 0.5547 s/iter. ETA=0:00:08
[08/24 08:25:45 d2.evaluation.evaluator]: Inference done 140/144. Dataloading: 0.0027 s/iter. Inference: 0.1365 s/iter. Eval: 0.4075 s/iter. Total: 0.5469 s/iter. ETA=0:00:02
[08/24 08:25:48 d2.evaluation.evaluator]: Total inference time: 0:01:16.648008 (0.551425 s / iter per device, on 1 devices)
[08/24 08:25:48 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:19 (0.136713 s / iter per device, on 1 devices)
[08/24 08:25:48 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:25:48 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:25:48 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/24 08:25:48 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:25:49 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[08/24 08:25:49 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:25:49 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.312
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.590
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.291
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.110
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.302
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.401
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.274
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.494
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.565
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.533
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.664
[08/24 08:25:49 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 31.195 | 59.011 | 29.055 | 10.957 | 30.181 | 40.103 |
Loading and preparing results...
DONE (t=0.15s)
creating index...
index created!
[08/24 08:25:49 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:25:49 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.13 seconds.
[08/24 08:25:49 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:25:49 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.402
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.589
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.490
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.324
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.592
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.318
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.599
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.680
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.392
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.656
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.776
[08/24 08:25:49 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 40.206 | 58.882 | 48.994 | 10.036 | 32.370 | 59.213 |
[08/24 08:25:49 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:25:49 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:25:49 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:25:49 d2.evaluation.testing]: copypaste: 31.1954,59.0112,29.0553,10.9565,30.1809,40.1035
[08/24 08:25:49 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:25:49 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:25:49 d2.evaluation.testing]: copypaste: 40.2057,58.8815,48.9939,10.0364,32.3698,59.2133
[08/24 08:25:49 d2.utils.events]:  eta: 0:09:34  iter: 359  total_loss: 0.6457  loss_cls: 0.1482  loss_box_reg: 0.3111  loss_mask: 0.2034  loss_rpn_cls: 0.01128  loss_rpn_loc: 0.006106  time: 0.9089  data_time: 0.0200  lr: 8.991e-05  max_mem: 6143M
[08/24 08:26:07 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:26:07 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:26:07 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:26:07 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:26:07 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:26:16 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0034 s/iter. Inference: 0.1347 s/iter. Eval: 0.3801 s/iter. Total: 0.5182 s/iter. ETA=0:01:08
[08/24 08:26:21 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0044 s/iter. Inference: 0.1321 s/iter. Eval: 0.3244 s/iter. Total: 0.4611 s/iter. ETA=0:00:55
[08/24 08:26:26 d2.evaluation.evaluator]: Inference done 36/144. Dataloading: 0.0036 s/iter. Inference: 0.1298 s/iter. Eval: 0.3047 s/iter. Total: 0.4383 s/iter. ETA=0:00:47
[08/24 08:26:32 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0034 s/iter. Inference: 0.1319 s/iter. Eval: 0.3319 s/iter. Total: 0.4673 s/iter. ETA=0:00:45
[08/24 08:26:37 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0034 s/iter. Inference: 0.1345 s/iter. Eval: 0.3668 s/iter. Total: 0.5050 s/iter. ETA=0:00:45
[08/24 08:26:42 d2.evaluation.evaluator]: Inference done 62/144. Dataloading: 0.0033 s/iter. Inference: 0.1359 s/iter. Eval: 0.3814 s/iter. Total: 0.5208 s/iter. ETA=0:00:42
[08/24 08:26:47 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0032 s/iter. Inference: 0.1362 s/iter. Eval: 0.3904 s/iter. Total: 0.5299 s/iter. ETA=0:00:38
[08/24 08:26:52 d2.evaluation.evaluator]: Inference done 85/144. Dataloading: 0.0032 s/iter. Inference: 0.1340 s/iter. Eval: 0.3636 s/iter. Total: 0.5009 s/iter. ETA=0:00:29
[08/24 08:26:58 d2.evaluation.evaluator]: Inference done 100/144. Dataloading: 0.0032 s/iter. Inference: 0.1321 s/iter. Eval: 0.3438 s/iter. Total: 0.4793 s/iter. ETA=0:00:21
[08/24 08:27:03 d2.evaluation.evaluator]: Inference done 110/144. Dataloading: 0.0031 s/iter. Inference: 0.1321 s/iter. Eval: 0.3461 s/iter. Total: 0.4815 s/iter. ETA=0:00:16
[08/24 08:27:08 d2.evaluation.evaluator]: Inference done 123/144. Dataloading: 0.0031 s/iter. Inference: 0.1314 s/iter. Eval: 0.3385 s/iter. Total: 0.4732 s/iter. ETA=0:00:09
[08/24 08:27:14 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0030 s/iter. Inference: 0.1307 s/iter. Eval: 0.3309 s/iter. Total: 0.4648 s/iter. ETA=0:00:03
[08/24 08:27:17 d2.evaluation.evaluator]: Total inference time: 0:01:04.836631 (0.466451 s / iter per device, on 1 devices)
[08/24 08:27:17 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:18 (0.130560 s / iter per device, on 1 devices)
[08/24 08:27:17 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:27:17 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:27:17 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/24 08:27:17 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:27:17 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/24 08:27:17 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:27:17 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.341
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.620
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.296
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.110
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.332
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.432
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.292
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.505
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.582
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.556
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.674
[08/24 08:27:18 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 34.128 | 61.991 | 29.627 | 10.992 | 33.164 | 43.187 |
Loading and preparing results...
DONE (t=0.12s)
creating index...
index created!
[08/24 08:27:18 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:27:18 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[08/24 08:27:18 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:27:18 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.429
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.623
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.519
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.106
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.355
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.611
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.329
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.592
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.687
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.417
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.661
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.780
[08/24 08:27:18 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 42.878 | 62.303 | 51.862 | 10.592 | 35.468 | 61.079 |
[08/24 08:27:18 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:27:18 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:27:18 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:27:18 d2.evaluation.testing]: copypaste: 34.1279,61.9906,29.6270,10.9918,33.1637,43.1866
[08/24 08:27:18 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:27:18 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:27:18 d2.evaluation.testing]: copypaste: 42.8782,62.3030,51.8619,10.5922,35.4681,61.0789
[08/24 08:27:18 d2.utils.events]:  eta: 0:09:16  iter: 379  total_loss: 0.7208  loss_cls: 0.1224  loss_box_reg: 0.3239  loss_mask: 0.2302  loss_rpn_cls: 0.01219  loss_rpn_loc: 0.007797  time: 0.9089  data_time: 0.0278  lr: 9.4905e-05  max_mem: 6143M
[08/24 08:27:36 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:27:36 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:27:36 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:27:36 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:27:36 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:27:43 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0027 s/iter. Inference: 0.1339 s/iter. Eval: 0.3534 s/iter. Total: 0.4901 s/iter. ETA=0:01:05
[08/24 08:27:49 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0028 s/iter. Inference: 0.1328 s/iter. Eval: 0.3233 s/iter. Total: 0.4591 s/iter. ETA=0:00:55
[08/24 08:27:54 d2.evaluation.evaluator]: Inference done 36/144. Dataloading: 0.0028 s/iter. Inference: 0.1297 s/iter. Eval: 0.2998 s/iter. Total: 0.4325 s/iter. ETA=0:00:46
[08/24 08:27:59 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0031 s/iter. Inference: 0.1316 s/iter. Eval: 0.3254 s/iter. Total: 0.4603 s/iter. ETA=0:00:45
[08/24 08:28:05 d2.evaluation.evaluator]: Inference done 54/144. Dataloading: 0.0031 s/iter. Inference: 0.1342 s/iter. Eval: 0.3602 s/iter. Total: 0.4978 s/iter. ETA=0:00:44
[08/24 08:28:10 d2.evaluation.evaluator]: Inference done 64/144. Dataloading: 0.0031 s/iter. Inference: 0.1345 s/iter. Eval: 0.3681 s/iter. Total: 0.5059 s/iter. ETA=0:00:40
[08/24 08:28:15 d2.evaluation.evaluator]: Inference done 75/144. Dataloading: 0.0030 s/iter. Inference: 0.1339 s/iter. Eval: 0.3617 s/iter. Total: 0.4988 s/iter. ETA=0:00:34
[08/24 08:28:21 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0029 s/iter. Inference: 0.1320 s/iter. Eval: 0.3408 s/iter. Total: 0.4759 s/iter. ETA=0:00:26
[08/24 08:28:26 d2.evaluation.evaluator]: Inference done 103/144. Dataloading: 0.0030 s/iter. Inference: 0.1311 s/iter. Eval: 0.3293 s/iter. Total: 0.4635 s/iter. ETA=0:00:19
[08/24 08:28:31 d2.evaluation.evaluator]: Inference done 114/144. Dataloading: 0.0030 s/iter. Inference: 0.1311 s/iter. Eval: 0.3314 s/iter. Total: 0.4656 s/iter. ETA=0:00:13
[08/24 08:28:36 d2.evaluation.evaluator]: Inference done 129/144. Dataloading: 0.0030 s/iter. Inference: 0.1298 s/iter. Eval: 0.3180 s/iter. Total: 0.4510 s/iter. ETA=0:00:06
[08/24 08:28:42 d2.evaluation.evaluator]: Inference done 143/144. Dataloading: 0.0028 s/iter. Inference: 0.1292 s/iter. Eval: 0.3123 s/iter. Total: 0.4445 s/iter. ETA=0:00:00
[08/24 08:28:43 d2.evaluation.evaluator]: Total inference time: 0:01:02.241254 (0.447779 s / iter per device, on 1 devices)
[08/24 08:28:43 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:17 (0.129442 s / iter per device, on 1 devices)
[08/24 08:28:43 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:28:43 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:28:43 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/24 08:28:43 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:28:43 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/24 08:28:43 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:28:43 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.360
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.640
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.349
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.117
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.350
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.453
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.295
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.523
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.584
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.342
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.552
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.683
[08/24 08:28:43 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 36.043 | 64.005 | 34.935 | 11.746 | 34.964 | 45.317 |
Loading and preparing results...
DONE (t=0.12s)
creating index...
index created!
[08/24 08:28:43 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:28:43 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[08/24 08:28:43 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:28:43 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.441
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.645
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.546
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.123
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.368
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.622
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.332
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.608
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.683
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.433
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.651
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.785
[08/24 08:28:43 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 44.078 | 64.481 | 54.646 | 12.350 | 36.797 | 62.187 |
[08/24 08:28:44 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:28:44 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:28:44 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:28:44 d2.evaluation.testing]: copypaste: 36.0432,64.0051,34.9345,11.7461,34.9638,45.3166
[08/24 08:28:44 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:28:44 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:28:44 d2.evaluation.testing]: copypaste: 44.0779,64.4806,54.6462,12.3496,36.7971,62.1873
[08/24 08:28:44 d2.utils.events]:  eta: 0:08:58  iter: 399  total_loss: 0.742  loss_cls: 0.1341  loss_box_reg: 0.3447  loss_mask: 0.2129  loss_rpn_cls: 0.01233  loss_rpn_loc: 0.009231  time: 0.9087  data_time: 0.0309  lr: 9.99e-05  max_mem: 6143M
[08/24 08:29:02 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:29:02 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:29:02 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:29:02 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:29:02 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:29:09 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.1311 s/iter. Eval: 0.3368 s/iter. Total: 0.4695 s/iter. ETA=0:01:02
[08/24 08:29:14 d2.evaluation.evaluator]: Inference done 24/144. Dataloading: 0.0031 s/iter. Inference: 0.1269 s/iter. Eval: 0.2819 s/iter. Total: 0.4121 s/iter. ETA=0:00:49
[08/24 08:29:19 d2.evaluation.evaluator]: Inference done 38/144. Dataloading: 0.0031 s/iter. Inference: 0.1254 s/iter. Eval: 0.2620 s/iter. Total: 0.3907 s/iter. ETA=0:00:41
[08/24 08:29:24 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0030 s/iter. Inference: 0.1286 s/iter. Eval: 0.3012 s/iter. Total: 0.4330 s/iter. ETA=0:00:41
[08/24 08:29:29 d2.evaluation.evaluator]: Inference done 54/144. Dataloading: 0.0030 s/iter. Inference: 0.1314 s/iter. Eval: 0.3430 s/iter. Total: 0.4776 s/iter. ETA=0:00:42
[08/24 08:29:34 d2.evaluation.evaluator]: Inference done 64/144. Dataloading: 0.0030 s/iter. Inference: 0.1320 s/iter. Eval: 0.3493 s/iter. Total: 0.4844 s/iter. ETA=0:00:38
[08/24 08:29:40 d2.evaluation.evaluator]: Inference done 75/144. Dataloading: 0.0032 s/iter. Inference: 0.1318 s/iter. Eval: 0.3460 s/iter. Total: 0.4813 s/iter. ETA=0:00:33
[08/24 08:29:45 d2.evaluation.evaluator]: Inference done 91/144. Dataloading: 0.0030 s/iter. Inference: 0.1298 s/iter. Eval: 0.3203 s/iter. Total: 0.4533 s/iter. ETA=0:00:24
[08/24 08:29:50 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0031 s/iter. Inference: 0.1291 s/iter. Eval: 0.3124 s/iter. Total: 0.4448 s/iter. ETA=0:00:17
[08/24 08:29:55 d2.evaluation.evaluator]: Inference done 117/144. Dataloading: 0.0030 s/iter. Inference: 0.1286 s/iter. Eval: 0.3084 s/iter. Total: 0.4402 s/iter. ETA=0:00:11
[08/24 08:30:00 d2.evaluation.evaluator]: Inference done 130/144. Dataloading: 0.0031 s/iter. Inference: 0.1281 s/iter. Eval: 0.3049 s/iter. Total: 0.4362 s/iter. ETA=0:00:06
[08/24 08:30:06 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0030 s/iter. Inference: 0.1278 s/iter. Eval: 0.3020 s/iter. Total: 0.4330 s/iter. ETA=0:00:00
[08/24 08:30:06 d2.evaluation.evaluator]: Total inference time: 0:01:00.239784 (0.433380 s / iter per device, on 1 devices)
[08/24 08:30:06 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:17 (0.127795 s / iter per device, on 1 devices)
[08/24 08:30:06 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:30:06 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:30:06 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/24 08:30:06 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:30:06 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/24 08:30:06 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:30:06 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.382
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.653
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.373
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.143
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.359
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.487
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.303
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.541
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.599
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.400
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.555
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.712
[08/24 08:30:06 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 38.161 | 65.274 | 37.331 | 14.274 | 35.933 | 48.672 |
Loading and preparing results...
DONE (t=0.11s)
creating index...
index created!
[08/24 08:30:07 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:30:07 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.
[08/24 08:30:07 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:30:07 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.452
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.661
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.548
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.133
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.382
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.625
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.339
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.611
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.685
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.458
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.649
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.791
[08/24 08:30:07 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.249 | 66.074 | 54.829 | 13.276 | 38.222 | 62.535 |
[08/24 08:30:07 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:30:07 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:30:07 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:30:07 d2.evaluation.testing]: copypaste: 38.1610,65.2735,37.3311,14.2735,35.9332,48.6720
[08/24 08:30:07 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:30:07 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:30:07 d2.evaluation.testing]: copypaste: 45.2486,66.0739,54.8285,13.2761,38.2216,62.5346
[08/24 08:30:07 d2.utils.events]:  eta: 0:08:40  iter: 419  total_loss: 0.6895  loss_cls: 0.1229  loss_box_reg: 0.3198  loss_mask: 0.188  loss_rpn_cls: 0.01041  loss_rpn_loc: 0.00845  time: 0.9087  data_time: 0.0342  lr: 0.0001049  max_mem: 6143M
[08/24 08:30:25 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:30:25 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:30:25 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:30:25 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:30:25 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:30:33 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0033 s/iter. Inference: 0.1328 s/iter. Eval: 0.4379 s/iter. Total: 0.5740 s/iter. ETA=0:01:16
[08/24 08:30:38 d2.evaluation.evaluator]: Inference done 25/144. Dataloading: 0.0033 s/iter. Inference: 0.1256 s/iter. Eval: 0.2932 s/iter. Total: 0.4223 s/iter. ETA=0:00:50
[08/24 08:30:43 d2.evaluation.evaluator]: Inference done 39/144. Dataloading: 0.0031 s/iter. Inference: 0.1252 s/iter. Eval: 0.2835 s/iter. Total: 0.4120 s/iter. ETA=0:00:43
[08/24 08:30:49 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0029 s/iter. Inference: 0.1281 s/iter. Eval: 0.3142 s/iter. Total: 0.4453 s/iter. ETA=0:00:42
[08/24 08:30:54 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0028 s/iter. Inference: 0.1297 s/iter. Eval: 0.3342 s/iter. Total: 0.4669 s/iter. ETA=0:00:40
[08/24 08:30:59 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0030 s/iter. Inference: 0.1303 s/iter. Eval: 0.3400 s/iter. Total: 0.4735 s/iter. ETA=0:00:35
[08/24 08:31:04 d2.evaluation.evaluator]: Inference done 82/144. Dataloading: 0.0029 s/iter. Inference: 0.1290 s/iter. Eval: 0.3206 s/iter. Total: 0.4527 s/iter. ETA=0:00:28
[08/24 08:31:09 d2.evaluation.evaluator]: Inference done 97/144. Dataloading: 0.0031 s/iter. Inference: 0.1277 s/iter. Eval: 0.3041 s/iter. Total: 0.4350 s/iter. ETA=0:00:20
[08/24 08:31:15 d2.evaluation.evaluator]: Inference done 110/144. Dataloading: 0.0032 s/iter. Inference: 0.1275 s/iter. Eval: 0.3019 s/iter. Total: 0.4327 s/iter. ETA=0:00:14
[08/24 08:31:20 d2.evaluation.evaluator]: Inference done 124/144. Dataloading: 0.0031 s/iter. Inference: 0.1269 s/iter. Eval: 0.2963 s/iter. Total: 0.4264 s/iter. ETA=0:00:08
[08/24 08:31:25 d2.evaluation.evaluator]: Inference done 139/144. Dataloading: 0.0030 s/iter. Inference: 0.1261 s/iter. Eval: 0.2867 s/iter. Total: 0.4160 s/iter. ETA=0:00:02
[08/24 08:31:27 d2.evaluation.evaluator]: Total inference time: 0:00:58.202998 (0.418727 s / iter per device, on 1 devices)
[08/24 08:31:27 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:17 (0.126262 s / iter per device, on 1 devices)
[08/24 08:31:28 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:31:28 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:31:28 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/24 08:31:28 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:31:28 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/24 08:31:28 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:31:28 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.394
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.657
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.405
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.149
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.371
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.498
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.310
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.553
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.577
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.723
[08/24 08:31:28 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 39.434 | 65.702 | 40.492 | 14.899 | 37.121 | 49.778 |
Loading and preparing results...
DONE (t=0.10s)
creating index...
index created!
[08/24 08:31:28 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:31:28 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.09 seconds.
[08/24 08:31:28 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:31:28 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.453
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.665
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.549
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.143
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.378
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.640
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.338
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.683
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.450
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.645
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.791
[08/24 08:31:28 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.269 | 66.497 | 54.907 | 14.287 | 37.751 | 63.965 |
[08/24 08:31:28 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:31:28 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:31:28 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:31:28 d2.evaluation.testing]: copypaste: 39.4341,65.7025,40.4916,14.8989,37.1207,49.7784
[08/24 08:31:28 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:31:28 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:31:28 d2.evaluation.testing]: copypaste: 45.2688,66.4974,54.9072,14.2871,37.7514,63.9653
[08/24 08:31:28 d2.utils.events]:  eta: 0:08:22  iter: 439  total_loss: 0.6894  loss_cls: 0.1405  loss_box_reg: 0.2663  loss_mask: 0.2266  loss_rpn_cls: 0.01504  loss_rpn_loc: 0.008135  time: 0.9090  data_time: 0.0345  lr: 0.00010989  max_mem: 6143M
[08/24 08:31:47 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:31:47 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:31:47 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:31:47 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:31:47 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:31:53 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0025 s/iter. Inference: 0.1209 s/iter. Eval: 0.2289 s/iter. Total: 0.3523 s/iter. ETA=0:00:46
[08/24 08:31:58 d2.evaluation.evaluator]: Inference done 28/144. Dataloading: 0.0027 s/iter. Inference: 0.1189 s/iter. Eval: 0.1937 s/iter. Total: 0.3156 s/iter. ETA=0:00:36
[08/24 08:32:03 d2.evaluation.evaluator]: Inference done 45/144. Dataloading: 0.0029 s/iter. Inference: 0.1189 s/iter. Eval: 0.1932 s/iter. Total: 0.3152 s/iter. ETA=0:00:31
[08/24 08:32:09 d2.evaluation.evaluator]: Inference done 55/144. Dataloading: 0.0028 s/iter. Inference: 0.1219 s/iter. Eval: 0.2295 s/iter. Total: 0.3544 s/iter. ETA=0:00:31
[08/24 08:32:14 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0029 s/iter. Inference: 0.1234 s/iter. Eval: 0.2484 s/iter. Total: 0.3748 s/iter. ETA=0:00:28
[08/24 08:32:19 d2.evaluation.evaluator]: Inference done 86/144. Dataloading: 0.0027 s/iter. Inference: 0.1217 s/iter. Eval: 0.2267 s/iter. Total: 0.3513 s/iter. ETA=0:00:20
[08/24 08:32:25 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0031 s/iter. Inference: 0.1213 s/iter. Eval: 0.2178 s/iter. Total: 0.3423 s/iter. ETA=0:00:13
[08/24 08:32:30 d2.evaluation.evaluator]: Inference done 120/144. Dataloading: 0.0031 s/iter. Inference: 0.1216 s/iter. Eval: 0.2148 s/iter. Total: 0.3396 s/iter. ETA=0:00:08
[08/24 08:32:35 d2.evaluation.evaluator]: Inference done 138/144. Dataloading: 0.0032 s/iter. Inference: 0.1211 s/iter. Eval: 0.2080 s/iter. Total: 0.3324 s/iter. ETA=0:00:01
[08/24 08:32:37 d2.evaluation.evaluator]: Total inference time: 0:00:46.458248 (0.334232 s / iter per device, on 1 devices)
[08/24 08:32:37 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:16 (0.121095 s / iter per device, on 1 devices)
[08/24 08:32:37 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:32:37 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:32:37 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/24 08:32:37 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:32:37 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[08/24 08:32:37 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:32:37 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.426
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.666
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.488
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.149
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.394
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.556
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.313
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.579
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.633
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.400
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.590
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.752
[08/24 08:32:37 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 42.598 | 66.595 | 48.803 | 14.945 | 39.381 | 55.613 |
Loading and preparing results...
DONE (t=0.08s)
creating index...
index created!
[08/24 08:32:38 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:32:38 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.08 seconds.
[08/24 08:32:38 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:32:38 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.466
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.678
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.552
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.140
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.388
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.657
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.334
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.622
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.685
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.458
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.646
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.794
[08/24 08:32:38 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.636 | 67.839 | 55.166 | 14.013 | 38.769 | 65.663 |
[08/24 08:32:38 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:32:38 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:32:38 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:32:38 d2.evaluation.testing]: copypaste: 42.5981,66.5951,48.8029,14.9455,39.3811,55.6126
[08/24 08:32:38 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:32:38 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:32:38 d2.evaluation.testing]: copypaste: 46.6356,67.8391,55.1663,14.0133,38.7693,65.6629
[08/24 08:32:38 d2.utils.events]:  eta: 0:08:04  iter: 459  total_loss: 0.613  loss_cls: 0.1053  loss_box_reg: 0.2481  loss_mask: 0.1968  loss_rpn_cls: 0.009589  loss_rpn_loc: 0.007071  time: 0.9102  data_time: 0.0501  lr: 0.00011489  max_mem: 6143M
[08/24 08:32:56 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:32:56 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:32:56 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:32:56 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:32:56 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:33:02 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.1215 s/iter. Eval: 0.2254 s/iter. Total: 0.3485 s/iter. ETA=0:00:46
[08/24 08:33:07 d2.evaluation.evaluator]: Inference done 28/144. Dataloading: 0.0024 s/iter. Inference: 0.1212 s/iter. Eval: 0.1962 s/iter. Total: 0.3200 s/iter. ETA=0:00:37
[08/24 08:33:12 d2.evaluation.evaluator]: Inference done 45/144. Dataloading: 0.0026 s/iter. Inference: 0.1204 s/iter. Eval: 0.1932 s/iter. Total: 0.3164 s/iter. ETA=0:00:31
[08/24 08:33:18 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0029 s/iter. Inference: 0.1243 s/iter. Eval: 0.2472 s/iter. Total: 0.3746 s/iter. ETA=0:00:34
[08/24 08:33:23 d2.evaluation.evaluator]: Inference done 66/144. Dataloading: 0.0029 s/iter. Inference: 0.1247 s/iter. Eval: 0.2519 s/iter. Total: 0.3797 s/iter. ETA=0:00:29
[08/24 08:33:28 d2.evaluation.evaluator]: Inference done 80/144. Dataloading: 0.0028 s/iter. Inference: 0.1244 s/iter. Eval: 0.2491 s/iter. Total: 0.3765 s/iter. ETA=0:00:24
[08/24 08:33:33 d2.evaluation.evaluator]: Inference done 100/144. Dataloading: 0.0029 s/iter. Inference: 0.1227 s/iter. Eval: 0.2258 s/iter. Total: 0.3516 s/iter. ETA=0:00:15
[08/24 08:33:38 d2.evaluation.evaluator]: Inference done 115/144. Dataloading: 0.0029 s/iter. Inference: 0.1224 s/iter. Eval: 0.2237 s/iter. Total: 0.3492 s/iter. ETA=0:00:10
[08/24 08:33:43 d2.evaluation.evaluator]: Inference done 133/144. Dataloading: 0.0031 s/iter. Inference: 0.1217 s/iter. Eval: 0.2158 s/iter. Total: 0.3408 s/iter. ETA=0:00:03
[08/24 08:33:47 d2.evaluation.evaluator]: Total inference time: 0:00:47.275298 (0.340110 s / iter per device, on 1 devices)
[08/24 08:33:47 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:16 (0.121525 s / iter per device, on 1 devices)
[08/24 08:33:47 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:33:47 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:33:47 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/24 08:33:47 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:33:47 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[08/24 08:33:47 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:33:47 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.443
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.680
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.521
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.162
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.414
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.573
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.328
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.587
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.640
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.417
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.598
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.755
[08/24 08:33:47 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 44.280 | 68.020 | 52.110 | 16.187 | 41.375 | 57.318 |
Loading and preparing results...
DONE (t=0.08s)
creating index...
index created!
[08/24 08:33:47 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:33:48 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.08 seconds.
[08/24 08:33:48 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:33:48 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.471
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.690
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.545
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.143
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.398
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.649
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.344
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.617
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.673
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.458
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.631
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.785
[08/24 08:33:48 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.147 | 68.969 | 54.476 | 14.251 | 39.776 | 64.862 |
[08/24 08:33:48 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:33:48 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:33:48 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:33:48 d2.evaluation.testing]: copypaste: 44.2800,68.0204,52.1096,16.1868,41.3746,57.3177
[08/24 08:33:48 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:33:48 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:33:48 d2.evaluation.testing]: copypaste: 47.1473,68.9688,54.4757,14.2507,39.7762,64.8623
[08/24 08:33:48 d2.utils.events]:  eta: 0:07:47  iter: 479  total_loss: 0.646  loss_cls: 0.1031  loss_box_reg: 0.2993  loss_mask: 0.2086  loss_rpn_cls: 0.01704  loss_rpn_loc: 0.01  time: 0.9105  data_time: 0.0299  lr: 0.00011988  max_mem: 6143M
[08/24 08:34:06 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:34:06 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:34:06 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:34:06 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:34:06 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:34:12 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0032 s/iter. Inference: 0.1239 s/iter. Eval: 0.2567 s/iter. Total: 0.3839 s/iter. ETA=0:00:51
[08/24 08:34:17 d2.evaluation.evaluator]: Inference done 28/144. Dataloading: 0.0029 s/iter. Inference: 0.1199 s/iter. Eval: 0.2001 s/iter. Total: 0.3230 s/iter. ETA=0:00:37
[08/24 08:34:23 d2.evaluation.evaluator]: Inference done 45/144. Dataloading: 0.0026 s/iter. Inference: 0.1200 s/iter. Eval: 0.1982 s/iter. Total: 0.3209 s/iter. ETA=0:00:31
[08/24 08:34:28 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0029 s/iter. Inference: 0.1247 s/iter. Eval: 0.2512 s/iter. Total: 0.3789 s/iter. ETA=0:00:34
[08/24 08:34:33 d2.evaluation.evaluator]: Inference done 66/144. Dataloading: 0.0028 s/iter. Inference: 0.1249 s/iter. Eval: 0.2556 s/iter. Total: 0.3835 s/iter. ETA=0:00:29
[08/24 08:34:38 d2.evaluation.evaluator]: Inference done 80/144. Dataloading: 0.0027 s/iter. Inference: 0.1243 s/iter. Eval: 0.2521 s/iter. Total: 0.3794 s/iter. ETA=0:00:24
[08/24 08:34:43 d2.evaluation.evaluator]: Inference done 100/144. Dataloading: 0.0027 s/iter. Inference: 0.1226 s/iter. Eval: 0.2270 s/iter. Total: 0.3525 s/iter. ETA=0:00:15
[08/24 08:34:48 d2.evaluation.evaluator]: Inference done 115/144. Dataloading: 0.0027 s/iter. Inference: 0.1224 s/iter. Eval: 0.2257 s/iter. Total: 0.3509 s/iter. ETA=0:00:10
[08/24 08:34:54 d2.evaluation.evaluator]: Inference done 133/144. Dataloading: 0.0027 s/iter. Inference: 0.1215 s/iter. Eval: 0.2165 s/iter. Total: 0.3410 s/iter. ETA=0:00:03
[08/24 08:34:58 d2.evaluation.evaluator]: Total inference time: 0:00:47.779185 (0.343735 s / iter per device, on 1 devices)
[08/24 08:34:58 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:16 (0.121482 s / iter per device, on 1 devices)
[08/24 08:34:58 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:34:58 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:34:58 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/24 08:34:58 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:34:58 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[08/24 08:34:58 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:34:58 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.457
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.682
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.535
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.158
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.414
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.598
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.334
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.589
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.649
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.375
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.618
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.752
[08/24 08:34:58 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.705 | 68.232 | 53.503 | 15.752 | 41.427 | 59.829 |
Loading and preparing results...
DONE (t=0.08s)
creating index...
index created!
[08/24 08:34:58 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:34:58 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.09 seconds.
[08/24 08:34:58 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:34:58 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.475
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.693
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.554
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.147
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.400
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.654
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.349
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.673
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.458
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.631
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.785
[08/24 08:34:58 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.468 | 69.269 | 55.424 | 14.658 | 39.994 | 65.429 |
[08/24 08:34:58 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:34:58 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:34:58 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:34:58 d2.evaluation.testing]: copypaste: 45.7050,68.2324,53.5031,15.7522,41.4266,59.8290
[08/24 08:34:58 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:34:58 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:34:58 d2.evaluation.testing]: copypaste: 47.4675,69.2691,55.4242,14.6578,39.9941,65.4286
[08/24 08:34:58 d2.utils.events]:  eta: 0:07:29  iter: 499  total_loss: 0.6906  loss_cls: 0.1272  loss_box_reg: 0.2852  loss_mask: 0.1988  loss_rpn_cls: 0.01136  loss_rpn_loc: 0.01226  time: 0.9115  data_time: 0.0425  lr: 0.00012488  max_mem: 6143M
[08/24 08:35:17 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:35:17 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:35:17 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:35:17 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:35:17 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:35:22 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0020 s/iter. Inference: 0.1198 s/iter. Eval: 0.1857 s/iter. Total: 0.3074 s/iter. ETA=0:00:40
[08/24 08:35:27 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0031 s/iter. Inference: 0.1179 s/iter. Eval: 0.1774 s/iter. Total: 0.2986 s/iter. ETA=0:00:34
[08/24 08:35:33 d2.evaluation.evaluator]: Inference done 45/144. Dataloading: 0.0038 s/iter. Inference: 0.1191 s/iter. Eval: 0.1868 s/iter. Total: 0.3099 s/iter. ETA=0:00:30
[08/24 08:35:38 d2.evaluation.evaluator]: Inference done 54/144. Dataloading: 0.0037 s/iter. Inference: 0.1228 s/iter. Eval: 0.2310 s/iter. Total: 0.3577 s/iter. ETA=0:00:32
[08/24 08:35:43 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0035 s/iter. Inference: 0.1237 s/iter. Eval: 0.2434 s/iter. Total: 0.3708 s/iter. ETA=0:00:28
[08/24 08:35:48 d2.evaluation.evaluator]: Inference done 86/144. Dataloading: 0.0036 s/iter. Inference: 0.1219 s/iter. Eval: 0.2209 s/iter. Total: 0.3464 s/iter. ETA=0:00:20
[08/24 08:35:53 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0034 s/iter. Inference: 0.1213 s/iter. Eval: 0.2091 s/iter. Total: 0.3340 s/iter. ETA=0:00:13
[08/24 08:35:58 d2.evaluation.evaluator]: Inference done 123/144. Dataloading: 0.0033 s/iter. Inference: 0.1205 s/iter. Eval: 0.2004 s/iter. Total: 0.3243 s/iter. ETA=0:00:06
[08/24 08:36:04 d2.evaluation.evaluator]: Inference done 141/144. Dataloading: 0.0032 s/iter. Inference: 0.1202 s/iter. Eval: 0.1954 s/iter. Total: 0.3189 s/iter. ETA=0:00:00
[08/24 08:36:05 d2.evaluation.evaluator]: Total inference time: 0:00:45.116889 (0.324582 s / iter per device, on 1 devices)
[08/24 08:36:05 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:16 (0.120516 s / iter per device, on 1 devices)
[08/24 08:36:05 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:36:05 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:36:05 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[08/24 08:36:05 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:36:05 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[08/24 08:36:05 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:36:05 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.460
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.693
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.528
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.150
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.421
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.604
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.342
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.597
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.647
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.342
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.607
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.773
[08/24 08:36:05 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.042 | 69.283 | 52.784 | 14.989 | 42.076 | 60.396 |
Loading and preparing results...
DONE (t=0.08s)
creating index...
index created!
[08/24 08:36:06 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:36:06 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[08/24 08:36:06 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:36:06 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.476
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.697
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.541
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.145
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.398
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.661
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.354
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.621
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.677
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.400
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.637
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.795
[08/24 08:36:06 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.577 | 69.721 | 54.052 | 14.537 | 39.780 | 66.126 |
[08/24 08:36:06 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:36:06 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:36:06 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:36:06 d2.evaluation.testing]: copypaste: 46.0424,69.2825,52.7835,14.9891,42.0760,60.3958
[08/24 08:36:06 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:36:06 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:36:06 d2.evaluation.testing]: copypaste: 47.5765,69.7212,54.0525,14.5367,39.7799,66.1265
[08/24 08:36:06 d2.utils.events]:  eta: 0:07:11  iter: 519  total_loss: 0.6926  loss_cls: 0.09976  loss_box_reg: 0.2374  loss_mask: 0.1886  loss_rpn_cls: 0.01246  loss_rpn_loc: 0.01067  time: 0.9112  data_time: 0.0213  lr: 0.00012987  max_mem: 6143M
[08/24 08:36:24 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:36:24 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:36:24 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:36:24 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:36:24 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:36:28 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0017 s/iter. Inference: 0.1157 s/iter. Eval: 0.1358 s/iter. Total: 0.2532 s/iter. ETA=0:00:33
[08/24 08:36:33 d2.evaluation.evaluator]: Inference done 30/144. Dataloading: 0.0032 s/iter. Inference: 0.1157 s/iter. Eval: 0.1431 s/iter. Total: 0.2621 s/iter. ETA=0:00:29
[08/24 08:36:39 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0033 s/iter. Inference: 0.1185 s/iter. Eval: 0.1541 s/iter. Total: 0.2761 s/iter. ETA=0:00:26
[08/24 08:36:44 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0035 s/iter. Inference: 0.1205 s/iter. Eval: 0.1859 s/iter. Total: 0.3101 s/iter. ETA=0:00:26
[08/24 08:36:49 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0034 s/iter. Inference: 0.1195 s/iter. Eval: 0.1813 s/iter. Total: 0.3045 s/iter. ETA=0:00:20
[08/24 08:36:54 d2.evaluation.evaluator]: Inference done 102/144. Dataloading: 0.0032 s/iter. Inference: 0.1174 s/iter. Eval: 0.1578 s/iter. Total: 0.2786 s/iter. ETA=0:00:11
[08/24 08:36:59 d2.evaluation.evaluator]: Inference done 122/144. Dataloading: 0.0030 s/iter. Inference: 0.1169 s/iter. Eval: 0.1550 s/iter. Total: 0.2752 s/iter. ETA=0:00:06
[08/24 08:37:04 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0029 s/iter. Inference: 0.1164 s/iter. Eval: 0.1503 s/iter. Total: 0.2698 s/iter. ETA=0:00:00
[08/24 08:37:04 d2.evaluation.evaluator]: Total inference time: 0:00:37.556484 (0.270191 s / iter per device, on 1 devices)
[08/24 08:37:04 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:16 (0.116390 s / iter per device, on 1 devices)
[08/24 08:37:05 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:37:05 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:37:05 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/24 08:37:05 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:37:05 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/24 08:37:05 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:37:05 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.468
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.696
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.535
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.164
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.421
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.586
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.633
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.367
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.594
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.748
[08/24 08:37:05 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.824 | 69.608 | 53.501 | 16.391 | 42.063 | 61.613 |
Loading and preparing results...
DONE (t=0.06s)
creating index...
index created!
[08/24 08:37:05 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:37:05 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[08/24 08:37:05 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:37:05 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.481
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.703
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.565
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.151
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.404
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.662
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.344
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.660
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.433
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.777
[08/24 08:37:05 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.128 | 70.260 | 56.505 | 15.109 | 40.445 | 66.163 |
[08/24 08:37:05 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:37:05 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:37:05 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:37:05 d2.evaluation.testing]: copypaste: 46.8236,69.6083,53.5012,16.3913,42.0626,61.6126
[08/24 08:37:05 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:37:05 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:37:05 d2.evaluation.testing]: copypaste: 48.1277,70.2596,56.5051,15.1086,40.4455,66.1632
[08/24 08:37:05 d2.utils.events]:  eta: 0:06:53  iter: 539  total_loss: 0.5386  loss_cls: 0.1016  loss_box_reg: 0.2214  loss_mask: 0.1751  loss_rpn_cls: 0.009612  loss_rpn_loc: 0.005029  time: 0.9108  data_time: 0.0283  lr: 0.00013487  max_mem: 6143M
[08/24 08:37:23 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:37:23 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:37:23 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:37:23 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:37:23 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:37:28 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0020 s/iter. Inference: 0.1157 s/iter. Eval: 0.1376 s/iter. Total: 0.2553 s/iter. ETA=0:00:33
[08/24 08:37:33 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0030 s/iter. Inference: 0.1176 s/iter. Eval: 0.1376 s/iter. Total: 0.2583 s/iter. ETA=0:00:29
[08/24 08:37:38 d2.evaluation.evaluator]: Inference done 48/144. Dataloading: 0.0029 s/iter. Inference: 0.1184 s/iter. Eval: 0.1602 s/iter. Total: 0.2817 s/iter. ETA=0:00:27
[08/24 08:37:44 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0031 s/iter. Inference: 0.1212 s/iter. Eval: 0.1981 s/iter. Total: 0.3226 s/iter. ETA=0:00:27
[08/24 08:37:49 d2.evaluation.evaluator]: Inference done 76/144. Dataloading: 0.0029 s/iter. Inference: 0.1205 s/iter. Eval: 0.1932 s/iter. Total: 0.3168 s/iter. ETA=0:00:21
[08/24 08:37:54 d2.evaluation.evaluator]: Inference done 100/144. Dataloading: 0.0029 s/iter. Inference: 0.1189 s/iter. Eval: 0.1716 s/iter. Total: 0.2935 s/iter. ETA=0:00:12
[08/24 08:37:59 d2.evaluation.evaluator]: Inference done 120/144. Dataloading: 0.0028 s/iter. Inference: 0.1182 s/iter. Eval: 0.1650 s/iter. Total: 0.2862 s/iter. ETA=0:00:06
[08/24 08:38:04 d2.evaluation.evaluator]: Inference done 142/144. Dataloading: 0.0030 s/iter. Inference: 0.1176 s/iter. Eval: 0.1568 s/iter. Total: 0.2776 s/iter. ETA=0:00:00
[08/24 08:38:05 d2.evaluation.evaluator]: Total inference time: 0:00:39.205929 (0.282057 s / iter per device, on 1 devices)
[08/24 08:38:05 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:16 (0.117911 s / iter per device, on 1 devices)
[08/24 08:38:05 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:38:05 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:38:06 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/24 08:38:06 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:38:06 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/24 08:38:06 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:38:06 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.472
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.701
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.551
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.155
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.420
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.625
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.337
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.597
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.651
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.375
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.614
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.767
[08/24 08:38:06 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.173 | 70.086 | 55.101 | 15.455 | 41.958 | 62.536 |
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
[08/24 08:38:06 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:38:06 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/24 08:38:06 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:38:06 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.484
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.705
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.550
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.136
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.412
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.666
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.351
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.620
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.675
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.433
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.637
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.785
[08/24 08:38:06 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.439 | 70.533 | 54.978 | 13.567 | 41.170 | 66.596 |
[08/24 08:38:06 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:38:06 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:38:06 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:38:06 d2.evaluation.testing]: copypaste: 47.1732,70.0862,55.1012,15.4551,41.9576,62.5359
[08/24 08:38:06 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:38:06 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:38:06 d2.evaluation.testing]: copypaste: 48.4392,70.5331,54.9781,13.5674,41.1700,66.5957
[08/24 08:38:06 d2.utils.events]:  eta: 0:06:36  iter: 559  total_loss: 0.5306  loss_cls: 0.1177  loss_box_reg: 0.1828  loss_mask: 0.1805  loss_rpn_cls: 0.0111  loss_rpn_loc: 0.008201  time: 0.9110  data_time: 0.0389  lr: 0.00013986  max_mem: 6143M
[08/24 08:38:24 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:38:24 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:38:24 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:38:24 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:38:24 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:38:29 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.1144 s/iter. Eval: 0.1194 s/iter. Total: 0.2354 s/iter. ETA=0:00:31
[08/24 08:38:34 d2.evaluation.evaluator]: Inference done 32/144. Dataloading: 0.0022 s/iter. Inference: 0.1157 s/iter. Eval: 0.1270 s/iter. Total: 0.2451 s/iter. ETA=0:00:27
[08/24 08:38:39 d2.evaluation.evaluator]: Inference done 48/144. Dataloading: 0.0023 s/iter. Inference: 0.1171 s/iter. Eval: 0.1535 s/iter. Total: 0.2730 s/iter. ETA=0:00:26
[08/24 08:38:44 d2.evaluation.evaluator]: Inference done 60/144. Dataloading: 0.0023 s/iter. Inference: 0.1194 s/iter. Eval: 0.1843 s/iter. Total: 0.3062 s/iter. ETA=0:00:25
[08/24 08:38:50 d2.evaluation.evaluator]: Inference done 76/144. Dataloading: 0.0025 s/iter. Inference: 0.1193 s/iter. Eval: 0.1880 s/iter. Total: 0.3099 s/iter. ETA=0:00:21
[08/24 08:38:55 d2.evaluation.evaluator]: Inference done 98/144. Dataloading: 0.0025 s/iter. Inference: 0.1184 s/iter. Eval: 0.1709 s/iter. Total: 0.2919 s/iter. ETA=0:00:13
[08/24 08:39:00 d2.evaluation.evaluator]: Inference done 117/144. Dataloading: 0.0025 s/iter. Inference: 0.1181 s/iter. Eval: 0.1674 s/iter. Total: 0.2882 s/iter. ETA=0:00:07
[08/24 08:39:05 d2.evaluation.evaluator]: Inference done 141/144. Dataloading: 0.0025 s/iter. Inference: 0.1169 s/iter. Eval: 0.1555 s/iter. Total: 0.2751 s/iter. ETA=0:00:00
[08/24 08:39:07 d2.evaluation.evaluator]: Total inference time: 0:00:39.241977 (0.282316 s / iter per device, on 1 devices)
[08/24 08:39:07 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:16 (0.117348 s / iter per device, on 1 devices)
[08/24 08:39:07 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:39:07 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:39:07 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/24 08:39:07 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:39:07 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.24 seconds.
[08/24 08:39:07 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:39:07 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.475
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.709
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.538
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.183
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.424
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.627
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.608
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.657
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.425
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.615
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.773
[08/24 08:39:07 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.534 | 70.902 | 53.840 | 18.279 | 42.412 | 62.657 |
Loading and preparing results...
DONE (t=0.06s)
creating index...
index created!
[08/24 08:39:07 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:39:07 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[08/24 08:39:07 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:39:07 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.485
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.711
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.555
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.131
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.413
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.668
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.353
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.620
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.673
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.442
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.633
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.785
[08/24 08:39:07 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.468 | 71.120 | 55.454 | 13.103 | 41.266 | 66.808 |
[08/24 08:39:07 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:39:07 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:39:07 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:39:07 d2.evaluation.testing]: copypaste: 47.5336,70.9024,53.8397,18.2794,42.4121,62.6571
[08/24 08:39:08 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:39:08 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:39:08 d2.evaluation.testing]: copypaste: 48.4680,71.1202,55.4541,13.1028,41.2664,66.8077
[08/24 08:39:08 d2.utils.events]:  eta: 0:06:18  iter: 579  total_loss: 0.5019  loss_cls: 0.09884  loss_box_reg: 0.1661  loss_mask: 0.1908  loss_rpn_cls: 0.009949  loss_rpn_loc: 0.005072  time: 0.9116  data_time: 0.0505  lr: 0.00014486  max_mem: 6143M
[08/24 08:39:26 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:39:26 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:39:26 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:39:26 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:39:26 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:39:31 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0018 s/iter. Inference: 0.1158 s/iter. Eval: 0.1659 s/iter. Total: 0.2835 s/iter. ETA=0:00:37
[08/24 08:39:36 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0038 s/iter. Inference: 0.1170 s/iter. Eval: 0.1618 s/iter. Total: 0.2828 s/iter. ETA=0:00:32
[08/24 08:39:41 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0037 s/iter. Inference: 0.1177 s/iter. Eval: 0.1686 s/iter. Total: 0.2902 s/iter. ETA=0:00:28
[08/24 08:39:47 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0036 s/iter. Inference: 0.1210 s/iter. Eval: 0.2079 s/iter. Total: 0.3328 s/iter. ETA=0:00:28
[08/24 08:39:52 d2.evaluation.evaluator]: Inference done 75/144. Dataloading: 0.0035 s/iter. Inference: 0.1207 s/iter. Eval: 0.2057 s/iter. Total: 0.3301 s/iter. ETA=0:00:22
[08/24 08:39:58 d2.evaluation.evaluator]: Inference done 94/144. Dataloading: 0.0038 s/iter. Inference: 0.1203 s/iter. Eval: 0.1935 s/iter. Total: 0.3178 s/iter. ETA=0:00:15
[08/24 08:40:03 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0036 s/iter. Inference: 0.1194 s/iter. Eval: 0.1851 s/iter. Total: 0.3083 s/iter. ETA=0:00:09
[08/24 08:40:08 d2.evaluation.evaluator]: Inference done 135/144. Dataloading: 0.0035 s/iter. Inference: 0.1187 s/iter. Eval: 0.1741 s/iter. Total: 0.2965 s/iter. ETA=0:00:02
[08/24 08:40:11 d2.evaluation.evaluator]: Total inference time: 0:00:41.627867 (0.299481 s / iter per device, on 1 devices)
[08/24 08:40:11 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:16 (0.118839 s / iter per device, on 1 devices)
[08/24 08:40:11 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:40:11 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:40:11 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/24 08:40:11 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:40:11 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/24 08:40:11 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:40:11 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.473
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.712
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.545
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.174
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.422
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.340
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.603
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.652
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.400
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.612
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.768
[08/24 08:40:11 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.338 | 71.186 | 54.458 | 17.361 | 42.245 | 61.933 |
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
[08/24 08:40:11 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:40:11 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[08/24 08:40:11 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:40:11 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.490
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.720
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.577
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.133
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.420
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.672
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.356
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.622
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.674
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.433
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.635
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.786
[08/24 08:40:11 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.992 | 71.994 | 57.672 | 13.291 | 41.951 | 67.232 |
[08/24 08:40:11 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:40:11 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:40:11 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:40:11 d2.evaluation.testing]: copypaste: 47.3384,71.1861,54.4582,17.3615,42.2448,61.9329
[08/24 08:40:11 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:40:11 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:40:11 d2.evaluation.testing]: copypaste: 48.9920,71.9942,57.6718,13.2907,41.9507,67.2323
[08/24 08:40:11 d2.utils.events]:  eta: 0:06:00  iter: 599  total_loss: 0.6417  loss_cls: 0.1148  loss_box_reg: 0.2229  loss_mask: 0.2399  loss_rpn_cls: 0.01455  loss_rpn_loc: 0.0133  time: 0.9121  data_time: 0.0354  lr: 0.00014985  max_mem: 6143M
[08/24 08:40:29 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:40:29 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:40:29 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:40:29 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:40:29 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:40:34 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0040 s/iter. Inference: 0.1253 s/iter. Eval: 0.1799 s/iter. Total: 0.3093 s/iter. ETA=0:00:41
[08/24 08:40:39 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0035 s/iter. Inference: 0.1179 s/iter. Eval: 0.1461 s/iter. Total: 0.2677 s/iter. ETA=0:00:30
[08/24 08:40:45 d2.evaluation.evaluator]: Inference done 48/144. Dataloading: 0.0031 s/iter. Inference: 0.1182 s/iter. Eval: 0.1599 s/iter. Total: 0.2813 s/iter. ETA=0:00:27
[08/24 08:40:50 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0030 s/iter. Inference: 0.1205 s/iter. Eval: 0.1932 s/iter. Total: 0.3170 s/iter. ETA=0:00:26
[08/24 08:40:55 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0030 s/iter. Inference: 0.1197 s/iter. Eval: 0.1863 s/iter. Total: 0.3092 s/iter. ETA=0:00:20
[08/24 08:41:00 d2.evaluation.evaluator]: Inference done 100/144. Dataloading: 0.0030 s/iter. Inference: 0.1185 s/iter. Eval: 0.1674 s/iter. Total: 0.2890 s/iter. ETA=0:00:12
[08/24 08:41:05 d2.evaluation.evaluator]: Inference done 121/144. Dataloading: 0.0030 s/iter. Inference: 0.1176 s/iter. Eval: 0.1597 s/iter. Total: 0.2805 s/iter. ETA=0:00:06
[08/24 08:41:10 d2.evaluation.evaluator]: Inference done 143/144. Dataloading: 0.0029 s/iter. Inference: 0.1168 s/iter. Eval: 0.1526 s/iter. Total: 0.2725 s/iter. ETA=0:00:00
[08/24 08:41:11 d2.evaluation.evaluator]: Total inference time: 0:00:38.516332 (0.277096 s / iter per device, on 1 devices)
[08/24 08:41:11 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:16 (0.117115 s / iter per device, on 1 devices)
[08/24 08:41:11 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:41:11 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:41:11 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/24 08:41:11 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:41:11 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/24 08:41:11 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:41:11 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.485
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.713
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.549
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.192
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.432
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.638
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.620
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.662
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.425
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.620
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.779
[08/24 08:41:11 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.540 | 71.334 | 54.851 | 19.205 | 43.194 | 63.751 |
Loading and preparing results...
DONE (t=0.06s)
creating index...
index created!
[08/24 08:41:11 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:41:11 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[08/24 08:41:11 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:41:11 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.492
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.719
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.578
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.138
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.415
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.683
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.351
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.629
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.672
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.475
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.624
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.791
[08/24 08:41:11 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.198 | 71.895 | 57.835 | 13.819 | 41.511 | 68.266 |
[08/24 08:41:11 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:41:11 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:41:11 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:41:11 d2.evaluation.testing]: copypaste: 48.5404,71.3340,54.8506,19.2050,43.1936,63.7507
[08/24 08:41:11 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:41:11 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:41:11 d2.evaluation.testing]: copypaste: 49.1982,71.8948,57.8345,13.8193,41.5114,68.2660
[08/24 08:41:11 d2.utils.events]:  eta: 0:05:42  iter: 619  total_loss: 0.4702  loss_cls: 0.07897  loss_box_reg: 0.1503  loss_mask: 0.19  loss_rpn_cls: 0.01139  loss_rpn_loc: 0.004608  time: 0.9118  data_time: 0.0283  lr: 0.00015485  max_mem: 6143M
[08/24 08:41:30 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:41:30 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:41:30 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:41:30 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:41:30 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:41:34 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0021 s/iter. Inference: 0.1122 s/iter. Eval: 0.0934 s/iter. Total: 0.2077 s/iter. ETA=0:00:27
[08/24 08:41:39 d2.evaluation.evaluator]: Inference done 35/144. Dataloading: 0.0030 s/iter. Inference: 0.1127 s/iter. Eval: 0.0964 s/iter. Total: 0.2122 s/iter. ETA=0:00:23
[08/24 08:41:44 d2.evaluation.evaluator]: Inference done 50/144. Dataloading: 0.0029 s/iter. Inference: 0.1173 s/iter. Eval: 0.1385 s/iter. Total: 0.2587 s/iter. ETA=0:00:24
[08/24 08:41:49 d2.evaluation.evaluator]: Inference done 66/144. Dataloading: 0.0029 s/iter. Inference: 0.1186 s/iter. Eval: 0.1543 s/iter. Total: 0.2759 s/iter. ETA=0:00:21
[08/24 08:41:55 d2.evaluation.evaluator]: Inference done 87/144. Dataloading: 0.0031 s/iter. Inference: 0.1182 s/iter. Eval: 0.1465 s/iter. Total: 0.2680 s/iter. ETA=0:00:15
[08/24 08:42:00 d2.evaluation.evaluator]: Inference done 111/144. Dataloading: 0.0030 s/iter. Inference: 0.1169 s/iter. Eval: 0.1346 s/iter. Total: 0.2547 s/iter. ETA=0:00:08
[08/24 08:42:05 d2.evaluation.evaluator]: Inference done 138/144. Dataloading: 0.0030 s/iter. Inference: 0.1158 s/iter. Eval: 0.1229 s/iter. Total: 0.2418 s/iter. ETA=0:00:01
[08/24 08:42:07 d2.evaluation.evaluator]: Total inference time: 0:00:34.277203 (0.246599 s / iter per device, on 1 devices)
[08/24 08:42:07 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:16 (0.116172 s / iter per device, on 1 devices)
[08/24 08:42:07 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:42:07 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:42:07 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/24 08:42:07 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:42:07 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/24 08:42:07 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:42:07 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.488
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.710
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.543
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.210
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.433
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.647
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.356
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.614
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.668
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.442
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.615
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.802
[08/24 08:42:07 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.842 | 71.034 | 54.340 | 20.994 | 43.269 | 64.749 |
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
[08/24 08:42:07 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:42:07 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/24 08:42:07 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:42:07 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.490
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.718
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.558
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.419
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.667
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.356
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.666
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.483
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.614
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.789
[08/24 08:42:07 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.040 | 71.761 | 55.808 | 16.716 | 41.856 | 66.655 |
[08/24 08:42:07 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:42:07 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:42:07 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:42:07 d2.evaluation.testing]: copypaste: 48.8416,71.0343,54.3397,20.9945,43.2693,64.7488
[08/24 08:42:07 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:42:07 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:42:07 d2.evaluation.testing]: copypaste: 49.0396,71.7611,55.8082,16.7161,41.8564,66.6546
[08/24 08:42:07 d2.utils.events]:  eta: 0:05:24  iter: 639  total_loss: 0.4375  loss_cls: 0.07146  loss_box_reg: 0.1846  loss_mask: 0.178  loss_rpn_cls: 0.01016  loss_rpn_loc: 0.004438  time: 0.9119  data_time: 0.0300  lr: 0.00015984  max_mem: 6143M
[08/24 08:42:26 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:42:26 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:42:26 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:42:26 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:42:26 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:42:30 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0028 s/iter. Inference: 0.1125 s/iter. Eval: 0.0986 s/iter. Total: 0.2140 s/iter. ETA=0:00:28
[08/24 08:42:35 d2.evaluation.evaluator]: Inference done 33/144. Dataloading: 0.0040 s/iter. Inference: 0.1138 s/iter. Eval: 0.1093 s/iter. Total: 0.2273 s/iter. ETA=0:00:25
[08/24 08:42:40 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0041 s/iter. Inference: 0.1164 s/iter. Eval: 0.1484 s/iter. Total: 0.2691 s/iter. ETA=0:00:25
[08/24 08:42:46 d2.evaluation.evaluator]: Inference done 64/144. Dataloading: 0.0038 s/iter. Inference: 0.1178 s/iter. Eval: 0.1652 s/iter. Total: 0.2870 s/iter. ETA=0:00:22
[08/24 08:42:51 d2.evaluation.evaluator]: Inference done 84/144. Dataloading: 0.0037 s/iter. Inference: 0.1174 s/iter. Eval: 0.1579 s/iter. Total: 0.2792 s/iter. ETA=0:00:16
[08/24 08:42:56 d2.evaluation.evaluator]: Inference done 106/144. Dataloading: 0.0038 s/iter. Inference: 0.1172 s/iter. Eval: 0.1468 s/iter. Total: 0.2679 s/iter. ETA=0:00:10
[08/24 08:43:01 d2.evaluation.evaluator]: Inference done 129/144. Dataloading: 0.0037 s/iter. Inference: 0.1164 s/iter. Eval: 0.1392 s/iter. Total: 0.2595 s/iter. ETA=0:00:03
[08/24 08:43:05 d2.evaluation.evaluator]: Total inference time: 0:00:36.023657 (0.259163 s / iter per device, on 1 devices)
[08/24 08:43:05 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:16 (0.116290 s / iter per device, on 1 devices)
[08/24 08:43:05 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:43:05 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:43:05 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/24 08:43:05 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:43:05 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[08/24 08:43:05 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:43:05 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.489
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.711
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.554
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.186
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.445
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.638
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.353
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.617
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.666
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.433
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.617
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.794
[08/24 08:43:05 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.902 | 71.144 | 55.361 | 18.644 | 44.451 | 63.840 |
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
[08/24 08:43:05 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:43:05 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/24 08:43:05 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:43:05 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.494
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.721
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.564
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.173
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.423
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.670
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.353
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.625
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.667
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.492
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.617
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.788
[08/24 08:43:05 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.374 | 72.083 | 56.367 | 17.264 | 42.292 | 67.023 |
[08/24 08:43:05 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:43:05 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:43:05 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:43:05 d2.evaluation.testing]: copypaste: 48.9025,71.1443,55.3609,18.6435,44.4510,63.8399
[08/24 08:43:05 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:43:05 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:43:05 d2.evaluation.testing]: copypaste: 49.3744,72.0831,56.3665,17.2643,42.2918,67.0227
[08/24 08:43:05 d2.utils.events]:  eta: 0:05:06  iter: 659  total_loss: 0.4973  loss_cls: 0.0825  loss_box_reg: 0.1688  loss_mask: 0.1833  loss_rpn_cls: 0.006485  loss_rpn_loc: 0.007096  time: 0.9122  data_time: 0.0318  lr: 0.00016484  max_mem: 6143M
[08/24 08:43:23 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:43:23 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:43:23 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:43:23 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:43:23 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:43:27 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.1130 s/iter. Eval: 0.0963 s/iter. Total: 0.2109 s/iter. ETA=0:00:28
[08/24 08:43:32 d2.evaluation.evaluator]: Inference done 33/144. Dataloading: 0.0027 s/iter. Inference: 0.1148 s/iter. Eval: 0.1077 s/iter. Total: 0.2259 s/iter. ETA=0:00:25
[08/24 08:43:37 d2.evaluation.evaluator]: Inference done 50/144. Dataloading: 0.0033 s/iter. Inference: 0.1178 s/iter. Eval: 0.1379 s/iter. Total: 0.2595 s/iter. ETA=0:00:24
[08/24 08:43:43 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0030 s/iter. Inference: 0.1182 s/iter. Eval: 0.1511 s/iter. Total: 0.2727 s/iter. ETA=0:00:21
[08/24 08:43:48 d2.evaluation.evaluator]: Inference done 93/144. Dataloading: 0.0030 s/iter. Inference: 0.1164 s/iter. Eval: 0.1303 s/iter. Total: 0.2501 s/iter. ETA=0:00:12
[08/24 08:43:53 d2.evaluation.evaluator]: Inference done 116/144. Dataloading: 0.0030 s/iter. Inference: 0.1153 s/iter. Eval: 0.1252 s/iter. Total: 0.2438 s/iter. ETA=0:00:06
[08/24 08:43:58 d2.evaluation.evaluator]: Inference done 143/144. Dataloading: 0.0031 s/iter. Inference: 0.1145 s/iter. Eval: 0.1160 s/iter. Total: 0.2339 s/iter. ETA=0:00:00
[08/24 08:43:59 d2.evaluation.evaluator]: Total inference time: 0:00:33.002434 (0.237428 s / iter per device, on 1 devices)
[08/24 08:43:59 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:15 (0.114720 s / iter per device, on 1 devices)
[08/24 08:43:59 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:43:59 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:43:59 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/24 08:43:59 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:43:59 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/24 08:43:59 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:43:59 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.498
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.721
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.547
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.194
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.451
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.647
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.367
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.625
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.673
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.433
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.803
[08/24 08:43:59 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.800 | 72.133 | 54.677 | 19.374 | 45.135 | 64.655 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[08/24 08:43:59 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:43:59 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/24 08:43:59 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:43:59 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.500
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.729
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.569
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.166
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.429
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.681
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.367
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.627
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.671
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.483
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.788
[08/24 08:43:59 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.033 | 72.893 | 56.935 | 16.620 | 42.946 | 68.137 |
[08/24 08:43:59 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:43:59 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:43:59 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:43:59 d2.evaluation.testing]: copypaste: 49.8004,72.1335,54.6774,19.3737,45.1349,64.6550
[08/24 08:43:59 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:43:59 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:43:59 d2.evaluation.testing]: copypaste: 50.0330,72.8932,56.9346,16.6198,42.9458,68.1365
[08/24 08:43:59 d2.utils.events]:  eta: 0:04:48  iter: 679  total_loss: 0.4806  loss_cls: 0.1011  loss_box_reg: 0.1938  loss_mask: 0.1952  loss_rpn_cls: 0.007695  loss_rpn_loc: 0.01024  time: 0.9124  data_time: 0.0296  lr: 0.00016983  max_mem: 6143M
[08/24 08:44:18 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:44:18 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:44:18 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:44:18 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:44:18 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:44:21 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.1113 s/iter. Eval: 0.0862 s/iter. Total: 0.1991 s/iter. ETA=0:00:26
[08/24 08:44:26 d2.evaluation.evaluator]: Inference done 34/144. Dataloading: 0.0025 s/iter. Inference: 0.1122 s/iter. Eval: 0.1007 s/iter. Total: 0.2155 s/iter. ETA=0:00:23
[08/24 08:44:32 d2.evaluation.evaluator]: Inference done 50/144. Dataloading: 0.0028 s/iter. Inference: 0.1163 s/iter. Eval: 0.1402 s/iter. Total: 0.2594 s/iter. ETA=0:00:24
[08/24 08:44:37 d2.evaluation.evaluator]: Inference done 66/144. Dataloading: 0.0030 s/iter. Inference: 0.1174 s/iter. Eval: 0.1561 s/iter. Total: 0.2767 s/iter. ETA=0:00:21
[08/24 08:44:42 d2.evaluation.evaluator]: Inference done 86/144. Dataloading: 0.0031 s/iter. Inference: 0.1175 s/iter. Eval: 0.1504 s/iter. Total: 0.2711 s/iter. ETA=0:00:15
[08/24 08:44:47 d2.evaluation.evaluator]: Inference done 110/144. Dataloading: 0.0031 s/iter. Inference: 0.1162 s/iter. Eval: 0.1383 s/iter. Total: 0.2577 s/iter. ETA=0:00:08
[08/24 08:44:52 d2.evaluation.evaluator]: Inference done 135/144. Dataloading: 0.0029 s/iter. Inference: 0.1151 s/iter. Eval: 0.1287 s/iter. Total: 0.2469 s/iter. ETA=0:00:02
[08/24 08:44:55 d2.evaluation.evaluator]: Total inference time: 0:00:34.676198 (0.249469 s / iter per device, on 1 devices)
[08/24 08:44:55 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:16 (0.115153 s / iter per device, on 1 devices)
[08/24 08:44:55 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:44:55 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:44:55 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/24 08:44:55 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:44:55 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[08/24 08:44:55 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:44:55 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.483
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.726
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.539
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.214
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.436
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.625
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.346
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.615
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.661
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.458
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.617
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.774
[08/24 08:44:55 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.303 | 72.645 | 53.932 | 21.418 | 43.566 | 62.503 |
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
[08/24 08:44:55 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:44:55 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/24 08:44:55 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:44:55 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.498
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.729
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.586
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.157
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.424
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.677
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.353
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.625
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.673
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.508
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.626
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.785
[08/24 08:44:55 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.802 | 72.862 | 58.608 | 15.714 | 42.417 | 67.748 |
[08/24 08:44:55 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:44:55 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:44:55 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:44:55 d2.evaluation.testing]: copypaste: 48.3026,72.6448,53.9325,21.4182,43.5664,62.5030
[08/24 08:44:55 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:44:55 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:44:55 d2.evaluation.testing]: copypaste: 49.8017,72.8621,58.6079,15.7141,42.4167,67.7484
[08/24 08:44:55 d2.utils.events]:  eta: 0:04:30  iter: 699  total_loss: 0.5112  loss_cls: 0.1003  loss_box_reg: 0.1704  loss_mask: 0.1604  loss_rpn_cls: 0.01166  loss_rpn_loc: 0.007412  time: 0.9128  data_time: 0.0391  lr: 0.00017483  max_mem: 6143M
[08/24 08:45:14 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:45:14 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:45:14 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:45:14 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:45:14 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:45:18 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0015 s/iter. Inference: 0.1132 s/iter. Eval: 0.1044 s/iter. Total: 0.2191 s/iter. ETA=0:00:29
[08/24 08:45:23 d2.evaluation.evaluator]: Inference done 32/144. Dataloading: 0.0026 s/iter. Inference: 0.1157 s/iter. Eval: 0.1216 s/iter. Total: 0.2401 s/iter. ETA=0:00:26
[08/24 08:45:29 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0033 s/iter. Inference: 0.1179 s/iter. Eval: 0.1540 s/iter. Total: 0.2754 s/iter. ETA=0:00:26
[08/24 08:45:34 d2.evaluation.evaluator]: Inference done 63/144. Dataloading: 0.0032 s/iter. Inference: 0.1192 s/iter. Eval: 0.1743 s/iter. Total: 0.2968 s/iter. ETA=0:00:24
[08/24 08:45:39 d2.evaluation.evaluator]: Inference done 81/144. Dataloading: 0.0031 s/iter. Inference: 0.1190 s/iter. Eval: 0.1710 s/iter. Total: 0.2933 s/iter. ETA=0:00:18
[08/24 08:45:44 d2.evaluation.evaluator]: Inference done 105/144. Dataloading: 0.0031 s/iter. Inference: 0.1173 s/iter. Eval: 0.1527 s/iter. Total: 0.2732 s/iter. ETA=0:00:10
[08/24 08:45:49 d2.evaluation.evaluator]: Inference done 125/144. Dataloading: 0.0032 s/iter. Inference: 0.1181 s/iter. Eval: 0.1492 s/iter. Total: 0.2707 s/iter. ETA=0:00:05
[08/24 08:45:54 d2.evaluation.evaluator]: Total inference time: 0:00:37.209561 (0.267695 s / iter per device, on 1 devices)
[08/24 08:45:54 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:16 (0.117579 s / iter per device, on 1 devices)
[08/24 08:45:54 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:45:54 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:45:54 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/24 08:45:54 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:45:54 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/24 08:45:54 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:45:54 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.481
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.730
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.554
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.194
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.442
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.346
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.656
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.433
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.767
[08/24 08:45:54 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.074 | 73.005 | 55.406 | 19.420 | 44.153 | 61.300 |
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
[08/24 08:45:54 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:45:54 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/24 08:45:54 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:45:54 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.497
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.735
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.576
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.178
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.426
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.674
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.353
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.625
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.672
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.500
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.626
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.783
[08/24 08:45:54 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.725 | 73.474 | 57.629 | 17.793 | 42.565 | 67.397 |
[08/24 08:45:54 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:45:54 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:45:54 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:45:54 d2.evaluation.testing]: copypaste: 48.0745,73.0046,55.4057,19.4198,44.1533,61.3004
[08/24 08:45:54 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:45:54 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:45:54 d2.evaluation.testing]: copypaste: 49.7255,73.4742,57.6290,17.7933,42.5648,67.3971
[08/24 08:45:54 d2.utils.events]:  eta: 0:04:12  iter: 719  total_loss: 0.598  loss_cls: 0.1062  loss_box_reg: 0.1969  loss_mask: 0.2118  loss_rpn_cls: 0.0105  loss_rpn_loc: 0.0141  time: 0.9132  data_time: 0.0426  lr: 0.00017982  max_mem: 6143M
[08/24 08:46:12 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:46:12 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:46:12 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:46:12 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:46:12 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:46:16 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.1117 s/iter. Eval: 0.0900 s/iter. Total: 0.2034 s/iter. ETA=0:00:27
[08/24 08:46:21 d2.evaluation.evaluator]: Inference done 33/144. Dataloading: 0.0027 s/iter. Inference: 0.1133 s/iter. Eval: 0.1077 s/iter. Total: 0.2239 s/iter. ETA=0:00:24
[08/24 08:46:26 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0043 s/iter. Inference: 0.1178 s/iter. Eval: 0.1447 s/iter. Total: 0.2670 s/iter. ETA=0:00:25
[08/24 08:46:32 d2.evaluation.evaluator]: Inference done 65/144. Dataloading: 0.0040 s/iter. Inference: 0.1187 s/iter. Eval: 0.1588 s/iter. Total: 0.2817 s/iter. ETA=0:00:22
[08/24 08:46:37 d2.evaluation.evaluator]: Inference done 87/144. Dataloading: 0.0038 s/iter. Inference: 0.1172 s/iter. Eval: 0.1477 s/iter. Total: 0.2688 s/iter. ETA=0:00:15
[08/24 08:46:42 d2.evaluation.evaluator]: Inference done 111/144. Dataloading: 0.0036 s/iter. Inference: 0.1160 s/iter. Eval: 0.1359 s/iter. Total: 0.2555 s/iter. ETA=0:00:08
[08/24 08:46:47 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0034 s/iter. Inference: 0.1148 s/iter. Eval: 0.1254 s/iter. Total: 0.2438 s/iter. ETA=0:00:01
[08/24 08:46:49 d2.evaluation.evaluator]: Total inference time: 0:00:34.427293 (0.247678 s / iter per device, on 1 devices)
[08/24 08:46:49 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:15 (0.115004 s / iter per device, on 1 devices)
[08/24 08:46:49 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:46:49 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:46:49 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/24 08:46:49 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:46:49 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/24 08:46:49 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:46:49 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.497
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.737
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.557
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.206
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.455
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.640
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.349
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.618
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.671
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.450
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.627
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.788
[08/24 08:46:49 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.749 | 73.722 | 55.710 | 20.634 | 45.480 | 63.960 |
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
[08/24 08:46:49 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:46:49 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[08/24 08:46:49 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:46:49 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.504
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.736
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.573
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.161
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.431
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.687
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.352
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.622
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.673
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.492
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.622
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.795
[08/24 08:46:49 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.434 | 73.565 | 57.321 | 16.111 | 43.071 | 68.661 |
[08/24 08:46:49 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:46:49 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:46:49 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:46:49 d2.evaluation.testing]: copypaste: 49.7491,73.7217,55.7102,20.6344,45.4801,63.9597
[08/24 08:46:49 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:46:49 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:46:49 d2.evaluation.testing]: copypaste: 50.4344,73.5651,57.3209,16.1108,43.0713,68.6611
[08/24 08:46:49 d2.utils.events]:  eta: 0:03:54  iter: 739  total_loss: 0.5013  loss_cls: 0.1089  loss_box_reg: 0.1493  loss_mask: 0.1854  loss_rpn_cls: 0.01129  loss_rpn_loc: 0.006537  time: 0.9129  data_time: 0.0330  lr: 0.00018482  max_mem: 6143M
[08/24 08:47:08 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:47:08 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:47:08 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:47:08 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:47:08 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:47:12 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0020 s/iter. Inference: 0.1154 s/iter. Eval: 0.1086 s/iter. Total: 0.2259 s/iter. ETA=0:00:30
[08/24 08:47:17 d2.evaluation.evaluator]: Inference done 32/144. Dataloading: 0.0030 s/iter. Inference: 0.1152 s/iter. Eval: 0.1187 s/iter. Total: 0.2371 s/iter. ETA=0:00:26
[08/24 08:47:22 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0029 s/iter. Inference: 0.1168 s/iter. Eval: 0.1473 s/iter. Total: 0.2671 s/iter. ETA=0:00:25
[08/24 08:47:28 d2.evaluation.evaluator]: Inference done 64/144. Dataloading: 0.0033 s/iter. Inference: 0.1180 s/iter. Eval: 0.1659 s/iter. Total: 0.2873 s/iter. ETA=0:00:22
[08/24 08:47:33 d2.evaluation.evaluator]: Inference done 81/144. Dataloading: 0.0033 s/iter. Inference: 0.1176 s/iter. Eval: 0.1686 s/iter. Total: 0.2896 s/iter. ETA=0:00:18
[08/24 08:47:38 d2.evaluation.evaluator]: Inference done 106/144. Dataloading: 0.0033 s/iter. Inference: 0.1162 s/iter. Eval: 0.1490 s/iter. Total: 0.2686 s/iter. ETA=0:00:10
[08/24 08:47:43 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0031 s/iter. Inference: 0.1152 s/iter. Eval: 0.1378 s/iter. Total: 0.2563 s/iter. ETA=0:00:03
[08/24 08:47:47 d2.evaluation.evaluator]: Total inference time: 0:00:35.895165 (0.258239 s / iter per device, on 1 devices)
[08/24 08:47:47 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:16 (0.115226 s / iter per device, on 1 devices)
[08/24 08:47:47 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:47:47 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:47:47 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/24 08:47:47 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:47:47 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/24 08:47:47 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:47:47 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.498
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.735
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.550
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.232
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.458
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.638
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.353
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.621
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.672
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.458
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.627
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.789
[08/24 08:47:47 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.837 | 73.473 | 55.007 | 23.181 | 45.844 | 63.794 |
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
[08/24 08:47:47 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:47:47 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/24 08:47:47 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:47:47 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.501
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.735
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.570
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.176
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.432
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.674
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.353
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.673
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.483
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.626
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.789
[08/24 08:47:47 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.142 | 73.516 | 56.958 | 17.605 | 43.209 | 67.373 |
[08/24 08:47:47 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:47:47 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:47:47 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:47:47 d2.evaluation.testing]: copypaste: 49.8370,73.4728,55.0070,23.1808,45.8445,63.7940
[08/24 08:47:47 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:47:47 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:47:47 d2.evaluation.testing]: copypaste: 50.1416,73.5163,56.9578,17.6045,43.2089,67.3732
[08/24 08:47:47 d2.utils.events]:  eta: 0:03:36  iter: 759  total_loss: 0.5106  loss_cls: 0.09578  loss_box_reg: 0.1599  loss_mask: 0.1866  loss_rpn_cls: 0.008341  loss_rpn_loc: 0.008857  time: 0.9132  data_time: 0.0450  lr: 0.00018981  max_mem: 6143M
[08/24 08:48:05 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:48:05 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:48:05 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:48:05 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:48:05 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:48:09 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0050 s/iter. Inference: 0.1165 s/iter. Eval: 0.1015 s/iter. Total: 0.2229 s/iter. ETA=0:00:29
[08/24 08:48:14 d2.evaluation.evaluator]: Inference done 37/144. Dataloading: 0.0041 s/iter. Inference: 0.1125 s/iter. Eval: 0.0843 s/iter. Total: 0.2011 s/iter. ETA=0:00:21
[08/24 08:48:19 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0042 s/iter. Inference: 0.1154 s/iter. Eval: 0.1247 s/iter. Total: 0.2444 s/iter. ETA=0:00:22
[08/24 08:48:24 d2.evaluation.evaluator]: Inference done 70/144. Dataloading: 0.0037 s/iter. Inference: 0.1163 s/iter. Eval: 0.1385 s/iter. Total: 0.2586 s/iter. ETA=0:00:19
[08/24 08:48:29 d2.evaluation.evaluator]: Inference done 100/144. Dataloading: 0.0040 s/iter. Inference: 0.1141 s/iter. Eval: 0.1124 s/iter. Total: 0.2306 s/iter. ETA=0:00:10
[08/24 08:48:34 d2.evaluation.evaluator]: Inference done 126/144. Dataloading: 0.0038 s/iter. Inference: 0.1137 s/iter. Eval: 0.1056 s/iter. Total: 0.2232 s/iter. ETA=0:00:04
[08/24 08:48:39 d2.evaluation.evaluator]: Total inference time: 0:00:31.433732 (0.226142 s / iter per device, on 1 devices)
[08/24 08:48:39 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:15 (0.114427 s / iter per device, on 1 devices)
[08/24 08:48:39 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:48:39 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:48:39 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/24 08:48:39 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:48:39 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[08/24 08:48:39 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:48:39 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.499
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.743
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.562
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.219
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.450
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.647
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.359
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.618
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.659
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.450
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.611
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.779
[08/24 08:48:39 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.859 | 74.269 | 56.159 | 21.881 | 45.008 | 64.700 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[08/24 08:48:39 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:48:39 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[08/24 08:48:39 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:48:39 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.504
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.741
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.584
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.197
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.430
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.679
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.363
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.666
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.517
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.617
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.777
[08/24 08:48:39 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.443 | 74.065 | 58.380 | 19.700 | 42.981 | 67.910 |
[08/24 08:48:39 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:48:39 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:48:39 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:48:39 d2.evaluation.testing]: copypaste: 49.8587,74.2694,56.1587,21.8811,45.0085,64.6997
[08/24 08:48:39 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:48:39 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:48:39 d2.evaluation.testing]: copypaste: 50.4432,74.0647,58.3805,19.6996,42.9811,67.9103
[08/24 08:48:39 d2.utils.events]:  eta: 0:03:18  iter: 779  total_loss: 0.4797  loss_cls: 0.07893  loss_box_reg: 0.1564  loss_mask: 0.1799  loss_rpn_cls: 0.009844  loss_rpn_loc: 0.007839  time: 0.9131  data_time: 0.0343  lr: 0.00019481  max_mem: 6143M
[08/24 08:48:57 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:48:57 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:48:57 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:48:57 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:48:57 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:49:01 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.1114 s/iter. Eval: 0.0850 s/iter. Total: 0.1980 s/iter. ETA=0:00:26
[08/24 08:49:06 d2.evaluation.evaluator]: Inference done 34/144. Dataloading: 0.0035 s/iter. Inference: 0.1126 s/iter. Eval: 0.1030 s/iter. Total: 0.2193 s/iter. ETA=0:00:24
[08/24 08:49:11 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0035 s/iter. Inference: 0.1168 s/iter. Eval: 0.1386 s/iter. Total: 0.2591 s/iter. ETA=0:00:24
[08/24 08:49:16 d2.evaluation.evaluator]: Inference done 66/144. Dataloading: 0.0036 s/iter. Inference: 0.1174 s/iter. Eval: 0.1496 s/iter. Total: 0.2707 s/iter. ETA=0:00:21
[08/24 08:49:21 d2.evaluation.evaluator]: Inference done 91/144. Dataloading: 0.0033 s/iter. Inference: 0.1156 s/iter. Eval: 0.1330 s/iter. Total: 0.2521 s/iter. ETA=0:00:13
[08/24 08:49:27 d2.evaluation.evaluator]: Inference done 117/144. Dataloading: 0.0034 s/iter. Inference: 0.1147 s/iter. Eval: 0.1211 s/iter. Total: 0.2394 s/iter. ETA=0:00:06
[08/24 08:49:32 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0033 s/iter. Inference: 0.1140 s/iter. Eval: 0.1159 s/iter. Total: 0.2334 s/iter. ETA=0:00:00
[08/24 08:49:32 d2.evaluation.evaluator]: Total inference time: 0:00:32.492925 (0.233762 s / iter per device, on 1 devices)
[08/24 08:49:32 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:15 (0.114008 s / iter per device, on 1 devices)
[08/24 08:49:32 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:49:32 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:49:32 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/24 08:49:32 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:49:32 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/24 08:49:32 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:49:32 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.488
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.739
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.558
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.193
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.452
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.625
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.349
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.656
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.400
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.618
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.768
[08/24 08:49:32 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.847 | 73.899 | 55.759 | 19.276 | 45.179 | 62.523 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[08/24 08:49:32 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:49:33 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/24 08:49:33 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:49:33 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.508
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.741
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.575
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.189
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.437
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.679
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.355
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.633
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.672
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.500
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.627
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.780
[08/24 08:49:33 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.771 | 74.083 | 57.486 | 18.882 | 43.745 | 67.854 |
[08/24 08:49:33 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:49:33 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:49:33 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:49:33 d2.evaluation.testing]: copypaste: 48.8467,73.8992,55.7587,19.2764,45.1790,62.5228
[08/24 08:49:33 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:49:33 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:49:33 d2.evaluation.testing]: copypaste: 50.7707,74.0832,57.4855,18.8821,43.7455,67.8537
[08/24 08:49:33 d2.utils.events]:  eta: 0:03:00  iter: 799  total_loss: 0.429  loss_cls: 0.0663  loss_box_reg: 0.1244  loss_mask: 0.196  loss_rpn_cls: 0.004573  loss_rpn_loc: 0.004533  time: 0.9126  data_time: 0.0318  lr: 0.0001998  max_mem: 6143M
[08/24 08:49:51 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:49:51 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:49:51 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:49:51 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:49:51 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:49:55 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.1119 s/iter. Eval: 0.0925 s/iter. Total: 0.2061 s/iter. ETA=0:00:27
[08/24 08:50:00 d2.evaluation.evaluator]: Inference done 32/144. Dataloading: 0.0041 s/iter. Inference: 0.1144 s/iter. Eval: 0.1172 s/iter. Total: 0.2358 s/iter. ETA=0:00:26
[08/24 08:50:05 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0036 s/iter. Inference: 0.1160 s/iter. Eval: 0.1435 s/iter. Total: 0.2633 s/iter. ETA=0:00:25
[08/24 08:50:10 d2.evaluation.evaluator]: Inference done 64/144. Dataloading: 0.0037 s/iter. Inference: 0.1171 s/iter. Eval: 0.1613 s/iter. Total: 0.2823 s/iter. ETA=0:00:22
[08/24 08:50:15 d2.evaluation.evaluator]: Inference done 82/144. Dataloading: 0.0036 s/iter. Inference: 0.1168 s/iter. Eval: 0.1608 s/iter. Total: 0.2813 s/iter. ETA=0:00:17
[08/24 08:50:20 d2.evaluation.evaluator]: Inference done 107/144. Dataloading: 0.0036 s/iter. Inference: 0.1155 s/iter. Eval: 0.1428 s/iter. Total: 0.2619 s/iter. ETA=0:00:09
[08/24 08:50:26 d2.evaluation.evaluator]: Inference done 133/144. Dataloading: 0.0037 s/iter. Inference: 0.1144 s/iter. Eval: 0.1301 s/iter. Total: 0.2484 s/iter. ETA=0:00:02
[08/24 08:50:29 d2.evaluation.evaluator]: Total inference time: 0:00:34.976853 (0.251632 s / iter per device, on 1 devices)
[08/24 08:50:29 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:15 (0.114530 s / iter per device, on 1 devices)
[08/24 08:50:29 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:50:29 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:50:29 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/24 08:50:29 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:50:29 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/24 08:50:29 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:50:29 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.497
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.732
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.565
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.202
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.455
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.641
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.354
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.626
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.671
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.417
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.629
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.791
[08/24 08:50:29 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.727 | 73.218 | 56.466 | 20.177 | 45.456 | 64.076 |
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
[08/24 08:50:29 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:50:29 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/24 08:50:29 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:50:29 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.504
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.737
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.569
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.174
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.438
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.672
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.354
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.629
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.674
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.475
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.628
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.789
[08/24 08:50:29 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.353 | 73.726 | 56.940 | 17.352 | 43.762 | 67.201 |
[08/24 08:50:29 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:50:29 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:50:29 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:50:29 d2.evaluation.testing]: copypaste: 49.7275,73.2178,56.4660,20.1775,45.4564,64.0758
[08/24 08:50:29 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:50:29 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:50:29 d2.evaluation.testing]: copypaste: 50.3534,73.7264,56.9400,17.3518,43.7623,67.2007
[08/24 08:50:29 d2.utils.events]:  eta: 0:02:42  iter: 819  total_loss: 0.5052  loss_cls: 0.09818  loss_box_reg: 0.1837  loss_mask: 0.173  loss_rpn_cls: 0.008736  loss_rpn_loc: 0.008074  time: 0.9131  data_time: 0.0459  lr: 0.0002048  max_mem: 6143M
[08/24 08:50:48 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:50:48 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:50:48 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:50:48 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:50:48 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:50:51 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0015 s/iter. Inference: 0.1098 s/iter. Eval: 0.0732 s/iter. Total: 0.1846 s/iter. ETA=0:00:24
[08/24 08:50:56 d2.evaluation.evaluator]: Inference done 36/144. Dataloading: 0.0028 s/iter. Inference: 0.1107 s/iter. Eval: 0.0848 s/iter. Total: 0.1985 s/iter. ETA=0:00:21
[08/24 08:51:01 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0027 s/iter. Inference: 0.1134 s/iter. Eval: 0.1200 s/iter. Total: 0.2363 s/iter. ETA=0:00:21
[08/24 08:51:06 d2.evaluation.evaluator]: Inference done 70/144. Dataloading: 0.0027 s/iter. Inference: 0.1145 s/iter. Eval: 0.1354 s/iter. Total: 0.2528 s/iter. ETA=0:00:18
[08/24 08:51:11 d2.evaluation.evaluator]: Inference done 100/144. Dataloading: 0.0028 s/iter. Inference: 0.1125 s/iter. Eval: 0.1102 s/iter. Total: 0.2256 s/iter. ETA=0:00:09
[08/24 08:51:16 d2.evaluation.evaluator]: Inference done 127/144. Dataloading: 0.0032 s/iter. Inference: 0.1126 s/iter. Eval: 0.1016 s/iter. Total: 0.2175 s/iter. ETA=0:00:03
[08/24 08:51:20 d2.evaluation.evaluator]: Total inference time: 0:00:30.488714 (0.219343 s / iter per device, on 1 devices)
[08/24 08:51:20 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:15 (0.113362 s / iter per device, on 1 devices)
[08/24 08:51:20 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:51:20 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:51:20 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/24 08:51:20 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:51:20 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[08/24 08:51:20 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:51:20 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.496
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.736
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.556
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.202
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.453
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.640
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.356
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.609
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.654
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.433
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.605
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.779
[08/24 08:51:20 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.552 | 73.560 | 55.630 | 20.217 | 45.289 | 64.034 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[08/24 08:51:21 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:51:21 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[08/24 08:51:21 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:51:21 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.507
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.744
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.588
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.185
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.438
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.675
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.356
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.659
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.483
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.776
[08/24 08:51:21 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.682 | 74.422 | 58.823 | 18.497 | 43.829 | 67.509 |
[08/24 08:51:21 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:51:21 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:51:21 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:51:21 d2.evaluation.testing]: copypaste: 49.5516,73.5599,55.6301,20.2173,45.2886,64.0342
[08/24 08:51:21 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:51:21 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:51:21 d2.evaluation.testing]: copypaste: 50.6817,74.4222,58.8226,18.4972,43.8295,67.5094
[08/24 08:51:21 d2.utils.events]:  eta: 0:02:24  iter: 839  total_loss: 0.418  loss_cls: 0.0824  loss_box_reg: 0.1637  loss_mask: 0.1667  loss_rpn_cls: 0.006425  loss_rpn_loc: 0.009084  time: 0.9134  data_time: 0.0294  lr: 0.00020979  max_mem: 6143M
[08/24 08:51:39 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:51:39 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:51:39 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:51:39 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:51:39 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:51:43 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.1131 s/iter. Eval: 0.0973 s/iter. Total: 0.2120 s/iter. ETA=0:00:28
[08/24 08:51:48 d2.evaluation.evaluator]: Inference done 33/144. Dataloading: 0.0023 s/iter. Inference: 0.1142 s/iter. Eval: 0.1133 s/iter. Total: 0.2300 s/iter. ETA=0:00:25
[08/24 08:51:53 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0026 s/iter. Inference: 0.1168 s/iter. Eval: 0.1450 s/iter. Total: 0.2647 s/iter. ETA=0:00:25
[08/24 08:51:58 d2.evaluation.evaluator]: Inference done 63/144. Dataloading: 0.0029 s/iter. Inference: 0.1183 s/iter. Eval: 0.1710 s/iter. Total: 0.2925 s/iter. ETA=0:00:23
[08/24 08:52:03 d2.evaluation.evaluator]: Inference done 83/144. Dataloading: 0.0034 s/iter. Inference: 0.1181 s/iter. Eval: 0.1607 s/iter. Total: 0.2825 s/iter. ETA=0:00:17
[08/24 08:52:09 d2.evaluation.evaluator]: Inference done 108/144. Dataloading: 0.0035 s/iter. Inference: 0.1163 s/iter. Eval: 0.1432 s/iter. Total: 0.2632 s/iter. ETA=0:00:09
[08/24 08:52:14 d2.evaluation.evaluator]: Inference done 133/144. Dataloading: 0.0033 s/iter. Inference: 0.1154 s/iter. Eval: 0.1324 s/iter. Total: 0.2513 s/iter. ETA=0:00:02
[08/24 08:52:17 d2.evaluation.evaluator]: Total inference time: 0:00:35.239312 (0.253520 s / iter per device, on 1 devices)
[08/24 08:52:17 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:16 (0.115402 s / iter per device, on 1 devices)
[08/24 08:52:17 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:52:17 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:52:17 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/24 08:52:17 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:52:17 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/24 08:52:17 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:52:17 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.501
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.741
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.561
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.459
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.643
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.363
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.621
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.669
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.450
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.789
[08/24 08:52:17 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.091 | 74.106 | 56.123 | 20.023 | 45.910 | 64.299 |
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
[08/24 08:52:17 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:52:17 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[08/24 08:52:17 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:52:17 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.507
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.749
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.594
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.183
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.438
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.684
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.363
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.627
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.667
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.525
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.615
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.785
[08/24 08:52:17 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.745 | 74.942 | 59.450 | 18.347 | 43.801 | 68.371 |
[08/24 08:52:17 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:52:17 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:52:17 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:52:17 d2.evaluation.testing]: copypaste: 50.0907,74.1065,56.1230,20.0232,45.9105,64.2993
[08/24 08:52:17 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:52:17 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:52:17 d2.evaluation.testing]: copypaste: 50.7452,74.9419,59.4499,18.3468,43.8011,68.3710
[08/24 08:52:17 d2.utils.events]:  eta: 0:02:06  iter: 859  total_loss: 0.5652  loss_cls: 0.1005  loss_box_reg: 0.193  loss_mask: 0.201  loss_rpn_cls: 0.01018  loss_rpn_loc: 0.01028  time: 0.9132  data_time: 0.0225  lr: 0.00021479  max_mem: 6143M
[08/24 08:52:36 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:52:36 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:52:36 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:52:36 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:52:36 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:52:39 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0020 s/iter. Inference: 0.1101 s/iter. Eval: 0.0709 s/iter. Total: 0.1830 s/iter. ETA=0:00:24
[08/24 08:52:44 d2.evaluation.evaluator]: Inference done 36/144. Dataloading: 0.0028 s/iter. Inference: 0.1109 s/iter. Eval: 0.0852 s/iter. Total: 0.1989 s/iter. ETA=0:00:21
[08/24 08:52:49 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0035 s/iter. Inference: 0.1133 s/iter. Eval: 0.1169 s/iter. Total: 0.2339 s/iter. ETA=0:00:21
[08/24 08:52:54 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0033 s/iter. Inference: 0.1145 s/iter. Eval: 0.1284 s/iter. Total: 0.2463 s/iter. ETA=0:00:17
[08/24 08:52:59 d2.evaluation.evaluator]: Inference done 101/144. Dataloading: 0.0033 s/iter. Inference: 0.1129 s/iter. Eval: 0.1059 s/iter. Total: 0.2222 s/iter. ETA=0:00:09
[08/24 08:53:04 d2.evaluation.evaluator]: Inference done 130/144. Dataloading: 0.0034 s/iter. Inference: 0.1119 s/iter. Eval: 0.0964 s/iter. Total: 0.2119 s/iter. ETA=0:00:02
[08/24 08:53:08 d2.evaluation.evaluator]: Total inference time: 0:00:29.859990 (0.214820 s / iter per device, on 1 devices)
[08/24 08:53:08 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:15 (0.112399 s / iter per device, on 1 devices)
[08/24 08:53:08 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:53:08 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:53:08 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/24 08:53:08 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:53:08 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/24 08:53:08 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:53:08 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.499
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.742
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.570
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.218
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.461
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.632
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.362
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.608
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.658
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.475
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.611
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.771
[08/24 08:53:08 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.918 | 74.218 | 57.044 | 21.811 | 46.067 | 63.164 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[08/24 08:53:08 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:53:08 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[08/24 08:53:08 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:53:08 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.510
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.747
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.601
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.177
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.445
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.676
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.363
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.620
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.661
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.500
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.611
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.776
[08/24 08:53:08 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.044 | 74.720 | 60.081 | 17.713 | 44.507 | 67.571 |
[08/24 08:53:08 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:53:08 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:53:08 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:53:08 d2.evaluation.testing]: copypaste: 49.9183,74.2182,57.0439,21.8112,46.0665,63.1643
[08/24 08:53:08 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:53:08 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:53:08 d2.evaluation.testing]: copypaste: 51.0436,74.7197,60.0811,17.7132,44.5066,67.5714
[08/24 08:53:08 d2.utils.events]:  eta: 0:01:48  iter: 879  total_loss: 0.4138  loss_cls: 0.06791  loss_box_reg: 0.1085  loss_mask: 0.1735  loss_rpn_cls: 0.005549  loss_rpn_loc: 0.003555  time: 0.9137  data_time: 0.0503  lr: 0.00021978  max_mem: 6143M
[08/24 08:53:27 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:53:27 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:53:27 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:53:27 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:53:27 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:53:30 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0027 s/iter. Inference: 0.1098 s/iter. Eval: 0.0677 s/iter. Total: 0.1802 s/iter. ETA=0:00:23
[08/24 08:53:35 d2.evaluation.evaluator]: Inference done 36/144. Dataloading: 0.0029 s/iter. Inference: 0.1104 s/iter. Eval: 0.0831 s/iter. Total: 0.1965 s/iter. ETA=0:00:21
[08/24 08:53:40 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0032 s/iter. Inference: 0.1130 s/iter. Eval: 0.1201 s/iter. Total: 0.2365 s/iter. ETA=0:00:21
[08/24 08:53:46 d2.evaluation.evaluator]: Inference done 70/144. Dataloading: 0.0033 s/iter. Inference: 0.1148 s/iter. Eval: 0.1370 s/iter. Total: 0.2552 s/iter. ETA=0:00:18
[08/24 08:53:51 d2.evaluation.evaluator]: Inference done 100/144. Dataloading: 0.0035 s/iter. Inference: 0.1133 s/iter. Eval: 0.1131 s/iter. Total: 0.2301 s/iter. ETA=0:00:10
[08/24 08:53:56 d2.evaluation.evaluator]: Inference done 129/144. Dataloading: 0.0036 s/iter. Inference: 0.1122 s/iter. Eval: 0.1012 s/iter. Total: 0.2170 s/iter. ETA=0:00:03
[08/24 08:54:00 d2.evaluation.evaluator]: Total inference time: 0:00:30.391043 (0.218641 s / iter per device, on 1 devices)
[08/24 08:54:00 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:15 (0.112121 s / iter per device, on 1 devices)
[08/24 08:54:00 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:54:00 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:54:00 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/24 08:54:00 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:54:00 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[08/24 08:54:00 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:54:00 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.498
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.742
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.573
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.199
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.462
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.629
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.362
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.611
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.656
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.442
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.617
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.762
[08/24 08:54:00 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.823 | 74.197 | 57.277 | 19.909 | 46.233 | 62.918 |
Loading and preparing results...
DONE (t=0.06s)
creating index...
index created!
[08/24 08:54:00 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:54:00 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.
[08/24 08:54:00 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:54:00 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.513
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.749
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.578
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.176
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.450
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.677
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.365
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.627
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.664
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.475
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.777
[08/24 08:54:00 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.337 | 74.917 | 57.760 | 17.638 | 45.013 | 67.650 |
[08/24 08:54:00 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:54:00 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:54:00 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:54:00 d2.evaluation.testing]: copypaste: 49.8233,74.1966,57.2773,19.9093,46.2333,62.9185
[08/24 08:54:00 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:54:00 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:54:00 d2.evaluation.testing]: copypaste: 51.3368,74.9170,57.7604,17.6381,45.0130,67.6505
[08/24 08:54:00 d2.utils.events]:  eta: 0:01:30  iter: 899  total_loss: 0.5167  loss_cls: 0.08213  loss_box_reg: 0.171  loss_mask: 0.2058  loss_rpn_cls: 0.007064  loss_rpn_loc: 0.006801  time: 0.9138  data_time: 0.0394  lr: 0.00022478  max_mem: 6143M
[08/24 08:54:18 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:54:18 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:54:18 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:54:18 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:54:18 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:54:21 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.1107 s/iter. Eval: 0.0695 s/iter. Total: 0.1818 s/iter. ETA=0:00:24
[08/24 08:54:27 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0036 s/iter. Inference: 0.1191 s/iter. Eval: 0.1161 s/iter. Total: 0.2389 s/iter. ETA=0:00:26
[08/24 08:54:32 d2.evaluation.evaluator]: Inference done 50/144. Dataloading: 0.0030 s/iter. Inference: 0.1178 s/iter. Eval: 0.1314 s/iter. Total: 0.2524 s/iter. ETA=0:00:23
[08/24 08:54:37 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0030 s/iter. Inference: 0.1186 s/iter. Eval: 0.1476 s/iter. Total: 0.2694 s/iter. ETA=0:00:20
[08/24 08:54:42 d2.evaluation.evaluator]: Inference done 95/144. Dataloading: 0.0032 s/iter. Inference: 0.1157 s/iter. Eval: 0.1234 s/iter. Total: 0.2424 s/iter. ETA=0:00:11
[08/24 08:54:47 d2.evaluation.evaluator]: Inference done 120/144. Dataloading: 0.0034 s/iter. Inference: 0.1148 s/iter. Eval: 0.1158 s/iter. Total: 0.2340 s/iter. ETA=0:00:05
[08/24 08:54:52 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0035 s/iter. Inference: 0.1142 s/iter. Eval: 0.1123 s/iter. Total: 0.2302 s/iter. ETA=0:00:00
[08/24 08:54:52 d2.evaluation.evaluator]: Total inference time: 0:00:32.049376 (0.230571 s / iter per device, on 1 devices)
[08/24 08:54:52 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:15 (0.114172 s / iter per device, on 1 devices)
[08/24 08:54:52 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:54:52 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:54:52 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/24 08:54:52 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:54:53 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/24 08:54:53 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:54:53 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.488
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.739
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.563
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.182
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.457
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.608
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.607
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.664
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.433
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.630
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.765
[08/24 08:54:53 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.791 | 73.928 | 56.303 | 18.211 | 45.718 | 60.838 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[08/24 08:54:53 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:54:53 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[08/24 08:54:53 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:54:53 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.509
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.748
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.597
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.166
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.448
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.677
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.624
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.671
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.467
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.628
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.783
[08/24 08:54:53 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.948 | 74.785 | 59.666 | 16.583 | 44.818 | 67.686 |
[08/24 08:54:53 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:54:53 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:54:53 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:54:53 d2.evaluation.testing]: copypaste: 48.7907,73.9275,56.3030,18.2110,45.7179,60.8379
[08/24 08:54:53 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:54:53 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:54:53 d2.evaluation.testing]: copypaste: 50.9484,74.7852,59.6664,16.5827,44.8177,67.6859
[08/24 08:54:53 d2.utils.events]:  eta: 0:01:12  iter: 919  total_loss: 0.4  loss_cls: 0.07146  loss_box_reg: 0.1529  loss_mask: 0.157  loss_rpn_cls: 0.005224  loss_rpn_loc: 0.005275  time: 0.9135  data_time: 0.0280  lr: 0.00022977  max_mem: 6143M
[08/24 08:55:12 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:55:12 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:55:12 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:55:12 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:55:12 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:55:15 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0017 s/iter. Inference: 0.1104 s/iter. Eval: 0.0717 s/iter. Total: 0.1838 s/iter. ETA=0:00:24
[08/24 08:55:20 d2.evaluation.evaluator]: Inference done 35/144. Dataloading: 0.0027 s/iter. Inference: 0.1119 s/iter. Eval: 0.0908 s/iter. Total: 0.2055 s/iter. ETA=0:00:22
[08/24 08:55:25 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0031 s/iter. Inference: 0.1140 s/iter. Eval: 0.1237 s/iter. Total: 0.2410 s/iter. ETA=0:00:21
[08/24 08:55:30 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0033 s/iter. Inference: 0.1156 s/iter. Eval: 0.1484 s/iter. Total: 0.2674 s/iter. ETA=0:00:20
[08/24 08:55:35 d2.evaluation.evaluator]: Inference done 96/144. Dataloading: 0.0032 s/iter. Inference: 0.1135 s/iter. Eval: 0.1208 s/iter. Total: 0.2376 s/iter. ETA=0:00:11
[08/24 08:55:41 d2.evaluation.evaluator]: Inference done 122/144. Dataloading: 0.0032 s/iter. Inference: 0.1130 s/iter. Eval: 0.1120 s/iter. Total: 0.2283 s/iter. ETA=0:00:05
[08/24 08:55:45 d2.evaluation.evaluator]: Total inference time: 0:00:31.398923 (0.225892 s / iter per device, on 1 devices)
[08/24 08:55:45 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:15 (0.112908 s / iter per device, on 1 devices)
[08/24 08:55:45 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:55:45 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:55:45 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/24 08:55:45 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:55:45 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[08/24 08:55:45 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:55:45 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.501
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.739
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.558
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.173
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.463
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.640
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.357
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.615
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.672
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.417
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.635
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.782
[08/24 08:55:45 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.116 | 73.935 | 55.778 | 17.309 | 46.334 | 64.034 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[08/24 08:55:45 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:55:46 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[08/24 08:55:46 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:55:46 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.514
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.739
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.580
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.165
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.449
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.682
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.355
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.624
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.674
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.483
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.630
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.783
[08/24 08:55:46 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.355 | 73.889 | 58.030 | 16.459 | 44.924 | 68.202 |
[08/24 08:55:46 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:55:46 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:55:46 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:55:46 d2.evaluation.testing]: copypaste: 50.1159,73.9345,55.7777,17.3087,46.3335,64.0344
[08/24 08:55:46 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:55:46 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:55:46 d2.evaluation.testing]: copypaste: 51.3546,73.8887,58.0302,16.4588,44.9245,68.2017
[08/24 08:55:46 d2.utils.events]:  eta: 0:00:54  iter: 939  total_loss: 0.3971  loss_cls: 0.07753  loss_box_reg: 0.1797  loss_mask: 0.1693  loss_rpn_cls: 0.005196  loss_rpn_loc: 0.005349  time: 0.9140  data_time: 0.0373  lr: 0.00023477  max_mem: 6143M
[08/24 08:56:04 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:56:04 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:56:04 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:56:04 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:56:04 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:56:07 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.1091 s/iter. Eval: 0.0574 s/iter. Total: 0.1682 s/iter. ETA=0:00:22
[08/24 08:56:12 d2.evaluation.evaluator]: Inference done 39/144. Dataloading: 0.0032 s/iter. Inference: 0.1121 s/iter. Eval: 0.0704 s/iter. Total: 0.1858 s/iter. ETA=0:00:19
[08/24 08:56:18 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0034 s/iter. Inference: 0.1137 s/iter. Eval: 0.1020 s/iter. Total: 0.2193 s/iter. ETA=0:00:19
[08/24 08:56:23 d2.evaluation.evaluator]: Inference done 78/144. Dataloading: 0.0038 s/iter. Inference: 0.1140 s/iter. Eval: 0.1073 s/iter. Total: 0.2252 s/iter. ETA=0:00:14
[08/24 08:56:28 d2.evaluation.evaluator]: Inference done 108/144. Dataloading: 0.0043 s/iter. Inference: 0.1131 s/iter. Eval: 0.0921 s/iter. Total: 0.2097 s/iter. ETA=0:00:07
[08/24 08:56:33 d2.evaluation.evaluator]: Inference done 140/144. Dataloading: 0.0042 s/iter. Inference: 0.1120 s/iter. Eval: 0.0815 s/iter. Total: 0.1978 s/iter. ETA=0:00:00
[08/24 08:56:34 d2.evaluation.evaluator]: Total inference time: 0:00:28.151728 (0.202530 s / iter per device, on 1 devices)
[08/24 08:56:34 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:15 (0.112231 s / iter per device, on 1 devices)
[08/24 08:56:34 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:56:34 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:56:34 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/24 08:56:34 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:56:34 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[08/24 08:56:34 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:56:34 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.512
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.747
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.565
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.193
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.465
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.661
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.361
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.617
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.655
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.392
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.609
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.783
[08/24 08:56:34 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.210 | 74.699 | 56.485 | 19.299 | 46.508 | 66.093 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[08/24 08:56:34 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:56:35 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[08/24 08:56:35 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:56:35 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.516
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.746
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.596
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.165
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.455
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.683
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.353
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.624
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.662
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.450
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.617
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.779
[08/24 08:56:35 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.644 | 74.623 | 59.610 | 16.517 | 45.470 | 68.265 |
[08/24 08:56:35 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:56:35 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:56:35 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:56:35 d2.evaluation.testing]: copypaste: 51.2101,74.6985,56.4853,19.2989,46.5079,66.0934
[08/24 08:56:35 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:56:35 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:56:35 d2.evaluation.testing]: copypaste: 51.6441,74.6233,59.6095,16.5173,45.4701,68.2647
[08/24 08:56:35 d2.utils.events]:  eta: 0:00:36  iter: 959  total_loss: 0.338  loss_cls: 0.0693  loss_box_reg: 0.1244  loss_mask: 0.1469  loss_rpn_cls: 0.004316  loss_rpn_loc: 0.004365  time: 0.9143  data_time: 0.0428  lr: 0.00023976  max_mem: 6143M
[08/24 08:56:53 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:56:53 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:56:53 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:56:53 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:56:53 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:56:57 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0036 s/iter. Inference: 0.1211 s/iter. Eval: 0.0891 s/iter. Total: 0.2137 s/iter. ETA=0:00:28
[08/24 08:57:02 d2.evaluation.evaluator]: Inference done 37/144. Dataloading: 0.0030 s/iter. Inference: 0.1125 s/iter. Eval: 0.0826 s/iter. Total: 0.1982 s/iter. ETA=0:00:21
[08/24 08:57:07 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0030 s/iter. Inference: 0.1150 s/iter. Eval: 0.1241 s/iter. Total: 0.2423 s/iter. ETA=0:00:22
[08/24 08:57:12 d2.evaluation.evaluator]: Inference done 70/144. Dataloading: 0.0035 s/iter. Inference: 0.1160 s/iter. Eval: 0.1406 s/iter. Total: 0.2603 s/iter. ETA=0:00:19
[08/24 08:57:18 d2.evaluation.evaluator]: Inference done 100/144. Dataloading: 0.0033 s/iter. Inference: 0.1142 s/iter. Eval: 0.1175 s/iter. Total: 0.2351 s/iter. ETA=0:00:10
[08/24 08:57:23 d2.evaluation.evaluator]: Inference done 128/144. Dataloading: 0.0033 s/iter. Inference: 0.1131 s/iter. Eval: 0.1058 s/iter. Total: 0.2224 s/iter. ETA=0:00:03
[08/24 08:57:26 d2.evaluation.evaluator]: Total inference time: 0:00:31.017311 (0.223146 s / iter per device, on 1 devices)
[08/24 08:57:26 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:15 (0.112993 s / iter per device, on 1 devices)
[08/24 08:57:26 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:57:26 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:57:26 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/24 08:57:27 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:57:27 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[08/24 08:57:27 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:57:27 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.511
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.746
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.559
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.172
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.470
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.657
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.366
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.622
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.670
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.633
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.791
[08/24 08:57:27 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.094 | 74.592 | 55.885 | 17.195 | 47.013 | 65.682 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[08/24 08:57:27 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:57:27 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[08/24 08:57:27 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:57:27 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.518
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.749
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.595
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.158
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.452
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.688
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.362
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.631
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.673
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.458
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.630
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.786
[08/24 08:57:27 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.767 | 74.912 | 59.491 | 15.824 | 45.210 | 68.831 |
[08/24 08:57:27 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:57:27 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:57:27 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:57:27 d2.evaluation.testing]: copypaste: 51.0941,74.5917,55.8854,17.1950,47.0129,65.6823
[08/24 08:57:27 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:57:27 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:57:27 d2.evaluation.testing]: copypaste: 51.7666,74.9124,59.4906,15.8240,45.2103,68.8312
[08/24 08:57:27 d2.utils.events]:  eta: 0:00:18  iter: 979  total_loss: 0.513  loss_cls: 0.09104  loss_box_reg: 0.1755  loss_mask: 0.1828  loss_rpn_cls: 0.007161  loss_rpn_loc: 0.01084  time: 0.9146  data_time: 0.0427  lr: 0.00024476  max_mem: 6143M
[08/24 08:57:45 d2.utils.events]:  eta: 0:00:00  iter: 999  total_loss: 0.4695  loss_cls: 0.08106  loss_box_reg: 0.1804  loss_mask: 0.1765  loss_rpn_cls: 0.008946  loss_rpn_loc: 0.006883  time: 0.9145  data_time: 0.0308  lr: 0.00024975  max_mem: 6143M
[08/24 08:57:45 d2.engine.hooks]: Overall training speed: 998 iterations in 0:15:12 (0.9145 s / it)
[08/24 08:57:45 d2.engine.hooks]: Total training time: 1:11:24 (0:56:11 on hooks)
[08/24 08:57:45 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[08/24 08:57:45 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[08/24 08:57:45 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[08/24 08:57:45 d2.data.common]: Serialized dataset takes 0.09 MiB
[08/24 08:57:45 d2.evaluation.evaluator]: Start inference on 144 batches
[08/24 08:57:49 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0017 s/iter. Inference: 0.1099 s/iter. Eval: 0.0683 s/iter. Total: 0.1800 s/iter. ETA=0:00:23
[08/24 08:57:54 d2.evaluation.evaluator]: Inference done 33/144. Dataloading: 0.0049 s/iter. Inference: 0.1140 s/iter. Eval: 0.1010 s/iter. Total: 0.2200 s/iter. ETA=0:00:24
[08/24 08:57:59 d2.evaluation.evaluator]: Inference done 51/144. Dataloading: 0.0045 s/iter. Inference: 0.1150 s/iter. Eval: 0.1232 s/iter. Total: 0.2428 s/iter. ETA=0:00:22
[08/24 08:58:04 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0040 s/iter. Inference: 0.1164 s/iter. Eval: 0.1387 s/iter. Total: 0.2592 s/iter. ETA=0:00:19
[08/24 08:58:09 d2.evaluation.evaluator]: Inference done 98/144. Dataloading: 0.0039 s/iter. Inference: 0.1138 s/iter. Eval: 0.1120 s/iter. Total: 0.2299 s/iter. ETA=0:00:10
[08/24 08:58:14 d2.evaluation.evaluator]: Inference done 125/144. Dataloading: 0.0040 s/iter. Inference: 0.1132 s/iter. Eval: 0.1031 s/iter. Total: 0.2204 s/iter. ETA=0:00:04
[08/24 08:58:18 d2.evaluation.evaluator]: Total inference time: 0:00:30.561036 (0.219864 s / iter per device, on 1 devices)
[08/24 08:58:18 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:15 (0.112957 s / iter per device, on 1 devices)
[08/24 08:58:18 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[08/24 08:58:18 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[08/24 08:58:18 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[08/24 08:58:18 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[08/24 08:58:18 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[08/24 08:58:18 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:58:18 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.513
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.756
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.585
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.225
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.477
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.648
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.362
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.624
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.667
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.392
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.629
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.785
[08/24 08:58:18 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.273 | 75.619 | 58.470 | 22.483 | 47.736 | 64.816 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[08/24 08:58:18 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[08/24 08:58:18 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[08/24 08:58:18 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[08/24 08:58:18 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.522
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.756
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.598
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.197
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.455
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.688
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.360
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.633
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.672
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.458
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.630
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.785
[08/24 08:58:18 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.217 | 75.611 | 59.831 | 19.749 | 45.535 | 68.774 |
[08/24 08:58:18 d2.engine.defaults]: Evaluation results for PET_val in csv format:
[08/24 08:58:18 d2.evaluation.testing]: copypaste: Task: bbox
[08/24 08:58:18 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:58:18 d2.evaluation.testing]: copypaste: 51.2734,75.6188,58.4698,22.4832,47.7364,64.8163
[08/24 08:58:18 d2.evaluation.testing]: copypaste: Task: segm
[08/24 08:58:18 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[08/24 08:58:18 d2.evaluation.testing]: copypaste: 52.2174,75.6110,59.8313,19.7490,45.5349,68.7743