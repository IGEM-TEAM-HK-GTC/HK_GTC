[09/04 07:55:50 d2.engine.defaults]: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[09/04 07:55:50 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [RandomBrightness(intensity_min=0.9, intensity_max=1.1), RandomContrast(intensity_min=0.9, intensity_max=1.1), RandomFlip(prob=0.5)]
[09/04 07:55:50 d2.data.datasets.coco]: Loaded 574 images in COCO format from ../input/petbottles/plastic data/annotations/instances_train.json
[09/04 07:55:50 d2.data.build]: Distribution of instances among all 1 categories:
|  category   | #instances   |
|:-----------:|:-------------|
| PET Bottles | 1145         |
|             |              |
[09/04 07:55:50 d2.data.build]: Using training sampler TrainingSampler
[09/04 07:55:50 d2.data.common]: Serializing 574 elements to byte tensors and concatenating them all ...
[09/04 07:55:50 d2.data.common]: Serialized dataset takes 0.45 MiB
model_final_a3ec72.pkl: 254MB [00:06, 41.3MB/s]                              
[09/04 07:56:01 d2.engine.train_loop]: Starting training from iteration 0
[09/04 07:56:18 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 07:56:18 d2.data.build]: Distribution of instances among all 1 categories:
|  category   | #instances   |
|:-----------:|:-------------|
| PET Bottles | 193          |
|             |              |
[09/04 07:56:18 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 07:56:18 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 07:56:18 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 07:56:18 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 07:56:28 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.1595 s/iter. Eval: 0.7002 s/iter. Total: 0.8613 s/iter. ETA=0:01:54
[09/04 07:56:33 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0019 s/iter. Inference: 0.1597 s/iter. Eval: 0.6906 s/iter. Total: 0.8524 s/iter. ETA=0:01:48
[09/04 07:56:39 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0019 s/iter. Inference: 0.1597 s/iter. Eval: 0.7138 s/iter. Total: 0.8757 s/iter. ETA=0:01:45
[09/04 07:56:45 d2.evaluation.evaluator]: Inference done 30/144. Dataloading: 0.0019 s/iter. Inference: 0.1595 s/iter. Eval: 0.7000 s/iter. Total: 0.8616 s/iter. ETA=0:01:38
[09/04 07:56:50 d2.evaluation.evaluator]: Inference done 36/144. Dataloading: 0.0019 s/iter. Inference: 0.1595 s/iter. Eval: 0.6974 s/iter. Total: 0.8591 s/iter. ETA=0:01:32
[09/04 07:56:55 d2.evaluation.evaluator]: Inference done 43/144. Dataloading: 0.0020 s/iter. Inference: 0.1596 s/iter. Eval: 0.6916 s/iter. Total: 0.8533 s/iter. ETA=0:01:26
[09/04 07:57:01 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0020 s/iter. Inference: 0.1596 s/iter. Eval: 0.6915 s/iter. Total: 0.8533 s/iter. ETA=0:01:21
[09/04 07:57:06 d2.evaluation.evaluator]: Inference done 56/144. Dataloading: 0.0020 s/iter. Inference: 0.1596 s/iter. Eval: 0.6879 s/iter. Total: 0.8498 s/iter. ETA=0:01:14
[09/04 07:57:12 d2.evaluation.evaluator]: Inference done 62/144. Dataloading: 0.0020 s/iter. Inference: 0.1602 s/iter. Eval: 0.6945 s/iter. Total: 0.8570 s/iter. ETA=0:01:10
[09/04 07:57:18 d2.evaluation.evaluator]: Inference done 69/144. Dataloading: 0.0020 s/iter. Inference: 0.1600 s/iter. Eval: 0.6912 s/iter. Total: 0.8534 s/iter. ETA=0:01:04
[09/04 07:57:23 d2.evaluation.evaluator]: Inference done 75/144. Dataloading: 0.0020 s/iter. Inference: 0.1600 s/iter. Eval: 0.6918 s/iter. Total: 0.8541 s/iter. ETA=0:00:58
[09/04 07:57:28 d2.evaluation.evaluator]: Inference done 81/144. Dataloading: 0.0020 s/iter. Inference: 0.1599 s/iter. Eval: 0.6906 s/iter. Total: 0.8528 s/iter. ETA=0:00:53
[09/04 07:57:33 d2.evaluation.evaluator]: Inference done 87/144. Dataloading: 0.0020 s/iter. Inference: 0.1598 s/iter. Eval: 0.6897 s/iter. Total: 0.8519 s/iter. ETA=0:00:48
[09/04 07:57:38 d2.evaluation.evaluator]: Inference done 93/144. Dataloading: 0.0020 s/iter. Inference: 0.1598 s/iter. Eval: 0.6892 s/iter. Total: 0.8514 s/iter. ETA=0:00:43
[09/04 07:57:43 d2.evaluation.evaluator]: Inference done 99/144. Dataloading: 0.0020 s/iter. Inference: 0.1601 s/iter. Eval: 0.6913 s/iter. Total: 0.8537 s/iter. ETA=0:00:38
[09/04 07:57:48 d2.evaluation.evaluator]: Inference done 105/144. Dataloading: 0.0020 s/iter. Inference: 0.1601 s/iter. Eval: 0.6915 s/iter. Total: 0.8539 s/iter. ETA=0:00:33
[09/04 07:57:54 d2.evaluation.evaluator]: Inference done 112/144. Dataloading: 0.0020 s/iter. Inference: 0.1601 s/iter. Eval: 0.6898 s/iter. Total: 0.8522 s/iter. ETA=0:00:27
[09/04 07:57:59 d2.evaluation.evaluator]: Inference done 118/144. Dataloading: 0.0020 s/iter. Inference: 0.1600 s/iter. Eval: 0.6902 s/iter. Total: 0.8526 s/iter. ETA=0:00:22
[09/04 07:58:05 d2.evaluation.evaluator]: Inference done 125/144. Dataloading: 0.0020 s/iter. Inference: 0.1599 s/iter. Eval: 0.6888 s/iter. Total: 0.8511 s/iter. ETA=0:00:16
[09/04 07:58:10 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0020 s/iter. Inference: 0.1599 s/iter. Eval: 0.6889 s/iter. Total: 0.8512 s/iter. ETA=0:00:11
[09/04 07:58:16 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0020 s/iter. Inference: 0.1600 s/iter. Eval: 0.6909 s/iter. Total: 0.8532 s/iter. ETA=0:00:05
[09/04 07:58:21 d2.evaluation.evaluator]: Inference done 143/144. Dataloading: 0.0020 s/iter. Inference: 0.1599 s/iter. Eval: 0.6909 s/iter. Total: 0.8531 s/iter. ETA=0:00:00
[09/04 07:58:22 d2.evaluation.evaluator]: Total inference time: 0:01:58.604737 (0.853271 s / iter per device, on 1 devices)
[09/04 07:58:22 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:22 (0.159866 s / iter per device, on 1 devices)
[09/04 07:58:22 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 07:58:22 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 07:58:22 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/04 07:58:22 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 07:58:22 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.
[09/04 07:58:22 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 07:58:22 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.009
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.087
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.095
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.089
[09/04 07:58:22 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.024 | 0.124  | 0.002  | 0.000 | 0.062 | 0.017 |
Loading and preparing results...
DONE (t=0.16s)
creating index...
index created!
[09/04 07:58:23 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 07:58:23 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[09/04 07:58:23 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 07:58:23 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000
[09/04 07:58:23 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.000 | 0.000  | 0.000  | 0.000 | 0.000 | 0.000 |
[09/04 07:58:23 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 07:58:23 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 07:58:23 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 07:58:23 d2.evaluation.testing]: copypaste: 0.0240,0.1238,0.0017,0.0000,0.0617,0.0167
[09/04 07:58:23 d2.evaluation.testing]: copypaste: Task: segm
[09/04 07:58:23 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 07:58:23 d2.evaluation.testing]: copypaste: 0.0000,0.0000,0.0000,0.0000,0.0000,0.0000
[09/04 07:58:23 d2.utils.events]:  eta: 0:14:15  iter: 19  total_loss: 1.723  loss_cls: 0.6882  loss_box_reg: 0.2643  loss_mask: 0.6998  loss_rpn_cls: 0.01294  loss_rpn_loc: 0.001804  time: 0.8744  data_time: 0.0240  lr: 4.9953e-06  max_mem: 6718M
[09/04 07:58:40 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 07:58:41 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 07:58:41 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 07:58:41 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 07:58:41 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 07:58:51 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0021 s/iter. Inference: 0.1609 s/iter. Eval: 0.7024 s/iter. Total: 0.8654 s/iter. ETA=0:01:55
[09/04 07:58:56 d2.evaluation.evaluator]: Inference done 18/144. Dataloading: 0.0026 s/iter. Inference: 0.1607 s/iter. Eval: 0.6807 s/iter. Total: 0.8441 s/iter. ETA=0:01:46
[09/04 07:59:02 d2.evaluation.evaluator]: Inference done 24/144. Dataloading: 0.0025 s/iter. Inference: 0.1608 s/iter. Eval: 0.6832 s/iter. Total: 0.8467 s/iter. ETA=0:01:41
[09/04 07:59:07 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0024 s/iter. Inference: 0.1607 s/iter. Eval: 0.6786 s/iter. Total: 0.8420 s/iter. ETA=0:01:35
[09/04 07:59:12 d2.evaluation.evaluator]: Inference done 37/144. Dataloading: 0.0025 s/iter. Inference: 0.1607 s/iter. Eval: 0.6804 s/iter. Total: 0.8438 s/iter. ETA=0:01:30
[09/04 07:59:18 d2.evaluation.evaluator]: Inference done 43/144. Dataloading: 0.0025 s/iter. Inference: 0.1612 s/iter. Eval: 0.6877 s/iter. Total: 0.8515 s/iter. ETA=0:01:26
[09/04 07:59:23 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0024 s/iter. Inference: 0.1609 s/iter. Eval: 0.6857 s/iter. Total: 0.8493 s/iter. ETA=0:01:20
[09/04 07:59:28 d2.evaluation.evaluator]: Inference done 55/144. Dataloading: 0.0026 s/iter. Inference: 0.1608 s/iter. Eval: 0.6848 s/iter. Total: 0.8485 s/iter. ETA=0:01:15
[09/04 07:59:34 d2.evaluation.evaluator]: Inference done 62/144. Dataloading: 0.0025 s/iter. Inference: 0.1607 s/iter. Eval: 0.6827 s/iter. Total: 0.8462 s/iter. ETA=0:01:09
[09/04 07:59:39 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0026 s/iter. Inference: 0.1606 s/iter. Eval: 0.6834 s/iter. Total: 0.8469 s/iter. ETA=0:01:04
[09/04 07:59:45 d2.evaluation.evaluator]: Inference done 75/144. Dataloading: 0.0026 s/iter. Inference: 0.1605 s/iter. Eval: 0.6813 s/iter. Total: 0.8447 s/iter. ETA=0:00:58
[09/04 07:59:50 d2.evaluation.evaluator]: Inference done 81/144. Dataloading: 0.0026 s/iter. Inference: 0.1607 s/iter. Eval: 0.6864 s/iter. Total: 0.8500 s/iter. ETA=0:00:53
[09/04 07:59:56 d2.evaluation.evaluator]: Inference done 88/144. Dataloading: 0.0025 s/iter. Inference: 0.1607 s/iter. Eval: 0.6859 s/iter. Total: 0.8494 s/iter. ETA=0:00:47
[09/04 08:00:01 d2.evaluation.evaluator]: Inference done 94/144. Dataloading: 0.0025 s/iter. Inference: 0.1607 s/iter. Eval: 0.6850 s/iter. Total: 0.8485 s/iter. ETA=0:00:42
[09/04 08:00:06 d2.evaluation.evaluator]: Inference done 100/144. Dataloading: 0.0025 s/iter. Inference: 0.1606 s/iter. Eval: 0.6842 s/iter. Total: 0.8476 s/iter. ETA=0:00:37
[09/04 08:00:11 d2.evaluation.evaluator]: Inference done 106/144. Dataloading: 0.0025 s/iter. Inference: 0.1608 s/iter. Eval: 0.6851 s/iter. Total: 0.8486 s/iter. ETA=0:00:32
[09/04 08:00:17 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0025 s/iter. Inference: 0.1606 s/iter. Eval: 0.6837 s/iter. Total: 0.8471 s/iter. ETA=0:00:26
[09/04 08:00:22 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0025 s/iter. Inference: 0.1610 s/iter. Eval: 0.6867 s/iter. Total: 0.8505 s/iter. ETA=0:00:21
[09/04 08:00:27 d2.evaluation.evaluator]: Inference done 125/144. Dataloading: 0.0024 s/iter. Inference: 0.1610 s/iter. Eval: 0.6861 s/iter. Total: 0.8498 s/iter. ETA=0:00:16
[09/04 08:00:33 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0024 s/iter. Inference: 0.1609 s/iter. Eval: 0.6865 s/iter. Total: 0.8502 s/iter. ETA=0:00:11
[09/04 08:00:38 d2.evaluation.evaluator]: Inference done 138/144. Dataloading: 0.0024 s/iter. Inference: 0.1609 s/iter. Eval: 0.6857 s/iter. Total: 0.8493 s/iter. ETA=0:00:05
[09/04 08:00:44 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0024 s/iter. Inference: 0.1608 s/iter. Eval: 0.6862 s/iter. Total: 0.8496 s/iter. ETA=0:00:00
[09/04 08:00:44 d2.evaluation.evaluator]: Total inference time: 0:01:58.150342 (0.850002 s / iter per device, on 1 devices)
[09/04 08:00:44 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:22 (0.160766 s / iter per device, on 1 devices)
[09/04 08:00:44 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:00:44 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:00:44 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/04 08:00:44 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:00:44 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[09/04 08:00:44 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:00:44 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.004
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.006
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.024
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.171
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.025
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.146
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.241
[09/04 08:00:44 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.100 | 0.443  | 0.008  | 0.005 | 0.178 | 0.096 |
Loading and preparing results...
DONE (t=0.31s)
creating index...
index created!
[09/04 08:00:45 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:00:45 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.21 seconds.
[09/04 08:00:45 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:00:45 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.006
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.003
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.006
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.017
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.069
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.341
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.067
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.295
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.471
[09/04 08:00:45 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.297 | 0.629  | 0.269  | 0.020 | 0.296 | 0.563 |
[09/04 08:00:45 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:00:45 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:00:45 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:00:45 d2.evaluation.testing]: copypaste: 0.0998,0.4433,0.0079,0.0049,0.1781,0.0959
[09/04 08:00:45 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:00:45 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:00:45 d2.evaluation.testing]: copypaste: 0.2974,0.6289,0.2690,0.0199,0.2959,0.5625
[09/04 08:00:45 d2.utils.events]:  eta: 0:13:57  iter: 39  total_loss: 1.731  loss_cls: 0.6274  loss_box_reg: 0.4413  loss_mask: 0.6851  loss_rpn_cls: 0.02039  loss_rpn_loc: 0.005897  time: 0.8725  data_time: 0.0064  lr: 9.9902e-06  max_mem: 6718M
[09/04 08:01:03 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:01:03 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:01:03 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:01:03 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:01:03 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:01:12 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0019 s/iter. Inference: 0.1599 s/iter. Eval: 0.7141 s/iter. Total: 0.8760 s/iter. ETA=0:01:56
[09/04 08:01:18 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0024 s/iter. Inference: 0.1597 s/iter. Eval: 0.6998 s/iter. Total: 0.8621 s/iter. ETA=0:01:49
[09/04 08:01:23 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0023 s/iter. Inference: 0.1602 s/iter. Eval: 0.6898 s/iter. Total: 0.8525 s/iter. ETA=0:01:43
[09/04 08:01:28 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0022 s/iter. Inference: 0.1605 s/iter. Eval: 0.7083 s/iter. Total: 0.8712 s/iter. ETA=0:01:40
[09/04 08:01:34 d2.evaluation.evaluator]: Inference done 36/144. Dataloading: 0.0022 s/iter. Inference: 0.1604 s/iter. Eval: 0.6992 s/iter. Total: 0.8620 s/iter. ETA=0:01:33
[09/04 08:01:39 d2.evaluation.evaluator]: Inference done 42/144. Dataloading: 0.0023 s/iter. Inference: 0.1607 s/iter. Eval: 0.6970 s/iter. Total: 0.8603 s/iter. ETA=0:01:27
[09/04 08:01:45 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0023 s/iter. Inference: 0.1605 s/iter. Eval: 0.6914 s/iter. Total: 0.8545 s/iter. ETA=0:01:21
[09/04 08:01:50 d2.evaluation.evaluator]: Inference done 55/144. Dataloading: 0.0023 s/iter. Inference: 0.1607 s/iter. Eval: 0.6910 s/iter. Total: 0.8543 s/iter. ETA=0:01:16
[09/04 08:01:56 d2.evaluation.evaluator]: Inference done 62/144. Dataloading: 0.0023 s/iter. Inference: 0.1606 s/iter. Eval: 0.6875 s/iter. Total: 0.8507 s/iter. ETA=0:01:09
[09/04 08:02:01 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0023 s/iter. Inference: 0.1606 s/iter. Eval: 0.6962 s/iter. Total: 0.8593 s/iter. ETA=0:01:05
[09/04 08:02:07 d2.evaluation.evaluator]: Inference done 75/144. Dataloading: 0.0023 s/iter. Inference: 0.1605 s/iter. Eval: 0.6927 s/iter. Total: 0.8557 s/iter. ETA=0:00:59
[09/04 08:02:12 d2.evaluation.evaluator]: Inference done 81/144. Dataloading: 0.0023 s/iter. Inference: 0.1604 s/iter. Eval: 0.6924 s/iter. Total: 0.8554 s/iter. ETA=0:00:53
[09/04 08:02:18 d2.evaluation.evaluator]: Inference done 88/144. Dataloading: 0.0023 s/iter. Inference: 0.1604 s/iter. Eval: 0.6901 s/iter. Total: 0.8531 s/iter. ETA=0:00:47
[09/04 08:02:23 d2.evaluation.evaluator]: Inference done 94/144. Dataloading: 0.0023 s/iter. Inference: 0.1605 s/iter. Eval: 0.6898 s/iter. Total: 0.8529 s/iter. ETA=0:00:42
[09/04 08:02:29 d2.evaluation.evaluator]: Inference done 101/144. Dataloading: 0.0023 s/iter. Inference: 0.1604 s/iter. Eval: 0.6879 s/iter. Total: 0.8508 s/iter. ETA=0:00:36
[09/04 08:02:34 d2.evaluation.evaluator]: Inference done 107/144. Dataloading: 0.0023 s/iter. Inference: 0.1606 s/iter. Eval: 0.6924 s/iter. Total: 0.8555 s/iter. ETA=0:00:31
[09/04 08:02:40 d2.evaluation.evaluator]: Inference done 114/144. Dataloading: 0.0023 s/iter. Inference: 0.1605 s/iter. Eval: 0.6907 s/iter. Total: 0.8537 s/iter. ETA=0:00:25
[09/04 08:02:45 d2.evaluation.evaluator]: Inference done 120/144. Dataloading: 0.0023 s/iter. Inference: 0.1604 s/iter. Eval: 0.6907 s/iter. Total: 0.8537 s/iter. ETA=0:00:20
[09/04 08:02:50 d2.evaluation.evaluator]: Inference done 126/144. Dataloading: 0.0023 s/iter. Inference: 0.1604 s/iter. Eval: 0.6899 s/iter. Total: 0.8528 s/iter. ETA=0:00:15
[09/04 08:02:55 d2.evaluation.evaluator]: Inference done 132/144. Dataloading: 0.0023 s/iter. Inference: 0.1604 s/iter. Eval: 0.6901 s/iter. Total: 0.8531 s/iter. ETA=0:00:10
[09/04 08:03:01 d2.evaluation.evaluator]: Inference done 139/144. Dataloading: 0.0023 s/iter. Inference: 0.1604 s/iter. Eval: 0.6891 s/iter. Total: 0.8521 s/iter. ETA=0:00:04
[09/04 08:03:06 d2.evaluation.evaluator]: Total inference time: 0:01:58.818202 (0.854807 s / iter per device, on 1 devices)
[09/04 08:03:06 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:22 (0.160380 s / iter per device, on 1 devices)
[09/04 08:03:06 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:03:06 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:03:06 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/04 08:03:06 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:03:06 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[09/04 08:03:06 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:03:06 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.018
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.008
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.005
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.013
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.088
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.288
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.025
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.258
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.386
[09/04 08:03:06 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.475 | 1.797  | 0.061  | 0.015 | 0.781 | 0.522 |
Loading and preparing results...
DONE (t=0.32s)
creating index...
index created!
[09/04 08:03:07 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:03:07 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.23 seconds.
[09/04 08:03:07 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:03:07 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.012
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.022
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.011
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.012
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.018
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.193
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.475
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.058
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.416
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.655
[09/04 08:03:07 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 1.162 | 2.216  | 1.058  | 0.040 | 1.222 | 1.829 |
[09/04 08:03:08 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:03:08 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:03:08 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:03:08 d2.evaluation.testing]: copypaste: 0.4755,1.7968,0.0607,0.0145,0.7808,0.5219
[09/04 08:03:08 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:03:08 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:03:08 d2.evaluation.testing]: copypaste: 1.1617,2.2158,1.0576,0.0400,1.2221,1.8295
[09/04 08:03:08 d2.utils.events]:  eta: 0:13:40  iter: 59  total_loss: 1.741  loss_cls: 0.5297  loss_box_reg: 0.5425  loss_mask: 0.6604  loss_rpn_cls: 0.01024  loss_rpn_loc: 0.006278  time: 0.8740  data_time: 0.0067  lr: 1.4985e-05  max_mem: 6718M
[09/04 08:03:25 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:03:25 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:03:25 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:03:25 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:03:25 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:03:35 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0023 s/iter. Inference: 0.1610 s/iter. Eval: 0.6904 s/iter. Total: 0.8537 s/iter. ETA=0:01:53
[09/04 08:03:40 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0030 s/iter. Inference: 0.1633 s/iter. Eval: 0.7167 s/iter. Total: 0.8832 s/iter. ETA=0:01:52
[09/04 08:03:45 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0027 s/iter. Inference: 0.1620 s/iter. Eval: 0.7145 s/iter. Total: 0.8795 s/iter. ETA=0:01:46
[09/04 08:03:51 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0027 s/iter. Inference: 0.1615 s/iter. Eval: 0.7085 s/iter. Total: 0.8729 s/iter. ETA=0:01:40
[09/04 08:03:56 d2.evaluation.evaluator]: Inference done 36/144. Dataloading: 0.0026 s/iter. Inference: 0.1611 s/iter. Eval: 0.6983 s/iter. Total: 0.8622 s/iter. ETA=0:01:33
[09/04 08:04:01 d2.evaluation.evaluator]: Inference done 42/144. Dataloading: 0.0025 s/iter. Inference: 0.1612 s/iter. Eval: 0.6971 s/iter. Total: 0.8611 s/iter. ETA=0:01:27
[09/04 08:04:07 d2.evaluation.evaluator]: Inference done 48/144. Dataloading: 0.0025 s/iter. Inference: 0.1611 s/iter. Eval: 0.6963 s/iter. Total: 0.8602 s/iter. ETA=0:01:22
[09/04 08:04:12 d2.evaluation.evaluator]: Inference done 54/144. Dataloading: 0.0024 s/iter. Inference: 0.1614 s/iter. Eval: 0.7010 s/iter. Total: 0.8651 s/iter. ETA=0:01:17
[09/04 08:04:18 d2.evaluation.evaluator]: Inference done 61/144. Dataloading: 0.0024 s/iter. Inference: 0.1611 s/iter. Eval: 0.6967 s/iter. Total: 0.8605 s/iter. ETA=0:01:11
[09/04 08:04:23 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0024 s/iter. Inference: 0.1611 s/iter. Eval: 0.6960 s/iter. Total: 0.8598 s/iter. ETA=0:01:06
[09/04 08:04:29 d2.evaluation.evaluator]: Inference done 74/144. Dataloading: 0.0024 s/iter. Inference: 0.1609 s/iter. Eval: 0.6929 s/iter. Total: 0.8565 s/iter. ETA=0:00:59
[09/04 08:04:34 d2.evaluation.evaluator]: Inference done 80/144. Dataloading: 0.0024 s/iter. Inference: 0.1609 s/iter. Eval: 0.6931 s/iter. Total: 0.8567 s/iter. ETA=0:00:54
[09/04 08:04:39 d2.evaluation.evaluator]: Inference done 86/144. Dataloading: 0.0024 s/iter. Inference: 0.1611 s/iter. Eval: 0.6959 s/iter. Total: 0.8597 s/iter. ETA=0:00:49
[09/04 08:04:44 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0024 s/iter. Inference: 0.1612 s/iter. Eval: 0.6954 s/iter. Total: 0.8593 s/iter. ETA=0:00:44
[09/04 08:04:50 d2.evaluation.evaluator]: Inference done 99/144. Dataloading: 0.0024 s/iter. Inference: 0.1611 s/iter. Eval: 0.6932 s/iter. Total: 0.8570 s/iter. ETA=0:00:38
[09/04 08:04:55 d2.evaluation.evaluator]: Inference done 105/144. Dataloading: 0.0024 s/iter. Inference: 0.1610 s/iter. Eval: 0.6930 s/iter. Total: 0.8567 s/iter. ETA=0:00:33
[09/04 08:05:01 d2.evaluation.evaluator]: Inference done 112/144. Dataloading: 0.0024 s/iter. Inference: 0.1610 s/iter. Eval: 0.6913 s/iter. Total: 0.8549 s/iter. ETA=0:00:27
[09/04 08:05:06 d2.evaluation.evaluator]: Inference done 118/144. Dataloading: 0.0024 s/iter. Inference: 0.1609 s/iter. Eval: 0.6914 s/iter. Total: 0.8550 s/iter. ETA=0:00:22
[09/04 08:05:12 d2.evaluation.evaluator]: Inference done 124/144. Dataloading: 0.0024 s/iter. Inference: 0.1611 s/iter. Eval: 0.6931 s/iter. Total: 0.8568 s/iter. ETA=0:00:17
[09/04 08:05:17 d2.evaluation.evaluator]: Inference done 130/144. Dataloading: 0.0023 s/iter. Inference: 0.1611 s/iter. Eval: 0.6928 s/iter. Total: 0.8566 s/iter. ETA=0:00:11
[09/04 08:05:22 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0023 s/iter. Inference: 0.1611 s/iter. Eval: 0.6913 s/iter. Total: 0.8550 s/iter. ETA=0:00:05
[09/04 08:05:28 d2.evaluation.evaluator]: Inference done 143/144. Dataloading: 0.0024 s/iter. Inference: 0.1610 s/iter. Eval: 0.6910 s/iter. Total: 0.8546 s/iter. ETA=0:00:00
[09/04 08:05:28 d2.evaluation.evaluator]: Total inference time: 0:01:58.824036 (0.854849 s / iter per device, on 1 devices)
[09/04 08:05:28 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:22 (0.160958 s / iter per device, on 1 devices)
[09/04 08:05:29 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:05:29 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:05:29 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/04 08:05:29 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:05:29 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.
[09/04 08:05:29 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:05:29 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.013
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.042
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.003
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.019
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.037
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.186
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.377
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.092
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.363
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.453
[09/04 08:05:29 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 1.265 | 4.163  | 0.301  | 0.096 | 1.886 | 1.497 |
Loading and preparing results...
DONE (t=0.33s)
creating index...
index created!
[09/04 08:05:30 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:05:30 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.23 seconds.
[09/04 08:05:30 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:05:30 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.026
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.048
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.024
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.026
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.041
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.073
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.301
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.548
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.133
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.503
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.702
[09/04 08:05:30 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 2.627 | 4.772  | 2.436  | 0.147 | 2.572 | 4.105 |
[09/04 08:05:30 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:05:30 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:05:30 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:05:30 d2.evaluation.testing]: copypaste: 1.2646,4.1626,0.3009,0.0962,1.8859,1.4972
[09/04 08:05:30 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:05:30 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:05:30 d2.evaluation.testing]: copypaste: 2.6272,4.7720,2.4359,0.1474,2.5716,4.1045
[09/04 08:05:30 d2.utils.events]:  eta: 0:13:21  iter: 79  total_loss: 1.336  loss_cls: 0.4085  loss_box_reg: 0.2845  loss_mask: 0.6159  loss_rpn_cls: 0.007986  loss_rpn_loc: 0.00284  time: 0.8720  data_time: 0.0062  lr: 1.998e-05  max_mem: 6718M
[09/04 08:05:47 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:05:47 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:05:47 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:05:47 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:05:47 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:05:57 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0020 s/iter. Inference: 0.1603 s/iter. Eval: 0.6712 s/iter. Total: 0.8335 s/iter. ETA=0:01:50
[09/04 08:06:02 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0022 s/iter. Inference: 0.1605 s/iter. Eval: 0.6792 s/iter. Total: 0.8421 s/iter. ETA=0:01:46
[09/04 08:06:08 d2.evaluation.evaluator]: Inference done 24/144. Dataloading: 0.0021 s/iter. Inference: 0.1605 s/iter. Eval: 0.6747 s/iter. Total: 0.8375 s/iter. ETA=0:01:40
[09/04 08:06:14 d2.evaluation.evaluator]: Inference done 30/144. Dataloading: 0.0021 s/iter. Inference: 0.1613 s/iter. Eval: 0.6875 s/iter. Total: 0.8512 s/iter. ETA=0:01:37
[09/04 08:06:19 d2.evaluation.evaluator]: Inference done 36/144. Dataloading: 0.0022 s/iter. Inference: 0.1616 s/iter. Eval: 0.6954 s/iter. Total: 0.8595 s/iter. ETA=0:01:32
[09/04 08:06:24 d2.evaluation.evaluator]: Inference done 42/144. Dataloading: 0.0021 s/iter. Inference: 0.1616 s/iter. Eval: 0.6950 s/iter. Total: 0.8590 s/iter. ETA=0:01:27
[09/04 08:06:30 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0023 s/iter. Inference: 0.1612 s/iter. Eval: 0.6908 s/iter. Total: 0.8545 s/iter. ETA=0:01:21
[09/04 08:06:35 d2.evaluation.evaluator]: Inference done 55/144. Dataloading: 0.0022 s/iter. Inference: 0.1611 s/iter. Eval: 0.6924 s/iter. Total: 0.8559 s/iter. ETA=0:01:16
[09/04 08:06:40 d2.evaluation.evaluator]: Inference done 61/144. Dataloading: 0.0022 s/iter. Inference: 0.1610 s/iter. Eval: 0.6908 s/iter. Total: 0.8543 s/iter. ETA=0:01:10
[09/04 08:06:45 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0023 s/iter. Inference: 0.1610 s/iter. Eval: 0.6907 s/iter. Total: 0.8542 s/iter. ETA=0:01:05
[09/04 08:06:51 d2.evaluation.evaluator]: Inference done 73/144. Dataloading: 0.0022 s/iter. Inference: 0.1609 s/iter. Eval: 0.6948 s/iter. Total: 0.8581 s/iter. ETA=0:01:00
[09/04 08:06:56 d2.evaluation.evaluator]: Inference done 79/144. Dataloading: 0.0022 s/iter. Inference: 0.1610 s/iter. Eval: 0.6950 s/iter. Total: 0.8585 s/iter. ETA=0:00:55
[09/04 08:07:02 d2.evaluation.evaluator]: Inference done 86/144. Dataloading: 0.0023 s/iter. Inference: 0.1610 s/iter. Eval: 0.6927 s/iter. Total: 0.8562 s/iter. ETA=0:00:49
[09/04 08:07:07 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0023 s/iter. Inference: 0.1609 s/iter. Eval: 0.6923 s/iter. Total: 0.8557 s/iter. ETA=0:00:44
[09/04 08:07:12 d2.evaluation.evaluator]: Inference done 99/144. Dataloading: 0.0023 s/iter. Inference: 0.1608 s/iter. Eval: 0.6902 s/iter. Total: 0.8536 s/iter. ETA=0:00:38
[09/04 08:07:18 d2.evaluation.evaluator]: Inference done 105/144. Dataloading: 0.0025 s/iter. Inference: 0.1609 s/iter. Eval: 0.6902 s/iter. Total: 0.8538 s/iter. ETA=0:00:33
[09/04 08:07:23 d2.evaluation.evaluator]: Inference done 111/144. Dataloading: 0.0024 s/iter. Inference: 0.1610 s/iter. Eval: 0.6925 s/iter. Total: 0.8562 s/iter. ETA=0:00:28
[09/04 08:07:28 d2.evaluation.evaluator]: Inference done 117/144. Dataloading: 0.0024 s/iter. Inference: 0.1609 s/iter. Eval: 0.6927 s/iter. Total: 0.8563 s/iter. ETA=0:00:23
[09/04 08:07:34 d2.evaluation.evaluator]: Inference done 124/144. Dataloading: 0.0024 s/iter. Inference: 0.1608 s/iter. Eval: 0.6911 s/iter. Total: 0.8546 s/iter. ETA=0:00:17
[09/04 08:07:39 d2.evaluation.evaluator]: Inference done 130/144. Dataloading: 0.0024 s/iter. Inference: 0.1607 s/iter. Eval: 0.6915 s/iter. Total: 0.8549 s/iter. ETA=0:00:11
[09/04 08:07:45 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0024 s/iter. Inference: 0.1607 s/iter. Eval: 0.6902 s/iter. Total: 0.8535 s/iter. ETA=0:00:05
[09/04 08:07:50 d2.evaluation.evaluator]: Inference done 143/144. Dataloading: 0.0024 s/iter. Inference: 0.1606 s/iter. Eval: 0.6908 s/iter. Total: 0.8540 s/iter. ETA=0:00:00
[09/04 08:07:51 d2.evaluation.evaluator]: Total inference time: 0:01:59.018896 (0.856251 s / iter per device, on 1 devices)
[09/04 08:07:51 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:22 (0.160598 s / iter per device, on 1 devices)
[09/04 08:07:51 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:07:51 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:07:52 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/04 08:07:52 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:07:52 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.
[09/04 08:07:52 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:07:52 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.027
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.074
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.011
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.034
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.033
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.085
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.258
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.418
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.117
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.394
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.515
[09/04 08:07:52 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 2.663 | 7.423  | 1.122  | 0.349 | 3.442 | 3.310 |
Loading and preparing results...
DONE (t=0.31s)
creating index...
index created!
[09/04 08:07:53 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:07:53 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.22 seconds.
[09/04 08:07:53 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:07:53 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.048
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.085
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.045
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.046
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.071
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.132
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.366
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.576
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.133
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.532
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.733
[09/04 08:07:53 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 4.811 | 8.468  | 4.538  | 0.370 | 4.649 | 7.141 |
[09/04 08:07:53 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:07:53 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:07:53 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:07:53 d2.evaluation.testing]: copypaste: 2.6633,7.4228,1.1216,0.3488,3.4420,3.3103
[09/04 08:07:53 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:07:53 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:07:53 d2.evaluation.testing]: copypaste: 4.8109,8.4683,4.5376,0.3696,4.6492,7.1407
[09/04 08:07:53 d2.utils.events]:  eta: 0:13:03  iter: 99  total_loss: 1.107  loss_cls: 0.3081  loss_box_reg: 0.2528  loss_mask: 0.5795  loss_rpn_cls: 0.006592  loss_rpn_loc: 0.001642  time: 0.8710  data_time: 0.0062  lr: 2.4975e-05  max_mem: 6718M
[09/04 08:08:10 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:08:10 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:08:10 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:08:10 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:08:10 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:08:20 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0017 s/iter. Inference: 0.1613 s/iter. Eval: 0.6785 s/iter. Total: 0.8415 s/iter. ETA=0:01:51
[09/04 08:08:26 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0024 s/iter. Inference: 0.1619 s/iter. Eval: 0.7336 s/iter. Total: 0.8982 s/iter. ETA=0:01:54
[09/04 08:08:31 d2.evaluation.evaluator]: Inference done 24/144. Dataloading: 0.0023 s/iter. Inference: 0.1612 s/iter. Eval: 0.7090 s/iter. Total: 0.8727 s/iter. ETA=0:01:44
[09/04 08:08:37 d2.evaluation.evaluator]: Inference done 30/144. Dataloading: 0.0023 s/iter. Inference: 0.1609 s/iter. Eval: 0.7060 s/iter. Total: 0.8695 s/iter. ETA=0:01:39
[09/04 08:08:42 d2.evaluation.evaluator]: Inference done 37/144. Dataloading: 0.0023 s/iter. Inference: 0.1607 s/iter. Eval: 0.6976 s/iter. Total: 0.8608 s/iter. ETA=0:01:32
[09/04 08:08:48 d2.evaluation.evaluator]: Inference done 43/144. Dataloading: 0.0023 s/iter. Inference: 0.1606 s/iter. Eval: 0.7039 s/iter. Total: 0.8670 s/iter. ETA=0:01:27
[09/04 08:08:54 d2.evaluation.evaluator]: Inference done 50/144. Dataloading: 0.0023 s/iter. Inference: 0.1605 s/iter. Eval: 0.6979 s/iter. Total: 0.8610 s/iter. ETA=0:01:20
[09/04 08:08:59 d2.evaluation.evaluator]: Inference done 56/144. Dataloading: 0.0023 s/iter. Inference: 0.1607 s/iter. Eval: 0.7069 s/iter. Total: 0.8701 s/iter. ETA=0:01:16
[09/04 08:09:05 d2.evaluation.evaluator]: Inference done 63/144. Dataloading: 0.0024 s/iter. Inference: 0.1606 s/iter. Eval: 0.7017 s/iter. Total: 0.8649 s/iter. ETA=0:01:10
[09/04 08:09:10 d2.evaluation.evaluator]: Inference done 69/144. Dataloading: 0.0024 s/iter. Inference: 0.1608 s/iter. Eval: 0.7023 s/iter. Total: 0.8658 s/iter. ETA=0:01:04
[09/04 08:09:16 d2.evaluation.evaluator]: Inference done 76/144. Dataloading: 0.0024 s/iter. Inference: 0.1608 s/iter. Eval: 0.6986 s/iter. Total: 0.8620 s/iter. ETA=0:00:58
[09/04 08:09:21 d2.evaluation.evaluator]: Inference done 82/144. Dataloading: 0.0024 s/iter. Inference: 0.1607 s/iter. Eval: 0.6979 s/iter. Total: 0.8612 s/iter. ETA=0:00:53
[09/04 08:09:27 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0024 s/iter. Inference: 0.1607 s/iter. Eval: 0.6954 s/iter. Total: 0.8586 s/iter. ETA=0:00:47
[09/04 08:09:33 d2.evaluation.evaluator]: Inference done 95/144. Dataloading: 0.0024 s/iter. Inference: 0.1607 s/iter. Eval: 0.7013 s/iter. Total: 0.8647 s/iter. ETA=0:00:42
[09/04 08:09:38 d2.evaluation.evaluator]: Inference done 101/144. Dataloading: 0.0024 s/iter. Inference: 0.1607 s/iter. Eval: 0.6997 s/iter. Total: 0.8630 s/iter. ETA=0:00:37
[09/04 08:09:43 d2.evaluation.evaluator]: Inference done 107/144. Dataloading: 0.0023 s/iter. Inference: 0.1607 s/iter. Eval: 0.6991 s/iter. Total: 0.8624 s/iter. ETA=0:00:31
[09/04 08:09:49 d2.evaluation.evaluator]: Inference done 114/144. Dataloading: 0.0023 s/iter. Inference: 0.1606 s/iter. Eval: 0.6969 s/iter. Total: 0.8600 s/iter. ETA=0:00:25
[09/04 08:09:54 d2.evaluation.evaluator]: Inference done 120/144. Dataloading: 0.0023 s/iter. Inference: 0.1606 s/iter. Eval: 0.6964 s/iter. Total: 0.8595 s/iter. ETA=0:00:20
[09/04 08:10:00 d2.evaluation.evaluator]: Inference done 127/144. Dataloading: 0.0023 s/iter. Inference: 0.1605 s/iter. Eval: 0.6958 s/iter. Total: 0.8589 s/iter. ETA=0:00:14
[09/04 08:10:05 d2.evaluation.evaluator]: Inference done 133/144. Dataloading: 0.0024 s/iter. Inference: 0.1605 s/iter. Eval: 0.6973 s/iter. Total: 0.8604 s/iter. ETA=0:00:09
[09/04 08:10:11 d2.evaluation.evaluator]: Inference done 140/144. Dataloading: 0.0024 s/iter. Inference: 0.1605 s/iter. Eval: 0.6955 s/iter. Total: 0.8586 s/iter. ETA=0:00:03
[09/04 08:10:14 d2.evaluation.evaluator]: Total inference time: 0:01:59.350288 (0.858635 s / iter per device, on 1 devices)
[09/04 08:10:14 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:22 (0.160427 s / iter per device, on 1 devices)
[09/04 08:10:14 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:10:14 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:10:15 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/04 08:10:15 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:10:15 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[09/04 08:10:15 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:10:15 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.050
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.125
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.024
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.013
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.066
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.062
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.136
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.311
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.466
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.142
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.443
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.565
[09/04 08:10:15 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 5.048 | 12.543 | 2.382  | 1.322 | 6.626 | 6.211 |
Loading and preparing results...
DONE (t=0.31s)
creating index...
index created!
[09/04 08:10:15 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:10:16 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.22 seconds.
[09/04 08:10:16 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:10:16 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.085
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.139
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.091
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.078
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.127
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.180
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.413
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.604
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.566
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.748
[09/04 08:10:16 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 8.454 | 13.874 | 9.103  | 0.758 | 7.808 | 12.680 |
[09/04 08:10:16 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:10:16 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:10:16 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:10:16 d2.evaluation.testing]: copypaste: 5.0476,12.5431,2.3816,1.3217,6.6260,6.2115
[09/04 08:10:16 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:10:16 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:10:16 d2.evaluation.testing]: copypaste: 8.4544,13.8736,9.1035,0.7576,7.8085,12.6801
[09/04 08:10:16 d2.utils.events]:  eta: 0:12:43  iter: 119  total_loss: 1.21  loss_cls: 0.3027  loss_box_reg: 0.3727  loss_mask: 0.5383  loss_rpn_cls: 0.01877  loss_rpn_loc: 0.006234  time: 0.8701  data_time: 0.0063  lr: 2.997e-05  max_mem: 6718M
[09/04 08:10:33 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:10:33 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:10:33 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:10:33 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:10:33 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:10:43 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0017 s/iter. Inference: 0.1609 s/iter. Eval: 0.6769 s/iter. Total: 0.8395 s/iter. ETA=0:01:51
[09/04 08:10:48 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0018 s/iter. Inference: 0.1619 s/iter. Eval: 0.6834 s/iter. Total: 0.8474 s/iter. ETA=0:01:47
[09/04 08:10:53 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0021 s/iter. Inference: 0.1612 s/iter. Eval: 0.6798 s/iter. Total: 0.8434 s/iter. ETA=0:01:42
[09/04 08:10:58 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0024 s/iter. Inference: 0.1617 s/iter. Eval: 0.6848 s/iter. Total: 0.8492 s/iter. ETA=0:01:37
[09/04 08:11:03 d2.evaluation.evaluator]: Inference done 35/144. Dataloading: 0.0023 s/iter. Inference: 0.1614 s/iter. Eval: 0.6824 s/iter. Total: 0.8464 s/iter. ETA=0:01:32
[09/04 08:11:09 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0023 s/iter. Inference: 0.1618 s/iter. Eval: 0.6960 s/iter. Total: 0.8603 s/iter. ETA=0:01:28
[09/04 08:11:15 d2.evaluation.evaluator]: Inference done 48/144. Dataloading: 0.0025 s/iter. Inference: 0.1615 s/iter. Eval: 0.6914 s/iter. Total: 0.8556 s/iter. ETA=0:01:22
[09/04 08:11:20 d2.evaluation.evaluator]: Inference done 54/144. Dataloading: 0.0027 s/iter. Inference: 0.1614 s/iter. Eval: 0.6966 s/iter. Total: 0.8609 s/iter. ETA=0:01:17
[09/04 08:11:26 d2.evaluation.evaluator]: Inference done 61/144. Dataloading: 0.0026 s/iter. Inference: 0.1613 s/iter. Eval: 0.6929 s/iter. Total: 0.8571 s/iter. ETA=0:01:11
[09/04 08:11:31 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0026 s/iter. Inference: 0.1613 s/iter. Eval: 0.6931 s/iter. Total: 0.8572 s/iter. ETA=0:01:06
[09/04 08:11:36 d2.evaluation.evaluator]: Inference done 73/144. Dataloading: 0.0026 s/iter. Inference: 0.1612 s/iter. Eval: 0.6912 s/iter. Total: 0.8551 s/iter. ETA=0:01:00
[09/04 08:11:42 d2.evaluation.evaluator]: Inference done 79/144. Dataloading: 0.0025 s/iter. Inference: 0.1615 s/iter. Eval: 0.6974 s/iter. Total: 0.8617 s/iter. ETA=0:00:56
[09/04 08:11:48 d2.evaluation.evaluator]: Inference done 86/144. Dataloading: 0.0026 s/iter. Inference: 0.1613 s/iter. Eval: 0.6948 s/iter. Total: 0.8590 s/iter. ETA=0:00:49
[09/04 08:11:53 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0025 s/iter. Inference: 0.1613 s/iter. Eval: 0.6947 s/iter. Total: 0.8587 s/iter. ETA=0:00:44
[09/04 08:11:59 d2.evaluation.evaluator]: Inference done 99/144. Dataloading: 0.0025 s/iter. Inference: 0.1612 s/iter. Eval: 0.6926 s/iter. Total: 0.8565 s/iter. ETA=0:00:38
[09/04 08:12:04 d2.evaluation.evaluator]: Inference done 105/144. Dataloading: 0.0025 s/iter. Inference: 0.1612 s/iter. Eval: 0.6924 s/iter. Total: 0.8563 s/iter. ETA=0:00:33
[09/04 08:12:09 d2.evaluation.evaluator]: Inference done 111/144. Dataloading: 0.0025 s/iter. Inference: 0.1611 s/iter. Eval: 0.6923 s/iter. Total: 0.8561 s/iter. ETA=0:00:28
[09/04 08:12:14 d2.evaluation.evaluator]: Inference done 117/144. Dataloading: 0.0025 s/iter. Inference: 0.1611 s/iter. Eval: 0.6948 s/iter. Total: 0.8585 s/iter. ETA=0:00:23
[09/04 08:12:19 d2.evaluation.evaluator]: Inference done 123/144. Dataloading: 0.0024 s/iter. Inference: 0.1610 s/iter. Eval: 0.6937 s/iter. Total: 0.8574 s/iter. ETA=0:00:18
[09/04 08:12:24 d2.evaluation.evaluator]: Inference done 129/144. Dataloading: 0.0024 s/iter. Inference: 0.1609 s/iter. Eval: 0.6938 s/iter. Total: 0.8574 s/iter. ETA=0:00:12
[09/04 08:12:30 d2.evaluation.evaluator]: Inference done 136/144. Dataloading: 0.0024 s/iter. Inference: 0.1609 s/iter. Eval: 0.6925 s/iter. Total: 0.8560 s/iter. ETA=0:00:06
[09/04 08:12:35 d2.evaluation.evaluator]: Inference done 142/144. Dataloading: 0.0024 s/iter. Inference: 0.1608 s/iter. Eval: 0.6925 s/iter. Total: 0.8560 s/iter. ETA=0:00:01
[09/04 08:12:37 d2.evaluation.evaluator]: Total inference time: 0:01:58.993870 (0.856071 s / iter per device, on 1 devices)
[09/04 08:12:37 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:22 (0.160721 s / iter per device, on 1 devices)
[09/04 08:12:37 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:12:37 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:12:37 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/04 08:12:37 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:12:38 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.
[09/04 08:12:38 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:12:38 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.102
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.219
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.057
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.031
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.117
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.140
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.164
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.349
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.500
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.482
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.586
[09/04 08:12:38 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 10.184 | 21.909 | 5.701  | 3.051 | 11.701 | 13.989 |
Loading and preparing results...
DONE (t=0.31s)
creating index...
index created!
[09/04 08:12:38 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:12:39 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.22 seconds.
[09/04 08:12:39 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:12:39 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.153
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.235
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.172
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.128
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.254
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.210
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.438
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.617
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.225
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.583
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.748
[09/04 08:12:39 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 15.347 | 23.549 | 17.169 | 2.051 | 12.839 | 25.426 |
[09/04 08:12:39 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:12:39 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:12:39 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:12:39 d2.evaluation.testing]: copypaste: 10.1841,21.9087,5.7005,3.0515,11.7006,13.9888
[09/04 08:12:39 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:12:39 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:12:39 d2.evaluation.testing]: copypaste: 15.3466,23.5493,17.1687,2.0513,12.8394,25.4263
[09/04 08:12:39 d2.utils.events]:  eta: 0:12:26  iter: 139  total_loss: 1.195  loss_cls: 0.2918  loss_box_reg: 0.4088  loss_mask: 0.4636  loss_rpn_cls: 0.01007  loss_rpn_loc: 0.004722  time: 0.8702  data_time: 0.0065  lr: 3.4965e-05  max_mem: 6718M
[09/04 08:12:56 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:12:56 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:12:56 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:12:56 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:12:56 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:13:06 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0018 s/iter. Inference: 0.1605 s/iter. Eval: 0.6662 s/iter. Total: 0.8285 s/iter. ETA=0:01:50
[09/04 08:13:11 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0023 s/iter. Inference: 0.1607 s/iter. Eval: 0.6788 s/iter. Total: 0.8421 s/iter. ETA=0:01:46
[09/04 08:13:16 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0025 s/iter. Inference: 0.1620 s/iter. Eval: 0.6938 s/iter. Total: 0.8585 s/iter. ETA=0:01:43
[09/04 08:13:22 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0026 s/iter. Inference: 0.1620 s/iter. Eval: 0.6934 s/iter. Total: 0.8582 s/iter. ETA=0:01:38
[09/04 08:13:27 d2.evaluation.evaluator]: Inference done 36/144. Dataloading: 0.0026 s/iter. Inference: 0.1617 s/iter. Eval: 0.6875 s/iter. Total: 0.8520 s/iter. ETA=0:01:32
[09/04 08:13:32 d2.evaluation.evaluator]: Inference done 42/144. Dataloading: 0.0025 s/iter. Inference: 0.1616 s/iter. Eval: 0.6888 s/iter. Total: 0.8532 s/iter. ETA=0:01:27
[09/04 08:13:38 d2.evaluation.evaluator]: Inference done 48/144. Dataloading: 0.0025 s/iter. Inference: 0.1614 s/iter. Eval: 0.6868 s/iter. Total: 0.8510 s/iter. ETA=0:01:21
[09/04 08:13:43 d2.evaluation.evaluator]: Inference done 54/144. Dataloading: 0.0027 s/iter. Inference: 0.1616 s/iter. Eval: 0.6876 s/iter. Total: 0.8521 s/iter. ETA=0:01:16
[09/04 08:13:48 d2.evaluation.evaluator]: Inference done 60/144. Dataloading: 0.0028 s/iter. Inference: 0.1617 s/iter. Eval: 0.6961 s/iter. Total: 0.8608 s/iter. ETA=0:01:12
[09/04 08:13:53 d2.evaluation.evaluator]: Inference done 66/144. Dataloading: 0.0027 s/iter. Inference: 0.1617 s/iter. Eval: 0.6961 s/iter. Total: 0.8607 s/iter. ETA=0:01:07
[09/04 08:13:59 d2.evaluation.evaluator]: Inference done 73/144. Dataloading: 0.0026 s/iter. Inference: 0.1615 s/iter. Eval: 0.6933 s/iter. Total: 0.8577 s/iter. ETA=0:01:00
[09/04 08:14:04 d2.evaluation.evaluator]: Inference done 79/144. Dataloading: 0.0027 s/iter. Inference: 0.1614 s/iter. Eval: 0.6928 s/iter. Total: 0.8571 s/iter. ETA=0:00:55
[09/04 08:14:10 d2.evaluation.evaluator]: Inference done 86/144. Dataloading: 0.0027 s/iter. Inference: 0.1613 s/iter. Eval: 0.6906 s/iter. Total: 0.8548 s/iter. ETA=0:00:49
[09/04 08:14:15 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0026 s/iter. Inference: 0.1613 s/iter. Eval: 0.6910 s/iter. Total: 0.8551 s/iter. ETA=0:00:44
[09/04 08:14:21 d2.evaluation.evaluator]: Inference done 98/144. Dataloading: 0.0027 s/iter. Inference: 0.1615 s/iter. Eval: 0.6938 s/iter. Total: 0.8582 s/iter. ETA=0:00:39
[09/04 08:14:26 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0026 s/iter. Inference: 0.1614 s/iter. Eval: 0.6946 s/iter. Total: 0.8588 s/iter. ETA=0:00:34
[09/04 08:14:32 d2.evaluation.evaluator]: Inference done 111/144. Dataloading: 0.0026 s/iter. Inference: 0.1613 s/iter. Eval: 0.6926 s/iter. Total: 0.8567 s/iter. ETA=0:00:28
[09/04 08:14:37 d2.evaluation.evaluator]: Inference done 117/144. Dataloading: 0.0026 s/iter. Inference: 0.1612 s/iter. Eval: 0.6923 s/iter. Total: 0.8563 s/iter. ETA=0:00:23
[09/04 08:14:43 d2.evaluation.evaluator]: Inference done 124/144. Dataloading: 0.0025 s/iter. Inference: 0.1612 s/iter. Eval: 0.6910 s/iter. Total: 0.8549 s/iter. ETA=0:00:17
[09/04 08:14:48 d2.evaluation.evaluator]: Inference done 130/144. Dataloading: 0.0025 s/iter. Inference: 0.1611 s/iter. Eval: 0.6910 s/iter. Total: 0.8549 s/iter. ETA=0:00:11
[09/04 08:14:53 d2.evaluation.evaluator]: Inference done 136/144. Dataloading: 0.0025 s/iter. Inference: 0.1612 s/iter. Eval: 0.6932 s/iter. Total: 0.8571 s/iter. ETA=0:00:06
[09/04 08:14:58 d2.evaluation.evaluator]: Inference done 142/144. Dataloading: 0.0025 s/iter. Inference: 0.1612 s/iter. Eval: 0.6936 s/iter. Total: 0.8575 s/iter. ETA=0:00:01
[09/04 08:15:00 d2.evaluation.evaluator]: Total inference time: 0:01:59.201771 (0.857567 s / iter per device, on 1 devices)
[09/04 08:15:00 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:22 (0.161120 s / iter per device, on 1 devices)
[09/04 08:15:00 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:15:00 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:15:00 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/04 08:15:00 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:15:01 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[09/04 08:15:01 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:15:01 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.154
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.316
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.093
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.059
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.170
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.218
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.180
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.392
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.519
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.267
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.501
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.595
[09/04 08:15:01 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 15.372 | 31.645 | 9.265  | 5.887 | 16.959 | 21.843 |
Loading and preparing results...
DONE (t=0.31s)
creating index...
index created!
[09/04 08:15:01 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:15:02 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.24 seconds.
[09/04 08:15:02 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:15:02 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.226
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.328
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.260
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.075
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.172
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.378
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.228
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.467
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.635
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.267
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.605
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.755
[09/04 08:15:02 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 22.595 | 32.842 | 25.983 | 7.467 | 17.156 | 37.767 |
[09/04 08:15:02 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:15:02 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:15:02 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:15:02 d2.evaluation.testing]: copypaste: 15.3720,31.6445,9.2648,5.8870,16.9590,21.8430
[09/04 08:15:02 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:15:02 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:15:02 d2.evaluation.testing]: copypaste: 22.5949,32.8424,25.9834,7.4671,17.1560,37.7670
[09/04 08:15:02 d2.utils.events]:  eta: 0:12:08  iter: 159  total_loss: 0.9568  loss_cls: 0.2168  loss_box_reg: 0.3146  loss_mask: 0.3993  loss_rpn_cls: 0.008258  loss_rpn_loc: 0.002624  time: 0.8705  data_time: 0.0062  lr: 3.996e-05  max_mem: 6718M
[09/04 08:15:19 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:15:19 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:15:19 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:15:19 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:15:19 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:15:29 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0030 s/iter. Inference: 0.1640 s/iter. Eval: 0.7644 s/iter. Total: 0.9314 s/iter. ETA=0:02:03
[09/04 08:15:35 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0028 s/iter. Inference: 0.1624 s/iter. Eval: 0.7368 s/iter. Total: 0.9023 s/iter. ETA=0:01:54
[09/04 08:15:41 d2.evaluation.evaluator]: Inference done 24/144. Dataloading: 0.0025 s/iter. Inference: 0.1612 s/iter. Eval: 0.7120 s/iter. Total: 0.8759 s/iter. ETA=0:01:45
[09/04 08:15:46 d2.evaluation.evaluator]: Inference done 30/144. Dataloading: 0.0024 s/iter. Inference: 0.1608 s/iter. Eval: 0.7111 s/iter. Total: 0.8745 s/iter. ETA=0:01:39
[09/04 08:15:51 d2.evaluation.evaluator]: Inference done 37/144. Dataloading: 0.0024 s/iter. Inference: 0.1597 s/iter. Eval: 0.6919 s/iter. Total: 0.8543 s/iter. ETA=0:01:31
[09/04 08:15:56 d2.evaluation.evaluator]: Inference done 43/144. Dataloading: 0.0024 s/iter. Inference: 0.1595 s/iter. Eval: 0.6901 s/iter. Total: 0.8523 s/iter. ETA=0:01:26
[09/04 08:16:02 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0024 s/iter. Inference: 0.1601 s/iter. Eval: 0.6976 s/iter. Total: 0.8604 s/iter. ETA=0:01:21
[09/04 08:16:07 d2.evaluation.evaluator]: Inference done 55/144. Dataloading: 0.0023 s/iter. Inference: 0.1601 s/iter. Eval: 0.6979 s/iter. Total: 0.8607 s/iter. ETA=0:01:16
[09/04 08:16:12 d2.evaluation.evaluator]: Inference done 61/144. Dataloading: 0.0023 s/iter. Inference: 0.1601 s/iter. Eval: 0.6958 s/iter. Total: 0.8585 s/iter. ETA=0:01:11
[09/04 08:16:17 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0023 s/iter. Inference: 0.1601 s/iter. Eval: 0.6971 s/iter. Total: 0.8598 s/iter. ETA=0:01:06
[09/04 08:16:22 d2.evaluation.evaluator]: Inference done 73/144. Dataloading: 0.0023 s/iter. Inference: 0.1599 s/iter. Eval: 0.6960 s/iter. Total: 0.8585 s/iter. ETA=0:01:00
[09/04 08:16:27 d2.evaluation.evaluator]: Inference done 80/144. Dataloading: 0.0024 s/iter. Inference: 0.1594 s/iter. Eval: 0.6860 s/iter. Total: 0.8481 s/iter. ETA=0:00:54
[09/04 08:16:33 d2.evaluation.evaluator]: Inference done 86/144. Dataloading: 0.0024 s/iter. Inference: 0.1598 s/iter. Eval: 0.6910 s/iter. Total: 0.8534 s/iter. ETA=0:00:49
[09/04 08:16:38 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0024 s/iter. Inference: 0.1600 s/iter. Eval: 0.6938 s/iter. Total: 0.8565 s/iter. ETA=0:00:44
[09/04 08:16:43 d2.evaluation.evaluator]: Inference done 98/144. Dataloading: 0.0024 s/iter. Inference: 0.1600 s/iter. Eval: 0.6929 s/iter. Total: 0.8556 s/iter. ETA=0:00:39
[09/04 08:16:48 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0025 s/iter. Inference: 0.1598 s/iter. Eval: 0.6919 s/iter. Total: 0.8544 s/iter. ETA=0:00:34
[09/04 08:16:54 d2.evaluation.evaluator]: Inference done 110/144. Dataloading: 0.0025 s/iter. Inference: 0.1598 s/iter. Eval: 0.6913 s/iter. Total: 0.8538 s/iter. ETA=0:00:29
[09/04 08:16:59 d2.evaluation.evaluator]: Inference done 116/144. Dataloading: 0.0025 s/iter. Inference: 0.1598 s/iter. Eval: 0.6914 s/iter. Total: 0.8539 s/iter. ETA=0:00:23
[09/04 08:17:04 d2.evaluation.evaluator]: Inference done 122/144. Dataloading: 0.0025 s/iter. Inference: 0.1597 s/iter. Eval: 0.6931 s/iter. Total: 0.8556 s/iter. ETA=0:00:18
[09/04 08:17:09 d2.evaluation.evaluator]: Inference done 128/144. Dataloading: 0.0025 s/iter. Inference: 0.1599 s/iter. Eval: 0.6928 s/iter. Total: 0.8554 s/iter. ETA=0:00:13
[09/04 08:17:14 d2.evaluation.evaluator]: Inference done 134/144. Dataloading: 0.0025 s/iter. Inference: 0.1600 s/iter. Eval: 0.6930 s/iter. Total: 0.8557 s/iter. ETA=0:00:08
[09/04 08:17:20 d2.evaluation.evaluator]: Inference done 141/144. Dataloading: 0.0025 s/iter. Inference: 0.1595 s/iter. Eval: 0.6881 s/iter. Total: 0.8504 s/iter. ETA=0:00:02
[09/04 08:17:22 d2.evaluation.evaluator]: Total inference time: 0:01:58.434518 (0.852047 s / iter per device, on 1 devices)
[09/04 08:17:22 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:22 (0.159500 s / iter per device, on 1 devices)
[09/04 08:17:22 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:17:22 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:17:23 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/04 08:17:23 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:17:23 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[09/04 08:17:23 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:17:23 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.200
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.388
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.145
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.060
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.196
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.298
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.199
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.397
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.533
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.275
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.513
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.615
[09/04 08:17:23 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 20.023 | 38.794 | 14.495 | 5.970 | 19.550 | 29.765 |
Loading and preparing results...
DONE (t=0.28s)
creating index...
index created!
[09/04 08:17:24 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:17:24 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.21 seconds.
[09/04 08:17:24 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:17:24 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.278
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.391
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.328
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.075
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.195
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.470
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.249
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.478
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.649
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.292
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.620
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.764
[09/04 08:17:24 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 27.822 | 39.146 | 32.798 | 7.503 | 19.505 | 47.036 |
[09/04 08:17:24 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:17:24 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:17:24 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:17:24 d2.evaluation.testing]: copypaste: 20.0229,38.7938,14.4948,5.9697,19.5502,29.7647
[09/04 08:17:24 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:17:24 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:17:24 d2.evaluation.testing]: copypaste: 27.8216,39.1459,32.7980,7.5027,19.5050,47.0365
[09/04 08:17:24 d2.utils.events]:  eta: 0:11:51  iter: 179  total_loss: 1.012  loss_cls: 0.1992  loss_box_reg: 0.369  loss_mask: 0.3589  loss_rpn_cls: 0.007045  loss_rpn_loc: 0.004363  time: 0.8702  data_time: 0.0061  lr: 4.4955e-05  max_mem: 6718M
[09/04 08:17:41 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:17:41 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:17:41 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:17:41 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:17:41 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:17:51 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0015 s/iter. Inference: 0.1610 s/iter. Eval: 0.6708 s/iter. Total: 0.8334 s/iter. ETA=0:01:50
[09/04 08:17:56 d2.evaluation.evaluator]: Inference done 17/144. Dataloading: 0.0023 s/iter. Inference: 0.1600 s/iter. Eval: 0.6774 s/iter. Total: 0.8399 s/iter. ETA=0:01:46
[09/04 08:18:01 d2.evaluation.evaluator]: Inference done 24/144. Dataloading: 0.0022 s/iter. Inference: 0.1578 s/iter. Eval: 0.6520 s/iter. Total: 0.8122 s/iter. ETA=0:01:37
[09/04 08:18:07 d2.evaluation.evaluator]: Inference done 31/144. Dataloading: 0.0022 s/iter. Inference: 0.1563 s/iter. Eval: 0.6341 s/iter. Total: 0.7928 s/iter. ETA=0:01:29
[09/04 08:18:12 d2.evaluation.evaluator]: Inference done 37/144. Dataloading: 0.0022 s/iter. Inference: 0.1566 s/iter. Eval: 0.6422 s/iter. Total: 0.8013 s/iter. ETA=0:01:25
[09/04 08:18:17 d2.evaluation.evaluator]: Inference done 44/144. Dataloading: 0.0023 s/iter. Inference: 0.1561 s/iter. Eval: 0.6373 s/iter. Total: 0.7959 s/iter. ETA=0:01:19
[09/04 08:18:23 d2.evaluation.evaluator]: Inference done 51/144. Dataloading: 0.0022 s/iter. Inference: 0.1567 s/iter. Eval: 0.6422 s/iter. Total: 0.8014 s/iter. ETA=0:01:14
[09/04 08:18:28 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0022 s/iter. Inference: 0.1572 s/iter. Eval: 0.6479 s/iter. Total: 0.8076 s/iter. ETA=0:01:10
[09/04 08:18:34 d2.evaluation.evaluator]: Inference done 64/144. Dataloading: 0.0023 s/iter. Inference: 0.1576 s/iter. Eval: 0.6502 s/iter. Total: 0.8103 s/iter. ETA=0:01:04
[09/04 08:18:39 d2.evaluation.evaluator]: Inference done 70/144. Dataloading: 0.0023 s/iter. Inference: 0.1579 s/iter. Eval: 0.6542 s/iter. Total: 0.8147 s/iter. ETA=0:01:00
[09/04 08:18:44 d2.evaluation.evaluator]: Inference done 78/144. Dataloading: 0.0024 s/iter. Inference: 0.1571 s/iter. Eval: 0.6415 s/iter. Total: 0.8013 s/iter. ETA=0:00:52
[09/04 08:18:50 d2.evaluation.evaluator]: Inference done 84/144. Dataloading: 0.0024 s/iter. Inference: 0.1576 s/iter. Eval: 0.6443 s/iter. Total: 0.8045 s/iter. ETA=0:00:48
[09/04 08:18:55 d2.evaluation.evaluator]: Inference done 91/144. Dataloading: 0.0024 s/iter. Inference: 0.1577 s/iter. Eval: 0.6461 s/iter. Total: 0.8065 s/iter. ETA=0:00:42
[09/04 08:19:01 d2.evaluation.evaluator]: Inference done 97/144. Dataloading: 0.0024 s/iter. Inference: 0.1579 s/iter. Eval: 0.6525 s/iter. Total: 0.8130 s/iter. ETA=0:00:38
[09/04 08:19:06 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0024 s/iter. Inference: 0.1576 s/iter. Eval: 0.6481 s/iter. Total: 0.8083 s/iter. ETA=0:00:32
[09/04 08:19:11 d2.evaluation.evaluator]: Inference done 110/144. Dataloading: 0.0024 s/iter. Inference: 0.1576 s/iter. Eval: 0.6496 s/iter. Total: 0.8097 s/iter. ETA=0:00:27
[09/04 08:19:17 d2.evaluation.evaluator]: Inference done 117/144. Dataloading: 0.0024 s/iter. Inference: 0.1576 s/iter. Eval: 0.6502 s/iter. Total: 0.8105 s/iter. ETA=0:00:21
[09/04 08:19:22 d2.evaluation.evaluator]: Inference done 124/144. Dataloading: 0.0024 s/iter. Inference: 0.1574 s/iter. Eval: 0.6485 s/iter. Total: 0.8085 s/iter. ETA=0:00:16
[09/04 08:19:28 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0024 s/iter. Inference: 0.1575 s/iter. Eval: 0.6483 s/iter. Total: 0.8084 s/iter. ETA=0:00:10
[09/04 08:19:33 d2.evaluation.evaluator]: Inference done 138/144. Dataloading: 0.0024 s/iter. Inference: 0.1573 s/iter. Eval: 0.6467 s/iter. Total: 0.8066 s/iter. ETA=0:00:04
[09/04 08:19:38 d2.evaluation.evaluator]: Total inference time: 0:01:51.601711 (0.802890 s / iter per device, on 1 devices)
[09/04 08:19:38 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:21 (0.156892 s / iter per device, on 1 devices)
[09/04 08:19:38 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:19:38 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:19:38 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/04 08:19:38 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:19:38 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[09/04 08:19:38 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:19:38 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.222
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.429
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.152
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.062
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.218
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.315
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.216
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.423
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.542
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.283
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.524
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.621
[09/04 08:19:38 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 22.161 | 42.866 | 15.228 | 6.162 | 21.838 | 31.517 |
Loading and preparing results...
DONE (t=0.27s)
creating index...
index created!
[09/04 08:19:39 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:19:39 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.19 seconds.
[09/04 08:19:39 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:19:39 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.301
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.424
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.361
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.075
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.207
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.507
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.258
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.505
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.650
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.292
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.622
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.764
[09/04 08:19:39 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 30.094 | 42.377 | 36.055 | 7.526 | 20.678 | 50.676 |
[09/04 08:19:39 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:19:39 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:19:39 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:19:39 d2.evaluation.testing]: copypaste: 22.1611,42.8661,15.2277,6.1618,21.8382,31.5170
[09/04 08:19:39 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:19:39 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:19:39 d2.evaluation.testing]: copypaste: 30.0945,42.3772,36.0555,7.5262,20.6781,50.6762
[09/04 08:19:39 d2.utils.events]:  eta: 0:11:33  iter: 199  total_loss: 0.8666  loss_cls: 0.1759  loss_box_reg: 0.256  loss_mask: 0.333  loss_rpn_cls: 0.00679  loss_rpn_loc: 0.005862  time: 0.8703  data_time: 0.0066  lr: 4.995e-05  max_mem: 6718M
[09/04 08:19:56 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:19:56 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:19:56 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:19:56 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:19:56 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:20:06 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0020 s/iter. Inference: 0.1599 s/iter. Eval: 0.6928 s/iter. Total: 0.8548 s/iter. ETA=0:01:53
[09/04 08:20:12 d2.evaluation.evaluator]: Inference done 18/144. Dataloading: 0.0021 s/iter. Inference: 0.1585 s/iter. Eval: 0.6652 s/iter. Total: 0.8260 s/iter. ETA=0:01:44
[09/04 08:20:18 d2.evaluation.evaluator]: Inference done 26/144. Dataloading: 0.0022 s/iter. Inference: 0.1558 s/iter. Eval: 0.6345 s/iter. Total: 0.7929 s/iter. ETA=0:01:33
[09/04 08:20:23 d2.evaluation.evaluator]: Inference done 33/144. Dataloading: 0.0026 s/iter. Inference: 0.1543 s/iter. Eval: 0.6300 s/iter. Total: 0.7871 s/iter. ETA=0:01:27
[09/04 08:20:28 d2.evaluation.evaluator]: Inference done 40/144. Dataloading: 0.0026 s/iter. Inference: 0.1535 s/iter. Eval: 0.6206 s/iter. Total: 0.7769 s/iter. ETA=0:01:20
[09/04 08:20:34 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0026 s/iter. Inference: 0.1540 s/iter. Eval: 0.6235 s/iter. Total: 0.7803 s/iter. ETA=0:01:15
[09/04 08:20:39 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0025 s/iter. Inference: 0.1547 s/iter. Eval: 0.6308 s/iter. Total: 0.7883 s/iter. ETA=0:01:11
[09/04 08:20:44 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0026 s/iter. Inference: 0.1553 s/iter. Eval: 0.6373 s/iter. Total: 0.7956 s/iter. ETA=0:01:07
[09/04 08:20:50 d2.evaluation.evaluator]: Inference done 66/144. Dataloading: 0.0026 s/iter. Inference: 0.1556 s/iter. Eval: 0.6381 s/iter. Total: 0.7965 s/iter. ETA=0:01:02
[09/04 08:20:55 d2.evaluation.evaluator]: Inference done 72/144. Dataloading: 0.0026 s/iter. Inference: 0.1561 s/iter. Eval: 0.6454 s/iter. Total: 0.8043 s/iter. ETA=0:00:57
[09/04 08:21:00 d2.evaluation.evaluator]: Inference done 80/144. Dataloading: 0.0025 s/iter. Inference: 0.1548 s/iter. Eval: 0.6307 s/iter. Total: 0.7884 s/iter. ETA=0:00:50
[09/04 08:21:05 d2.evaluation.evaluator]: Inference done 86/144. Dataloading: 0.0026 s/iter. Inference: 0.1552 s/iter. Eval: 0.6345 s/iter. Total: 0.7925 s/iter. ETA=0:00:45
[09/04 08:21:10 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0026 s/iter. Inference: 0.1555 s/iter. Eval: 0.6372 s/iter. Total: 0.7956 s/iter. ETA=0:00:41
[09/04 08:21:15 d2.evaluation.evaluator]: Inference done 99/144. Dataloading: 0.0025 s/iter. Inference: 0.1552 s/iter. Eval: 0.6325 s/iter. Total: 0.7906 s/iter. ETA=0:00:35
[09/04 08:21:21 d2.evaluation.evaluator]: Inference done 106/144. Dataloading: 0.0025 s/iter. Inference: 0.1552 s/iter. Eval: 0.6315 s/iter. Total: 0.7896 s/iter. ETA=0:00:30
[09/04 08:21:26 d2.evaluation.evaluator]: Inference done 112/144. Dataloading: 0.0025 s/iter. Inference: 0.1553 s/iter. Eval: 0.6340 s/iter. Total: 0.7920 s/iter. ETA=0:00:25
[09/04 08:21:31 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0025 s/iter. Inference: 0.1550 s/iter. Eval: 0.6320 s/iter. Total: 0.7897 s/iter. ETA=0:00:19
[09/04 08:21:36 d2.evaluation.evaluator]: Inference done 125/144. Dataloading: 0.0025 s/iter. Inference: 0.1551 s/iter. Eval: 0.6347 s/iter. Total: 0.7926 s/iter. ETA=0:00:15
[09/04 08:21:42 d2.evaluation.evaluator]: Inference done 132/144. Dataloading: 0.0025 s/iter. Inference: 0.1551 s/iter. Eval: 0.6355 s/iter. Total: 0.7935 s/iter. ETA=0:00:09
[09/04 08:21:47 d2.evaluation.evaluator]: Inference done 139/144. Dataloading: 0.0026 s/iter. Inference: 0.1549 s/iter. Eval: 0.6319 s/iter. Total: 0.7897 s/iter. ETA=0:00:03
[09/04 08:21:51 d2.evaluation.evaluator]: Total inference time: 0:01:49.610584 (0.788565 s / iter per device, on 1 devices)
[09/04 08:21:51 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:21 (0.154803 s / iter per device, on 1 devices)
[09/04 08:21:51 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:21:51 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:21:51 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/04 08:21:51 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:21:51 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.
[09/04 08:21:51 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:21:51 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.222
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.440
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.140
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.065
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.236
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.302
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.222
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.436
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.547
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.275
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.537
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.614
[09/04 08:21:51 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 22.244 | 44.021 | 13.959 | 6.454 | 23.568 | 30.192 |
Loading and preparing results...
DONE (t=0.25s)
creating index...
index created!
[09/04 08:21:52 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:21:52 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.19 seconds.
[09/04 08:21:52 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:21:52 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.307
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.435
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.359
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.076
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.217
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.507
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.275
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.523
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.662
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.636
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.773
[09/04 08:21:52 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 30.668 | 43.495 | 35.854 | 7.580 | 21.672 | 50.725 |
[09/04 08:21:52 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:21:52 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:21:52 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:21:52 d2.evaluation.testing]: copypaste: 22.2442,44.0207,13.9594,6.4536,23.5678,30.1918
[09/04 08:21:52 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:21:52 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:21:52 d2.evaluation.testing]: copypaste: 30.6681,43.4950,35.8537,7.5803,21.6724,50.7248
[09/04 08:21:52 d2.utils.events]:  eta: 0:11:16  iter: 219  total_loss: 0.9233  loss_cls: 0.1818  loss_box_reg: 0.3647  loss_mask: 0.3084  loss_rpn_cls: 0.008339  loss_rpn_loc: 0.006298  time: 0.8705  data_time: 0.0063  lr: 5.4945e-05  max_mem: 6718M
[09/04 08:22:10 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:22:10 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:22:10 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:22:10 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:22:10 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:22:19 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0018 s/iter. Inference: 0.1625 s/iter. Eval: 0.7048 s/iter. Total: 0.8691 s/iter. ETA=0:01:55
[09/04 08:22:25 d2.evaluation.evaluator]: Inference done 18/144. Dataloading: 0.0021 s/iter. Inference: 0.1577 s/iter. Eval: 0.6447 s/iter. Total: 0.8047 s/iter. ETA=0:01:41
[09/04 08:22:30 d2.evaluation.evaluator]: Inference done 26/144. Dataloading: 0.0023 s/iter. Inference: 0.1545 s/iter. Eval: 0.6037 s/iter. Total: 0.7607 s/iter. ETA=0:01:29
[09/04 08:22:35 d2.evaluation.evaluator]: Inference done 33/144. Dataloading: 0.0022 s/iter. Inference: 0.1540 s/iter. Eval: 0.5970 s/iter. Total: 0.7534 s/iter. ETA=0:01:23
[09/04 08:22:41 d2.evaluation.evaluator]: Inference done 41/144. Dataloading: 0.0022 s/iter. Inference: 0.1530 s/iter. Eval: 0.5851 s/iter. Total: 0.7405 s/iter. ETA=0:01:16
[09/04 08:22:47 d2.evaluation.evaluator]: Inference done 48/144. Dataloading: 0.0023 s/iter. Inference: 0.1539 s/iter. Eval: 0.5961 s/iter. Total: 0.7525 s/iter. ETA=0:01:12
[09/04 08:22:52 d2.evaluation.evaluator]: Inference done 54/144. Dataloading: 0.0025 s/iter. Inference: 0.1548 s/iter. Eval: 0.6073 s/iter. Total: 0.7648 s/iter. ETA=0:01:08
[09/04 08:22:57 d2.evaluation.evaluator]: Inference done 61/144. Dataloading: 0.0025 s/iter. Inference: 0.1549 s/iter. Eval: 0.6077 s/iter. Total: 0.7653 s/iter. ETA=0:01:03
[09/04 08:23:03 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0025 s/iter. Inference: 0.1552 s/iter. Eval: 0.6141 s/iter. Total: 0.7721 s/iter. ETA=0:00:58
[09/04 08:23:08 d2.evaluation.evaluator]: Inference done 76/144. Dataloading: 0.0025 s/iter. Inference: 0.1539 s/iter. Eval: 0.6022 s/iter. Total: 0.7587 s/iter. ETA=0:00:51
[09/04 08:23:14 d2.evaluation.evaluator]: Inference done 83/144. Dataloading: 0.0026 s/iter. Inference: 0.1541 s/iter. Eval: 0.6043 s/iter. Total: 0.7612 s/iter. ETA=0:00:46
[09/04 08:23:19 d2.evaluation.evaluator]: Inference done 90/144. Dataloading: 0.0026 s/iter. Inference: 0.1540 s/iter. Eval: 0.6024 s/iter. Total: 0.7591 s/iter. ETA=0:00:40
[09/04 08:23:24 d2.evaluation.evaluator]: Inference done 97/144. Dataloading: 0.0025 s/iter. Inference: 0.1541 s/iter. Eval: 0.6056 s/iter. Total: 0.7624 s/iter. ETA=0:00:35
[09/04 08:23:30 d2.evaluation.evaluator]: Inference done 105/144. Dataloading: 0.0025 s/iter. Inference: 0.1536 s/iter. Eval: 0.5998 s/iter. Total: 0.7561 s/iter. ETA=0:00:29
[09/04 08:23:35 d2.evaluation.evaluator]: Inference done 112/144. Dataloading: 0.0025 s/iter. Inference: 0.1534 s/iter. Eval: 0.5995 s/iter. Total: 0.7556 s/iter. ETA=0:00:24
[09/04 08:23:41 d2.evaluation.evaluator]: Inference done 120/144. Dataloading: 0.0025 s/iter. Inference: 0.1533 s/iter. Eval: 0.5963 s/iter. Total: 0.7523 s/iter. ETA=0:00:18
[09/04 08:23:46 d2.evaluation.evaluator]: Inference done 127/144. Dataloading: 0.0025 s/iter. Inference: 0.1533 s/iter. Eval: 0.5970 s/iter. Total: 0.7529 s/iter. ETA=0:00:12
[09/04 08:23:52 d2.evaluation.evaluator]: Inference done 134/144. Dataloading: 0.0025 s/iter. Inference: 0.1536 s/iter. Eval: 0.5989 s/iter. Total: 0.7551 s/iter. ETA=0:00:07
[09/04 08:23:57 d2.evaluation.evaluator]: Inference done 142/144. Dataloading: 0.0024 s/iter. Inference: 0.1531 s/iter. Eval: 0.5942 s/iter. Total: 0.7499 s/iter. ETA=0:00:01
[09/04 08:23:59 d2.evaluation.evaluator]: Total inference time: 0:01:44.347154 (0.750699 s / iter per device, on 1 devices)
[09/04 08:23:59 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:21 (0.153090 s / iter per device, on 1 devices)
[09/04 08:23:59 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:23:59 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:23:59 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/04 08:23:59 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:23:59 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.09 seconds.
[09/04 08:23:59 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:23:59 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.219
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.438
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.156
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.065
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.239
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.291
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.218
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.443
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.546
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.292
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.534
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.614
[09/04 08:23:59 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 21.906 | 43.752 | 15.644 | 6.533 | 23.867 | 29.056 |
Loading and preparing results...
DONE (t=0.23s)
creating index...
index created!
[09/04 08:24:00 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:24:00 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.18 seconds.
[09/04 08:24:00 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:24:00 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.304
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.441
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.356
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.076
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.214
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.502
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.277
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.537
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.669
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.643
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.773
[09/04 08:24:00 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 30.390 | 44.115 | 35.594 | 7.622 | 21.420 | 50.155 |
[09/04 08:24:00 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:24:00 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:24:00 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:24:00 d2.evaluation.testing]: copypaste: 21.9062,43.7524,15.6440,6.5332,23.8669,29.0564
[09/04 08:24:00 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:24:00 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:24:00 d2.evaluation.testing]: copypaste: 30.3901,44.1152,35.5939,7.6216,21.4202,50.1548
[09/04 08:24:00 d2.utils.events]:  eta: 0:10:58  iter: 239  total_loss: 0.8305  loss_cls: 0.1681  loss_box_reg: 0.3693  loss_mask: 0.2467  loss_rpn_cls: 0.003913  loss_rpn_loc: 0.002601  time: 0.8712  data_time: 0.0064  lr: 5.994e-05  max_mem: 6718M
[09/04 08:24:18 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:24:18 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:24:18 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:24:18 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:24:18 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:24:27 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0018 s/iter. Inference: 0.1586 s/iter. Eval: 0.6523 s/iter. Total: 0.8127 s/iter. ETA=0:01:48
[09/04 08:24:33 d2.evaluation.evaluator]: Inference done 20/144. Dataloading: 0.0032 s/iter. Inference: 0.1487 s/iter. Eval: 0.5394 s/iter. Total: 0.6915 s/iter. ETA=0:01:25
[09/04 08:24:38 d2.evaluation.evaluator]: Inference done 28/144. Dataloading: 0.0028 s/iter. Inference: 0.1481 s/iter. Eval: 0.5304 s/iter. Total: 0.6815 s/iter. ETA=0:01:19
[09/04 08:24:44 d2.evaluation.evaluator]: Inference done 36/144. Dataloading: 0.0030 s/iter. Inference: 0.1486 s/iter. Eval: 0.5335 s/iter. Total: 0.6852 s/iter. ETA=0:01:14
[09/04 08:24:49 d2.evaluation.evaluator]: Inference done 44/144. Dataloading: 0.0031 s/iter. Inference: 0.1485 s/iter. Eval: 0.5305 s/iter. Total: 0.6824 s/iter. ETA=0:01:08
[09/04 08:24:54 d2.evaluation.evaluator]: Inference done 50/144. Dataloading: 0.0030 s/iter. Inference: 0.1500 s/iter. Eval: 0.5520 s/iter. Total: 0.7052 s/iter. ETA=0:01:06
[09/04 08:25:00 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0030 s/iter. Inference: 0.1508 s/iter. Eval: 0.5629 s/iter. Total: 0.7169 s/iter. ETA=0:01:02
[09/04 08:25:05 d2.evaluation.evaluator]: Inference done 64/144. Dataloading: 0.0029 s/iter. Inference: 0.1510 s/iter. Eval: 0.5682 s/iter. Total: 0.7223 s/iter. ETA=0:00:57
[09/04 08:25:10 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0029 s/iter. Inference: 0.1512 s/iter. Eval: 0.5707 s/iter. Total: 0.7250 s/iter. ETA=0:00:52
[09/04 08:25:15 d2.evaluation.evaluator]: Inference done 80/144. Dataloading: 0.0029 s/iter. Inference: 0.1500 s/iter. Eval: 0.5550 s/iter. Total: 0.7082 s/iter. ETA=0:00:45
[09/04 08:25:21 d2.evaluation.evaluator]: Inference done 88/144. Dataloading: 0.0028 s/iter. Inference: 0.1496 s/iter. Eval: 0.5504 s/iter. Total: 0.7030 s/iter. ETA=0:00:39
[09/04 08:25:26 d2.evaluation.evaluator]: Inference done 96/144. Dataloading: 0.0028 s/iter. Inference: 0.1498 s/iter. Eval: 0.5514 s/iter. Total: 0.7042 s/iter. ETA=0:00:33
[09/04 08:25:32 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0027 s/iter. Inference: 0.1493 s/iter. Eval: 0.5472 s/iter. Total: 0.6994 s/iter. ETA=0:00:27
[09/04 08:25:37 d2.evaluation.evaluator]: Inference done 112/144. Dataloading: 0.0027 s/iter. Inference: 0.1493 s/iter. Eval: 0.5477 s/iter. Total: 0.6999 s/iter. ETA=0:00:22
[09/04 08:25:43 d2.evaluation.evaluator]: Inference done 122/144. Dataloading: 0.0027 s/iter. Inference: 0.1485 s/iter. Eval: 0.5384 s/iter. Total: 0.6898 s/iter. ETA=0:00:15
[09/04 08:25:48 d2.evaluation.evaluator]: Inference done 130/144. Dataloading: 0.0027 s/iter. Inference: 0.1485 s/iter. Eval: 0.5375 s/iter. Total: 0.6889 s/iter. ETA=0:00:09
[09/04 08:25:54 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0027 s/iter. Inference: 0.1487 s/iter. Eval: 0.5408 s/iter. Total: 0.6923 s/iter. ETA=0:00:04
[09/04 08:25:58 d2.evaluation.evaluator]: Total inference time: 0:01:35.940809 (0.690222 s / iter per device, on 1 devices)
[09/04 08:25:58 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:20 (0.148339 s / iter per device, on 1 devices)
[09/04 08:25:58 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:25:58 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:25:58 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/04 08:25:59 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:25:59 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.09 seconds.
[09/04 08:25:59 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:25:59 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.219
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.437
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.153
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.064
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.233
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.299
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.223
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.437
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.534
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.292
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.503
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.630
[09/04 08:25:59 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 21.859 | 43.744 | 15.262 | 6.439 | 23.328 | 29.886 |
Loading and preparing results...
DONE (t=0.21s)
creating index...
index created!
[09/04 08:25:59 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:25:59 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.17 seconds.
[09/04 08:25:59 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:25:59 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.308
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.445
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.377
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.077
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.218
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.508
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.279
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.533
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.674
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.392
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.642
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.780
[09/04 08:25:59 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 30.848 | 44.457 | 37.686 | 7.722 | 21.833 | 50.768 |
[09/04 08:25:59 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:25:59 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:25:59 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:25:59 d2.evaluation.testing]: copypaste: 21.8586,43.7439,15.2617,6.4386,23.3281,29.8856
[09/04 08:25:59 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:25:59 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:25:59 d2.evaluation.testing]: copypaste: 30.8483,44.4570,37.6856,7.7225,21.8329,50.7679
[09/04 08:25:59 d2.utils.events]:  eta: 0:10:41  iter: 259  total_loss: 0.7916  loss_cls: 0.1236  loss_box_reg: 0.3996  loss_mask: 0.2324  loss_rpn_cls: 0.003845  loss_rpn_loc: 0.002084  time: 0.8712  data_time: 0.0062  lr: 6.4935e-05  max_mem: 6718M
[09/04 08:26:17 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:26:17 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:26:17 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:26:17 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:26:17 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:26:27 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0037 s/iter. Inference: 0.1600 s/iter. Eval: 0.6983 s/iter. Total: 0.8620 s/iter. ETA=0:01:54
[09/04 08:26:32 d2.evaluation.evaluator]: Inference done 20/144. Dataloading: 0.0029 s/iter. Inference: 0.1487 s/iter. Eval: 0.5583 s/iter. Total: 0.7102 s/iter. ETA=0:01:28
[09/04 08:26:38 d2.evaluation.evaluator]: Inference done 28/144. Dataloading: 0.0026 s/iter. Inference: 0.1481 s/iter. Eval: 0.5492 s/iter. Total: 0.7001 s/iter. ETA=0:01:21
[09/04 08:26:43 d2.evaluation.evaluator]: Inference done 36/144. Dataloading: 0.0025 s/iter. Inference: 0.1479 s/iter. Eval: 0.5488 s/iter. Total: 0.6994 s/iter. ETA=0:01:15
[09/04 08:26:48 d2.evaluation.evaluator]: Inference done 44/144. Dataloading: 0.0024 s/iter. Inference: 0.1474 s/iter. Eval: 0.5372 s/iter. Total: 0.6872 s/iter. ETA=0:01:08
[09/04 08:26:53 d2.evaluation.evaluator]: Inference done 50/144. Dataloading: 0.0024 s/iter. Inference: 0.1491 s/iter. Eval: 0.5574 s/iter. Total: 0.7091 s/iter. ETA=0:01:06
[09/04 08:26:59 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0024 s/iter. Inference: 0.1506 s/iter. Eval: 0.5737 s/iter. Total: 0.7269 s/iter. ETA=0:01:03
[09/04 08:27:05 d2.evaluation.evaluator]: Inference done 64/144. Dataloading: 0.0025 s/iter. Inference: 0.1511 s/iter. Eval: 0.5785 s/iter. Total: 0.7324 s/iter. ETA=0:00:58
[09/04 08:27:10 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0026 s/iter. Inference: 0.1513 s/iter. Eval: 0.5810 s/iter. Total: 0.7350 s/iter. ETA=0:00:53
[09/04 08:27:15 d2.evaluation.evaluator]: Inference done 80/144. Dataloading: 0.0025 s/iter. Inference: 0.1498 s/iter. Eval: 0.5638 s/iter. Total: 0.7163 s/iter. ETA=0:00:45
[09/04 08:27:20 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0026 s/iter. Inference: 0.1487 s/iter. Eval: 0.5490 s/iter. Total: 0.7005 s/iter. ETA=0:00:38
[09/04 08:27:26 d2.evaluation.evaluator]: Inference done 97/144. Dataloading: 0.0025 s/iter. Inference: 0.1487 s/iter. Eval: 0.5500 s/iter. Total: 0.7014 s/iter. ETA=0:00:32
[09/04 08:27:31 d2.evaluation.evaluator]: Inference done 105/144. Dataloading: 0.0025 s/iter. Inference: 0.1484 s/iter. Eval: 0.5472 s/iter. Total: 0.6983 s/iter. ETA=0:00:27
[09/04 08:27:37 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0025 s/iter. Inference: 0.1486 s/iter. Eval: 0.5475 s/iter. Total: 0.6988 s/iter. ETA=0:00:21
[09/04 08:27:42 d2.evaluation.evaluator]: Inference done 122/144. Dataloading: 0.0025 s/iter. Inference: 0.1478 s/iter. Eval: 0.5385 s/iter. Total: 0.6890 s/iter. ETA=0:00:15
[09/04 08:27:47 d2.evaluation.evaluator]: Inference done 130/144. Dataloading: 0.0025 s/iter. Inference: 0.1495 s/iter. Eval: 0.5354 s/iter. Total: 0.6876 s/iter. ETA=0:00:09
[09/04 08:27:53 d2.evaluation.evaluator]: Inference done 138/144. Dataloading: 0.0025 s/iter. Inference: 0.1494 s/iter. Eval: 0.5349 s/iter. Total: 0.6870 s/iter. ETA=0:00:04
[09/04 08:27:57 d2.evaluation.evaluator]: Total inference time: 0:01:35.209298 (0.684959 s / iter per device, on 1 devices)
[09/04 08:27:57 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:20 (0.149081 s / iter per device, on 1 devices)
[09/04 08:27:57 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:27:57 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:27:57 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/04 08:27:57 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:27:57 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.09 seconds.
[09/04 08:27:57 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:27:57 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.242
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.472
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.185
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.068
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.269
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.322
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.233
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.452
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.537
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.267
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.516
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.624
[09/04 08:27:57 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 24.192 | 47.225 | 18.488 | 6.754 | 26.869 | 32.212 |
Loading and preparing results...
DONE (t=0.23s)
creating index...
index created!
[09/04 08:27:58 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:27:58 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.16 seconds.
[09/04 08:27:58 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:27:58 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.324
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.470
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.383
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.079
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.233
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.534
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.284
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.549
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.669
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.637
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.782
[09/04 08:27:58 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 32.391 | 46.962 | 38.301 | 7.924 | 23.264 | 53.439 |
[09/04 08:27:58 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:27:58 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:27:58 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:27:58 d2.evaluation.testing]: copypaste: 24.1924,47.2255,18.4878,6.7542,26.8686,32.2118
[09/04 08:27:58 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:27:58 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:27:58 d2.evaluation.testing]: copypaste: 32.3908,46.9622,38.3014,7.9241,23.2643,53.4385
[09/04 08:27:58 d2.utils.events]:  eta: 0:10:24  iter: 279  total_loss: 0.9057  loss_cls: 0.1683  loss_box_reg: 0.3983  loss_mask: 0.2033  loss_rpn_cls: 0.007107  loss_rpn_loc: 0.005844  time: 0.8712  data_time: 0.0064  lr: 6.993e-05  max_mem: 6718M
[09/04 08:28:16 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:28:16 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:28:16 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:28:16 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:28:16 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:28:24 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0023 s/iter. Inference: 0.1506 s/iter. Eval: 0.5566 s/iter. Total: 0.7094 s/iter. ETA=0:01:34
[09/04 08:28:29 d2.evaluation.evaluator]: Inference done 21/144. Dataloading: 0.0029 s/iter. Inference: 0.1409 s/iter. Eval: 0.4420 s/iter. Total: 0.5860 s/iter. ETA=0:01:12
[09/04 08:28:34 d2.evaluation.evaluator]: Inference done 30/144. Dataloading: 0.0025 s/iter. Inference: 0.1397 s/iter. Eval: 0.4340 s/iter. Total: 0.5765 s/iter. ETA=0:01:05
[09/04 08:28:40 d2.evaluation.evaluator]: Inference done 39/144. Dataloading: 0.0028 s/iter. Inference: 0.1403 s/iter. Eval: 0.4438 s/iter. Total: 0.5871 s/iter. ETA=0:01:01
[09/04 08:28:46 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0030 s/iter. Inference: 0.1417 s/iter. Eval: 0.4631 s/iter. Total: 0.6080 s/iter. ETA=0:00:58
[09/04 08:28:51 d2.evaluation.evaluator]: Inference done 54/144. Dataloading: 0.0029 s/iter. Inference: 0.1438 s/iter. Eval: 0.4872 s/iter. Total: 0.6342 s/iter. ETA=0:00:57
[09/04 08:28:57 d2.evaluation.evaluator]: Inference done 62/144. Dataloading: 0.0029 s/iter. Inference: 0.1445 s/iter. Eval: 0.4941 s/iter. Total: 0.6416 s/iter. ETA=0:00:52
[09/04 08:29:02 d2.evaluation.evaluator]: Inference done 70/144. Dataloading: 0.0028 s/iter. Inference: 0.1451 s/iter. Eval: 0.5012 s/iter. Total: 0.6493 s/iter. ETA=0:00:48
[09/04 08:29:07 d2.evaluation.evaluator]: Inference done 81/144. Dataloading: 0.0029 s/iter. Inference: 0.1432 s/iter. Eval: 0.4769 s/iter. Total: 0.6232 s/iter. ETA=0:00:39
[09/04 08:29:13 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0028 s/iter. Inference: 0.1420 s/iter. Eval: 0.4629 s/iter. Total: 0.6079 s/iter. ETA=0:00:31
[09/04 08:29:19 d2.evaluation.evaluator]: Inference done 103/144. Dataloading: 0.0028 s/iter. Inference: 0.1411 s/iter. Eval: 0.4521 s/iter. Total: 0.5962 s/iter. ETA=0:00:24
[09/04 08:29:24 d2.evaluation.evaluator]: Inference done 112/144. Dataloading: 0.0027 s/iter. Inference: 0.1413 s/iter. Eval: 0.4542 s/iter. Total: 0.5984 s/iter. ETA=0:00:19
[09/04 08:29:29 d2.evaluation.evaluator]: Inference done 123/144. Dataloading: 0.0027 s/iter. Inference: 0.1405 s/iter. Eval: 0.4436 s/iter. Total: 0.5870 s/iter. ETA=0:00:12
[09/04 08:29:35 d2.evaluation.evaluator]: Inference done 133/144. Dataloading: 0.0027 s/iter. Inference: 0.1402 s/iter. Eval: 0.4386 s/iter. Total: 0.5817 s/iter. ETA=0:00:06
[09/04 08:29:40 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0027 s/iter. Inference: 0.1396 s/iter. Eval: 0.4331 s/iter. Total: 0.5756 s/iter. ETA=0:00:00
[09/04 08:29:40 d2.evaluation.evaluator]: Total inference time: 0:01:20.057618 (0.575954 s / iter per device, on 1 devices)
[09/04 08:29:40 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:19 (0.139627 s / iter per device, on 1 devices)
[09/04 08:29:40 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:29:40 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:29:40 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/04 08:29:40 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:29:40 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[09/04 08:29:40 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:29:40 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.277
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.510
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.252
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.071
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.301
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.376
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.243
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.468
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.560
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.540
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.658
[09/04 08:29:40 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 27.653 | 51.001 | 25.204 | 7.135 | 30.084 | 37.565 |
Loading and preparing results...
DONE (t=0.17s)
creating index...
index created!
[09/04 08:29:41 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:29:41 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.14 seconds.
[09/04 08:29:41 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:29:41 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.356
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.511
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.420
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.081
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.268
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.565
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.295
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.559
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.668
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.634
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.788
[09/04 08:29:41 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 35.599 | 51.125 | 42.014 | 8.109 | 26.834 | 56.471 |
[09/04 08:29:41 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:29:41 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:29:41 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:29:41 d2.evaluation.testing]: copypaste: 27.6532,51.0009,25.2037,7.1351,30.0838,37.5648
[09/04 08:29:41 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:29:41 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:29:41 d2.evaluation.testing]: copypaste: 35.5992,51.1247,42.0139,8.1089,26.8338,56.4709
[09/04 08:29:41 d2.utils.events]:  eta: 0:10:07  iter: 299  total_loss: 0.9016  loss_cls: 0.1646  loss_box_reg: 0.4652  loss_mask: 0.1933  loss_rpn_cls: 0.005909  loss_rpn_loc: 0.009902  time: 0.8719  data_time: 0.0083  lr: 7.4925e-05  max_mem: 6718M
[09/04 08:29:59 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:29:59 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:29:59 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:29:59 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:29:59 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:30:07 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0019 s/iter. Inference: 0.1480 s/iter. Eval: 0.5251 s/iter. Total: 0.6750 s/iter. ETA=0:01:29
[09/04 08:30:13 d2.evaluation.evaluator]: Inference done 21/144. Dataloading: 0.0022 s/iter. Inference: 0.1398 s/iter. Eval: 0.4378 s/iter. Total: 0.5800 s/iter. ETA=0:01:11
[09/04 08:30:18 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0025 s/iter. Inference: 0.1404 s/iter. Eval: 0.4530 s/iter. Total: 0.5961 s/iter. ETA=0:01:08
[09/04 08:30:23 d2.evaluation.evaluator]: Inference done 39/144. Dataloading: 0.0024 s/iter. Inference: 0.1394 s/iter. Eval: 0.4366 s/iter. Total: 0.5786 s/iter. ETA=0:01:00
[09/04 08:30:28 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0024 s/iter. Inference: 0.1409 s/iter. Eval: 0.4532 s/iter. Total: 0.5966 s/iter. ETA=0:00:57
[09/04 08:30:34 d2.evaluation.evaluator]: Inference done 54/144. Dataloading: 0.0024 s/iter. Inference: 0.1431 s/iter. Eval: 0.4811 s/iter. Total: 0.6268 s/iter. ETA=0:00:56
[09/04 08:30:39 d2.evaluation.evaluator]: Inference done 62/144. Dataloading: 0.0024 s/iter. Inference: 0.1438 s/iter. Eval: 0.4869 s/iter. Total: 0.6333 s/iter. ETA=0:00:51
[09/04 08:30:45 d2.evaluation.evaluator]: Inference done 70/144. Dataloading: 0.0025 s/iter. Inference: 0.1444 s/iter. Eval: 0.4950 s/iter. Total: 0.6420 s/iter. ETA=0:00:47
[09/04 08:30:50 d2.evaluation.evaluator]: Inference done 81/144. Dataloading: 0.0025 s/iter. Inference: 0.1425 s/iter. Eval: 0.4740 s/iter. Total: 0.6192 s/iter. ETA=0:00:39
[09/04 08:30:56 d2.evaluation.evaluator]: Inference done 93/144. Dataloading: 0.0025 s/iter. Inference: 0.1409 s/iter. Eval: 0.4534 s/iter. Total: 0.5970 s/iter. ETA=0:00:30
[09/04 08:31:01 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0025 s/iter. Inference: 0.1403 s/iter. Eval: 0.4440 s/iter. Total: 0.5870 s/iter. ETA=0:00:23
[09/04 08:31:07 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0025 s/iter. Inference: 0.1404 s/iter. Eval: 0.4457 s/iter. Total: 0.5888 s/iter. ETA=0:00:18
[09/04 08:31:12 d2.evaluation.evaluator]: Inference done 124/144. Dataloading: 0.0025 s/iter. Inference: 0.1396 s/iter. Eval: 0.4360 s/iter. Total: 0.5783 s/iter. ETA=0:00:11
[09/04 08:31:18 d2.evaluation.evaluator]: Inference done 134/144. Dataloading: 0.0025 s/iter. Inference: 0.1393 s/iter. Eval: 0.4329 s/iter. Total: 0.5749 s/iter. ETA=0:00:05
[09/04 08:31:23 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0024 s/iter. Inference: 0.1388 s/iter. Eval: 0.4288 s/iter. Total: 0.5702 s/iter. ETA=0:00:00
[09/04 08:31:23 d2.evaluation.evaluator]: Total inference time: 0:01:19.318045 (0.570633 s / iter per device, on 1 devices)
[09/04 08:31:23 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:19 (0.138841 s / iter per device, on 1 devices)
[09/04 08:31:23 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:31:23 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:31:23 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/04 08:31:23 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:31:23 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[09/04 08:31:23 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:31:23 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.288
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.539
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.242
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.073
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.308
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.382
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.263
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.485
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.564
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.225
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.550
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.650
[09/04 08:31:23 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 28.790 | 53.907 | 24.157 | 7.260 | 30.847 | 38.242 |
Loading and preparing results...
DONE (t=0.16s)
creating index...
index created!
[09/04 08:31:23 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:31:24 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.14 seconds.
[09/04 08:31:24 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:31:24 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.372
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.534
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.447
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.082
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.293
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.569
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.308
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.569
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.669
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.342
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.640
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.780
[09/04 08:31:24 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 37.171 | 53.385 | 44.717 | 8.214 | 29.268 | 56.857 |
[09/04 08:31:24 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:31:24 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:31:24 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:31:24 d2.evaluation.testing]: copypaste: 28.7905,53.9071,24.1568,7.2602,30.8467,38.2421
[09/04 08:31:24 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:31:24 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:31:24 d2.evaluation.testing]: copypaste: 37.1706,53.3848,44.7166,8.2137,29.2678,56.8568
[09/04 08:31:24 d2.utils.events]:  eta: 0:09:50  iter: 319  total_loss: 0.725  loss_cls: 0.1212  loss_box_reg: 0.3776  loss_mask: 0.2185  loss_rpn_cls: 0.007278  loss_rpn_loc: 0.004364  time: 0.8720  data_time: 0.0066  lr: 7.992e-05  max_mem: 6718M
[09/04 08:31:41 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:31:41 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:31:41 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:31:41 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:31:41 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:31:49 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0020 s/iter. Inference: 0.1409 s/iter. Eval: 0.4480 s/iter. Total: 0.5909 s/iter. ETA=0:01:18
[09/04 08:31:55 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0024 s/iter. Inference: 0.1334 s/iter. Eval: 0.3736 s/iter. Total: 0.5095 s/iter. ETA=0:01:01
[09/04 08:32:00 d2.evaluation.evaluator]: Inference done 34/144. Dataloading: 0.0025 s/iter. Inference: 0.1326 s/iter. Eval: 0.3613 s/iter. Total: 0.4967 s/iter. ETA=0:00:54
[09/04 08:32:05 d2.evaluation.evaluator]: Inference done 44/144. Dataloading: 0.0024 s/iter. Inference: 0.1336 s/iter. Eval: 0.3737 s/iter. Total: 0.5100 s/iter. ETA=0:00:51
[09/04 08:32:11 d2.evaluation.evaluator]: Inference done 52/144. Dataloading: 0.0025 s/iter. Inference: 0.1362 s/iter. Eval: 0.4029 s/iter. Total: 0.5420 s/iter. ETA=0:00:49
[09/04 08:32:17 d2.evaluation.evaluator]: Inference done 61/144. Dataloading: 0.0024 s/iter. Inference: 0.1377 s/iter. Eval: 0.4159 s/iter. Total: 0.5562 s/iter. ETA=0:00:46
[09/04 08:32:22 d2.evaluation.evaluator]: Inference done 70/144. Dataloading: 0.0024 s/iter. Inference: 0.1381 s/iter. Eval: 0.4207 s/iter. Total: 0.5614 s/iter. ETA=0:00:41
[09/04 08:32:27 d2.evaluation.evaluator]: Inference done 84/144. Dataloading: 0.0026 s/iter. Inference: 0.1357 s/iter. Eval: 0.3891 s/iter. Total: 0.5276 s/iter. ETA=0:00:31
[09/04 08:32:32 d2.evaluation.evaluator]: Inference done 98/144. Dataloading: 0.0026 s/iter. Inference: 0.1339 s/iter. Eval: 0.3669 s/iter. Total: 0.5036 s/iter. ETA=0:00:23
[09/04 08:32:38 d2.evaluation.evaluator]: Inference done 108/144. Dataloading: 0.0027 s/iter. Inference: 0.1343 s/iter. Eval: 0.3728 s/iter. Total: 0.5099 s/iter. ETA=0:00:18
[09/04 08:32:43 d2.evaluation.evaluator]: Inference done 120/144. Dataloading: 0.0026 s/iter. Inference: 0.1338 s/iter. Eval: 0.3665 s/iter. Total: 0.5031 s/iter. ETA=0:00:12
[09/04 08:32:48 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0027 s/iter. Inference: 0.1335 s/iter. Eval: 0.3631 s/iter. Total: 0.4994 s/iter. ETA=0:00:06
[09/04 08:32:54 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0026 s/iter. Inference: 0.1328 s/iter. Eval: 0.3563 s/iter. Total: 0.4919 s/iter. ETA=0:00:00
[09/04 08:32:54 d2.evaluation.evaluator]: Total inference time: 0:01:08.429484 (0.492298 s / iter per device, on 1 devices)
[09/04 08:32:54 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:18 (0.132841 s / iter per device, on 1 devices)
[09/04 08:32:54 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:32:54 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:32:54 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/04 08:32:54 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:32:54 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[09/04 08:32:54 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:32:54 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.312
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.559
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.302
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.071
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.327
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.423
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.272
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.497
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.573
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.233
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.553
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.668
[09/04 08:32:54 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 31.239 | 55.871 | 30.183 | 7.134 | 32.659 | 42.310 |
Loading and preparing results...
DONE (t=0.14s)
creating index...
index created!
[09/04 08:32:55 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:32:55 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.12 seconds.
[09/04 08:32:55 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:32:55 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.385
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.558
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.458
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.082
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.299
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.587
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.306
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.564
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.661
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.633
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.770
[09/04 08:32:55 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 38.523 | 55.828 | 45.779 | 8.184 | 29.935 | 58.709 |
[09/04 08:32:55 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:32:55 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:32:55 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:32:55 d2.evaluation.testing]: copypaste: 31.2389,55.8705,30.1832,7.1335,32.6586,42.3100
[09/04 08:32:55 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:32:55 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:32:55 d2.evaluation.testing]: copypaste: 38.5232,55.8277,45.7792,8.1840,29.9353,58.7090
[09/04 08:32:55 d2.utils.events]:  eta: 0:09:32  iter: 339  total_loss: 0.6831  loss_cls: 0.1129  loss_box_reg: 0.3509  loss_mask: 0.1545  loss_rpn_cls: 0.004758  loss_rpn_loc: 0.003256  time: 0.8720  data_time: 0.0091  lr: 8.4915e-05  max_mem: 6718M
[09/04 08:33:13 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:33:13 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:33:13 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:33:13 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:33:13 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:33:20 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0031 s/iter. Inference: 0.1409 s/iter. Eval: 0.4390 s/iter. Total: 0.5830 s/iter. ETA=0:01:17
[09/04 08:33:26 d2.evaluation.evaluator]: Inference done 24/144. Dataloading: 0.0026 s/iter. Inference: 0.1321 s/iter. Eval: 0.3322 s/iter. Total: 0.4671 s/iter. ETA=0:00:56
[09/04 08:33:31 d2.evaluation.evaluator]: Inference done 36/144. Dataloading: 0.0029 s/iter. Inference: 0.1315 s/iter. Eval: 0.3248 s/iter. Total: 0.4595 s/iter. ETA=0:00:49
[09/04 08:33:37 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0028 s/iter. Inference: 0.1325 s/iter. Eval: 0.3481 s/iter. Total: 0.4836 s/iter. ETA=0:00:47
[09/04 08:33:42 d2.evaluation.evaluator]: Inference done 54/144. Dataloading: 0.0028 s/iter. Inference: 0.1346 s/iter. Eval: 0.3750 s/iter. Total: 0.5126 s/iter. ETA=0:00:46
[09/04 08:33:47 d2.evaluation.evaluator]: Inference done 64/144. Dataloading: 0.0027 s/iter. Inference: 0.1350 s/iter. Eval: 0.3788 s/iter. Total: 0.5167 s/iter. ETA=0:00:41
[09/04 08:33:53 d2.evaluation.evaluator]: Inference done 75/144. Dataloading: 0.0026 s/iter. Inference: 0.1351 s/iter. Eval: 0.3735 s/iter. Total: 0.5114 s/iter. ETA=0:00:35
[09/04 08:33:58 d2.evaluation.evaluator]: Inference done 91/144. Dataloading: 0.0026 s/iter. Inference: 0.1323 s/iter. Eval: 0.3403 s/iter. Total: 0.4753 s/iter. ETA=0:00:25
[09/04 08:34:03 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0026 s/iter. Inference: 0.1316 s/iter. Eval: 0.3334 s/iter. Total: 0.4678 s/iter. ETA=0:00:18
[09/04 08:34:08 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0025 s/iter. Inference: 0.1322 s/iter. Eval: 0.3419 s/iter. Total: 0.4768 s/iter. ETA=0:00:14
[09/04 08:34:14 d2.evaluation.evaluator]: Inference done 127/144. Dataloading: 0.0026 s/iter. Inference: 0.1312 s/iter. Eval: 0.3315 s/iter. Total: 0.4655 s/iter. ETA=0:00:07
[09/04 08:34:19 d2.evaluation.evaluator]: Inference done 140/144. Dataloading: 0.0026 s/iter. Inference: 0.1307 s/iter. Eval: 0.3256 s/iter. Total: 0.4591 s/iter. ETA=0:00:01
[09/04 08:34:21 d2.evaluation.evaluator]: Total inference time: 0:01:03.854888 (0.459388 s / iter per device, on 1 devices)
[09/04 08:34:21 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:18 (0.130662 s / iter per device, on 1 devices)
[09/04 08:34:21 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:34:21 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:34:21 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/04 08:34:21 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:34:21 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[09/04 08:34:21 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:34:21 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.344
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.584
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.369
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.084
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.353
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.471
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.277
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.518
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.587
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.283
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.555
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.698
[09/04 08:34:21 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 34.403 | 58.383 | 36.881 | 8.385 | 35.269 | 47.083 |
Loading and preparing results...
DONE (t=0.12s)
creating index...
index created!
[09/04 08:34:21 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:34:21 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[09/04 08:34:21 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:34:21 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.401
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.586
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.473
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.083
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.321
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.599
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.307
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.574
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.664
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.633
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.774
[09/04 08:34:21 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 40.142 | 58.582 | 47.326 | 8.314 | 32.102 | 59.856 |
[09/04 08:34:21 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:34:21 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:34:21 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:34:21 d2.evaluation.testing]: copypaste: 34.4030,58.3825,36.8809,8.3845,35.2692,47.0833
[09/04 08:34:21 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:34:21 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:34:21 d2.evaluation.testing]: copypaste: 40.1425,58.5817,47.3264,8.3142,32.1024,59.8559
[09/04 08:34:21 d2.utils.events]:  eta: 0:09:16  iter: 359  total_loss: 0.7292  loss_cls: 0.09827  loss_box_reg: 0.4038  loss_mask: 0.1677  loss_rpn_cls: 0.003462  loss_rpn_loc: 0.004881  time: 0.8727  data_time: 0.0092  lr: 8.991e-05  max_mem: 6718M
[09/04 08:34:39 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:34:39 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:34:39 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:34:39 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:34:39 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:34:47 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0020 s/iter. Inference: 0.1398 s/iter. Eval: 0.4159 s/iter. Total: 0.5577 s/iter. ETA=0:01:14
[09/04 08:34:52 d2.evaluation.evaluator]: Inference done 23/144. Dataloading: 0.0025 s/iter. Inference: 0.1314 s/iter. Eval: 0.3346 s/iter. Total: 0.4687 s/iter. ETA=0:00:56
[09/04 08:34:57 d2.evaluation.evaluator]: Inference done 35/144. Dataloading: 0.0027 s/iter. Inference: 0.1317 s/iter. Eval: 0.3288 s/iter. Total: 0.4635 s/iter. ETA=0:00:50
[09/04 08:35:03 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0026 s/iter. Inference: 0.1326 s/iter. Eval: 0.3434 s/iter. Total: 0.4788 s/iter. ETA=0:00:46
[09/04 08:35:08 d2.evaluation.evaluator]: Inference done 54/144. Dataloading: 0.0025 s/iter. Inference: 0.1349 s/iter. Eval: 0.3722 s/iter. Total: 0.5098 s/iter. ETA=0:00:45
[09/04 08:35:14 d2.evaluation.evaluator]: Inference done 63/144. Dataloading: 0.0025 s/iter. Inference: 0.1355 s/iter. Eval: 0.3848 s/iter. Total: 0.5230 s/iter. ETA=0:00:42
[09/04 08:35:19 d2.evaluation.evaluator]: Inference done 74/144. Dataloading: 0.0024 s/iter. Inference: 0.1350 s/iter. Eval: 0.3764 s/iter. Total: 0.5140 s/iter. ETA=0:00:35
[09/04 08:35:24 d2.evaluation.evaluator]: Inference done 89/144. Dataloading: 0.0025 s/iter. Inference: 0.1328 s/iter. Eval: 0.3468 s/iter. Total: 0.4824 s/iter. ETA=0:00:26
[09/04 08:35:29 d2.evaluation.evaluator]: Inference done 103/144. Dataloading: 0.0026 s/iter. Inference: 0.1318 s/iter. Eval: 0.3343 s/iter. Total: 0.4689 s/iter. ETA=0:00:19
[09/04 08:35:35 d2.evaluation.evaluator]: Inference done 112/144. Dataloading: 0.0025 s/iter. Inference: 0.1324 s/iter. Eval: 0.3426 s/iter. Total: 0.4776 s/iter. ETA=0:00:15
[09/04 08:35:40 d2.evaluation.evaluator]: Inference done 126/144. Dataloading: 0.0026 s/iter. Inference: 0.1314 s/iter. Eval: 0.3322 s/iter. Total: 0.4663 s/iter. ETA=0:00:08
[09/04 08:35:45 d2.evaluation.evaluator]: Inference done 139/144. Dataloading: 0.0026 s/iter. Inference: 0.1308 s/iter. Eval: 0.3272 s/iter. Total: 0.4608 s/iter. ETA=0:00:02
[09/04 08:35:48 d2.evaluation.evaluator]: Total inference time: 0:01:04.318691 (0.462724 s / iter per device, on 1 devices)
[09/04 08:35:48 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:18 (0.130727 s / iter per device, on 1 devices)
[09/04 08:35:48 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:35:48 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:35:48 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/04 08:35:48 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:35:48 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[09/04 08:35:48 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:35:48 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.367
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.609
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.381
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.098
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.373
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.495
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.289
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.536
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.597
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.250
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.561
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.723
[09/04 08:35:48 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 36.746 | 60.869 | 38.119 | 9.784 | 37.283 | 49.473 |
Loading and preparing results...
DONE (t=0.13s)
creating index...
index created!
[09/04 08:35:48 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:35:48 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.11 seconds.
[09/04 08:35:48 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:35:48 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.420
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.608
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.488
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.101
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.340
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.615
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.585
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.663
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.325
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.630
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.782
[09/04 08:35:48 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 41.986 | 60.828 | 48.777 | 10.087 | 34.046 | 61.549 |
[09/04 08:35:48 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:35:48 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:35:48 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:35:48 d2.evaluation.testing]: copypaste: 36.7457,60.8694,38.1187,9.7840,37.2828,49.4726
[09/04 08:35:48 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:35:48 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:35:48 d2.evaluation.testing]: copypaste: 41.9855,60.8280,48.7775,10.0873,34.0456,61.5489
[09/04 08:35:48 d2.utils.events]:  eta: 0:08:58  iter: 379  total_loss: 0.687  loss_cls: 0.1195  loss_box_reg: 0.3042  loss_mask: 0.1844  loss_rpn_cls: 0.00564  loss_rpn_loc: 0.003704  time: 0.8726  data_time: 0.0081  lr: 9.4905e-05  max_mem: 6718M
[09/04 08:36:06 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:36:06 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:36:06 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:36:06 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:36:06 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:36:13 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0018 s/iter. Inference: 0.1322 s/iter. Eval: 0.3411 s/iter. Total: 0.4752 s/iter. ETA=0:01:03
[09/04 08:36:18 d2.evaluation.evaluator]: Inference done 25/144. Dataloading: 0.0026 s/iter. Inference: 0.1272 s/iter. Eval: 0.2735 s/iter. Total: 0.4035 s/iter. ETA=0:00:48
[09/04 08:36:23 d2.evaluation.evaluator]: Inference done 37/144. Dataloading: 0.0024 s/iter. Inference: 0.1271 s/iter. Eval: 0.2792 s/iter. Total: 0.4089 s/iter. ETA=0:00:43
[09/04 08:36:28 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0024 s/iter. Inference: 0.1295 s/iter. Eval: 0.3111 s/iter. Total: 0.4432 s/iter. ETA=0:00:43
[09/04 08:36:34 d2.evaluation.evaluator]: Inference done 54/144. Dataloading: 0.0023 s/iter. Inference: 0.1319 s/iter. Eval: 0.3431 s/iter. Total: 0.4774 s/iter. ETA=0:00:42
[09/04 08:36:39 d2.evaluation.evaluator]: Inference done 64/144. Dataloading: 0.0023 s/iter. Inference: 0.1323 s/iter. Eval: 0.3511 s/iter. Total: 0.4859 s/iter. ETA=0:00:38
[09/04 08:36:44 d2.evaluation.evaluator]: Inference done 75/144. Dataloading: 0.0024 s/iter. Inference: 0.1319 s/iter. Eval: 0.3498 s/iter. Total: 0.4844 s/iter. ETA=0:00:33
[09/04 08:36:49 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0025 s/iter. Inference: 0.1297 s/iter. Eval: 0.3176 s/iter. Total: 0.4500 s/iter. ETA=0:00:23
[09/04 08:36:54 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0025 s/iter. Inference: 0.1294 s/iter. Eval: 0.3144 s/iter. Total: 0.4465 s/iter. ETA=0:00:17
[09/04 08:37:00 d2.evaluation.evaluator]: Inference done 115/144. Dataloading: 0.0024 s/iter. Inference: 0.1295 s/iter. Eval: 0.3165 s/iter. Total: 0.4487 s/iter. ETA=0:00:13
[09/04 08:37:05 d2.evaluation.evaluator]: Inference done 130/144. Dataloading: 0.0024 s/iter. Inference: 0.1285 s/iter. Eval: 0.3048 s/iter. Total: 0.4359 s/iter. ETA=0:00:06
[09/04 08:37:10 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0024 s/iter. Inference: 0.1281 s/iter. Eval: 0.3012 s/iter. Total: 0.4319 s/iter. ETA=0:00:00
[09/04 08:37:10 d2.evaluation.evaluator]: Total inference time: 0:01:00.093214 (0.432325 s / iter per device, on 1 devices)
[09/04 08:37:10 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:17 (0.128133 s / iter per device, on 1 devices)
[09/04 08:37:10 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:37:10 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:37:10 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[09/04 08:37:11 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:37:11 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[09/04 08:37:11 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:37:11 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.402
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.635
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.454
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.109
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.394
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.537
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.304
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.556
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.607
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.258
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.572
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.732
[09/04 08:37:11 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 40.174 | 63.548 | 45.408 | 10.937 | 39.372 | 53.724 |
Loading and preparing results...
DONE (t=0.12s)
creating index...
index created!
[09/04 08:37:11 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:37:11 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.
[09/04 08:37:11 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:37:11 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.439
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.632
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.515
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.105
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.365
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.627
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.322
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.600
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.669
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.637
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.785
[09/04 08:37:11 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 43.897 | 63.152 | 51.483 | 10.510 | 36.466 | 62.732 |
[09/04 08:37:11 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:37:11 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:37:11 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:37:11 d2.evaluation.testing]: copypaste: 40.1742,63.5476,45.4081,10.9365,39.3715,53.7239
[09/04 08:37:11 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:37:11 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:37:11 d2.evaluation.testing]: copypaste: 43.8972,63.1517,51.4827,10.5104,36.4662,62.7321
[09/04 08:37:11 d2.utils.events]:  eta: 0:08:41  iter: 399  total_loss: 0.7539  loss_cls: 0.1411  loss_box_reg: 0.3397  loss_mask: 0.1993  loss_rpn_cls: 0.004446  loss_rpn_loc: 0.004758  time: 0.8728  data_time: 0.0087  lr: 9.99e-05  max_mem: 6718M
[09/04 08:37:29 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:37:29 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:37:29 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:37:29 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:37:29 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:37:35 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0020 s/iter. Inference: 0.1250 s/iter. Eval: 0.2461 s/iter. Total: 0.3730 s/iter. ETA=0:00:49
[09/04 08:37:40 d2.evaluation.evaluator]: Inference done 28/144. Dataloading: 0.0024 s/iter. Inference: 0.1208 s/iter. Eval: 0.1987 s/iter. Total: 0.3220 s/iter. ETA=0:00:37
[09/04 08:37:45 d2.evaluation.evaluator]: Inference done 43/144. Dataloading: 0.0029 s/iter. Inference: 0.1212 s/iter. Eval: 0.2042 s/iter. Total: 0.3284 s/iter. ETA=0:00:33
[09/04 08:37:50 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0027 s/iter. Inference: 0.1243 s/iter. Eval: 0.2448 s/iter. Total: 0.3719 s/iter. ETA=0:00:33
[09/04 08:37:56 d2.evaluation.evaluator]: Inference done 66/144. Dataloading: 0.0026 s/iter. Inference: 0.1247 s/iter. Eval: 0.2533 s/iter. Total: 0.3807 s/iter. ETA=0:00:29
[09/04 08:38:01 d2.evaluation.evaluator]: Inference done 80/144. Dataloading: 0.0025 s/iter. Inference: 0.1248 s/iter. Eval: 0.2494 s/iter. Total: 0.3768 s/iter. ETA=0:00:24
[09/04 08:38:06 d2.evaluation.evaluator]: Inference done 100/144. Dataloading: 0.0026 s/iter. Inference: 0.1233 s/iter. Eval: 0.2241 s/iter. Total: 0.3502 s/iter. ETA=0:00:15
[09/04 08:38:11 d2.evaluation.evaluator]: Inference done 113/144. Dataloading: 0.0027 s/iter. Inference: 0.1236 s/iter. Eval: 0.2301 s/iter. Total: 0.3565 s/iter. ETA=0:00:11
[09/04 08:38:16 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0027 s/iter. Inference: 0.1227 s/iter. Eval: 0.2207 s/iter. Total: 0.3463 s/iter. ETA=0:00:04
[09/04 08:38:20 d2.evaluation.evaluator]: Total inference time: 0:00:47.724456 (0.343341 s / iter per device, on 1 devices)
[09/04 08:38:20 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:17 (0.122338 s / iter per device, on 1 devices)
[09/04 08:38:20 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:38:20 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:38:20 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 08:38:20 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:38:20 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/04 08:38:20 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:38:20 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.427
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.653
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.476
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.111
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.414
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.571
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.572
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.275
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.583
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.744
[09/04 08:38:20 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 42.652 | 65.340 | 47.634 | 11.061 | 41.411 | 57.074 |
Loading and preparing results...
DONE (t=0.09s)
creating index...
index created!
[09/04 08:38:21 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:38:21 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.08 seconds.
[09/04 08:38:21 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:38:21 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.454
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.650
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.536
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.105
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.373
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.647
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.331
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.603
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.659
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.620
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.782
[09/04 08:38:21 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.402 | 64.978 | 53.605 | 10.487 | 37.340 | 64.747 |
[09/04 08:38:21 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:38:21 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:38:21 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:38:21 d2.evaluation.testing]: copypaste: 42.6523,65.3399,47.6343,11.0608,41.4107,57.0738
[09/04 08:38:21 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:38:21 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:38:21 d2.evaluation.testing]: copypaste: 45.4023,64.9782,53.6054,10.4873,37.3397,64.7466
[09/04 08:38:21 d2.utils.events]:  eta: 0:08:24  iter: 419  total_loss: 0.6194  loss_cls: 0.09774  loss_box_reg: 0.3055  loss_mask: 0.1519  loss_rpn_cls: 0.008581  loss_rpn_loc: 0.002488  time: 0.8730  data_time: 0.0084  lr: 0.0001049  max_mem: 6718M
[09/04 08:38:38 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:38:38 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:38:38 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:38:38 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:38:38 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:38:44 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.1210 s/iter. Eval: 0.2014 s/iter. Total: 0.3241 s/iter. ETA=0:00:43
[09/04 08:38:49 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0025 s/iter. Inference: 0.1191 s/iter. Eval: 0.1792 s/iter. Total: 0.3010 s/iter. ETA=0:00:34
[09/04 08:38:54 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0023 s/iter. Inference: 0.1189 s/iter. Eval: 0.1768 s/iter. Total: 0.2982 s/iter. ETA=0:00:29
[09/04 08:38:59 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0023 s/iter. Inference: 0.1212 s/iter. Eval: 0.2068 s/iter. Total: 0.3304 s/iter. ETA=0:00:28
[09/04 08:39:04 d2.evaluation.evaluator]: Inference done 69/144. Dataloading: 0.0026 s/iter. Inference: 0.1233 s/iter. Eval: 0.2262 s/iter. Total: 0.3523 s/iter. ETA=0:00:26
[09/04 08:39:09 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0026 s/iter. Inference: 0.1205 s/iter. Eval: 0.1934 s/iter. Total: 0.3167 s/iter. ETA=0:00:16
[09/04 08:39:15 d2.evaluation.evaluator]: Inference done 109/144. Dataloading: 0.0025 s/iter. Inference: 0.1205 s/iter. Eval: 0.1920 s/iter. Total: 0.3152 s/iter. ETA=0:00:11
[09/04 08:39:20 d2.evaluation.evaluator]: Inference done 128/144. Dataloading: 0.0025 s/iter. Inference: 0.1200 s/iter. Eval: 0.1859 s/iter. Total: 0.3085 s/iter. ETA=0:00:04
[09/04 08:39:25 d2.evaluation.evaluator]: Total inference time: 0:00:42.676386 (0.307024 s / iter per device, on 1 devices)
[09/04 08:39:25 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:16 (0.119748 s / iter per device, on 1 devices)
[09/04 08:39:25 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:39:25 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:39:25 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 08:39:25 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:39:25 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/04 08:39:25 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:39:25 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.439
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.659
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.483
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.130
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.428
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.590
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.319
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.585
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.632
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.587
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.767
[09/04 08:39:25 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 43.921 | 65.935 | 48.341 | 13.040 | 42.797 | 59.040 |
Loading and preparing results...
DONE (t=0.08s)
creating index...
index created!
[09/04 08:39:25 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:39:25 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[09/04 08:39:25 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:39:25 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.655
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.534
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.111
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.380
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.649
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.326
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.601
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.653
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.612
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.779
[09/04 08:39:25 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.772 | 65.474 | 53.438 | 11.119 | 37.988 | 64.897 |
[09/04 08:39:25 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:39:25 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:39:25 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:39:25 d2.evaluation.testing]: copypaste: 43.9206,65.9349,48.3409,13.0399,42.7972,59.0398
[09/04 08:39:25 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:39:25 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:39:25 d2.evaluation.testing]: copypaste: 45.7719,65.4740,53.4378,11.1190,37.9877,64.8967
[09/04 08:39:25 d2.utils.events]:  eta: 0:08:07  iter: 439  total_loss: 0.7047  loss_cls: 0.121  loss_box_reg: 0.3533  loss_mask: 0.1486  loss_rpn_cls: 0.01094  loss_rpn_loc: 0.004428  time: 0.8732  data_time: 0.0080  lr: 0.00010989  max_mem: 6718M
[09/04 08:39:43 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:39:43 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:39:43 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:39:43 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:39:43 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:39:48 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0018 s/iter. Inference: 0.1172 s/iter. Eval: 0.1495 s/iter. Total: 0.2685 s/iter. ETA=0:00:35
[09/04 08:39:53 d2.evaluation.evaluator]: Inference done 32/144. Dataloading: 0.0031 s/iter. Inference: 0.1149 s/iter. Eval: 0.1272 s/iter. Total: 0.2454 s/iter. ETA=0:00:27
[09/04 08:39:58 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0028 s/iter. Inference: 0.1173 s/iter. Eval: 0.1568 s/iter. Total: 0.2771 s/iter. ETA=0:00:26
[09/04 08:40:03 d2.evaluation.evaluator]: Inference done 64/144. Dataloading: 0.0027 s/iter. Inference: 0.1184 s/iter. Eval: 0.1727 s/iter. Total: 0.2941 s/iter. ETA=0:00:23
[09/04 08:40:09 d2.evaluation.evaluator]: Inference done 84/144. Dataloading: 0.0026 s/iter. Inference: 0.1179 s/iter. Eval: 0.1637 s/iter. Total: 0.2844 s/iter. ETA=0:00:17
[09/04 08:40:14 d2.evaluation.evaluator]: Inference done 105/144. Dataloading: 0.0026 s/iter. Inference: 0.1177 s/iter. Eval: 0.1564 s/iter. Total: 0.2769 s/iter. ETA=0:00:10
[09/04 08:40:19 d2.evaluation.evaluator]: Inference done 125/144. Dataloading: 0.0028 s/iter. Inference: 0.1174 s/iter. Eval: 0.1527 s/iter. Total: 0.2729 s/iter. ETA=0:00:05
[09/04 08:40:24 d2.evaluation.evaluator]: Total inference time: 0:00:37.580323 (0.270362 s / iter per device, on 1 devices)
[09/04 08:40:24 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:16 (0.119073 s / iter per device, on 1 devices)
[09/04 08:40:24 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:40:24 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:40:24 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 08:40:24 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:40:24 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 08:40:24 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:40:24 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.456
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.679
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.502
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.146
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.438
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.608
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.335
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.591
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.633
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.592
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.762
[09/04 08:40:24 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.574 | 67.869 | 50.203 | 14.591 | 43.756 | 60.761 |
Loading and preparing results...
DONE (t=0.06s)
creating index...
index created!
[09/04 08:40:24 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:40:24 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[09/04 08:40:24 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:40:24 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.468
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.672
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.541
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.117
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.386
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.657
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.339
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.608
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.650
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.609
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.777
[09/04 08:40:24 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.789 | 67.171 | 54.088 | 11.664 | 38.559 | 65.709 |
[09/04 08:40:24 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:40:24 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:40:24 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:40:24 d2.evaluation.testing]: copypaste: 45.5737,67.8694,50.2034,14.5906,43.7561,60.7613
[09/04 08:40:24 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:40:24 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:40:24 d2.evaluation.testing]: copypaste: 46.7894,67.1707,54.0878,11.6643,38.5588,65.7092
[09/04 08:40:24 d2.utils.events]:  eta: 0:07:50  iter: 459  total_loss: 0.4945  loss_cls: 0.07352  loss_box_reg: 0.2182  loss_mask: 0.1439  loss_rpn_cls: 0.006232  loss_rpn_loc: 0.004378  time: 0.8732  data_time: 0.0081  lr: 0.00011489  max_mem: 6718M
[09/04 08:40:42 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:40:42 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:40:42 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:40:42 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:40:42 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:40:46 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.1130 s/iter. Eval: 0.1003 s/iter. Total: 0.2148 s/iter. ETA=0:00:28
[09/04 08:40:51 d2.evaluation.evaluator]: Inference done 33/144. Dataloading: 0.0031 s/iter. Inference: 0.1165 s/iter. Eval: 0.1076 s/iter. Total: 0.2273 s/iter. ETA=0:00:25
[09/04 08:40:56 d2.evaluation.evaluator]: Inference done 50/144. Dataloading: 0.0029 s/iter. Inference: 0.1175 s/iter. Eval: 0.1346 s/iter. Total: 0.2551 s/iter. ETA=0:00:23
[09/04 08:41:02 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0027 s/iter. Inference: 0.1186 s/iter. Eval: 0.1556 s/iter. Total: 0.2771 s/iter. ETA=0:00:21
[09/04 08:41:07 d2.evaluation.evaluator]: Inference done 95/144. Dataloading: 0.0025 s/iter. Inference: 0.1160 s/iter. Eval: 0.1283 s/iter. Total: 0.2469 s/iter. ETA=0:00:12
[09/04 08:41:12 d2.evaluation.evaluator]: Inference done 114/144. Dataloading: 0.0026 s/iter. Inference: 0.1161 s/iter. Eval: 0.1324 s/iter. Total: 0.2512 s/iter. ETA=0:00:07
[09/04 08:41:17 d2.evaluation.evaluator]: Inference done 139/144. Dataloading: 0.0029 s/iter. Inference: 0.1156 s/iter. Eval: 0.1237 s/iter. Total: 0.2424 s/iter. ETA=0:00:01
[09/04 08:41:19 d2.evaluation.evaluator]: Total inference time: 0:00:34.048005 (0.244950 s / iter per device, on 1 devices)
[09/04 08:41:19 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:16 (0.115638 s / iter per device, on 1 devices)
[09/04 08:41:19 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:41:19 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:41:19 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 08:41:19 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:41:19 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 08:41:19 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:41:19 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.463
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.690
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.506
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.152
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.434
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.620
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.332
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.596
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.634
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.325
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.595
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.758
[09/04 08:41:19 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.259 | 68.962 | 50.609 | 15.246 | 43.369 | 62.009 |
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
[09/04 08:41:19 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:41:19 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[09/04 08:41:19 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:41:19 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.475
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.685
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.556
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.129
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.389
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.666
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.338
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.609
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.650
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.604
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.782
[09/04 08:41:19 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.456 | 68.476 | 55.586 | 12.879 | 38.921 | 66.555 |
[09/04 08:41:19 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:41:19 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:41:19 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:41:19 d2.evaluation.testing]: copypaste: 46.2591,68.9621,50.6093,15.2460,43.3689,62.0091
[09/04 08:41:19 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:41:19 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:41:19 d2.evaluation.testing]: copypaste: 47.4564,68.4762,55.5865,12.8792,38.9209,66.5553
[09/04 08:41:19 d2.utils.events]:  eta: 0:07:32  iter: 479  total_loss: 0.4516  loss_cls: 0.08994  loss_box_reg: 0.228  loss_mask: 0.139  loss_rpn_cls: 0.004018  loss_rpn_loc: 0.003354  time: 0.8732  data_time: 0.0092  lr: 0.00011988  max_mem: 6718M
[09/04 08:41:37 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:41:37 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:41:37 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:41:37 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:41:37 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:41:42 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0019 s/iter. Inference: 0.1194 s/iter. Eval: 0.1618 s/iter. Total: 0.2830 s/iter. ETA=0:00:37
[09/04 08:41:47 d2.evaluation.evaluator]: Inference done 30/144. Dataloading: 0.0027 s/iter. Inference: 0.1193 s/iter. Eval: 0.1501 s/iter. Total: 0.2723 s/iter. ETA=0:00:31
[09/04 08:41:52 d2.evaluation.evaluator]: Inference done 46/144. Dataloading: 0.0027 s/iter. Inference: 0.1211 s/iter. Eval: 0.1671 s/iter. Total: 0.2911 s/iter. ETA=0:00:28
[09/04 08:41:57 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0028 s/iter. Inference: 0.1232 s/iter. Eval: 0.2034 s/iter. Total: 0.3296 s/iter. ETA=0:00:28
[09/04 08:42:02 d2.evaluation.evaluator]: Inference done 69/144. Dataloading: 0.0028 s/iter. Inference: 0.1243 s/iter. Eval: 0.2200 s/iter. Total: 0.3473 s/iter. ETA=0:00:26
[09/04 08:42:08 d2.evaluation.evaluator]: Inference done 93/144. Dataloading: 0.0028 s/iter. Inference: 0.1214 s/iter. Eval: 0.1858 s/iter. Total: 0.3103 s/iter. ETA=0:00:15
[09/04 08:42:13 d2.evaluation.evaluator]: Inference done 112/144. Dataloading: 0.0029 s/iter. Inference: 0.1207 s/iter. Eval: 0.1814 s/iter. Total: 0.3052 s/iter. ETA=0:00:09
[09/04 08:42:18 d2.evaluation.evaluator]: Inference done 134/144. Dataloading: 0.0029 s/iter. Inference: 0.1195 s/iter. Eval: 0.1708 s/iter. Total: 0.2934 s/iter. ETA=0:00:02
[09/04 08:42:21 d2.evaluation.evaluator]: Total inference time: 0:00:40.683872 (0.292690 s / iter per device, on 1 devices)
[09/04 08:42:21 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:16 (0.119306 s / iter per device, on 1 devices)
[09/04 08:42:21 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:42:21 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:42:21 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 08:42:21 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:42:21 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/04 08:42:21 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:42:21 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.465
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.690
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.515
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.152
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.448
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.621
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.338
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.595
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.646
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.767
[09/04 08:42:21 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.501 | 68.976 | 51.546 | 15.236 | 44.830 | 62.114 |
Loading and preparing results...
DONE (t=0.11s)
creating index...
index created!
[09/04 08:42:21 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:42:21 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.12 seconds.
[09/04 08:42:21 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:42:22 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.472
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.688
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.543
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.135
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.388
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.661
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.339
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.607
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.655
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.615
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.782
[09/04 08:42:22 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.189 | 68.806 | 54.290 | 13.515 | 38.752 | 66.099 |
[09/04 08:42:22 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:42:22 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:42:22 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:42:22 d2.evaluation.testing]: copypaste: 46.5013,68.9756,51.5460,15.2364,44.8299,62.1139
[09/04 08:42:22 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:42:22 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:42:22 d2.evaluation.testing]: copypaste: 47.1894,68.8057,54.2902,13.5155,38.7521,66.0990
[09/04 08:42:22 d2.utils.events]:  eta: 0:07:15  iter: 499  total_loss: 0.5679  loss_cls: 0.1504  loss_box_reg: 0.2388  loss_mask: 0.1821  loss_rpn_cls: 0.00411  loss_rpn_loc: 0.005824  time: 0.8733  data_time: 0.0084  lr: 0.00012488  max_mem: 6718M
[09/04 08:42:39 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:42:39 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:42:39 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:42:39 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:42:39 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:42:44 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.1144 s/iter. Eval: 0.1237 s/iter. Total: 0.2397 s/iter. ETA=0:00:31
[09/04 08:42:49 d2.evaluation.evaluator]: Inference done 33/144. Dataloading: 0.0021 s/iter. Inference: 0.1140 s/iter. Eval: 0.1188 s/iter. Total: 0.2351 s/iter. ETA=0:00:26
[09/04 08:42:54 d2.evaluation.evaluator]: Inference done 48/144. Dataloading: 0.0023 s/iter. Inference: 0.1181 s/iter. Eval: 0.1569 s/iter. Total: 0.2775 s/iter. ETA=0:00:26
[09/04 08:42:59 d2.evaluation.evaluator]: Inference done 60/144. Dataloading: 0.0023 s/iter. Inference: 0.1203 s/iter. Eval: 0.1860 s/iter. Total: 0.3087 s/iter. ETA=0:00:25
[09/04 08:43:04 d2.evaluation.evaluator]: Inference done 76/144. Dataloading: 0.0025 s/iter. Inference: 0.1200 s/iter. Eval: 0.1876 s/iter. Total: 0.3103 s/iter. ETA=0:00:21
[09/04 08:43:09 d2.evaluation.evaluator]: Inference done 101/144. Dataloading: 0.0025 s/iter. Inference: 0.1179 s/iter. Eval: 0.1612 s/iter. Total: 0.2817 s/iter. ETA=0:00:12
[09/04 08:43:15 d2.evaluation.evaluator]: Inference done 121/144. Dataloading: 0.0028 s/iter. Inference: 0.1174 s/iter. Eval: 0.1573 s/iter. Total: 0.2776 s/iter. ETA=0:00:06
[09/04 08:43:20 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0028 s/iter. Inference: 0.1170 s/iter. Eval: 0.1506 s/iter. Total: 0.2706 s/iter. ETA=0:00:00
[09/04 08:43:20 d2.evaluation.evaluator]: Total inference time: 0:00:37.665061 (0.270972 s / iter per device, on 1 devices)
[09/04 08:43:20 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:16 (0.117007 s / iter per device, on 1 devices)
[09/04 08:43:20 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:43:20 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:43:20 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 08:43:20 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:43:20 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 08:43:20 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:43:20 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.695
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.519
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.144
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.429
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.620
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.327
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.584
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.630
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.308
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.590
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.758
[09/04 08:43:20 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 45.834 | 69.481 | 51.916 | 14.352 | 42.907 | 61.959 |
Loading and preparing results...
DONE (t=0.06s)
creating index...
index created!
[09/04 08:43:20 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:43:20 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[09/04 08:43:20 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:43:20 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.476
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.693
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.541
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.126
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.391
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.668
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.336
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.607
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.655
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.342
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.614
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.785
[09/04 08:43:20 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.555 | 69.328 | 54.148 | 12.592 | 39.147 | 66.827 |
[09/04 08:43:20 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:43:20 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:43:20 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:43:20 d2.evaluation.testing]: copypaste: 45.8343,69.4813,51.9159,14.3525,42.9074,61.9594
[09/04 08:43:20 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:43:20 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:43:20 d2.evaluation.testing]: copypaste: 47.5549,69.3278,54.1479,12.5917,39.1473,66.8268
[09/04 08:43:20 d2.utils.events]:  eta: 0:06:58  iter: 519  total_loss: 0.513  loss_cls: 0.1039  loss_box_reg: 0.2281  loss_mask: 0.1259  loss_rpn_cls: 0.00562  loss_rpn_loc: 0.005671  time: 0.8736  data_time: 0.0081  lr: 0.00012987  max_mem: 6718M
[09/04 08:43:38 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:43:38 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:43:38 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:43:38 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:43:38 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:43:42 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.1134 s/iter. Eval: 0.1009 s/iter. Total: 0.2159 s/iter. ETA=0:00:28
[09/04 08:43:47 d2.evaluation.evaluator]: Inference done 33/144. Dataloading: 0.0024 s/iter. Inference: 0.1151 s/iter. Eval: 0.1073 s/iter. Total: 0.2249 s/iter. ETA=0:00:24
[09/04 08:43:52 d2.evaluation.evaluator]: Inference done 49/144. Dataloading: 0.0029 s/iter. Inference: 0.1173 s/iter. Eval: 0.1415 s/iter. Total: 0.2618 s/iter. ETA=0:00:24
[09/04 08:43:57 d2.evaluation.evaluator]: Inference done 64/144. Dataloading: 0.0030 s/iter. Inference: 0.1190 s/iter. Eval: 0.1601 s/iter. Total: 0.2822 s/iter. ETA=0:00:22
[09/04 08:44:03 d2.evaluation.evaluator]: Inference done 86/144. Dataloading: 0.0030 s/iter. Inference: 0.1181 s/iter. Eval: 0.1474 s/iter. Total: 0.2686 s/iter. ETA=0:00:15
[09/04 08:44:08 d2.evaluation.evaluator]: Inference done 110/144. Dataloading: 0.0029 s/iter. Inference: 0.1167 s/iter. Eval: 0.1371 s/iter. Total: 0.2570 s/iter. ETA=0:00:08
[09/04 08:44:13 d2.evaluation.evaluator]: Inference done 137/144. Dataloading: 0.0028 s/iter. Inference: 0.1153 s/iter. Eval: 0.1247 s/iter. Total: 0.2430 s/iter. ETA=0:00:01
[09/04 08:44:15 d2.evaluation.evaluator]: Total inference time: 0:00:33.926252 (0.244074 s / iter per device, on 1 devices)
[09/04 08:44:15 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:16 (0.115239 s / iter per device, on 1 devices)
[09/04 08:44:15 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:44:15 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:44:15 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 08:44:15 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:44:15 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 08:44:15 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:44:15 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.470
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.694
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.522
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.141
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.427
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.649
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.335
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.591
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.637
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.267
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.599
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.771
[09/04 08:44:15 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.995 | 69.373 | 52.233 | 14.147 | 42.747 | 64.875 |
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
[09/04 08:44:15 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:44:15 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[09/04 08:44:15 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:44:15 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.476
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.690
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.545
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.122
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.390
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.674
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.335
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.604
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.647
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.292
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.604
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.785
[09/04 08:44:15 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.564 | 69.007 | 54.475 | 12.184 | 38.978 | 67.420 |
[09/04 08:44:15 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:44:15 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:44:15 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:44:15 d2.evaluation.testing]: copypaste: 46.9949,69.3731,52.2332,14.1471,42.7468,64.8747
[09/04 08:44:15 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:44:15 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:44:15 d2.evaluation.testing]: copypaste: 47.5640,69.0071,54.4748,12.1842,38.9780,67.4196
[09/04 08:44:15 d2.utils.events]:  eta: 0:06:40  iter: 539  total_loss: 0.502  loss_cls: 0.08537  loss_box_reg: 0.1744  loss_mask: 0.1593  loss_rpn_cls: 0.004833  loss_rpn_loc: 0.006226  time: 0.8738  data_time: 0.0097  lr: 0.00013487  max_mem: 6718M
[09/04 08:44:33 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:44:33 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:44:33 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:44:33 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:44:33 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:44:37 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0017 s/iter. Inference: 0.1127 s/iter. Eval: 0.0911 s/iter. Total: 0.2055 s/iter. ETA=0:00:27
[09/04 08:44:42 d2.evaluation.evaluator]: Inference done 34/144. Dataloading: 0.0036 s/iter. Inference: 0.1147 s/iter. Eval: 0.1032 s/iter. Total: 0.2217 s/iter. ETA=0:00:24
[09/04 08:44:47 d2.evaluation.evaluator]: Inference done 50/144. Dataloading: 0.0034 s/iter. Inference: 0.1169 s/iter. Eval: 0.1361 s/iter. Total: 0.2565 s/iter. ETA=0:00:24
[09/04 08:44:53 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0032 s/iter. Inference: 0.1185 s/iter. Eval: 0.1553 s/iter. Total: 0.2772 s/iter. ETA=0:00:21
[09/04 08:44:58 d2.evaluation.evaluator]: Inference done 93/144. Dataloading: 0.0030 s/iter. Inference: 0.1184 s/iter. Eval: 0.1317 s/iter. Total: 0.2532 s/iter. ETA=0:00:12
[09/04 08:45:03 d2.evaluation.evaluator]: Inference done 114/144. Dataloading: 0.0031 s/iter. Inference: 0.1181 s/iter. Eval: 0.1310 s/iter. Total: 0.2524 s/iter. ETA=0:00:07
[09/04 08:45:08 d2.evaluation.evaluator]: Inference done 142/144. Dataloading: 0.0032 s/iter. Inference: 0.1164 s/iter. Eval: 0.1188 s/iter. Total: 0.2386 s/iter. ETA=0:00:00
[09/04 08:45:09 d2.evaluation.evaluator]: Total inference time: 0:00:33.601003 (0.241734 s / iter per device, on 1 devices)
[09/04 08:45:09 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:16 (0.116575 s / iter per device, on 1 devices)
[09/04 08:45:09 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:45:09 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:45:09 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 08:45:09 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:45:09 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 08:45:09 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:45:09 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.469
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.693
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.511
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.145
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.438
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.643
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.336
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.595
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.641
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.599
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.773
[09/04 08:45:09 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.876 | 69.272 | 51.140 | 14.538 | 43.842 | 64.339 |
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
[09/04 08:45:09 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:45:09 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[09/04 08:45:09 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:45:09 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.481
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.691
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.556
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.127
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.397
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.681
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.337
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.611
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.653
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.608
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.792
[09/04 08:45:09 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.079 | 69.119 | 55.638 | 12.742 | 39.710 | 68.149 |
[09/04 08:45:09 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:45:09 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:45:09 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:45:09 d2.evaluation.testing]: copypaste: 46.8762,69.2722,51.1396,14.5384,43.8415,64.3389
[09/04 08:45:09 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:45:09 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:45:09 d2.evaluation.testing]: copypaste: 48.0794,69.1193,55.6379,12.7421,39.7102,68.1489
[09/04 08:45:09 d2.utils.events]:  eta: 0:06:23  iter: 559  total_loss: 0.5327  loss_cls: 0.08647  loss_box_reg: 0.1944  loss_mask: 0.1395  loss_rpn_cls: 0.006817  loss_rpn_loc: 0.003476  time: 0.8740  data_time: 0.0091  lr: 0.00013986  max_mem: 6718M
[09/04 08:45:27 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:45:27 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:45:27 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:45:27 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:45:27 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:45:32 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0017 s/iter. Inference: 0.1156 s/iter. Eval: 0.1221 s/iter. Total: 0.2395 s/iter. ETA=0:00:31
[09/04 08:45:37 d2.evaluation.evaluator]: Inference done 29/144. Dataloading: 0.0028 s/iter. Inference: 0.1195 s/iter. Eval: 0.1529 s/iter. Total: 0.2753 s/iter. ETA=0:00:31
[09/04 08:45:42 d2.evaluation.evaluator]: Inference done 47/144. Dataloading: 0.0027 s/iter. Inference: 0.1193 s/iter. Eval: 0.1622 s/iter. Total: 0.2844 s/iter. ETA=0:00:27
[09/04 08:45:47 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0028 s/iter. Inference: 0.1222 s/iter. Eval: 0.1958 s/iter. Total: 0.3210 s/iter. ETA=0:00:27
[09/04 08:45:52 d2.evaluation.evaluator]: Inference done 73/144. Dataloading: 0.0027 s/iter. Inference: 0.1222 s/iter. Eval: 0.2001 s/iter. Total: 0.3251 s/iter. ETA=0:00:23
[09/04 08:45:58 d2.evaluation.evaluator]: Inference done 100/144. Dataloading: 0.0029 s/iter. Inference: 0.1195 s/iter. Eval: 0.1684 s/iter. Total: 0.2910 s/iter. ETA=0:00:12
[09/04 08:46:03 d2.evaluation.evaluator]: Inference done 121/144. Dataloading: 0.0028 s/iter. Inference: 0.1187 s/iter. Eval: 0.1612 s/iter. Total: 0.2828 s/iter. ETA=0:00:06
[09/04 08:46:08 d2.evaluation.evaluator]: Inference done 142/144. Dataloading: 0.0028 s/iter. Inference: 0.1186 s/iter. Eval: 0.1568 s/iter. Total: 0.2784 s/iter. ETA=0:00:00
[09/04 08:46:09 d2.evaluation.evaluator]: Total inference time: 0:00:39.258538 (0.282436 s / iter per device, on 1 devices)
[09/04 08:46:09 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:16 (0.118834 s / iter per device, on 1 devices)
[09/04 08:46:10 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:46:10 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:46:10 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 08:46:10 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:46:10 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 08:46:10 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:46:10 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.469
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.705
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.541
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.163
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.427
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.637
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.594
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.642
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.308
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.609
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.761
[09/04 08:46:10 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.876 | 70.506 | 54.068 | 16.346 | 42.659 | 63.716 |
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
[09/04 08:46:10 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:46:10 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.
[09/04 08:46:10 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:46:10 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.485
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.706
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.562
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.133
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.416
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.670
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.611
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.668
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.633
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.786
[09/04 08:46:10 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.539 | 70.621 | 56.166 | 13.310 | 41.583 | 67.004 |
[09/04 08:46:10 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:46:10 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:46:10 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:46:10 d2.evaluation.testing]: copypaste: 46.8760,70.5055,54.0682,16.3462,42.6592,63.7156
[09/04 08:46:10 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:46:10 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:46:10 d2.evaluation.testing]: copypaste: 48.5386,70.6211,56.1658,13.3101,41.5835,67.0043
[09/04 08:46:10 d2.utils.events]:  eta: 0:06:05  iter: 579  total_loss: 0.5632  loss_cls: 0.1105  loss_box_reg: 0.2149  loss_mask: 0.1717  loss_rpn_cls: 0.008795  loss_rpn_loc: 0.00312  time: 0.8742  data_time: 0.0095  lr: 0.00014486  max_mem: 6718M
[09/04 08:46:27 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:46:27 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:46:27 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:46:27 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:46:27 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:46:31 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0017 s/iter. Inference: 0.1187 s/iter. Eval: 0.0846 s/iter. Total: 0.2050 s/iter. ETA=0:00:27
[09/04 08:46:36 d2.evaluation.evaluator]: Inference done 38/144. Dataloading: 0.0020 s/iter. Inference: 0.1122 s/iter. Eval: 0.0758 s/iter. Total: 0.1901 s/iter. ETA=0:00:20
[09/04 08:46:41 d2.evaluation.evaluator]: Inference done 55/144. Dataloading: 0.0027 s/iter. Inference: 0.1150 s/iter. Eval: 0.1079 s/iter. Total: 0.2257 s/iter. ETA=0:00:20
[09/04 08:46:46 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0026 s/iter. Inference: 0.1152 s/iter. Eval: 0.1104 s/iter. Total: 0.2283 s/iter. ETA=0:00:15
[09/04 08:46:51 d2.evaluation.evaluator]: Inference done 107/144. Dataloading: 0.0027 s/iter. Inference: 0.1133 s/iter. Eval: 0.0942 s/iter. Total: 0.2104 s/iter. ETA=0:00:07
[09/04 08:46:56 d2.evaluation.evaluator]: Inference done 135/144. Dataloading: 0.0028 s/iter. Inference: 0.1126 s/iter. Eval: 0.0889 s/iter. Total: 0.2045 s/iter. ETA=0:00:01
[09/04 08:46:58 d2.evaluation.evaluator]: Total inference time: 0:00:28.593739 (0.205710 s / iter per device, on 1 devices)
[09/04 08:46:58 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:15 (0.112537 s / iter per device, on 1 devices)
[09/04 08:46:58 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:46:58 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:46:58 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 08:46:58 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:46:59 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 08:46:59 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:46:59 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.487
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.714
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.561
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.173
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.449
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.663
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.351
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.602
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.637
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.225
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.594
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.786
[09/04 08:46:59 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.735 | 71.364 | 56.094 | 17.266 | 44.900 | 66.316 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[09/04 08:46:59 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:46:59 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/04 08:46:59 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:46:59 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.494
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.712
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.574
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.149
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.414
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.683
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.351
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.644
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.258
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.605
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.782
[09/04 08:46:59 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.406 | 71.171 | 57.368 | 14.900 | 41.387 | 68.313 |
[09/04 08:46:59 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:46:59 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:46:59 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:46:59 d2.evaluation.testing]: copypaste: 48.7354,71.3640,56.0941,17.2661,44.9003,66.3157
[09/04 08:46:59 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:46:59 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:46:59 d2.evaluation.testing]: copypaste: 49.4063,71.1708,57.3680,14.9004,41.3874,68.3130
[09/04 08:46:59 d2.utils.events]:  eta: 0:05:48  iter: 599  total_loss: 0.4514  loss_cls: 0.1084  loss_box_reg: 0.1766  loss_mask: 0.135  loss_rpn_cls: 0.005612  loss_rpn_loc: 0.00438  time: 0.8742  data_time: 0.0090  lr: 0.00014985  max_mem: 6718M
[09/04 08:47:16 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:47:16 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:47:16 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:47:16 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:47:16 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:47:20 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.1104 s/iter. Eval: 0.0740 s/iter. Total: 0.1859 s/iter. ETA=0:00:24
[09/04 08:47:25 d2.evaluation.evaluator]: Inference done 36/144. Dataloading: 0.0025 s/iter. Inference: 0.1117 s/iter. Eval: 0.0844 s/iter. Total: 0.1987 s/iter. ETA=0:00:21
[09/04 08:47:30 d2.evaluation.evaluator]: Inference done 54/144. Dataloading: 0.0025 s/iter. Inference: 0.1146 s/iter. Eval: 0.1118 s/iter. Total: 0.2292 s/iter. ETA=0:00:20
[09/04 08:47:35 d2.evaluation.evaluator]: Inference done 74/144. Dataloading: 0.0026 s/iter. Inference: 0.1149 s/iter. Eval: 0.1188 s/iter. Total: 0.2365 s/iter. ETA=0:00:16
[09/04 08:47:40 d2.evaluation.evaluator]: Inference done 103/144. Dataloading: 0.0029 s/iter. Inference: 0.1135 s/iter. Eval: 0.1022 s/iter. Total: 0.2188 s/iter. ETA=0:00:08
[09/04 08:47:45 d2.evaluation.evaluator]: Inference done 128/144. Dataloading: 0.0031 s/iter. Inference: 0.1137 s/iter. Eval: 0.0987 s/iter. Total: 0.2156 s/iter. ETA=0:00:03
[09/04 08:47:49 d2.evaluation.evaluator]: Total inference time: 0:00:30.223033 (0.217432 s / iter per device, on 1 devices)
[09/04 08:47:49 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:15 (0.113714 s / iter per device, on 1 devices)
[09/04 08:47:49 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:47:49 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:47:49 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 08:47:49 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:47:49 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 08:47:49 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:47:49 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.494
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.721
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.567
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.184
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.452
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.661
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.347
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.612
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.651
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.275
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.792
[09/04 08:47:49 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.350 | 72.102 | 56.747 | 18.397 | 45.173 | 66.093 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[09/04 08:47:49 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:47:49 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/04 08:47:49 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:47:49 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.501
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.718
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.577
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.159
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.426
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.680
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.348
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.617
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.657
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.308
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.618
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.788
[09/04 08:47:49 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.116 | 71.792 | 57.721 | 15.920 | 42.614 | 68.026 |
[09/04 08:47:49 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:47:49 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:47:49 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:47:49 d2.evaluation.testing]: copypaste: 49.3503,72.1024,56.7467,18.3966,45.1732,66.0933
[09/04 08:47:49 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:47:49 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:47:49 d2.evaluation.testing]: copypaste: 50.1160,71.7923,57.7205,15.9196,42.6140,68.0264
[09/04 08:47:49 d2.utils.events]:  eta: 0:05:31  iter: 619  total_loss: 0.361  loss_cls: 0.04927  loss_box_reg: 0.1444  loss_mask: 0.1737  loss_rpn_cls: 0.005584  loss_rpn_loc: 0.002047  time: 0.8742  data_time: 0.0077  lr: 0.00015485  max_mem: 6718M
[09/04 08:48:07 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:48:07 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:48:07 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:48:07 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:48:07 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:48:11 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0023 s/iter. Inference: 0.1110 s/iter. Eval: 0.0833 s/iter. Total: 0.1966 s/iter. ETA=0:00:26
[09/04 08:48:16 d2.evaluation.evaluator]: Inference done 36/144. Dataloading: 0.0026 s/iter. Inference: 0.1130 s/iter. Eval: 0.0904 s/iter. Total: 0.2061 s/iter. ETA=0:00:22
[09/04 08:48:21 d2.evaluation.evaluator]: Inference done 52/144. Dataloading: 0.0029 s/iter. Inference: 0.1162 s/iter. Eval: 0.1234 s/iter. Total: 0.2429 s/iter. ETA=0:00:22
[09/04 08:48:26 d2.evaluation.evaluator]: Inference done 69/144. Dataloading: 0.0028 s/iter. Inference: 0.1171 s/iter. Eval: 0.1407 s/iter. Total: 0.2609 s/iter. ETA=0:00:19
[09/04 08:48:31 d2.evaluation.evaluator]: Inference done 100/144. Dataloading: 0.0029 s/iter. Inference: 0.1147 s/iter. Eval: 0.1146 s/iter. Total: 0.2323 s/iter. ETA=0:00:10
[09/04 08:48:36 d2.evaluation.evaluator]: Inference done 125/144. Dataloading: 0.0029 s/iter. Inference: 0.1139 s/iter. Eval: 0.1086 s/iter. Total: 0.2256 s/iter. ETA=0:00:04
[09/04 08:48:41 d2.evaluation.evaluator]: Total inference time: 0:00:31.225347 (0.224643 s / iter per device, on 1 devices)
[09/04 08:48:41 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:15 (0.113662 s / iter per device, on 1 devices)
[09/04 08:48:41 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:48:41 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:48:41 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 08:48:41 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:48:41 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 08:48:41 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:48:41 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.481
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.726
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.569
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.191
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.451
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.636
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.337
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.597
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.638
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.325
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.593
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.774
[09/04 08:48:41 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.147 | 72.567 | 56.861 | 19.106 | 45.088 | 63.622 |
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
[09/04 08:48:41 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:48:41 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.
[09/04 08:48:41 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:48:41 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.499
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.724
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.589
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.177
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.422
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.680
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.346
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.612
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.658
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.615
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.788
[09/04 08:48:41 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.877 | 72.358 | 58.879 | 17.660 | 42.197 | 67.996 |
[09/04 08:48:41 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:48:41 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:48:41 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:48:41 d2.evaluation.testing]: copypaste: 48.1473,72.5673,56.8607,19.1058,45.0875,63.6215
[09/04 08:48:41 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:48:41 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:48:41 d2.evaluation.testing]: copypaste: 49.8767,72.3581,58.8792,17.6603,42.1970,67.9961
[09/04 08:48:41 d2.utils.events]:  eta: 0:05:13  iter: 639  total_loss: 0.323  loss_cls: 0.05445  loss_box_reg: 0.1096  loss_mask: 0.1159  loss_rpn_cls: 0.006109  loss_rpn_loc: 0.002521  time: 0.8740  data_time: 0.0073  lr: 0.00015984  max_mem: 6718M
[09/04 08:48:58 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:48:58 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:48:58 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:48:58 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:48:59 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:49:02 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0017 s/iter. Inference: 0.1116 s/iter. Eval: 0.0785 s/iter. Total: 0.1918 s/iter. ETA=0:00:25
[09/04 08:49:07 d2.evaluation.evaluator]: Inference done 34/144. Dataloading: 0.0032 s/iter. Inference: 0.1144 s/iter. Eval: 0.0960 s/iter. Total: 0.2138 s/iter. ETA=0:00:23
[09/04 08:49:12 d2.evaluation.evaluator]: Inference done 51/144. Dataloading: 0.0034 s/iter. Inference: 0.1166 s/iter. Eval: 0.1264 s/iter. Total: 0.2466 s/iter. ETA=0:00:22
[09/04 08:49:18 d2.evaluation.evaluator]: Inference done 67/144. Dataloading: 0.0035 s/iter. Inference: 0.1174 s/iter. Eval: 0.1465 s/iter. Total: 0.2675 s/iter. ETA=0:00:20
[09/04 08:49:23 d2.evaluation.evaluator]: Inference done 93/144. Dataloading: 0.0037 s/iter. Inference: 0.1164 s/iter. Eval: 0.1255 s/iter. Total: 0.2457 s/iter. ETA=0:00:12
[09/04 08:49:28 d2.evaluation.evaluator]: Inference done 117/144. Dataloading: 0.0036 s/iter. Inference: 0.1156 s/iter. Eval: 0.1193 s/iter. Total: 0.2386 s/iter. ETA=0:00:06
[09/04 08:49:33 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0034 s/iter. Inference: 0.1147 s/iter. Eval: 0.1130 s/iter. Total: 0.2312 s/iter. ETA=0:00:00
[09/04 08:49:33 d2.evaluation.evaluator]: Total inference time: 0:00:32.192241 (0.231599 s / iter per device, on 1 devices)
[09/04 08:49:33 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:15 (0.114696 s / iter per device, on 1 devices)
[09/04 08:49:33 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:49:33 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:49:33 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 08:49:33 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:49:33 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 08:49:33 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:49:33 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.490
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.723
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.539
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.207
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.453
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.648
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.353
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.609
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.651
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.780
[09/04 08:49:33 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.963 | 72.262 | 53.918 | 20.719 | 45.332 | 64.787 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[09/04 08:49:34 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:49:34 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/04 08:49:34 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:49:34 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.492
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.721
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.564
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.161
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.416
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.674
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.351
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.605
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.648
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.605
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.779
[09/04 08:49:34 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.231 | 72.086 | 56.361 | 16.099 | 41.648 | 67.419 |
[09/04 08:49:34 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:49:34 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:49:34 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:49:34 d2.evaluation.testing]: copypaste: 48.9631,72.2616,53.9183,20.7191,45.3324,64.7869
[09/04 08:49:34 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:49:34 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:49:34 d2.evaluation.testing]: copypaste: 49.2310,72.0857,56.3612,16.0993,41.6480,67.4194
[09/04 08:49:34 d2.utils.events]:  eta: 0:04:56  iter: 659  total_loss: 0.5587  loss_cls: 0.1176  loss_box_reg: 0.2127  loss_mask: 0.1939  loss_rpn_cls: 0.002805  loss_rpn_loc: 0.004663  time: 0.8741  data_time: 0.0081  lr: 0.00016484  max_mem: 6718M
[09/04 08:49:51 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:49:51 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:49:51 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:49:51 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:49:51 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:49:55 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0065 s/iter. Inference: 0.1271 s/iter. Eval: 0.1190 s/iter. Total: 0.2526 s/iter. ETA=0:00:33
[09/04 08:50:00 d2.evaluation.evaluator]: Inference done 37/144. Dataloading: 0.0041 s/iter. Inference: 0.1146 s/iter. Eval: 0.0864 s/iter. Total: 0.2053 s/iter. ETA=0:00:21
[09/04 08:50:05 d2.evaluation.evaluator]: Inference done 56/144. Dataloading: 0.0035 s/iter. Inference: 0.1150 s/iter. Eval: 0.1089 s/iter. Total: 0.2277 s/iter. ETA=0:00:20
[09/04 08:50:10 d2.evaluation.evaluator]: Inference done 78/144. Dataloading: 0.0034 s/iter. Inference: 0.1156 s/iter. Eval: 0.1090 s/iter. Total: 0.2283 s/iter. ETA=0:00:15
[09/04 08:50:15 d2.evaluation.evaluator]: Inference done 109/144. Dataloading: 0.0035 s/iter. Inference: 0.1137 s/iter. Eval: 0.0914 s/iter. Total: 0.2088 s/iter. ETA=0:00:07
[09/04 08:50:21 d2.evaluation.evaluator]: Inference done 140/144. Dataloading: 0.0034 s/iter. Inference: 0.1127 s/iter. Eval: 0.0826 s/iter. Total: 0.1990 s/iter. ETA=0:00:00
[09/04 08:50:22 d2.evaluation.evaluator]: Total inference time: 0:00:28.122301 (0.202319 s / iter per device, on 1 devices)
[09/04 08:50:22 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:15 (0.112884 s / iter per device, on 1 devices)
[09/04 08:50:22 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:50:22 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:50:22 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 08:50:22 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:50:22 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 08:50:22 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:50:22 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.494
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.723
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.557
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.192
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.458
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.663
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.356
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.609
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.639
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.242
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.598
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.783
[09/04 08:50:22 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.362 | 72.328 | 55.708 | 19.174 | 45.753 | 66.331 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[09/04 08:50:22 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:50:22 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/04 08:50:22 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:50:22 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.493
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.714
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.566
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.161
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.416
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.681
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.353
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.608
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.637
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.250
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.596
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.780
[09/04 08:50:22 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.290 | 71.434 | 56.615 | 16.143 | 41.645 | 68.130 |
[09/04 08:50:22 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:50:22 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:50:22 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:50:22 d2.evaluation.testing]: copypaste: 49.3620,72.3280,55.7080,19.1738,45.7532,66.3306
[09/04 08:50:22 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:50:22 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:50:22 d2.evaluation.testing]: copypaste: 49.2905,71.4339,56.6154,16.1427,41.6452,68.1299
[09/04 08:50:22 d2.utils.events]:  eta: 0:04:38  iter: 679  total_loss: 0.4267  loss_cls: 0.07665  loss_box_reg: 0.182  loss_mask: 0.1356  loss_rpn_cls: 0.001567  loss_rpn_loc: 0.004449  time: 0.8742  data_time: 0.0091  lr: 0.00016983  max_mem: 6718M
[09/04 08:50:39 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:50:40 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:50:40 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:50:40 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:50:40 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:50:42 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0018 s/iter. Inference: 0.1089 s/iter. Eval: 0.0469 s/iter. Total: 0.1577 s/iter. ETA=0:00:20
[09/04 08:50:47 d2.evaluation.evaluator]: Inference done 39/144. Dataloading: 0.0038 s/iter. Inference: 0.1112 s/iter. Eval: 0.0609 s/iter. Total: 0.1760 s/iter. ETA=0:00:18
[09/04 08:50:53 d2.evaluation.evaluator]: Inference done 62/144. Dataloading: 0.0032 s/iter. Inference: 0.1125 s/iter. Eval: 0.0803 s/iter. Total: 0.1961 s/iter. ETA=0:00:16
[09/04 08:50:58 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0033 s/iter. Inference: 0.1116 s/iter. Eval: 0.0713 s/iter. Total: 0.1862 s/iter. ETA=0:00:09
[09/04 08:51:03 d2.evaluation.evaluator]: Inference done 121/144. Dataloading: 0.0039 s/iter. Inference: 0.1117 s/iter. Eval: 0.0681 s/iter. Total: 0.1838 s/iter. ETA=0:00:04
[09/04 08:51:07 d2.evaluation.evaluator]: Total inference time: 0:00:25.577820 (0.184013 s / iter per device, on 1 devices)
[09/04 08:51:07 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:15 (0.111696 s / iter per device, on 1 devices)
[09/04 08:51:07 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:51:07 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:51:07 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 08:51:07 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:51:07 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 08:51:07 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:51:07 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.494
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.722
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.584
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.195
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.465
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.658
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.356
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.608
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.640
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.233
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.591
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.798
[09/04 08:51:07 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.411 | 72.173 | 58.436 | 19.519 | 46.533 | 65.809 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[09/04 08:51:07 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:51:07 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 08:51:07 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:51:07 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.501
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.720
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.562
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.164
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.427
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.687
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.353
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.617
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.644
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.267
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.600
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.788
[09/04 08:51:07 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.129 | 71.953 | 56.215 | 16.374 | 42.659 | 68.709 |
[09/04 08:51:07 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:51:07 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:51:07 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:51:07 d2.evaluation.testing]: copypaste: 49.4107,72.1733,58.4356,19.5194,46.5327,65.8089
[09/04 08:51:07 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:51:07 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:51:07 d2.evaluation.testing]: copypaste: 50.1287,71.9534,56.2146,16.3737,42.6587,68.7094
[09/04 08:51:07 d2.utils.events]:  eta: 0:04:21  iter: 699  total_loss: 0.254  loss_cls: 0.04618  loss_box_reg: 0.08623  loss_mask: 0.1034  loss_rpn_cls: 0.002513  loss_rpn_loc: 0.001427  time: 0.8741  data_time: 0.0082  lr: 0.00017483  max_mem: 6718M
[09/04 08:51:25 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:51:25 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:51:25 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:51:25 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:51:25 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:51:29 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0039 s/iter. Inference: 0.1127 s/iter. Eval: 0.0864 s/iter. Total: 0.2031 s/iter. ETA=0:00:27
[09/04 08:51:34 d2.evaluation.evaluator]: Inference done 34/144. Dataloading: 0.0038 s/iter. Inference: 0.1164 s/iter. Eval: 0.1006 s/iter. Total: 0.2208 s/iter. ETA=0:00:24
[09/04 08:51:39 d2.evaluation.evaluator]: Inference done 51/144. Dataloading: 0.0036 s/iter. Inference: 0.1171 s/iter. Eval: 0.1331 s/iter. Total: 0.2539 s/iter. ETA=0:00:23
[09/04 08:51:44 d2.evaluation.evaluator]: Inference done 68/144. Dataloading: 0.0035 s/iter. Inference: 0.1175 s/iter. Eval: 0.1454 s/iter. Total: 0.2666 s/iter. ETA=0:00:20
[09/04 08:51:49 d2.evaluation.evaluator]: Inference done 97/144. Dataloading: 0.0035 s/iter. Inference: 0.1155 s/iter. Eval: 0.1185 s/iter. Total: 0.2377 s/iter. ETA=0:00:11
[09/04 08:51:54 d2.evaluation.evaluator]: Inference done 124/144. Dataloading: 0.0035 s/iter. Inference: 0.1147 s/iter. Eval: 0.1084 s/iter. Total: 0.2267 s/iter. ETA=0:00:04
[09/04 08:51:59 d2.evaluation.evaluator]: Total inference time: 0:00:31.242795 (0.224768 s / iter per device, on 1 devices)
[09/04 08:51:59 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:15 (0.114199 s / iter per device, on 1 devices)
[09/04 08:51:59 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:51:59 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:51:59 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 08:51:59 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:51:59 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 08:51:59 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:51:59 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.487
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.722
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.563
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.171
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.441
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.653
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.350
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.612
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.655
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.620
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.779
[09/04 08:51:59 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.688 | 72.216 | 56.328 | 17.119 | 44.136 | 65.301 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[09/04 08:51:59 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:51:59 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/04 08:51:59 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:51:59 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.498
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.718
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.574
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.152
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.418
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.686
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.348
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.617
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.666
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.383
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.626
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.786
[09/04 08:51:59 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.819 | 71.788 | 57.416 | 15.194 | 41.754 | 68.644 |
[09/04 08:51:59 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:51:59 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:51:59 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:51:59 d2.evaluation.testing]: copypaste: 48.6884,72.2164,56.3279,17.1191,44.1359,65.3013
[09/04 08:51:59 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:51:59 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:51:59 d2.evaluation.testing]: copypaste: 49.8188,71.7877,57.4156,15.1944,41.7543,68.6443
[09/04 08:51:59 d2.utils.events]:  eta: 0:04:03  iter: 719  total_loss: 0.6111  loss_cls: 0.09701  loss_box_reg: 0.2215  loss_mask: 0.1798  loss_rpn_cls: 0.003032  loss_rpn_loc: 0.005252  time: 0.8741  data_time: 0.0075  lr: 0.00017982  max_mem: 6718M
[09/04 08:52:17 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:52:17 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:52:17 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:52:17 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:52:17 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:52:20 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.1087 s/iter. Eval: 0.0500 s/iter. Total: 0.1604 s/iter. ETA=0:00:21
[09/04 08:52:25 d2.evaluation.evaluator]: Inference done 39/144. Dataloading: 0.0028 s/iter. Inference: 0.1118 s/iter. Eval: 0.0665 s/iter. Total: 0.1812 s/iter. ETA=0:00:19
[09/04 08:52:30 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0028 s/iter. Inference: 0.1131 s/iter. Eval: 0.0925 s/iter. Total: 0.2085 s/iter. ETA=0:00:17
[09/04 08:52:35 d2.evaluation.evaluator]: Inference done 87/144. Dataloading: 0.0035 s/iter. Inference: 0.1130 s/iter. Eval: 0.0828 s/iter. Total: 0.1994 s/iter. ETA=0:00:11
[09/04 08:52:40 d2.evaluation.evaluator]: Inference done 116/144. Dataloading: 0.0038 s/iter. Inference: 0.1129 s/iter. Eval: 0.0758 s/iter. Total: 0.1926 s/iter. ETA=0:00:05
[09/04 08:52:45 d2.evaluation.evaluator]: Total inference time: 0:00:26.149546 (0.188126 s / iter per device, on 1 devices)
[09/04 08:52:45 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:15 (0.112332 s / iter per device, on 1 devices)
[09/04 08:52:45 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:52:45 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:52:45 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 08:52:45 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:52:45 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 08:52:45 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:52:45 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.487
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.708
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.536
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.155
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.451
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.661
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.367
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.609
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.645
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.597
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.805
[09/04 08:52:45 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.738 | 70.827 | 53.572 | 15.468 | 45.141 | 66.087 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[09/04 08:52:45 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:52:45 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 08:52:45 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:52:45 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.495
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.706
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.569
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.155
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.418
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.686
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.369
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.615
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.646
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.283
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.596
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.800
[09/04 08:52:45 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.470 | 70.626 | 56.939 | 15.486 | 41.795 | 68.615 |
[09/04 08:52:45 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:52:45 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:52:45 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:52:45 d2.evaluation.testing]: copypaste: 48.7376,70.8265,53.5717,15.4677,45.1412,66.0873
[09/04 08:52:45 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:52:45 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:52:45 d2.evaluation.testing]: copypaste: 49.4700,70.6259,56.9386,15.4857,41.7949,68.6154
[09/04 08:52:45 d2.utils.events]:  eta: 0:03:46  iter: 739  total_loss: 0.4833  loss_cls: 0.09729  loss_box_reg: 0.1495  loss_mask: 0.1597  loss_rpn_cls: 0.002663  loss_rpn_loc: 0.002645  time: 0.8742  data_time: 0.0086  lr: 0.00018482  max_mem: 6718M
[09/04 08:53:02 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:53:02 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:53:02 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:53:02 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:53:02 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:53:06 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0018 s/iter. Inference: 0.1137 s/iter. Eval: 0.0720 s/iter. Total: 0.1875 s/iter. ETA=0:00:24
[09/04 08:53:11 d2.evaluation.evaluator]: Inference done 34/144. Dataloading: 0.0033 s/iter. Inference: 0.1141 s/iter. Eval: 0.0987 s/iter. Total: 0.2163 s/iter. ETA=0:00:23
[09/04 08:53:16 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0029 s/iter. Inference: 0.1151 s/iter. Eval: 0.1182 s/iter. Total: 0.2365 s/iter. ETA=0:00:21
[09/04 08:53:21 d2.evaluation.evaluator]: Inference done 71/144. Dataloading: 0.0030 s/iter. Inference: 0.1160 s/iter. Eval: 0.1295 s/iter. Total: 0.2487 s/iter. ETA=0:00:18
[09/04 08:53:26 d2.evaluation.evaluator]: Inference done 103/144. Dataloading: 0.0034 s/iter. Inference: 0.1134 s/iter. Eval: 0.1036 s/iter. Total: 0.2205 s/iter. ETA=0:00:09
[09/04 08:53:31 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0033 s/iter. Inference: 0.1130 s/iter. Eval: 0.0962 s/iter. Total: 0.2127 s/iter. ETA=0:00:02
[09/04 08:53:34 d2.evaluation.evaluator]: Total inference time: 0:00:29.729937 (0.213884 s / iter per device, on 1 devices)
[09/04 08:53:34 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:15 (0.112949 s / iter per device, on 1 devices)
[09/04 08:53:34 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:53:34 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:53:34 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 08:53:34 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:53:34 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 08:53:34 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:53:35 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.496
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.723
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.567
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.162
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.469
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.650
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.363
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.662
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.308
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.627
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.788
[09/04 08:53:35 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.624 | 72.338 | 56.693 | 16.175 | 46.888 | 65.007 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[09/04 08:53:35 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:53:35 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/04 08:53:35 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:53:35 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.506
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.727
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.587
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.154
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.429
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.689
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.360
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.621
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.660
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.383
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.614
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.791
[09/04 08:53:35 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.593 | 72.693 | 58.716 | 15.374 | 42.853 | 68.930 |
[09/04 08:53:35 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:53:35 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:53:35 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:53:35 d2.evaluation.testing]: copypaste: 49.6245,72.3383,56.6926,16.1754,46.8876,65.0069
[09/04 08:53:35 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:53:35 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:53:35 d2.evaluation.testing]: copypaste: 50.5934,72.6931,58.7163,15.3745,42.8527,68.9304
[09/04 08:53:35 d2.utils.events]:  eta: 0:03:29  iter: 759  total_loss: 0.4148  loss_cls: 0.07903  loss_box_reg: 0.1452  loss_mask: 0.1316  loss_rpn_cls: 0.002331  loss_rpn_loc: 0.00316  time: 0.8740  data_time: 0.0067  lr: 0.00018981  max_mem: 6718M
[09/04 08:53:52 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:53:52 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:53:52 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:53:52 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:53:52 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:53:56 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0021 s/iter. Inference: 0.1096 s/iter. Eval: 0.0680 s/iter. Total: 0.1797 s/iter. ETA=0:00:23
[09/04 08:54:01 d2.evaluation.evaluator]: Inference done 37/144. Dataloading: 0.0027 s/iter. Inference: 0.1112 s/iter. Eval: 0.0765 s/iter. Total: 0.1905 s/iter. ETA=0:00:20
[09/04 08:54:06 d2.evaluation.evaluator]: Inference done 56/144. Dataloading: 0.0027 s/iter. Inference: 0.1145 s/iter. Eval: 0.1045 s/iter. Total: 0.2220 s/iter. ETA=0:00:19
[09/04 08:54:11 d2.evaluation.evaluator]: Inference done 77/144. Dataloading: 0.0027 s/iter. Inference: 0.1147 s/iter. Eval: 0.1111 s/iter. Total: 0.2287 s/iter. ETA=0:00:15
[09/04 08:54:16 d2.evaluation.evaluator]: Inference done 103/144. Dataloading: 0.0036 s/iter. Inference: 0.1156 s/iter. Eval: 0.0999 s/iter. Total: 0.2192 s/iter. ETA=0:00:08
[09/04 08:54:21 d2.evaluation.evaluator]: Inference done 131/144. Dataloading: 0.0036 s/iter. Inference: 0.1143 s/iter. Eval: 0.0925 s/iter. Total: 0.2106 s/iter. ETA=0:00:02
[09/04 08:54:24 d2.evaluation.evaluator]: Total inference time: 0:00:29.493869 (0.212186 s / iter per device, on 1 devices)
[09/04 08:54:24 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:15 (0.114240 s / iter per device, on 1 devices)
[09/04 08:54:24 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:54:24 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:54:24 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 08:54:24 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:54:24 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 08:54:24 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:54:24 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.501
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.735
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.547
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.185
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.476
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.650
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.664
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.626
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.794
[09/04 08:54:24 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.097 | 73.539 | 54.729 | 18.473 | 47.570 | 64.986 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[09/04 08:54:24 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:54:24 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/04 08:54:24 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:54:24 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.516
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.734
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.601
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.160
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.435
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.706
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.353
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.624
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.670
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.383
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.621
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.808
[09/04 08:54:24 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.606 | 73.364 | 60.124 | 16.024 | 43.526 | 70.602 |
[09/04 08:54:24 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:54:24 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:54:24 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:54:24 d2.evaluation.testing]: copypaste: 50.0965,73.5390,54.7288,18.4734,47.5705,64.9862
[09/04 08:54:24 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:54:24 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:54:24 d2.evaluation.testing]: copypaste: 51.6060,73.3638,60.1240,16.0244,43.5259,70.6015
[09/04 08:54:24 d2.utils.events]:  eta: 0:03:11  iter: 779  total_loss: 0.4711  loss_cls: 0.1053  loss_box_reg: 0.1865  loss_mask: 0.1416  loss_rpn_cls: 0.003586  loss_rpn_loc: 0.005679  time: 0.8742  data_time: 0.0081  lr: 0.00019481  max_mem: 6718M
[09/04 08:54:42 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:54:42 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:54:42 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:54:42 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:54:42 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:54:46 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0061 s/iter. Inference: 0.1249 s/iter. Eval: 0.1126 s/iter. Total: 0.2436 s/iter. ETA=0:00:32
[09/04 08:54:51 d2.evaluation.evaluator]: Inference done 34/144. Dataloading: 0.0053 s/iter. Inference: 0.1161 s/iter. Eval: 0.1022 s/iter. Total: 0.2237 s/iter. ETA=0:00:24
[09/04 08:54:56 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0040 s/iter. Inference: 0.1165 s/iter. Eval: 0.1252 s/iter. Total: 0.2459 s/iter. ETA=0:00:22
[09/04 08:55:01 d2.evaluation.evaluator]: Inference done 72/144. Dataloading: 0.0038 s/iter. Inference: 0.1165 s/iter. Eval: 0.1320 s/iter. Total: 0.2524 s/iter. ETA=0:00:18
[09/04 08:55:06 d2.evaluation.evaluator]: Inference done 103/144. Dataloading: 0.0035 s/iter. Inference: 0.1142 s/iter. Eval: 0.1086 s/iter. Total: 0.2264 s/iter. ETA=0:00:09
[09/04 08:55:11 d2.evaluation.evaluator]: Inference done 128/144. Dataloading: 0.0035 s/iter. Inference: 0.1141 s/iter. Eval: 0.1034 s/iter. Total: 0.2212 s/iter. ETA=0:00:03
[09/04 08:55:15 d2.evaluation.evaluator]: Total inference time: 0:00:30.899325 (0.222297 s / iter per device, on 1 devices)
[09/04 08:55:15 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:15 (0.113934 s / iter per device, on 1 devices)
[09/04 08:55:15 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:55:15 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:55:15 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 08:55:15 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:55:15 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 08:55:15 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:55:15 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.506
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.742
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.562
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.174
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.480
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.656
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.360
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.665
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.375
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.617
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.800
[09/04 08:55:15 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.625 | 74.174 | 56.195 | 17.418 | 48.031 | 65.624 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[09/04 08:55:16 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:55:16 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/04 08:55:16 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:55:16 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.516
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.744
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.582
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.164
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.438
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.700
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.360
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.627
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.665
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.433
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.611
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.802
[09/04 08:55:16 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.646 | 74.414 | 58.174 | 16.356 | 43.845 | 70.023 |
[09/04 08:55:16 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:55:16 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:55:16 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:55:16 d2.evaluation.testing]: copypaste: 50.6251,74.1744,56.1954,17.4180,48.0306,65.6236
[09/04 08:55:16 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:55:16 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:55:16 d2.evaluation.testing]: copypaste: 51.6455,74.4145,58.1740,16.3557,43.8450,70.0231
[09/04 08:55:16 d2.utils.events]:  eta: 0:02:54  iter: 799  total_loss: 0.4242  loss_cls: 0.06853  loss_box_reg: 0.2062  loss_mask: 0.148  loss_rpn_cls: 0.002353  loss_rpn_loc: 0.00494  time: 0.8742  data_time: 0.0085  lr: 0.0001998  max_mem: 6718M
[09/04 08:55:33 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:55:33 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:55:33 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:55:33 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:55:33 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:55:36 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.1074 s/iter. Eval: 0.0483 s/iter. Total: 0.1573 s/iter. ETA=0:00:20
[09/04 08:55:41 d2.evaluation.evaluator]: Inference done 39/144. Dataloading: 0.0033 s/iter. Inference: 0.1121 s/iter. Eval: 0.0616 s/iter. Total: 0.1771 s/iter. ETA=0:00:18
[09/04 08:55:46 d2.evaluation.evaluator]: Inference done 62/144. Dataloading: 0.0030 s/iter. Inference: 0.1126 s/iter. Eval: 0.0794 s/iter. Total: 0.1951 s/iter. ETA=0:00:16
[09/04 08:55:51 d2.evaluation.evaluator]: Inference done 92/144. Dataloading: 0.0035 s/iter. Inference: 0.1123 s/iter. Eval: 0.0710 s/iter. Total: 0.1868 s/iter. ETA=0:00:09
[09/04 08:55:56 d2.evaluation.evaluator]: Inference done 120/144. Dataloading: 0.0043 s/iter. Inference: 0.1129 s/iter. Eval: 0.0676 s/iter. Total: 0.1851 s/iter. ETA=0:00:04
[09/04 08:56:01 d2.evaluation.evaluator]: Total inference time: 0:00:25.453730 (0.183120 s / iter per device, on 1 devices)
[09/04 08:56:01 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:15 (0.112321 s / iter per device, on 1 devices)
[09/04 08:56:01 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:56:01 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:56:01 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 08:56:01 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:56:01 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 08:56:01 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:56:01 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.513
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.747
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.593
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.187
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.482
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.664
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.365
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.618
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.661
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.614
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.802
[09/04 08:56:01 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.335 | 74.734 | 59.295 | 18.686 | 48.237 | 66.373 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[09/04 08:56:01 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:56:01 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 08:56:01 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:56:01 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.514
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.737
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.590
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.158
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.449
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.686
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.363
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.654
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.408
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.601
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.792
[09/04 08:56:01 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.402 | 73.718 | 59.024 | 15.800 | 44.851 | 68.602 |
[09/04 08:56:01 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:56:01 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:56:01 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:56:01 d2.evaluation.testing]: copypaste: 51.3354,74.7339,59.2954,18.6864,48.2374,66.3728
[09/04 08:56:01 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:56:01 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:56:01 d2.evaluation.testing]: copypaste: 51.4016,73.7180,59.0242,15.8002,44.8512,68.6024
[09/04 08:56:01 d2.utils.events]:  eta: 0:02:36  iter: 819  total_loss: 0.413  loss_cls: 0.09202  loss_box_reg: 0.1786  loss_mask: 0.1401  loss_rpn_cls: 0.002883  loss_rpn_loc: 0.005305  time: 0.8743  data_time: 0.0083  lr: 0.0002048  max_mem: 6718M
[09/04 08:56:18 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:56:18 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:56:18 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:56:18 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:56:18 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:56:21 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0035 s/iter. Inference: 0.1084 s/iter. Eval: 0.0499 s/iter. Total: 0.1618 s/iter. ETA=0:00:21
[09/04 08:56:26 d2.evaluation.evaluator]: Inference done 37/144. Dataloading: 0.0047 s/iter. Inference: 0.1130 s/iter. Eval: 0.0728 s/iter. Total: 0.1906 s/iter. ETA=0:00:20
[09/04 08:56:32 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0040 s/iter. Inference: 0.1141 s/iter. Eval: 0.0906 s/iter. Total: 0.2088 s/iter. ETA=0:00:17
[09/04 08:56:37 d2.evaluation.evaluator]: Inference done 87/144. Dataloading: 0.0040 s/iter. Inference: 0.1128 s/iter. Eval: 0.0824 s/iter. Total: 0.1993 s/iter. ETA=0:00:11
[09/04 08:56:42 d2.evaluation.evaluator]: Inference done 118/144. Dataloading: 0.0039 s/iter. Inference: 0.1118 s/iter. Eval: 0.0735 s/iter. Total: 0.1894 s/iter. ETA=0:00:04
[09/04 08:56:46 d2.evaluation.evaluator]: Total inference time: 0:00:26.083429 (0.187651 s / iter per device, on 1 devices)
[09/04 08:56:46 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:15 (0.111528 s / iter per device, on 1 devices)
[09/04 08:56:46 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:56:46 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:56:46 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 08:56:46 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:56:46 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 08:56:46 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:56:46 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.494
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.745
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.574
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.155
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.474
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.635
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.361
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.602
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.642
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.602
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.771
[09/04 08:56:46 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.390 | 74.458 | 57.410 | 15.484 | 47.353 | 63.495 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[09/04 08:56:47 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:56:47 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 08:56:47 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:56:47 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.510
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.744
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.577
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.163
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.439
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.687
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.364
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.655
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.408
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.603
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.789
[09/04 08:56:47 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.956 | 74.410 | 57.747 | 16.273 | 43.936 | 68.718 |
[09/04 08:56:47 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:56:47 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:56:47 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:56:47 d2.evaluation.testing]: copypaste: 49.3901,74.4576,57.4098,15.4844,47.3527,63.4950
[09/04 08:56:47 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:56:47 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:56:47 d2.evaluation.testing]: copypaste: 50.9562,74.4099,57.7469,16.2730,43.9355,68.7184
[09/04 08:56:47 d2.utils.events]:  eta: 0:02:19  iter: 839  total_loss: 0.3482  loss_cls: 0.05636  loss_box_reg: 0.178  loss_mask: 0.1103  loss_rpn_cls: 0.001979  loss_rpn_loc: 0.003853  time: 0.8743  data_time: 0.0083  lr: 0.00020979  max_mem: 6718M
[09/04 08:57:04 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:57:04 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:57:04 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:57:04 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:57:04 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:57:07 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0028 s/iter. Inference: 0.1088 s/iter. Eval: 0.0542 s/iter. Total: 0.1658 s/iter. ETA=0:00:22
[09/04 08:57:12 d2.evaluation.evaluator]: Inference done 38/144. Dataloading: 0.0036 s/iter. Inference: 0.1141 s/iter. Eval: 0.0652 s/iter. Total: 0.1831 s/iter. ETA=0:00:19
[09/04 08:57:18 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0034 s/iter. Inference: 0.1149 s/iter. Eval: 0.0949 s/iter. Total: 0.2134 s/iter. ETA=0:00:18
[09/04 08:57:23 d2.evaluation.evaluator]: Inference done 85/144. Dataloading: 0.0035 s/iter. Inference: 0.1141 s/iter. Eval: 0.0890 s/iter. Total: 0.2068 s/iter. ETA=0:00:12
[09/04 08:57:28 d2.evaluation.evaluator]: Inference done 116/144. Dataloading: 0.0034 s/iter. Inference: 0.1127 s/iter. Eval: 0.0786 s/iter. Total: 0.1948 s/iter. ETA=0:00:05
[09/04 08:57:33 d2.evaluation.evaluator]: Inference done 144/144. Dataloading: 0.0037 s/iter. Inference: 0.1133 s/iter. Eval: 0.0778 s/iter. Total: 0.1949 s/iter. ETA=0:00:00
[09/04 08:57:33 d2.evaluation.evaluator]: Total inference time: 0:00:27.140403 (0.195255 s / iter per device, on 1 devices)
[09/04 08:57:33 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:15 (0.113271 s / iter per device, on 1 devices)
[09/04 08:57:33 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:57:33 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:57:33 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 08:57:33 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:57:33 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 08:57:33 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:57:33 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.515
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.750
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.593
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.188
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.477
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.666
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.365
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.665
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.367
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.622
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.795
[09/04 08:57:33 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.481 | 74.980 | 59.322 | 18.772 | 47.657 | 66.607 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[09/04 08:57:33 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:57:34 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/04 08:57:34 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:57:34 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.521
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.748
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.604
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.149
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.441
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.707
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.363
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.622
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.664
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.400
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.797
[09/04 08:57:34 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.102 | 74.777 | 60.443 | 14.907 | 44.131 | 70.681 |
[09/04 08:57:34 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:57:34 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:57:34 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:57:34 d2.evaluation.testing]: copypaste: 51.4813,74.9798,59.3220,18.7717,47.6566,66.6070
[09/04 08:57:34 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:57:34 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:57:34 d2.evaluation.testing]: copypaste: 52.1021,74.7769,60.4435,14.9072,44.1306,70.6806
[09/04 08:57:34 d2.utils.events]:  eta: 0:02:02  iter: 859  total_loss: 0.4009  loss_cls: 0.09011  loss_box_reg: 0.1806  loss_mask: 0.1351  loss_rpn_cls: 0.002024  loss_rpn_loc: 0.004887  time: 0.8744  data_time: 0.0080  lr: 0.00021479  max_mem: 6718M
[09/04 08:57:51 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:57:51 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:57:51 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:57:51 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:57:51 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:57:54 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0040 s/iter. Inference: 0.1071 s/iter. Eval: 0.0434 s/iter. Total: 0.1546 s/iter. ETA=0:00:20
[09/04 08:57:59 d2.evaluation.evaluator]: Inference done 43/144. Dataloading: 0.0036 s/iter. Inference: 0.1098 s/iter. Eval: 0.0486 s/iter. Total: 0.1621 s/iter. ETA=0:00:16
[09/04 08:58:04 d2.evaluation.evaluator]: Inference done 66/144. Dataloading: 0.0035 s/iter. Inference: 0.1114 s/iter. Eval: 0.0681 s/iter. Total: 0.1830 s/iter. ETA=0:00:14
[09/04 08:58:09 d2.evaluation.evaluator]: Inference done 96/144. Dataloading: 0.0040 s/iter. Inference: 0.1114 s/iter. Eval: 0.0631 s/iter. Total: 0.1786 s/iter. ETA=0:00:08
[09/04 08:58:14 d2.evaluation.evaluator]: Inference done 129/144. Dataloading: 0.0041 s/iter. Inference: 0.1112 s/iter. Eval: 0.0572 s/iter. Total: 0.1726 s/iter. ETA=0:00:02
[09/04 08:58:17 d2.evaluation.evaluator]: Total inference time: 0:00:23.961249 (0.172383 s / iter per device, on 1 devices)
[09/04 08:58:17 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:15 (0.111009 s / iter per device, on 1 devices)
[09/04 08:58:17 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:58:17 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:58:17 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 08:58:17 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:58:17 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 08:58:17 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:58:17 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.515
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.739
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.590
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.164
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.484
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.663
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.360
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.660
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.606
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.812
[09/04 08:58:17 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.547 | 73.905 | 58.984 | 16.425 | 48.381 | 66.294 |
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
[09/04 08:58:17 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:58:17 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 08:58:17 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:58:17 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.515
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.739
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.619
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.150
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.439
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.697
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.356
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.615
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.650
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.408
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.592
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.794
[09/04 08:58:17 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.501 | 73.869 | 61.921 | 15.014 | 43.939 | 69.673 |
[09/04 08:58:17 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:58:17 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:58:17 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:58:17 d2.evaluation.testing]: copypaste: 51.5468,73.9050,58.9839,16.4249,48.3808,66.2943
[09/04 08:58:17 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:58:17 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:58:17 d2.evaluation.testing]: copypaste: 51.5006,73.8692,61.9207,15.0141,43.9392,69.6733
[09/04 08:58:17 d2.utils.events]:  eta: 0:01:44  iter: 879  total_loss: 0.3968  loss_cls: 0.07321  loss_box_reg: 0.1162  loss_mask: 0.1385  loss_rpn_cls: 0.00444  loss_rpn_loc: 0.002992  time: 0.8744  data_time: 0.0086  lr: 0.00021978  max_mem: 6718M
[09/04 08:58:34 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:58:34 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:58:34 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:58:34 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:58:34 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:58:38 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0054 s/iter. Inference: 0.1234 s/iter. Eval: 0.1139 s/iter. Total: 0.2426 s/iter. ETA=0:00:32
[09/04 08:58:43 d2.evaluation.evaluator]: Inference done 39/144. Dataloading: 0.0045 s/iter. Inference: 0.1128 s/iter. Eval: 0.0799 s/iter. Total: 0.1972 s/iter. ETA=0:00:20
[09/04 08:58:49 d2.evaluation.evaluator]: Inference done 58/144. Dataloading: 0.0041 s/iter. Inference: 0.1147 s/iter. Eval: 0.1054 s/iter. Total: 0.2243 s/iter. ETA=0:00:19
[09/04 08:58:54 d2.evaluation.evaluator]: Inference done 82/144. Dataloading: 0.0039 s/iter. Inference: 0.1140 s/iter. Eval: 0.1018 s/iter. Total: 0.2198 s/iter. ETA=0:00:13
[09/04 08:58:59 d2.evaluation.evaluator]: Inference done 112/144. Dataloading: 0.0041 s/iter. Inference: 0.1131 s/iter. Eval: 0.0882 s/iter. Total: 0.2055 s/iter. ETA=0:00:06
[09/04 08:59:04 d2.evaluation.evaluator]: Inference done 143/144. Dataloading: 0.0041 s/iter. Inference: 0.1120 s/iter. Eval: 0.0797 s/iter. Total: 0.1959 s/iter. ETA=0:00:00
[09/04 08:59:04 d2.evaluation.evaluator]: Total inference time: 0:00:27.584785 (0.198452 s / iter per device, on 1 devices)
[09/04 08:59:04 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:15 (0.112104 s / iter per device, on 1 devices)
[09/04 08:59:04 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:59:04 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:59:04 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 08:59:04 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:59:04 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 08:59:04 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:59:04 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.497
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.719
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.562
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.175
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.492
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.644
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.359
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.609
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.656
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.789
[09/04 08:59:04 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.701 | 71.914 | 56.172 | 17.492 | 49.237 | 64.407 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[09/04 08:59:05 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:59:05 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/04 08:59:05 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:59:05 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.501
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.720
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.559
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.439
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.675
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.359
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.612
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.659
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.400
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.791
[09/04 08:59:05 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.085 | 72.017 | 55.917 | 16.710 | 43.948 | 67.522 |
[09/04 08:59:05 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:59:05 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:59:05 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:59:05 d2.evaluation.testing]: copypaste: 49.7012,71.9144,56.1721,17.4923,49.2374,64.4065
[09/04 08:59:05 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:59:05 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:59:05 d2.evaluation.testing]: copypaste: 50.0854,72.0173,55.9172,16.7103,43.9479,67.5217
[09/04 08:59:05 d2.utils.events]:  eta: 0:01:27  iter: 899  total_loss: 0.2907  loss_cls: 0.03668  loss_box_reg: 0.1007  loss_mask: 0.1099  loss_rpn_cls: 0.0009833  loss_rpn_loc: 0.001832  time: 0.8742  data_time: 0.0090  lr: 0.00022478  max_mem: 6718M
[09/04 08:59:22 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 08:59:22 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 08:59:22 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 08:59:22 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 08:59:22 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 08:59:26 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.1108 s/iter. Eval: 0.0701 s/iter. Total: 0.1825 s/iter. ETA=0:00:24
[09/04 08:59:31 d2.evaluation.evaluator]: Inference done 37/144. Dataloading: 0.0022 s/iter. Inference: 0.1108 s/iter. Eval: 0.0774 s/iter. Total: 0.1906 s/iter. ETA=0:00:20
[09/04 08:59:36 d2.evaluation.evaluator]: Inference done 53/144. Dataloading: 0.0025 s/iter. Inference: 0.1156 s/iter. Eval: 0.1215 s/iter. Total: 0.2398 s/iter. ETA=0:00:21
[09/04 08:59:41 d2.evaluation.evaluator]: Inference done 69/144. Dataloading: 0.0024 s/iter. Inference: 0.1167 s/iter. Eval: 0.1392 s/iter. Total: 0.2585 s/iter. ETA=0:00:19
[09/04 08:59:46 d2.evaluation.evaluator]: Inference done 96/144. Dataloading: 0.0030 s/iter. Inference: 0.1162 s/iter. Eval: 0.1177 s/iter. Total: 0.2370 s/iter. ETA=0:00:11
[09/04 08:59:51 d2.evaluation.evaluator]: Inference done 124/144. Dataloading: 0.0030 s/iter. Inference: 0.1145 s/iter. Eval: 0.1056 s/iter. Total: 0.2234 s/iter. ETA=0:00:04
[09/04 08:59:55 d2.evaluation.evaluator]: Total inference time: 0:00:30.937497 (0.222572 s / iter per device, on 1 devices)
[09/04 08:59:55 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:15 (0.114309 s / iter per device, on 1 devices)
[09/04 08:59:55 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 08:59:55 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 08:59:55 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 08:59:55 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 08:59:56 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 08:59:56 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:59:56 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.505
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.742
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.576
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.175
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.464
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.665
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.365
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.621
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.668
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.342
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.628
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.798
[09/04 08:59:56 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.513 | 74.156 | 57.611 | 17.517 | 46.436 | 66.524 |
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[09/04 08:59:56 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 08:59:56 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/04 08:59:56 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 08:59:56 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.515
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.738
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.582
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.175
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.447
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.689
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.364
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.670
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.408
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.626
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.794
[09/04 08:59:56 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.525 | 73.792 | 58.235 | 17.544 | 44.666 | 68.946 |
[09/04 08:59:56 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 08:59:56 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 08:59:56 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:59:56 d2.evaluation.testing]: copypaste: 50.5131,74.1565,57.6105,17.5170,46.4357,66.5244
[09/04 08:59:56 d2.evaluation.testing]: copypaste: Task: segm
[09/04 08:59:56 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 08:59:56 d2.evaluation.testing]: copypaste: 51.5253,73.7919,58.2349,17.5438,44.6659,68.9458
[09/04 08:59:56 d2.utils.events]:  eta: 0:01:09  iter: 919  total_loss: 0.5301  loss_cls: 0.106  loss_box_reg: 0.1564  loss_mask: 0.1558  loss_rpn_cls: 0.002162  loss_rpn_loc: 0.003652  time: 0.8743  data_time: 0.0102  lr: 0.00022977  max_mem: 6718M
[09/04 09:00:13 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 09:00:13 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 09:00:13 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 09:00:13 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 09:00:13 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 09:00:17 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0040 s/iter. Inference: 0.1259 s/iter. Eval: 0.0974 s/iter. Total: 0.2274 s/iter. ETA=0:00:30
[09/04 09:00:22 d2.evaluation.evaluator]: Inference done 40/144. Dataloading: 0.0030 s/iter. Inference: 0.1122 s/iter. Eval: 0.0679 s/iter. Total: 0.1833 s/iter. ETA=0:00:19
[09/04 09:00:27 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0035 s/iter. Inference: 0.1144 s/iter. Eval: 0.0996 s/iter. Total: 0.2177 s/iter. ETA=0:00:18
[09/04 09:00:32 d2.evaluation.evaluator]: Inference done 87/144. Dataloading: 0.0039 s/iter. Inference: 0.1127 s/iter. Eval: 0.0891 s/iter. Total: 0.2058 s/iter. ETA=0:00:11
[09/04 09:00:37 d2.evaluation.evaluator]: Inference done 118/144. Dataloading: 0.0042 s/iter. Inference: 0.1117 s/iter. Eval: 0.0775 s/iter. Total: 0.1937 s/iter. ETA=0:00:05
[09/04 09:00:42 d2.evaluation.evaluator]: Total inference time: 0:00:26.465649 (0.190400 s / iter per device, on 1 devices)
[09/04 09:00:42 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:15 (0.111222 s / iter per device, on 1 devices)
[09/04 09:00:42 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 09:00:42 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 09:00:42 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 09:00:42 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 09:00:42 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 09:00:42 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 09:00:42 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.504
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.736
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.589
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.157
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.456
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.676
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.365
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.609
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.648
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.325
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.594
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.802
[09/04 09:00:42 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.389 | 73.616 | 58.891 | 15.709 | 45.562 | 67.631 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[09/04 09:00:42 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 09:00:42 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 09:00:42 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 09:00:42 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.512
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.736
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.574
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.160
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.445
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.690
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.367
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.656
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.433
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.602
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.791
[09/04 09:00:42 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.157 | 73.626 | 57.370 | 15.982 | 44.549 | 68.975 |
[09/04 09:00:42 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 09:00:42 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 09:00:42 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 09:00:42 d2.evaluation.testing]: copypaste: 50.3886,73.6163,58.8905,15.7087,45.5622,67.6309
[09/04 09:00:42 d2.evaluation.testing]: copypaste: Task: segm
[09/04 09:00:42 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 09:00:42 d2.evaluation.testing]: copypaste: 51.1570,73.6264,57.3700,15.9818,44.5486,68.9754
[09/04 09:00:42 d2.utils.events]:  eta: 0:00:52  iter: 939  total_loss: 0.3167  loss_cls: 0.06381  loss_box_reg: 0.1158  loss_mask: 0.1369  loss_rpn_cls: 0.004025  loss_rpn_loc: 0.002609  time: 0.8743  data_time: 0.0086  lr: 0.00023477  max_mem: 6718M
[09/04 09:01:00 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 09:01:00 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 09:01:00 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 09:01:00 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 09:01:00 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 09:01:03 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0018 s/iter. Inference: 0.1103 s/iter. Eval: 0.0586 s/iter. Total: 0.1706 s/iter. ETA=0:00:22
[09/04 09:01:08 d2.evaluation.evaluator]: Inference done 39/144. Dataloading: 0.0029 s/iter. Inference: 0.1103 s/iter. Eval: 0.0706 s/iter. Total: 0.1840 s/iter. ETA=0:00:19
[09/04 09:01:13 d2.evaluation.evaluator]: Inference done 57/144. Dataloading: 0.0034 s/iter. Inference: 0.1125 s/iter. Eval: 0.1007 s/iter. Total: 0.2167 s/iter. ETA=0:00:18
[09/04 09:01:18 d2.evaluation.evaluator]: Inference done 78/144. Dataloading: 0.0032 s/iter. Inference: 0.1129 s/iter. Eval: 0.1071 s/iter. Total: 0.2232 s/iter. ETA=0:00:14
[09/04 09:01:23 d2.evaluation.evaluator]: Inference done 104/144. Dataloading: 0.0037 s/iter. Inference: 0.1136 s/iter. Eval: 0.0977 s/iter. Total: 0.2151 s/iter. ETA=0:00:08
[09/04 09:01:28 d2.evaluation.evaluator]: Inference done 134/144. Dataloading: 0.0038 s/iter. Inference: 0.1125 s/iter. Eval: 0.0878 s/iter. Total: 0.2043 s/iter. ETA=0:00:02
[09/04 09:01:31 d2.evaluation.evaluator]: Total inference time: 0:00:28.515021 (0.205144 s / iter per device, on 1 devices)
[09/04 09:01:31 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:15 (0.112367 s / iter per device, on 1 devices)
[09/04 09:01:31 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 09:01:31 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 09:01:31 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 09:01:31 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 09:01:31 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.
[09/04 09:01:31 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 09:01:31 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.504
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.746
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.576
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.188
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.463
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.652
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.361
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.616
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.660
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.383
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.614
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.791
[09/04 09:01:31 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.373 | 74.568 | 57.621 | 18.797 | 46.295 | 65.160 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[09/04 09:01:31 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 09:01:31 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.05 seconds.
[09/04 09:01:31 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 09:01:31 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.517
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.742
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.600
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.178
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.447
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.694
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.363
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.663
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.450
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.794
[09/04 09:01:31 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.725 | 74.195 | 60.023 | 17.784 | 44.666 | 69.437 |
[09/04 09:01:31 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 09:01:31 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 09:01:31 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 09:01:31 d2.evaluation.testing]: copypaste: 50.3728,74.5675,57.6208,18.7969,46.2946,65.1599
[09/04 09:01:31 d2.evaluation.testing]: copypaste: Task: segm
[09/04 09:01:31 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 09:01:31 d2.evaluation.testing]: copypaste: 51.7250,74.1954,60.0229,17.7842,44.6661,69.4370
[09/04 09:01:31 d2.utils.events]:  eta: 0:00:34  iter: 959  total_loss: 0.5127  loss_cls: 0.09623  loss_box_reg: 0.2293  loss_mask: 0.1518  loss_rpn_cls: 0.006673  loss_rpn_loc: 0.006626  time: 0.8745  data_time: 0.0089  lr: 0.00023976  max_mem: 6718M
[09/04 09:01:48 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 09:01:48 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 09:01:48 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 09:01:48 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 09:01:48 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 09:01:51 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0016 s/iter. Inference: 0.1083 s/iter. Eval: 0.0548 s/iter. Total: 0.1646 s/iter. ETA=0:00:21
[09/04 09:01:56 d2.evaluation.evaluator]: Inference done 38/144. Dataloading: 0.0034 s/iter. Inference: 0.1107 s/iter. Eval: 0.0713 s/iter. Total: 0.1855 s/iter. ETA=0:00:19
[09/04 09:02:01 d2.evaluation.evaluator]: Inference done 59/144. Dataloading: 0.0036 s/iter. Inference: 0.1120 s/iter. Eval: 0.0907 s/iter. Total: 0.2064 s/iter. ETA=0:00:17
[09/04 09:02:06 d2.evaluation.evaluator]: Inference done 87/144. Dataloading: 0.0040 s/iter. Inference: 0.1121 s/iter. Eval: 0.0815 s/iter. Total: 0.1977 s/iter. ETA=0:00:11
[09/04 09:02:12 d2.evaluation.evaluator]: Inference done 119/144. Dataloading: 0.0044 s/iter. Inference: 0.1114 s/iter. Eval: 0.0708 s/iter. Total: 0.1867 s/iter. ETA=0:00:04
[09/04 09:02:16 d2.evaluation.evaluator]: Total inference time: 0:00:25.476754 (0.183286 s / iter per device, on 1 devices)
[09/04 09:02:16 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:15 (0.110817 s / iter per device, on 1 devices)
[09/04 09:02:16 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 09:02:16 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 09:02:16 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 09:02:16 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 09:02:16 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 09:02:16 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 09:02:16 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.512
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.753
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.606
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.199
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.469
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.661
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.368
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.618
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.662
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.400
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.615
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.792
[09/04 09:02:16 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.226 | 75.284 | 60.595 | 19.885 | 46.851 | 66.148 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[09/04 09:02:16 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 09:02:16 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 09:02:16 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 09:02:16 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.519
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.748
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.597
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.186
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.451
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.688
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.365
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.621
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.661
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.450
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.609
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.791
[09/04 09:02:16 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 51.893 | 74.807 | 59.699 | 18.568 | 45.101 | 68.845 |
[09/04 09:02:16 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 09:02:16 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 09:02:16 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 09:02:16 d2.evaluation.testing]: copypaste: 51.2258,75.2840,60.5951,19.8846,46.8508,66.1484
[09/04 09:02:16 d2.evaluation.testing]: copypaste: Task: segm
[09/04 09:02:16 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 09:02:16 d2.evaluation.testing]: copypaste: 51.8926,74.8066,59.6994,18.5678,45.1015,68.8448
[09/04 09:02:16 d2.utils.events]:  eta: 0:00:17  iter: 979  total_loss: 0.2712  loss_cls: 0.04504  loss_box_reg: 0.1247  loss_mask: 0.09972  loss_rpn_cls: 0.001471  loss_rpn_loc: 0.002015  time: 0.8744  data_time: 0.0087  lr: 0.00024476  max_mem: 6718M
[09/04 09:02:34 d2.utils.events]:  eta: 0:00:00  iter: 999  total_loss: 0.3679  loss_cls: 0.0543  loss_box_reg: 0.1643  loss_mask: 0.1291  loss_rpn_cls: 0.002076  loss_rpn_loc: 0.003292  time: 0.8746  data_time: 0.0093  lr: 0.00024975  max_mem: 6718M
[09/04 09:02:34 d2.engine.hooks]: Overall training speed: 998 iterations in 0:14:32 (0.8746 s / it)
[09/04 09:02:34 d2.engine.hooks]: Total training time: 1:06:31 (0:51:58 on hooks)
[09/04 09:02:34 d2.data.datasets.coco]: Loaded 144 images in COCO format from ../input/petbottles/plastic data/annotations/instances_val.json
[09/04 09:02:34 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[09/04 09:02:34 d2.data.common]: Serializing 144 elements to byte tensors and concatenating them all ...
[09/04 09:02:34 d2.data.common]: Serialized dataset takes 0.09 MiB
[09/04 09:02:34 d2.evaluation.evaluator]: Start inference on 144 batches
[09/04 09:02:37 d2.evaluation.evaluator]: Inference done 11/144. Dataloading: 0.0015 s/iter. Inference: 0.1084 s/iter. Eval: 0.0596 s/iter. Total: 0.1696 s/iter. ETA=0:00:22
[09/04 09:02:42 d2.evaluation.evaluator]: Inference done 40/144. Dataloading: 0.0033 s/iter. Inference: 0.1109 s/iter. Eval: 0.0609 s/iter. Total: 0.1752 s/iter. ETA=0:00:18
[09/04 09:02:48 d2.evaluation.evaluator]: Inference done 61/144. Dataloading: 0.0030 s/iter. Inference: 0.1121 s/iter. Eval: 0.0875 s/iter. Total: 0.2027 s/iter. ETA=0:00:16
[09/04 09:02:53 d2.evaluation.evaluator]: Inference done 90/144. Dataloading: 0.0032 s/iter. Inference: 0.1116 s/iter. Eval: 0.0779 s/iter. Total: 0.1929 s/iter. ETA=0:00:10
[09/04 09:02:58 d2.evaluation.evaluator]: Inference done 122/144. Dataloading: 0.0033 s/iter. Inference: 0.1111 s/iter. Eval: 0.0695 s/iter. Total: 0.1840 s/iter. ETA=0:00:04
[09/04 09:03:02 d2.evaluation.evaluator]: Total inference time: 0:00:25.718721 (0.185027 s / iter per device, on 1 devices)
[09/04 09:03:02 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:15 (0.111347 s / iter per device, on 1 devices)
[09/04 09:03:02 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[09/04 09:03:02 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[09/04 09:03:02 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
[09/04 09:03:02 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[09/04 09:03:02 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.02 seconds.
[09/04 09:03:02 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 09:03:02 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.505
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.746
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.584
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.210
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.482
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.641
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.617
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.658
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.795
[09/04 09:03:02 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.492 | 74.576 | 58.403 | 21.005 | 48.235 | 64.114 |
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[09/04 09:03:02 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[09/04 09:03:02 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.04 seconds.
[09/04 09:03:02 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[09/04 09:03:02 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.523
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.748
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.599
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.190
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.457
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.690
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.357
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.625
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.666
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.408
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.794
[09/04 09:03:02 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 52.259 | 74.775 | 59.923 | 18.953 | 45.652 | 69.022 |
[09/04 09:03:02 d2.engine.defaults]: Evaluation results for pet_val in csv format:
[09/04 09:03:02 d2.evaluation.testing]: copypaste: Task: bbox
[09/04 09:03:02 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 09:03:02 d2.evaluation.testing]: copypaste: 50.4918,74.5759,58.4031,21.0046,48.2354,64.1136
[09/04 09:03:02 d2.evaluation.testing]: copypaste: Task: segm
[09/04 09:03:02 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[09/04 09:03:02 d2.evaluation.testing]: copypaste: 52.2586,74.7752,59.9233,18.9525,45.6516,69.0221